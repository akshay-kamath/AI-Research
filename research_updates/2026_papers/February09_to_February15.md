# üìå AI Research Papers (February09 to February15)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [LongStream: Long-Sequence Streaming Autoregressive Visual Geometry](https://arxiv.org/abs/2602.13172v1) | Chong Cheng, Xianda Chen, Tao Xie, Wei Yin, Weiqiang Ren, Qian Zhang, Xiaoyuang Guo, Hao Wang | 2026-02-13 | LLM | Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/ | [üîó Paper](https://arxiv.org/abs/2602.13172v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Learning functional components of PDEs from data using neural networks](https://arxiv.org/abs/2602.13174v1) | Torkel E. Loman, Yurij Salmaniw, Antonio Leon Villares, Jose A. Carrillo, Ruth E. Baker | 2026-02-13 | Diffusion Models | Partial differential equations often contain unknown functions that are difficult or impossible to measure directly, hampering our ability to derive predictions from the model. Workflows for recovering scalar PDE parameters from data are well studied: here we show how similar workflows can be used to recover functions from data. Specifically, we embed neural networks into the PDE and show how, as they are trained on data, they can approximate unknown functions with arbitrary accuracy. Using nonlocal aggregation-diffusion equations as a case study, we recover interaction kernels and external potentials from steady state data. Specifically, we investigate how a wide range of factors, such as the number of available solutions, their properties, sampling density, and measurement noise, affect our ability to successfully recover functions. Our approach is advantageous because it can utilise standard parameter-fitting workflows, and in that the trained PDE can be treated as a normal PDE for purposes such as generating system predictions. | [üîó Paper](https://arxiv.org/abs/2602.13174v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Imitating What Works: Simulation-Filtered Modular Policy Learning from Human Videos](https://arxiv.org/abs/2602.13197v1) | Albert J. Zhai, Kuo-Hao Zeng, Jiasen Lu, Ali Farhadi, Shenlong Wang, Wei-Chiu Ma | 2026-02-13 | Multimodal AI | The ability to learn manipulation skills by watching videos of humans has the potential to unlock a new source of highly scalable data for robot learning. Here, we tackle prehensile manipulation, in which tasks involve grasping an object before performing various post-grasp motions. Human videos offer strong signals for learning the post-grasp motions, but they are less useful for learning the prerequisite grasping behaviors, especially for robots without human-like hands. A promising way forward is to use a modular policy design, leveraging a dedicated grasp generator to produce stable grasps. However, arbitrary stable grasps are often not task-compatible, hindering the robot's ability to perform the desired downstream motion. To address this challenge, we present Perceive-Simulate-Imitate (PSI), a framework for training a modular manipulation policy using human video motion data processed by paired grasp-trajectory filtering in simulation. This simulation step extends the trajectory data with grasp suitability labels, which allows for supervised learning of task-oriented grasping capabilities. We show through real-world experiments that our framework can be used to learn precise manipulation skills efficiently without any robot data, resulting in significantly more robust performance than using a grasp generator naively. | [üîó Paper](https://arxiv.org/abs/2602.13197v1) |
| [FlexAM: Flexible Appearance-Motion Decomposition for Versatile Video Generation Control](https://arxiv.org/abs/2602.13185v1) | Mingzhi Sheng, Zekai Gu, Peng Li, Cheng Lin, Hao-Xiang Guo, Ying-Cong Chen, Yuan Liu | 2026-02-13 | Multimodal AI | Effective and generalizable control in video generation remains a significant challenge. While many methods rely on ambiguous or task-specific signals, we argue that a fundamental disentanglement of "appearance" and "motion" provides a more robust and scalable pathway. We propose FlexAM, a unified framework built upon a novel 3D control signal. This signal represents video dynamics as a point cloud, introducing three key enhancements: multi-frequency positional encoding to distinguish fine-grained motion, depth-aware positional encoding, and a flexible control signal for balancing precision and generative quality. This representation allows FlexAM to effectively disentangle appearance and motion, enabling a wide range of tasks including I2V/V2V editing, camera control, and spatial object editing. Extensive experiments demonstrate that FlexAM achieves superior performance across all evaluated tasks. | [üîó Paper](https://arxiv.org/abs/2602.13185v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Profiling systematic uncertainties in Simulation-Based Inference with Factorizable Normalizing Flows](https://arxiv.org/abs/2602.13184v1) | Davide Valsecchi, Mauro Doneg√†, Rainer Wallny | 2026-02-13 | Optimization | Unbinned likelihood fits aim at maximizing the information one can extract from experimental data, yet their application in realistic statistical analyses is often hindered by the computational cost of profiling systematic uncertainties. Additionally, current machine learning-based inference methods are typically limited to estimating scalar parameters in a multidimensional space rather than full differential distributions. We propose a general framework for Simulation-Based Inference (SBI) that efficiently profiles nuisance parameters while measuring multivariate Distributions of Interest (DoI), defined as learnable invertible transformations of the feature space. We introduce Factorizable Normalizing Flows to model systematic variations as parametric deformations of a nominal density, preserving tractability without combinatorial explosion. Crucially, we develop an amortized training strategy that learns the conditional dependence of the DoI on nuisance parameters in a single optimization process, bypassing the need for repetitive training during the likelihood scan. This allows for the simultaneous extraction of the underlying distribution and the robust profiling of nuisances. The method is validated on a synthetic dataset emulating a high-energy physics measurement with multiple systematic sources, demonstrating its potential for unbinned, functional measurements in complex analyses. | [üîó Paper](https://arxiv.org/abs/2602.13184v1) |
| [Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps](https://arxiv.org/abs/2602.13177v1) | Swati Gupta, Jai Moondra, Mohit Singh | 2026-02-13 | Optimization | OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).   Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization. | [üîó Paper](https://arxiv.org/abs/2602.13177v1) |
| [A Data-Driven Algorithm for Model-Free Control Synthesis](https://arxiv.org/abs/2602.13157v1) | Sean Bowerfind, Matthew R. Kirchner, Gary Hewer | 2026-02-13 | Optimization | Presented is an algorithm to synthesize the optimal infinite-horizon LQR feedback controller for continuous-time systems. The algorithm does not require knowledge of the system dynamics but instead uses only a finite-length sampling of arbitrary input-output data. The algorithm is based on a constrained optimization problem that enforces a necessary condition on the dynamics of the optimal value function along any trajectory. In addition to calculating the standard LQR gain matrix, a feedforward gain can be found to implement a reference tracking controller. This paper presents a theoretical justification for the method and shows several examples, including a validation test on a real scale aircraft. | [üîó Paper](https://arxiv.org/abs/2602.13157v1) |
| [In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach](https://arxiv.org/abs/2602.13156v1) | Yiran Gao, Kim Hammar, Tao Li | 2026-02-13 | Optimization, RLHF, Training & Evaluation, Security & Adversarial ML, LLM, Prompt Engineering | Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large language models' (LLM) pre-trained security knowledge and in-context learning to create an end-to-end agentic solution for incident response planning. Specifically, our agent integrates four functionalities, perception, reasoning, planning, and action, into one lightweight LLM (14b model). Through fine-tuning and chain-of-thought reasoning, our LLM agent is capable of processing system logs and inferring the underlying network state (perception), updating its conjecture of attack models (reasoning), simulating consequences under different response strategies (planning), and generating an effective response (action). By comparing LLM-simulated outcomes with actual observations, the LLM agent repeatedly refines its attack conjecture and corresponding response, thereby demonstrating in-context adaptation. Our agentic approach is free of modeling and can run on commodity hardware. When evaluated on incident logs reported in the literature, our agent achieves recovery up to 23% faster than those of frontier LLMs. | [üîó Paper](https://arxiv.org/abs/2602.13156v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [$\texttt{GPUmonty}$: A GPU-accelerated relativistic Monte Carlo radiative transfer code](https://arxiv.org/abs/2602.13198v1) | Pedro Naethe Motta, Rodrigo Nemmen, Abhishek V. Joshi | 2026-02-13 | Scaling Laws | We introduce $\texttt{GPUmonty}$, a CUDA/C-based Monte Carlo radiative transfer code accelerated using graphics processing units (GPUs). $\texttt{GPUmonty}$ derives from the CPU-based code $\texttt{grmonty}$ and offloads the most computationally expensive stages of the calculation -- superphoton generation, sampling, tracking, and scattering -- to the GPU. Whereas $\texttt{grmonty}$ handles photons sequentially, $\texttt{GPUmonty}$ processes large numbers of superphotons concurrently, leveraging the single-instruction, multiple-thread (SIMT) execution model of modern GPUs. Benchmarks demonstrate a speedup of about $12\times$ relative to the original CPU implementation on a single GPU, with runtime limited primarily by register pressure rather than compute or memory bandwidth saturation. We validate the implementation through analytic tests for a optically thin synchrotron sphere, as well as comparisons with $\texttt{igrmonty}$ for scattering synchrotron sphere and GRMHD simulation data. Relative errors remain below a percent level and convergence is consistent with the expected $N_{\rm s}^{-1/2}$ Monte Carlo scaling. By significantly reducing computational costs, GPUmonty enables the extensive parameter space surveys and faster spectra modeling required to interpret horizon-scale observations of supermassive black holes. $\texttt{GPUmonty}$ is publicly available under the GNU General Public License. | [üîó Paper](https://arxiv.org/abs/2602.13198v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control](https://arxiv.org/abs/2602.13193v1) | William Chen, Jagdeep Singh Bhatia, Catherine Glossop, Nikhil Mathihalli, Ria Doshi, Andy Tang, Danny Driess, Karl Pertsch, Sergey Levine | 2026-02-13 | Training & Evaluation, Multimodal AI | Pretrained vision-language models (VLMs) can make semantic and visual inferences across diverse settings, providing valuable common-sense priors for robotic control. However, effectively grounding this knowledge in robot behaviors remains an open challenge. Prior methods often employ a hierarchical approach where VLMs reason over high-level commands to be executed by separate low-level policies, e.g., vision-language-action models (VLAs). The interface between VLMs and VLAs is usually natural language task instructions, which fundamentally limits how much VLM reasoning can steer low-level behavior. We thus introduce Steerable Policies: VLAs trained on rich synthetic commands at various levels of abstraction, like subtasks, motions, and grounded pixel coordinates. By improving low-level controllability, Steerable Policies can unlock pretrained knowledge in VLMs, enabling improved task generalization. We demonstrate this benefit by controlling our Steerable Policies with both a learned high-level embodied reasoner and an off-the-shelf VLM prompted to reason over command abstractions via in-context learning. Across extensive real-world manipulation experiments, these two novel methods outperform prior embodied reasoning VLAs and VLM-based hierarchical baselines, including on challenging generalization and long-horizon tasks.   Website: steerable-policies.github.io | [üîó Paper](https://arxiv.org/abs/2602.13193v1) |
| [Nuclear gradients from auxiliary-field quantum Monte Carlo and their application in geometry optimization and transition state search](https://arxiv.org/abs/2602.13187v1) | Jo S. Kurian, Ankit Mahajan, Sandeep Sharma | 2026-02-13 | Training & Evaluation, Optimization | In this article, we present a method for computing accurate and scalable nuclear forces within the phaseless auxiliary-field quantum Monte Carlo (AFQMC) framework. Our approach leverages automatic differentiation of the energy functional to obtain nuclear gradients at a computational cost comparable to that of energy evaluation. The accuracy of the method is validated against finite difference calculations, showing excellent agreement. We then explore several machine learning (ML) strategies for learning noisy AFQMC data. These ML potentials are subsequently used to perform geometry optimizations and nudged elastic band (NEB) calculations, successfully identifying the transition state of the formamide-formimidic acid tautomerization. The resulting transition state geometry and barrier heights are in close agreement with coupled-cluster reference values. This work paves the way for highly accurate geometry optimization, molecular dynamics, or reaction path calculations. | [üîó Paper](https://arxiv.org/abs/2602.13187v1) |
| [Monocular Markerless Motion Capture Enables Quantitative Assessment of Upper Extremity Reachable Workspace](https://arxiv.org/abs/2602.13176v1) | Seth Donahue, J. D. Peiffer, R. Tyler Richardson, Yishan Zhong, Shaun Q. Y. Tan, Benoit Marteau, Stephanie R. Russo, May D. Wang, R. James Cotton, Ross Chafetz | 2026-02-13 | Training & Evaluation, Responsible AI, Model Evaluation, Multimodal AI | To validate a clinically accessible approach for quantifying the Upper Extremity Reachable Workspace (UERW) using a single (monocular) camera and Artificial Intelligence (AI)-driven Markerless Motion Capture (MMC) for biomechanical analysis. Objective assessment and validation of these techniques for specific clinically oriented tasks are crucial for their adoption in clinical motion analysis. AI-driven monocular MMC reduces the barriers to adoption in the clinic and has the potential to reduce the overhead for analysis of this common clinical assessment. Nine adult participants with no impairments performed the standardized UERW task, which entails reaching targets distributed across a virtual sphere centered on the torso, with targets displayed in a VR headset. Movements were simultaneously captured using a marker-based motion capture system and a set of eight FLIR cameras. We performed monocular video analysis on two of these video camera views to compare a frontal and offset camera configurations. The frontal camera orientation demonstrated strong agreement with the marker-based reference, exhibiting a minimal mean bias of $0.61 \pm 0.12$ \% reachspace reached per octanct (mean $\pm$ standard deviation). In contrast, the offset camera view underestimated the percent workspace reached ($-5.66 \pm 0.45$ \% reachspace reached). Conclusion: The findings support the feasibility of a frontal monocular camera configuration for UERW assessment, particularly for anterior workspace evaluation where agreement with marker-based motion capture was highest. The overall performance demonstrates clinical potential for practical, single-camera assessments. This study provides the first validation of monocular MMC system for the assessment of the UERW task. By reducing technical complexity, this approach enables broader implementation of quantitative upper extremity mobility assessment. | [üîó Paper](https://arxiv.org/abs/2602.13176v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Realistic Face Reconstruction from Facial Embeddings via Diffusion Models](https://arxiv.org/abs/2602.13168v1) | Dong Han, Yong Li, Joachim Denzler | 2026-02-13 | Model Evaluation, Diffusion Models, Responsible AI | With the advancement of face recognition (FR) systems, privacy-preserving face recognition (PPFR) systems have gained popularity for their accurate recognition, enhanced facial privacy protection, and robustness to various attacks. However, there are limited studies to further verify privacy risks by reconstructing realistic high-resolution face images from embeddings of these systems, especially for PPFR. In this work, we propose the face embedding mapping (FEM), a general framework that explores Kolmogorov-Arnold Network (KAN) for conducting the embedding-to-face attack by leveraging pre-trained Identity-Preserving diffusion model against state-of-the-art (SOTA) FR and PPFR systems. Based on extensive experiments, we verify that reconstructed faces can be used for accessing other real-word FR systems. Besides, the proposed method shows the robustness in reconstructing faces from the partial and protected face embeddings. Moreover, FEM can be utilized as a tool for evaluating safety of FR and PPFR systems in terms of privacy leakage. All images used in this work are from public datasets. | [üîó Paper](https://arxiv.org/abs/2602.13168v1) |
## üîπ Production and Deployment

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Asynchronous Verified Semantic Caching for Tiered LLM Architectures](https://arxiv.org/abs/2602.13165v1) | Asmit Kumar Singh, Haozhe Wang, Laxmi Naga Santosh Attaluri, Tak Chiam, Weihua Zhu | 2026-02-13 | Production and Deployment | Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency. | [üîó Paper](https://arxiv.org/abs/2602.13165v1) |
## üîπ Graph AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Learning to Approximate Uniform Facility Location via Graph Neural Networks](https://arxiv.org/abs/2602.13155v1) | Chendi Qian, Christopher Morris, Stefanie Jegelka, Christian Sohler | 2026-02-13 | Graph AI, Optimization, RLHF | There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization. | [üîó Paper](https://arxiv.org/abs/2602.13155v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Peaceful Anarcho-Accelerationism: Decentralized Full Automation for a Society of Universal Care](https://arxiv.org/abs/2602.13154v1) | Eduardo C. Garrido-Merch√°n | 2026-02-13 | Responsible AI, RLHF | The convergence of large language models that automate cognitive labor and deep reinforcement learning agents that automate physical labor implies the near-complete elimination of human employment. The universal approximation theorem and foundational DRL results establish that all labor is in principle automatable. The critical question is not whether full automation will arrive, but who will control it. This paper introduces peaceful anarcho-accelerationism: a sociotechnical framework ensuring that full automation is decentralized, commons-governed, and oriented toward universal care. We propose the Liberation Stack, a layered architecture of energy, manufacturing, food, communication, knowledge, and governance commons built on open-source technologies. We show that this framework builds bridges with liberalism, socialism, environmentalism, feminism, cooperativism, and the hacker ethic. Empirical evidence from Linux, Wikipedia, Mondragon, Rojava, and guifi.net confirms that commons-based systems already operate at scale. We argue that full automation renders money obsolete and propose Universal Desired Resources (UDR), a post-monetary design principle where every person requests what they need from the robotic commons, constrained only by ecological sustainability. Drawing on the independence of phenomenal consciousness from computational intelligence, we establish that delegating labor to non-conscious machines is care at civilizational scale, and that moral policy can be studied through deep reinforcement learning. We conclude with a phased roadmap toward the care-centered society, including milestones, assumptions, and limitations. | [üîó Paper](https://arxiv.org/abs/2602.13154v1) |
## üîπ Memory & Context Length

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [CoPE-VideoLM: Codec Primitives For Efficient Video Language Models](https://arxiv.org/abs/2602.13191v1) | Sayan Deb Sarkar, R√©mi Pautrat, Ondrej Miksik, Marc Pollefeys, Iro Armeni, Mahdi Rad, Mihai Dusmanu | 2026-02-13 | Memory & Context Length, LLM, Optimization, Multimodal AI | Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\%$ and token usage by up to $93\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding. | [üîó Paper](https://arxiv.org/abs/2602.13191v1) |
## üîπ Security & Adversarial ML

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Operator Learning for Families of Finite-State Mean-Field Games](https://arxiv.org/abs/2602.13169v1) | William Hofgard, Asaf Cohen, Mathieu Lauri√®re | 2026-02-13 | Security & Adversarial ML | Finite-state mean-field games (MFGs) arise as limits of large interacting particle systems and are governed by an MFG system, a coupled forward-backward differential equation consisting of a forward Kolmogorov-Fokker-Planck (KFP) equation describing the population distribution and a backward Hamilton-Jacobi-Bellman (HJB) equation defining the value function. Solving MFG systems efficiently is challenging, with the structure of each system depending on an initial distribution of players and the terminal cost of the game. We propose an operator learning framework that solves parametric families of MFGs, enabling generalization without retraining for new initial distributions and terminal costs. We provide theoretical guarantees on the approximation error, parametric complexity, and generalization performance of our method, based on a novel regularity result for an appropriately defined flow map corresponding to an MFG system. We demonstrate empirically that our framework achieves accurate approximation for two representative instances of MFGs: a cybersecurity example and a high-dimensional quadratic model commonly used as a benchmark for numerical methods for MFGs. | [üîó Paper](https://arxiv.org/abs/2602.13169v1) |
| [Bloom Filter Look-Up Tables for Private and Secure Distributed Databases in Web3 (Revised Version)](https://arxiv.org/abs/2602.13167v1) | Shlomi Dolev, Ehud Gudes, Daniel Shlomo | 2026-02-13 | Security & Adversarial ML | The rapid growth of decentralized systems in theWeb3 ecosystem has introduced numerous challenges, particularly in ensuring data security, privacy, and scalability [3, 8]. These systems rely heavily on distributed architectures, requiring robust mechanisms to manage data and interactions among participants securely. One critical aspect of decentralized systems is key management, which is essential for encrypting files, securing database segments, and enabling private transactions. However, securely managing cryptographic keys in a distributed environment poses significant risks, especially when nodes in the network can be compromised [9]. This research proposes a decentralized database scheme specifically designed for secure and private key management. Our approach ensures that cryptographic keys are not stored explicitly at any location, preventing their discovery even if an attacker gains control of multiple nodes. Instead of traditional storage, keys are encoded and distributed using the BFLUT (Bloom Filter for Private Look-Up Tables) algorithm [7], which enables secure retrieval without direct exposure. The system leverages OrbitDB [4], IPFS [1], and IPNS [10] for decentralized data management, providing robust support for consistency, scalability, and simultaneous updates. By combining these technologies, our scheme enhances both security and privacy while maintaining high performance and reliability. Our findings demonstrate the system's capability to securely manage keys, prevent unauthorized access, and ensure privacy, making it a foundational solution for Web3 applications requiring decentralized security. | [üîó Paper](https://arxiv.org/abs/2602.13167v1) |
## üîπ LLM Ops

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151v1) | Jo√£o Vitor Boer Abitante, Joana Meneguzzo Pasquali, Luan Fonseca Garcia, Ewerton de Oliveira, Thomas da Silva Paula, Rodrigo C. Barros, Lucas S. Kupssinsk√º | 2026-02-13 | LLM Ops, LLM, Optimization | Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment. | [üîó Paper](https://arxiv.org/abs/2602.13151v1) |
## üîπ RAG

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation](https://arxiv.org/abs/2602.13179v1) | Jiankun Zhang, Shenglai Zeng, Kai Guo, Xinnan Dai, Hui Liu, Jiliang Tang, Yi Chang | 2026-02-13 | RAG, Multimodal AI, Fine-Tuning, Optimization, Training & Evaluation, Model Evaluation | Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench | [üîó Paper](https://arxiv.org/abs/2602.13179v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Gravitational Background of Alice-Vortices and R7-Branes](https://arxiv.org/abs/2602.13196v1) | Atakan √áavu≈üoƒülu, Mirjam Cvetiƒç, Jonathan J. Heckman, Jeffrey Kuntz, Chitraang Murdia | 2026-02-13 | General AI | Codimension-two vortex solutions are important solitonic objects in both quantum field theory and gravity. In this paper, we construct a class of codimension-two Alice-vortex solutions in axio-dilaton gravity, in which monodromy around the vortex enacts the axion transformation $C_0 \mapsto -C_0$. In IIB supergravity, this furnishes a class of R7-brane backgrounds of the sort predicted by the Swampland Cobordism Conjecture. Such configurations generically carry an intrinsic dipole moment. We extract additional properties of such branes from scattering probes. These results provide further evidence that the worldvolume theory of an R7-brane is an 8D non-supersymmetric interacting quantum field theory. | [üîó Paper](https://arxiv.org/abs/2602.13196v1) |
| [Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision](https://arxiv.org/abs/2602.13195v1) | Aadarsh Sahoo, Georgia Gkioxari | 2026-02-13 | General AI | Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., "left-most apple") and overlooks functional and physical reasoning (e.g., "where can I safely store the knife?"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/ | [üîó Paper](https://arxiv.org/abs/2602.13195v1) |
| [Semantic Chunking and the Entropy of Natural Language](https://arxiv.org/abs/2602.13194v1) | Weishun Zhong, Doron Sivan, Tankut Can, Mikhail Katkov, Misha Tsodyks | 2026-02-13 | General AI | The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model. | [üîó Paper](https://arxiv.org/abs/2602.13194v1) |
| [Matter-induced plaquette terms in a $\mathbb{Z}_2$ lattice gauge theory](https://arxiv.org/abs/2602.13192v1) | Matja≈æ Kebriƒç, Fabian D√∂schl, Umberto Borla, Jad C. Halimeh, Ulrich Schollw√∂ck, Annabelle Bohrdt, Fabian Grusdt | 2026-02-13 | General AI | Lattice gauge theories (LGTs) provide a powerful framework for studying confinement, topological order, and exotic quantum matter. In particular, the paradigmatic phenomenon of confinement, where dynamical matter is coupled to gauge fields and forms bound states, remains an open problem. In addition, LGTs can provide low-energy descriptions of quantum spin liquids, which is the focus of ongoing experimental research. However, the study of LGTs is often limited theoretically by their numerical complexity and experimentally in implementing challenging multi-body interactions, such as the plaquette terms crucial for the realization of many exotic phases of matter. Here we investigate a $(2+1)$D $\mathbb{Z}_2$ LGT coupled to hard-core bosonic matter featuring a global U(1) symmetry, and show that dynamical matter naturally induces sizable plaquette interactions even in the absence of explicit plaquette terms in the Hamiltonian. Using a combination of density matrix renormalization group simulations and neural quantum state calculations up to a system size of $20 \times 20$, we analyze the model across different fillings and electric field strengths. At small coupling strength, we find a large plaquette expectation value, independent of system size, for a wide range of fillings, which decreases in the presence of stronger electric fields. Furthermore, we observe signatures of a confinement-deconfinement transition at weak coupling strengths. Our results demonstrate that dynamical U(1) matter can induce complex multi-body interactions, suggesting a natural route to the realization of strong plaquette terms and paving the way for realizing a topological quantum spin liquid protected by a large gap. | [üîó Paper](https://arxiv.org/abs/2602.13192v1) |
| [Disorder viscosity correction approach to calculate spinodal temperature and wavelength](https://arxiv.org/abs/2602.13190v1) | Simon Divilov, Hagen Eckert, Nico Hotz, Xiomara Campilongo, Stefano Curtarolo | 2026-02-13 | General AI | Spinodal decomposition, a key mechanism to microstructure formation in materials, has long posed challenges for predictive modeling, due to the need for parameter-free approaches that accurately capture local energy landscapes. In this work, we propose an approach to predict spinodal behavior by introducing a disorder viscosity correction to bulk free energies computed from finite, small, representative cells. We approximate the energy penalty required to transition into a disordered state to enable the stabilization of locally concave bulk free energy regions - essential for interface formation - while suppressing long-range concentration fluctuations. This approximation circumvents the complexity of full ab initio parameterization of interfacial properties and is well-suited for high-throughput and machine-learning frameworks. Our approach captures the necessary physics underpinning spinodal kinetics, offering a scalable route to predict spinodal regions in compositionally complex and high-entropy materials. | [üîó Paper](https://arxiv.org/abs/2602.13190v1) |
| [Addressing the Hubble tension with Sterile Neutrino Dark Matter](https://arxiv.org/abs/2602.13189v1) | Debtosh Chowdhury, Md Sariful Islam | 2026-02-13 | General AI | One of the promising dark matter (DM) candidates is a keV scale sterile neutrino. In the early universe the observed relic of the sterile neutrino DM is generated via the \textit{Dodelson-Widrow} mechanism. However, this production scenario is severely constraint by various astrophysical observations. Many non-standard interactions between active ($ŒΩ_a$) and sterile ($ŒΩ_s$) neutrino have been proposed to evade these astrophysical bounds. Here, we study sterile neutrino in the context of a mass-varying scenario by coupling both active and sterile neutrino to a scalar field. This novel mechanism opens up a new parameter space that generates the observed DM relic and alleviates the \textit{Hubble tension}. We find that the resulting parameter space can be fully probed by future X-ray missions. | [üîó Paper](https://arxiv.org/abs/2602.13189v1) |
| [Determinant and Pfaffian formulas for particle annihilation](https://arxiv.org/abs/2602.13183v1) | Piotr ≈öniady | 2026-02-13 | General AI | When particles on a line collide, they may annihilate-both are destroyed. Computing exact annihilation probabilities has been difficult because collisions reduce the particle count, while determinantal methods require a fixed count throughout. The ghost particle method, introduced in a companion paper for coalescence, keeps destroyed particles walking as invisible ghosts that restore the missing dimension. We apply this method to annihilation: when two particles annihilate, both trajectories continue as invisible walkers, yielding an exact determinantal formula that specifies the number of annihilations, where survivors end up, and where ghosts end up. For complete annihilation (no survivors), the formula simplifies to a Pfaffian-an algebraic relative of the determinant built from pairwise quantities-connecting to Pfaffian point process theory. The annihilation formula also yields results about coalescence: pairwise coalescence can be reinterpreted as complete annihilation, producing a Pfaffian coalescence formula. These formulas are exact for any finite initial configuration and apply to discrete lattice paths, birth-death chains, and continuous diffusions including Brownian motion. | [üîó Paper](https://arxiv.org/abs/2602.13183v1) |
| [The Fuzzy Front Ends: Reflections on the Never-Ending Story of Visualization Co-Design](https://arxiv.org/abs/2602.13182v1) | Wei Wei, Foroozan Daneshzand, Zezhong Wang, Erica Mattson, Charles Perin, Sheelagh Carpendale | 2026-02-13 | General AI | Co-design is an increasingly popular approach in HCI and visualization, yet there is little guidance on how to effectively apply this method in visualization contexts. In this paper, we visually present our experience of a two-and-a-half-year co-design project with the local arts community. Focusing on facilitating community exploration and sense-making around arts funding distribution, the project involved a series of co-design sessions between visualization researchers and members of the arts community. Through these iterative sessions, we built shared understanding and developed visualization prototypes tailored to community needs. However, the practice is far from complete, and we found ourselves continually returning to the "fuzzy front end" of the co-design process. We share this ongoing story through comic-style visuals and reflect on three fuzzy front ends that we encountered during the project. By sharing these experiences with the visualization community, we hope to offer insights that others can draw on in their own community-engaged co-design work. | [üîó Paper](https://arxiv.org/abs/2602.13182v1) |
| [Selection of CMIP6 Models for Regional Precipitation Projection and Climate Change Assessment in the Jhelum and Chenab River Basins](https://arxiv.org/abs/2602.13181v1) | Saad Ahmed Jamal, Ammara Nusrat, Muhammad Azmat, Muhammad Osama Nusrat | 2026-02-13 | General AI | Effective water resource management depends on accurate projections of flows in water channels. For projected climate data, use of different General Circulation Models (GCM) simulates contrasting results. This study shows selection of GCM for the latest generation CMIP6 for hydroclimate change impact studies. Envelope based method was used for the selection, which includes components based on machine learning techniques, allowing the selection of GCMs without the need for in-situ reference data. According to our knowledge, for the first time, such a comparison was performed for the CMIP6 Shared Socioeconomic Pathway (SSP) scenarios data. In addition, the effect of climate change under SSP scenarios was studied, along with the calculation of extreme indices. Finally, GCMs were compared to quantify spatiotemporal differences between CMIP5 and CMIP6 data. Results provide NorESM2 LM, FGOALS g3 as selected models for the Jhelum and Chenab River. Highly vulnerable regions under the effect of climate change were highlighted through spatial maps, which included parts of Punjab, Jammu, and Kashmir. Upon comparison of CMIP5 and CMIP6, no discernible difference was found between the RCP and SSP scenarios precipitation projections. In the future, more detailed statistical comparisons could further reinforce the proposition. | [üîó Paper](https://arxiv.org/abs/2602.13181v1) |
| [Exact moment models for conservation laws in phase space](https://arxiv.org/abs/2602.13180v1) | Tileuzhan Mukhamet, Katharina Kormann | 2026-02-13 | General AI | Moment equations offer a compelling alternative to the kinetic description of plasmas, gases, and liquids. Their simulation requires fewer degrees of freedom than phase space models, yet it can still incorporate kinetic effects to a certain extent. To derive moment equations, we use a parameterization of the distribution function using centered moments, as proposed by Burby. This yields moment equations for which the parameterized distribution function exactly solves the hyperbolic conservation law. Similarly, a particle model is derived based on a parametrization of the distribution function using phase space moments. Finally, we present the application of the method to the non-relativistic and relativistic Vlasov--Maxwell equations. | [üîó Paper](https://arxiv.org/abs/2602.13180v1) |
| [Discrete Invariants of Koszul Artin-Schelter Regular Algebras of Dimension four](https://arxiv.org/abs/2602.13178v1) | Vishal Bhatoy, Colin Ingalls | 2026-02-13 | General AI | We compute the superpotentials for known families of Koszul Artin-Schelter regular algebras of dimension four using Magma, and apply Schur-Weyl duality from representation theory to determine the relevant invariants. Through the Borel-Weil theorem, we interpret these invariants as sections of line bundles over partial flag varieties, resulting in geometric invariants that, in some cases, correspond to K3 surfaces. We compute discrete invariants of these geometric invariants and use them to distinguish algebras. | [üîó Paper](https://arxiv.org/abs/2602.13178v1) |
| [Absorption imaging of quantum gases near surfaces using incoherent light](https://arxiv.org/abs/2602.13175v1) | Julia Fekete, Poppy Joshi, Peter Kr√ºger, Fedja Oruƒçeviƒá | 2026-02-13 | General AI | We introduce an absorption imaging technique for ultracold gases that suppresses interference fringes and coherence-induced artifacts by reducing the transverse spatial coherence of the imaging light. The method preserves the narrow spectral bandwidth required for resonant absorption imaging and is implemented as a modular extension to standard imaging setups using a rotating diffuser. We demonstrate tunability of the illumination light's coherence without modifying the imaging optics. Using this approach, we achieve reliable imaging of ultracold atomic clouds in micron-scale proximity to complex surfaces, where standing waves, edge diffraction, and speckle severely limit conventional absorption imaging. | [üîó Paper](https://arxiv.org/abs/2602.13175v1) |
| [Accuracy Comes at a Cost: Optimal Localisation Against a Flow](https://arxiv.org/abs/2602.13173v1) | Till Welker, Patrick Pietzonka | 2026-02-13 | General AI | How much work does it cost for a propelled particle to stay localised near a stationary target, defying both thermal noise and a constant flow that would carry it away? We study the control of such a particle in finite time and find optimal protocols for time-dependent swim velocity and diffusivity, without feedback. Accuracy, quantified via the mean squared deviation from the target, and energetic cost turn out to be related by a trade-off, which complements the one between precision and cost known in stochastic thermodynamics. We show that accuracy better than a certain threshold requires active driving, which comes at a cost that increases with accuracy. The optimal protocols have discontinuous swim velocity and diffusivity, switching between a passive drift state with vanishing diffusivity and an active propulsion state. This study highlights how a time-dependent diffusivity enhances optimal control and sets benchmarks for cost and accuracy of artificial self-propelled particles navigating noisy environments. | [üîó Paper](https://arxiv.org/abs/2602.13173v1) |
| [Complex to Rational Fast Matrix Multiplication](https://arxiv.org/abs/2602.13171v1) | Yoav Moran, Oded Schwartz, Shuncheng Yuan | 2026-02-13 | General AI | Fast matrix multiplication algorithms are asymptotically faster than the classical cubic-time algorithm, but they are often slower in practice. One important obstacle is the use of complex coefficients, which increases arithmetic overhead and limits practical efficiency. This paper focuses on transforming complex-coefficient matrix multiplication schemes into equivalent real- or rational-coefficient ones. We present a systematic method that, given a complex-coefficient scheme, either constructs a family of equivalent rational algorithms or proves that no equivalent rational scheme exists. Our approach relies only on basic linear-algebraic properties of similarity transformations of complex matrices. This method recovers the previously known ad hoc results of Dumas, Pernet, and Sedoglavic (2025) and extends them to more general settings, including algorithms involving rational coefficients and square roots, with $i=\sqrt{-1}$ as a special case.   Using this framework, we show that no rational scheme is equivalent to Smirnov's $\langle4,4,9,104\rangle$ $\mathbb{Q}[\sqrt{161}]$ algorithm (2022) and that no real scheme is equivalent to the $\langle4,4,4,48\rangle$ complex algorithm of Kaporin (2024). More generally, our approach can also be used to prove the non-existence of integer-coefficient schemes. | [üîó Paper](https://arxiv.org/abs/2602.13171v1) |
| [Source Code Hotspots: A Diagnostic Method for Quality Issues](https://arxiv.org/abs/2602.13170v1) | Saleha Muzammil, Mughees Ur Rehman, Zoe Kotti, Diomidis Spinellis | 2026-02-13 | General AI | Software source code often harbours "hotspots": small portions of the code that change far more often than the rest of the project and thus concentrate maintenance activity. We mine the complete version histories of 91 evolving, actively developed GitHub repositories and identify 15 recurring line-level hotspot patterns that explain why these hotspots emerge. The three most prevalent patterns are Pinned Version Bump (26%), revealing brittle release practices; Long Line Change (17%), signalling deficient layout; and Formatting Ping-Pong (9%), indicating missing or inconsistent style automation. Surprisingly, automated accounts generate 74% of all hotspot edits, suggesting that bot activity is a dominant but largely avoidable source of noise in change histories. By mapping each pattern to concrete refactoring guidelines and continuous integration checks, our taxonomy equips practitioners with actionable steps to curb hotspots and systematically improve software quality in terms of configurability, stability, and changeability. | [üîó Paper](https://arxiv.org/abs/2602.13170v1) |
| [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166v1) | Hugo Henry, Arthur Tsai, Kelly Cohen | 2026-02-13 | General AI | This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments. | [üîó Paper](https://arxiv.org/abs/2602.13166v1) |
| [Early-warning the compact-to-dendritic transition via spatiotemporal learning of two-dimensional growth images](https://arxiv.org/abs/2602.13164v1) | Hyunjun Jang, Chung Bin Park, Jeonghoon Kim, Jeongmin Kim | 2026-02-13 | General AI | Transitions between distinct dynamical regimes are ubiquitous in nonequilibrium systems. As a prototypical example, deposition growth is often accompanied by irreversible morphological instabilities. Forecasting such transitions from pre-transition configurations remains fundamentally challenging, as early precursors are weak, spatially heterogeneous, and masked by inherent fluctuations. Here, we investigate compact-to-dendritic transitions (CDTs) in a two-dimensional particle-based electrodeposition model and formulate a horizon-based early-warning task using trajectory-resolved transition points. We demonstrate that anticipating the CDT is intrinsically a spatiotemporal problem: neither static morphological descriptors nor temporal learning applied to predefined features alone yields reliable predictive signals. In contrast, end-to-end learning of jointly optimized spatial and temporal representations from growth images enables robust anticipation across a wide range of prediction horizons. Analysis of the learned latent dynamics reveals the emergence of a low-dimensional surrogate variable that tracks progressive morphological destabilization and undergoes reorganization near the transition. We further show that the learned spatiotemporal representation exhibits limited but systematic transferability across reaction-rate conditions, with predictive performance degrading as the inference condition departs from the training condition, consistent with changes in the latent-state dynamics. Overall, our results establish a general formulation for forecasting incipient instabilities in nonequilibrium interfacial growth, with implications for the predictive monitoring and control of pattern-forming driven systems. | [üîó Paper](https://arxiv.org/abs/2602.13164v1) |
| [Human Emotion-Mediated Soft Robotic Arts: Exploring the Intersection of Human Emotions, Soft Robotics and Arts](https://arxiv.org/abs/2602.13163v1) | Saitarun Nadipineni, Chenhao Hong, Tanishtha Ramlall, Chapa Sirithunge, Kaspar Althoefer, Fumiya Iida, Thilina Dulantha Lalitharatne | 2026-02-13 | General AI | Soft robotics has emerged as a versatile field with applications across various domains, from healthcare to industrial automation, and more recently, art and interactive installations. The inherent flexibility, adaptability, and safety of soft robots make them ideal for applications that require delicate, organic, and lifelike movement, allowing for immersive and responsive interactions. This study explores the intersection of human emotions, soft robotics, and art to establish and create new forms of human emotion-mediated soft robotic art. In this paper, we introduce two soft embodiments: a soft character and a soft flower as an art display that dynamically responds to brain signals based on alpha waves, reflecting different emotion levels. We present how human emotions can be measured as alpha waves based on brain/EEG signals, how we map the alpha waves to the dynamic movements of the two soft embodiments, and demonstrate our proposed concept using experiments. The findings of this study highlight how soft robotics can embody human emotional states, offering a new medium for insightful artistic expression and interaction, and demonstrating how art displays can be embodied. | [üîó Paper](https://arxiv.org/abs/2602.13163v1) |
| [Structural barriers of the discrete Hasimoto map applied to protein backbone geometry](https://arxiv.org/abs/2602.13160v1) | Yiquan Wang | 2026-02-13 | General AI | Determining the three-dimensional structure of a protein from its amino-acid sequence remains a fundamental problem in biophysics. The discrete Frenet geometry of the C$_Œ±$ backbone can be mapped, via a Hasimoto-type transform, onto a complex scalar field $œà=Œ∫\,e^{i\sumœÑ}$ satisfying a discrete nonlinear Schr√∂dinger equation (DNLS), whose soliton solutions reproduce observed secondary-structure motifs. Whether this mapping, which provides an elegant geometric description of folded states, can be extended to a predictive framework for protein folding remains an open question. We derive an exact closed-form decomposition of the DNLS effective potential $V_{\text{eff}}=V_{\text{re}}+iV_{\text{im}}$ in terms of curvature ratios and torsion angles, validating the result to machine precision across 856 non-redundant proteins. Our analysis identifies three structural barriers to forward prediction: (i)~$V_{\text{im}}$ encodes chirality via the odd symmetry of $\sinœÑ$, accounting for ${\sim}31\%$ of the total information and implying a $2^N$ degeneracy if neglected; (ii)~$V_{\text{re}}$ is determined primarily (${\sim}95\%$) by local geometry, rendering it effectively sequence-agnostic; and (iii)~self-consistent field iterations fail to recover native structures (mean RMSD $= 13.1$\,√Ö) even with hydrogen-bond terms, yielding torsion correlations indistinguishable from zero. Constructively, we demonstrate that the residual of the DNLS dispersion relation serves as a geometric order parameter for $Œ±$-helices (ROC AUC $= 0.72$), defining them as regions of maximal integrability. These findings establish that the Hasimoto map functions as a kinematic identity rather than a dynamical governing equation, presenting fundamental obstacles to its use as a predictive framework for protein folding. | [üîó Paper](https://arxiv.org/abs/2602.13160v1) |
| [Temporally-Sampled Efficiently Adaptive State Lattices for Autonomous Ground Robot Navigation in Partially Observed Environments](https://arxiv.org/abs/2602.13159v1) | Ashwin Satish Menon, Eric R. Damm, Eli S. Lancaster, Felix A. Sanchez, Jason M. Gregory, Thomas M. Howard | 2026-02-13 | General AI | Due to sensor limitations, environments that off-road mobile robots operate in are often only partially observable. As the robots move throughout the environment and towards their goal, the optimal route is continuously revised as the sensors perceive new information. In traditional autonomous navigation architectures, a regional motion planner will consume the environment map and output a trajectory for the local motion planner to use as a reference. Due to the continuous revision of the regional plan guidance as a result of changing map information, the reference trajectories which are passed down to the local planner can differ significantly across sequential planning cycles. This rapidly changing guidance can result in unsafe navigation behavior, often requiring manual safety interventions during autonomous traversals in off-road environments. To remedy this problem, we propose Temporally-Sampled Efficiently Adaptive State Lattices (TSEASL), which is a regional planner arbitration architecture that considers updated and optimized versions of previously generated trajectories against the currently generated trajectory. When tested on a Clearpath Robotics Warthog Unmanned Ground Vehicle as well as real map data collected from the Warthog, results indicate that when running TSEASL, the robot did not require manual interventions in the same locations where the robot was running the baseline planner. Additionally, higher levels of planner stability were recorded with TSEASL over the baseline. The paper concludes with a discussion of further improvements to TSEASL in order to make it more generalizable to various off-road autonomy scenarios. | [üîó Paper](https://arxiv.org/abs/2602.13159v1) |
| [A new mixture model for spatiotemporal exceedances with flexible tail dependence](https://arxiv.org/abs/2602.13158v1) | Ryan Li, Brian J. Reich, Emily C. Hector, Reetam Majumder | 2026-02-13 | General AI | We propose a new model and estimation framework for spatiotemporal streamflow exceedances above a threshold that flexibly captures asymptotic dependence and independence in the tail of the distribution. We model streamflow using a mixture of processes with spatial, temporal and spatiotemporal asymptotic dependence regimes. A censoring mechanism allows us to use only observations above a threshold to estimate marginal and joint probabilities of extreme events. As the likelihood is intractable, we use simulation-based inference powered by random forests to estimate model parameters from summary statistics of the data. Simulations and modeling of streamflow data from the U.S. Geological Survey illustrate the feasibility and practicality of our approach. | [üîó Paper](https://arxiv.org/abs/2602.13158v1) |
| [Detecting Parameter Instabilities in Functional Concurrent Linear Regression](https://arxiv.org/abs/2602.13152v1) | Rupsa Basu, Sven Otto | 2026-02-13 | General AI | We develop methodology to detect structural breaks in the slope function of a concurrent functional linear regression model for functional time series in $C[0,1]$. Our test is based on a CUSUM process of regressor-weighted OLS residual functions. To accommodate both global and local changes, we propose $L^2$- and sup-norm versions, with the sup-norm particularly sensitive to spike-like changes. Under H√∂lder regularity and weak dependence conditions, we establish a functional strong invariance principle, derive the asymptotic null distribution, and show that the resulting tests are consistent against a broad class of alternatives with breaks in the slope function. Simulation studies illustrate finite-sample size and power. We apply the method to sports data obtained via body-worn sensors from running athletes, focusing on hip and knee joint-angle trajectories recorded during a fatiguing run. As fatigue accumulates, runners adapt their movement patterns, and sufficiently pronounced adjustments are expected to appear as a change point in the regression relationship. In this manner, we illustrate how the proposed tests support interpretable inference for biomechanical functional time series. | [üîó Paper](https://arxiv.org/abs/2602.13152v1) |
| [3-D Reconfigurable Intelligent Surface: From Reflection to Transmission and From Single Hemisphere to Full 3-D Coverage](https://arxiv.org/abs/2602.13150v1) | Ruiqi Wang, Yiming Yang, Atif Shamim | 2026-02-13 | General AI | Reconfigurable intelligent surfaces (RIS) are conventionally implemented as two-dimensional (2D) electromagnetic (EM) structures to steer incident waves toward desired reflection angles. This approach limits the reflection to a single hemisphere, and the beam-scanning range is relatively small. In this work, a novel three-dimensional (3D) RIS concept is proposed, where beam-scanning can be realized not only through reflection from the illuminated surface but also through controlled transmission toward adjacent surfaces, enabling near blind-spot-free coverage in the full 3D spatial domain. A cube-based 3D-RIS design operating at millimeter-wave (mm-Wave) frequencies and consisting of six interconnected RIS surfaces is presented. Each surface integrates reconfigurable receiving and reflecting arrays with orthogonal polarizations to ensure intrinsic EM isolation, while a reconfigurable feeding network supports dynamic operation. A subarray-based synthesis approach with binary amplitude gating and predefined phase offsets is developed through a unified theoretical model. This model, validated through full-wave simulations, enables efficient beam switching through a shared aperture. Based on this framework, an 8 x 12 element surface comprising six 4 x 4 subarrays is designed, with each surface covering an angular range from -30 deg to +30 deg. The experimental prototype has been characterized in the 24 to 30 GHz band, and the results demonstrate a gain enhancement of 14.7 dB for reflection, while 14.1 dB is achieved for transmission to the neighboring surface. Finally, wireless communication trials using the Pluto software-defined radio platform combined with frequency up/down converters confirm improved constellation quality and a 6-7 dB improvement in error vector magnitude (EVM) for both reflection and neighboring surface transmission scenarios. | [üîó Paper](https://arxiv.org/abs/2602.13150v1) |
| [Propagation processes on (hyper)graphs: where zero forcing and burning meet](https://arxiv.org/abs/2602.13149v1) | Aida Abiad, Pax Mallee | 2026-02-13 | General AI | The burning and forcing processes are both instances of propagation processes on graphs that are commonly used to model real-world spreading phenomena. The contribution of this paper is two-fold. We first establish a connection between these two propagation processes via hypergraphs. We do so by showing a sharp upper bound on the zero forcing number of the incidence graph of a hypergraph in terms of the lazy burning number of the hypergraph, which builds up on and improves a result by Bonato, Jones, Marbach, Mishura and Zhang (Theor. Comput. Sci., 2025). Secondly, we deepen the understanding of the role of the burning process in the context of graph spectral characterizations, whose goal is to understand which graph properties are encoded in the spectrum. While for several graph properties, including the zero forcing number, it is known that the spectrum does not encode them, this question remained open for the burning number. We solve this problem by constructing infinitely many pairs of cospectral graphs which have a different burning number. | [üîó Paper](https://arxiv.org/abs/2602.13149v1) |
| [TrustMee: Self-Verifying Remote Attestation Evidence](https://arxiv.org/abs/2602.13148v1) | Parsa Sadri Sinaki, Zainab Ahmad, Wentao Xie, Merlijn Sebrechts, Jimmy Kj√§llman, Lachlan J. Gunn | 2026-02-13 | General AI | Hardware-secured remote attestation is essential to establishing trust in the integrity of confidential virtual machines (cVMs), but is difficult to use in practice because verifying attestation evidence requires the use of hardware-specific cryptographic logic. This increases both maintenance costs and the verifiers' trusted computing base. We introduce the concept of self-verifying remote attestation evidence. Each attestation bundle includes verification logic as a WebAssembly component signed by a trusted party. This approach transforms evidence verification into a standard code-signing problem: the verifier checks the signature on the embedded logic and then executes it to validate the evidence. As a result, verifiers can validate attestation evidence without any platform-specific knowledge. We implement this concept as TrustMee, a platform-agnostic verification driver for the Trustee framework. We demonstrate its functionality with self-verifying evidence for AMD SEV-SNP and Intel TDX attestations, producing attestation claims in the standard EAT Attestation Result (EAR) format. | [üîó Paper](https://arxiv.org/abs/2602.13148v1) |
| [Non-chiral ephemeral edge states and cascading of exceptional points in the non-reciprocal Haldane model](https://arxiv.org/abs/2602.13147v1) | Aditi A. Prabhudesai, H. S. Chhabra, Suraj S. Hegde | 2026-02-13 | General AI | We study a variant of the Haldane honeycomb model that has non-reciprocal hoppings between the next-nearest neighbours. The system on a torus hosts time-reversal symmetry protected exceptional rings(ER) in the spectrum. The ERs act as Berry-curvature flux tubes i.e the Berry curvature is non-zero only inside the ERs. The system on a cylinder having zig-zag boundaries (and transverse momentum $k_x$) hosts edge-states that have zero group velocity at $k_x=œÄ$ and are therefore `non-chiral'. The edge states undergo a bifurcation transition at an exceptional point(EP)in the BZ and delocalise into the bulk. As the non-reciprocity is increased, the bulk states that are approaching each other are converted into pairs of EPs due to non-Hermiticity. As the non-reciprocity is further increased, there is a `Russian doll'-like nested proliferation of pairs of EPs, leading to an EP-cascade. The proliferation of EPs takes place only at specific values of the non-hermiticity parameter, leading to a step-like structure in the EP-pair density when plotted as a function of non-Hermiticity. Further, using wave packet dynamics, we find a tunable regime where the non-chiral edge states can be dynamically stabilised for large timescales. The `self-acceleration' term in the equations of motion tends to diffuse the wave packets into the bulk, thus making them `ephemeral edge states'. But we find that for small non-hermiticity, the edge localisation is stabilised until late times for sufficiently wider wave packets. Thus, we have brought forth an intriguing phenomenology of the exceptional phase of the non-reciprocal Haldane model, which may bear direct relevance for systems such as disordered Kitaev honeycomb model, wherein such ERs have been predicted. | [üîó Paper](https://arxiv.org/abs/2602.13147v1) |
| [Mean-Force Hamiltonians from Influence Functionals](https://arxiv.org/abs/2602.13146v1) | Gerard McCaul | 2026-02-13 | General AI | The Hamiltonian of mean force (HMF) provides the standard starting point for strong-coupling thermodynamics, yet explicit operator forms are known only in restricted settings. We present a quenched density framework that uses the Hubbard-Stratonovich transformation to rewrite the reduced equilibrium state as an average over local propagators in imaginary time. This approach rigorously separates the statistical definition of the environment from the algebraic structure of the system response. We apply this framework to the minimal case of a harmonic environment with a coupling commuting with the system Hamiltonian. In this scenario the correction to the HMF has an exact, closed-form expression. We validate this result against finite-bath trace-out calculations and stochastic imaginary-time sampling in a five-level projector-coupled model. | [üîó Paper](https://arxiv.org/abs/2602.13146v1) |
| [Single snapshot non-Markovianity of Pauli channels](https://arxiv.org/abs/2602.13145v1) | Alireza Seif, Moein Malekakhlagh, Swarnadeep Majumder Luke C. G. Govia | 2026-02-13 | General AI | Pauli channels are widely used to describe errors in quantum computers, particularly when noise is shaped via Pauli twirling. A common assumption is that such channels admit a Markovian generator, namely a Pauli-Lindblad model with non-negative rates, but the validity of this assumption has not been systematically examined. Here, using CP-indivisibility as our criterion for non-Markovianity, we study multi-qubit Pauli channels from a single snapshot of the dynamics. We find that while the generator always has the same structure as the standard Pauli-Lindblad model, the rates may be negative or complex. We show that random Pauli channels are almost always non-Markovian, with the probability of encountering a negative rate converging doubly exponentially to unity with the number of qubits. For physically motivated noise models shaped by Pauli twirling, including single-qubit over-rotations and two-qubit amplitude damping errors, we find that negative rates are generic, even when the underlying physical noise is Markovian. We generalize probabilistic error amplification and cancellation to non-Markovian generators, and quantify the sampling overhead introduced by negative and complex rates. Experiments on superconducting qubits confirm that allowing negative rates in the learned noise model yields more accurate predictions than restricting to non-negative rates. | [üîó Paper](https://arxiv.org/abs/2602.13145v1) |
| [The Only Distributive Law Over the Powerset Monad Is the One You Know](https://arxiv.org/abs/2602.13144v1) | Sergey Goncharov, Dirk Hofmann, Pedro Nora, Lutz Schr√∂der, Paul Wild | 2026-02-13 | General AI | Distributive laws of set functors over the powerset monad (also known as Kleisli laws for the powerset monad) are well-known to be in one-to-one correspondence with extensions of set functors to functors on the category of sets and relations. We study the question of existence and uniqueness of such distributive laws. Our main result entails that an accessible set functor admits a distributive law over the powerset monad if and only if it preserves weak pullbacks, in which case the so-called power law (which induces the Barr extension) is the unique one. Furthermore, we show that the powerset functor admits exactly three distributive laws over the powerset monad, revealing that uniqueness may fail for non-accessible functors. | [üîó Paper](https://arxiv.org/abs/2602.13144v1) |
