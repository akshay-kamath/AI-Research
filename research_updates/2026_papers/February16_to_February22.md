# üìå AI Research Papers (February16 to February22)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [SARAH: Spatially Aware Real-time Agentic Humans](https://arxiv.org/abs/2602.18432v1) | Evonne Ng, Siwei Zhang, Zhang Chen, Michael Zollhoefer, Alexander Richard | 2026-02-20 | LLM, Multimodal AI, RLHF | As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close this gap with the first real-time, fully causal method for spatially-aware conversational motion, deployable on a streaming VR headset. Given a user's position and dyadic audio, our approach produces full-body motion that aligns gestures with speech while orienting the agent according to the user. Our architecture combines a causal transformer-based VAE with interleaved latent tokens for streaming inference and a flow matching model conditioned on user trajectory and audio. To support varying gaze preferences, we introduce a gaze scoring mechanism with classifier-free guidance to decouple learning from control: the model captures natural spatial alignment from data, while users can adjust eye contact intensity at inference time. On the Embody 3D dataset, our method achieves state-of-the-art motion quality at over 300 FPS -- 3x faster than non-causal baselines -- while capturing the subtle spatial dynamics of natural conversation. We validate our approach on a live VR system, bringing spatially-aware conversational agents to real-time deployment. Please see https://evonneng.github.io/sarah/ for details. | [üîó Paper](https://arxiv.org/abs/2602.18432v1) |
| [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422v1) | Linxi Xie, Lisong C. Sun, Ashley Neall, Tong Wu, Shengqu Cai, Gordon Wetzstein | 2026-02-20 | LLM, Multimodal AI, Diffusion Models | Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines. | [üîó Paper](https://arxiv.org/abs/2602.18422v1) |
| [Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures](https://arxiv.org/abs/2602.18417v1) | Joshua Nunley | 2026-02-20 | LLM | This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments. | [üîó Paper](https://arxiv.org/abs/2602.18417v1) |
| [Exploiting Completeness Perception with Diffusion Transformer for Unified 3D MRI Synthesis](https://arxiv.org/abs/2602.18400v1) | Junkai Liu, Nay Aung, Theodoros N. Arvanitis, Joao A. C. Lima, Steffen E. Petersen, Daniel C. Alexander, Le Zhang | 2026-02-20 | LLM, Model Evaluation, Responsible AI, Diffusion Models | Missing data problems, such as missing modalities in multi-modal brain MRI and missing slices in cardiac MRI, pose significant challenges in clinical practice. Existing methods rely on external guidance to supply detailed missing state for instructing generative models to synthesize missing MRIs. However, manual indicators are not always available or reliable in real-world scenarios due to the unpredictable nature of clinical environments. Moreover, these explicit masks are not informative enough to provide guidance for improving semantic consistency. In this work, we argue that generative models should infer and recognize missing states in a self-perceptive manner, enabling them to better capture subtle anatomical and pathological variations. Towards this goal, we propose CoPeDiT, a general-purpose latent diffusion model equipped with completeness perception for unified synthesis of 3D MRIs. Specifically, we incorporate dedicated pretext tasks into our tokenizer, CoPeVAE, empowering it to learn completeness-aware discriminative prompts, and design MDiT3D, a specialized diffusion transformer architecture for 3D MRI synthesis, that effectively uses the learned prompts as guidance to enhance semantic consistency in 3D space. Comprehensive evaluations on three large-scale MRI datasets demonstrate that CoPeDiT significantly outperforms state-of-the-art methods, achieving superior robustness, generalizability, and flexibility. The code is available at https://github.com/JK-Liu7/CoPeDiT . | [üîó Paper](https://arxiv.org/abs/2602.18400v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning](https://arxiv.org/abs/2602.18428v1) | Mojtaba Sahraee-Ardakan, Mauricio Delbracio, Peyman Milanfar | 2026-02-20 | Diffusion Models | Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\text{marg}}(\mathbf{u}) = -\log p(\mathbf{u})$, where $p(\mathbf{u}) = \int p(\mathbf{u} t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift. | [üîó Paper](https://arxiv.org/abs/2602.18428v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Chandra Proper Motions and Milliarcsecond Astrometry of Nineteen Pulsars](https://arxiv.org/abs/2602.18436v1) | Jack T. Dinsmore, Roger W. Romani | 2026-02-20 | RLHF | We present X-ray proper motion (PM) measurements of 19 pulsars using new and archival data from the Chandra X-ray Observatory, including pulsar wind trails and X-ray filaments. Precise X-ray PMs are often limited by uncertainties in aligning observations to a common reference frame. Our analysis uses unresolved X-ray flux from stars in the Gaia catalog in addition to X-ray bright point sources for alignment, improving uncertainties. We obtain absolute positions referenced to Gaia with typical astrometric precision $\sim$10 mas and PM statistical uncertainties down to 1.3 mas yr$^{-1}$, the most precise X-ray PM achieved to date. With our improved frame alignment, PM accuracies are now limited by the pulsar flux in most cases. These results reveal a new X-ray filament and illuminate the wind nebula structures and origins of several of these pulsars. | [üîó Paper](https://arxiv.org/abs/2602.18436v1) |
| [AI-Wrapped: Participatory, Privacy-Preserving Measurement of Longitudinal LLM Use In-the-Wild](https://arxiv.org/abs/2602.18415v1) | Cathy Mengying Fang, Sheer Karny, Chayapatr Archiwaranguprok, Yasith Samaradivakara, Pat Pataranutaporn, Pattie Maes | 2026-02-20 | RLHF | Alignment research on large language models (LLMs) increasingly depends on understanding how these systems are used in everyday contexts. yet naturalistic interaction data is difficult to access due to privacy constraints and platform control. We present AI-Wrapped, a prototype workflow for collecting naturalistic LLM usage data while providing participants with an immediate ``wrapped''-style report on their usage statistics, top topics, and safety-relevant behavioral patterns. We report findings from an initial deployment with 82 U.S.-based adults across 48,495 conversations from their 2025 histories. Participants used LLMs for both instrumental and reflective purposes, including creative work, professional tasks, and emotional or existential themes. Some usage patterns were consistent with potential over-reliance or perfectionistic refinement, while heavier users showed comparatively more reflective exchanges than primarily transactional ones. Methodologically, even with zero data retention and PII removal, participants may remain hesitant to share chat data due to perceived privacy and judgment risks, underscoring the importance of trust, agency, and transparent design when building measurement infrastructure for alignment research. | [üîó Paper](https://arxiv.org/abs/2602.18415v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Participation Ratio as a Quantum Probe of Hierarchical Stickiness](https://arxiv.org/abs/2602.18412v1) | Ariel A. Galindo Duque, Miguel A. Prado Reynoso, Miguel Gonzalez, Jorge G. Hirsch | 2026-02-20 | Multimodal AI | We investigate how quantum localization encodes the hierarchical stickiness that governs transport in mixed classical phase spaces. Using the periodically driven kicked top, we show that the participation ratio (PR) of coherent states in the Floquet eigenbasis resolves the same layered structure that appears classically as a multimodal distribution of finite-time Lyapunov exponents (FTLEs). To establish a quantitative correspondence, we introduce a Gaussian coarse graining of the FTLE matched to the intrinsic semiclassical resolution of coherent states. Both local correlations and global comparisons of probability distributions demonstrate that quantum and classical indicators agree optimally within a finite window of evolution times, where sticky structures are most clearly resolved. Our results promote the participation ratio from a global measure of chaos to a sensitive probe of hierarchical transport and provide a practical route for diagnosing anomalous localization in driven quantum systems. | [üîó Paper](https://arxiv.org/abs/2602.18412v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429v1) | Harshul Raj Surana, Arijit Maji, Aryan Vats, Akash Ghosh, Sriparna Saha, Amit Sheth | 2026-02-20 | Optimization, LLM, Fine-Tuning, Prompt Engineering | Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models. | [üîó Paper](https://arxiv.org/abs/2602.18429v1) |
| [Polytopes of alternating sign matrices with dihedral-subgroup symmetry](https://arxiv.org/abs/2602.18427v1) | P√©ter Madarasi | 2026-02-20 | Optimization | We investigate the convex hulls of the eight dihedral symmetry classes of $n \times n$ alternating sign matrices, i.e., ASMs invariant under a subgroup of the symmetry group of the square. Extending the prefix-sum description of the ASM polytope, we develop a uniform core--assembly framework: each symmetry class is encoded by a set of core positions and an affine assembly map that reconstructs the full matrix from its core. This reduction transfers polyhedral questions to lower-dimensional core polytopes, which are better suited to the tool set of polyhedral combinatorics, while retaining complete information about the original symmetry class. For the vertical, vertical--horizontal, half-turn, diagonal, diagonal--antidiagonal, and total symmetry classes, we give explicit polynomial-size linear inequality descriptions of the associated polytopes. In these cases, we also determine the dimension and provide facet descriptions. The quarter-turn symmetry class behaves differently: the natural relaxation admits fractional vertices, and we need to extend the system with a structured family of parity-type Chv√°tal--Gomory inequalities to obtain the quarter-turn symmetric ASM polytope. Our framework leads to efficient algorithms for computing minimum-cost ASMs in each symmetry class and provides a direct link between the combinatorics of symmetric ASMs and tools from polyhedral combinatorics and combinatorial optimization. | [üîó Paper](https://arxiv.org/abs/2602.18427v1) |
| [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425v1) | Deniz Qian, Hung-Ting Chen, Eunsol Choi | 2026-02-20 | Optimization | Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario. | [üîó Paper](https://arxiv.org/abs/2602.18425v1) |
| [SPQ: An Ensemble Technique for Large Language Model Compression](https://arxiv.org/abs/2602.18420v1) | Jiamin Yao, Eren Gultepe | 2026-02-20 | Optimization, LLM, Training & Evaluation | This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/ | [üîó Paper](https://arxiv.org/abs/2602.18420v1) |
| [Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems](https://arxiv.org/abs/2602.18419v1) | Geri Skenderi, Lorenzo Buffoni, Francesco D'Amico, David Machado, Raffaele Marino, Matteo Negri, Federico Ricci-Tersenghi, Carlo Lucibello, Maria Chiara Angelini | 2026-02-20 | Optimization, Model Evaluation, Graph AI, Training & Evaluation | Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench. | [üîó Paper](https://arxiv.org/abs/2602.18419v1) |
| [Convex Block-Cholesky Approach to Risk-Constrained Low-thrust Trajectory Design under Operational Uncertainty](https://arxiv.org/abs/2602.18416v1) | Kenshiro Oguri, Gregory Lantoine | 2026-02-20 | Optimization, Responsible AI, Model Evaluation | Designing robust trajectories under uncertainties is an emerging technology that may represent a key paradigm shift in space mission design. As we pursue more ambitious scientific goals (e.g., multi-moon tours, missions with extensive components of autonomy), it becomes more crucial that missions are designed with navigation (Nav) processes in mind. The effect of Nav processes is statistical by nature, as they consist of orbit determination (OD) and flight-path control (FPC). Thus, this mission design paradigm calls for techniques that appropriately quantify statistical effects of Nav, evaluate associated risks, and design missions that ensure sufficiently low risk while minimizing a statistical performance metric; a common metric is Delta-V99: worst-case (99%-quantile) Delta-V expenditure including statistical FPC efforts. In response to the need, this paper develops an algorithm for risk-constrained trajectory optimization under operational uncertainties due to initial state dispersion, navigation error, maneuver execution error, and imperfect dynamics modeling. We formulate it as a nonlinear stochastic optimal control problem and develop a computationally tractable algorithm that combines optimal covariance steering and sequential convex programming (SCP). Specifically, the proposed algorithm takes a block-Cholesky approach for convex formulation of optimal covariance steering, and leverages a recent SCP algorithm, SCvx*, for reliable numerical convergence. We apply the developed algorithm to risk-constrained, statistical trajectory optimization for exploration of dwarf planet Ceres with a Mars gravity assist, and demonstrate the robustness of the statistically-optimal trajectory and FPC policies via nonlinear Monte Carlo simulation. | [üîó Paper](https://arxiv.org/abs/2602.18416v1) |
| [An algebraic theory of Lojasiewicz exponents](https://arxiv.org/abs/2602.18410v1) | Tai Huy Ha | 2026-02-20 | Optimization | We develop a unified algebraic and valuative theory of Lojasiewicz exponents for pairs of graded families and filtrations of ideals. Within this framework, local Lojasiewicz exponents, gradient exponents, and exponents at infinity are all realized as asymptotic containment thresholds between filtrations, governed by integral closure. This reformulation shows that Lojasiewicz exponents are fundamentally valuative optimization problems.   The central structural contribution of the paper is a finite-max principle. Under verifiable algebraic hypotheses, the a priori infinite valuative supremum bounding the Lojasiewicz exponent reduces to a finite maximum, and computes the Lojasiewicz exponent precisely. We identify two complementary mechanisms leading to this phenomenon: finite testing arising from normalized blowups and Noetherian Rees algebras, and attainment via compactness of normalized valuation spaces under linear boundedness assumptions.   This finite-max framework yields strong structural consequences. We prove rigidity results showing that common extremal valuations force equality of Lojasiewicz ratios, and we establish stratification and stability phenomena for Lojasiewicz exponents in families, including fractional linearity and wall-chamber behavior along natural one-parameter deformations.   The theory recovers and explains classical results in toric and Newton-polyhedral settings, particularly, for Newton nondegenete case, where the Lojasiewicz exponent is computed by finitely many toric divisorial valuations corresponding to facet data.   Finally, we illustrate why the hypotheses underlying the finite-max principle are essential, delineating the precise scope of the theory. | [üîó Paper](https://arxiv.org/abs/2602.18410v1) |
| [Modeling UAV-aided Roadside Cell-Free Networks with Mat√©rn Hard-Core Point Processes](https://arxiv.org/abs/2602.18408v1) | Chenrui Qiu, Yongxu Zhu, Bo Tan, George K. Karagiannidis, Tasos Dagiuklas | 2026-02-20 | Optimization | This paper investigates a uncrewed aerial vehicles (UAV)-assisted cell-free architecture for vehicular networks in road-constrained environments. Roads are modeled using a Poisson Line Process (PLP), with multi-layer roadside access points (APs) deployed via 1-D Poisson Point Process (PPP). Each user forms a localized cell-free cluster by associating with the nearest AP in each layer along its corresponding road. This forms a road-constrained cell-free architecture. To enhance coverage, UAV act as an aerial tier, extending access from 1-D road-constrained layouts (embedded in 2-D) to 3-D. We employ a Mat√©rn Hard-Core (MHC) point process to model the spatial distribution of UAV base stations, ensuring a minimum safety distance between them. In order to enable tractable analysis of the aggregate signal from multiple APs, a distance-based power control scheme is introduced. Leveraging tools from stochastic geometry, we have studied the coverage probability. Furthermore, we analyze the impact of key system parameters on coverage performance, providing useful insights into the deployment and optimization of UAV-assisted cell-free vehicular networks. | [üîó Paper](https://arxiv.org/abs/2602.18408v1) |
| [A Generalized Information Bottleneck Method: A Decision-Theoretic Perspective](https://arxiv.org/abs/2602.18405v1) | Akira Kamatsuka, Takahiro Yoshida | 2026-02-20 | Optimization, Training & Evaluation | The information bottleneck (IB) method seeks a compressed representation of data that preserves information relevant to a target variable for prediction while discarding irrelevant information from the original data. In its classical formulation, the IB method employs mutual information to evaluate the compression between the original and compressed data and the utility of the representation for the target variable. In this study, we investigate a generalized IB problem, where the evaluation of utility is based on the $\mathcal{H}$-mutual information that satisfies the concave (\texttt{CV}) and averaging (\texttt{AVG}) conditions. This class of information measures admits a statistical decision-theoretic interpretation via its equivalence to the expected value of sample information. Based on this interpretation, we derive an alternating optimization algorithm to assess the tradeoff between compression and utility in the generalized IB problem. | [üîó Paper](https://arxiv.org/abs/2602.18405v1) |
| [Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study](https://arxiv.org/abs/2602.18403v1) | Orfeas Bourchas, George Papalambrou | 2026-02-20 | Optimization | Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning. | [üîó Paper](https://arxiv.org/abs/2602.18403v1) |
| [Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO](https://arxiv.org/abs/2602.18386v1) | Mohamed Elgouhary, Amr S. El-Wakeel | 2026-02-20 | Optimization, RLHF | Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control. | [üîó Paper](https://arxiv.org/abs/2602.18386v1) |
| [FedZMG: Efficient Client-Side Optimization in Federated Learning](https://arxiv.org/abs/2602.18384v1) | Fotios Zantalis, Evangelos Zervas, Grigorios Koulouras | 2026-02-20 | Optimization, Responsible AI, Model Evaluation | Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings. | [üîó Paper](https://arxiv.org/abs/2602.18384v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434v1) | Vatsal Agarwal, Saksham Suri, Matthew Gwilliam, Pulkit Kumar, Abhinav Shrivastava | 2026-02-20 | Scaling Laws, Multimodal AI | Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B. | [üîó Paper](https://arxiv.org/abs/2602.18434v1) |
| [How Fast Can I Run My VLA? Demystifying VLA Inference Performance with VLA-Perf](https://arxiv.org/abs/2602.18397v1) | Wenqi Jiang, Jason Clemons, Karu Sankaralingam, Christos Kozyrakis | 2026-02-20 | Scaling Laws, Production and Deployment, Multimodal AI, Training & Evaluation | Vision-Language-Action (VLA) models have recently demonstrated impressive capabilities across various embodied AI tasks. While deploying VLA models on real-world robots imposes strict real-time inference constraints, the inference performance landscape of VLA remains poorly understood due to the large combinatorial space of model architectures and inference systems. In this paper, we ask a fundamental research question: How should we design future VLA models and systems to support real-time inference? To address this question, we first introduce VLA-Perf, an analytical performance model that can analyze inference performance for arbitrary combinations of VLA models and inference systems. Using VLA-Perf, we conduct the first systematic study of the VLA inference performance landscape. From a model-design perspective, we examine how inference performance is affected by model scaling, model architectural choices, long-context video inputs, asynchronous inference, and dual-system model pipelines. From the deployment perspective, we analyze where VLA inference should be executed -- on-device, on edge servers, or in the cloud -- and how hardware capability and network performance jointly determine end-to-end latency. By distilling 15 key takeaways from our comprehensive evaluation, we hope this work can provide practical guidance for the design of future VLA models and inference systems. | [üîó Paper](https://arxiv.org/abs/2602.18397v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424v1) | Xia Su, Ruiqi Chen, Benlin Liu, Jingwei Ma, Zonglin Di, Ranjay Krishna, Jon Froehlich | 2026-02-20 | Model Evaluation, Multimodal AI, Training & Evaluation | Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav | [üîó Paper](https://arxiv.org/abs/2602.18424v1) |
## üîπ AI Safety

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Pole-Expansion of the T-Matrix Based on a Matrix-Valued AAA-Algorithm](https://arxiv.org/abs/2602.18414v1) | Jan David Fischbach, Fridtjof Betz, Lukas Rebholz, Puneet Garg, Kristina Frizyuk, Felix Binkowski, Sven Burger, Martin Hammerschmidt, Carsten Rockstuhl | 2026-02-20 | AI Safety | The transition matrix (T-matrix) is a complete description of an object's linear scattering response. As such, it has found wide adoption for the theoretical and computational description of multiple-scattering phenomena. In its original form, the T-matrix describes the interaction of a scatterer with a monochromatic source. In practice, however, information about the T-matrix is usually needed in an extended spectral domain. To access the frequency-dispersion, one might naively sample T-matrices over a finely resolved set of discrete frequencies and store one T-matrix per frequency. This approach has multiple drawbacks: it is computationally expensive, requires excessive memory, and it disregards the physical origin of the spectral features, weakening physical interpretability. To overcome these major limitations, we leverage a pole-expansion technique to represent the T-matrix with arbitrary frequency resolution within a selected frequency domain via a set of resonant contributions. A matrix-valued variant of the recently established adaptive Antoulas-Anderson (AAA) algorithm for rational approximation enables us to compute the pole-expansion at minimal computational cost using only a small number of direct evaluations. We demonstrate the benefits of such a representation with examples ranging from semi-analytically accessible scatterers to quasi-dual bound states in the continuum. To allow the wider community to capitalize on these findings, we provide open-source tools to perform the presented pole-expansion of the T-matrix. | [üîó Paper](https://arxiv.org/abs/2602.18414v1) |
## üîπ Graph AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Unifying approach to uniform expressivity of graph neural networks](https://arxiv.org/abs/2602.18409v1) | Huan Luo, Jonni Virtema | 2026-02-20 | Graph AI | The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs. | [üîó Paper](https://arxiv.org/abs/2602.18409v1) |
## üîπ Ongoing Learning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges](https://arxiv.org/abs/2602.18406v1) | Minh Dinh, St√©phane Deny | 2026-02-20 | Ongoing Learning, Scaling Laws | Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets. | [üîó Paper](https://arxiv.org/abs/2602.18406v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Assigning Confidence: K-partition Ensembles](https://arxiv.org/abs/2602.18435v1) | Aggelos Semoglou, John Pavlopoulos | 2026-02-20 | Responsible AI, Model Evaluation | Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality. | [üîó Paper](https://arxiv.org/abs/2602.18435v1) |
| [PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing](https://arxiv.org/abs/2602.18396v1) | Ehsan Lari, Reza Arablouei, Stefan Werner | 2026-02-20 | Responsible AI, Model Evaluation | We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary's perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification. | [üîó Paper](https://arxiv.org/abs/2602.18396v1) |
| [Detection prospects of solar $g$-modes with LISA](https://arxiv.org/abs/2602.18385v1) | Aman Awasthi | 2026-02-20 | Responsible AI, Model Evaluation | The possibility of detecting solar oscillation modes using space-based gravitational-wave detectors has been investigated in the context of gravitational-wave interferometry, with Polnarev \cite{Polnarev:2009xf} demonstrating that low-frequency solar modes could, in principle, produce detectable signals in a LISA-type interferometer. Motivated by this work, I revisit the problem using current solar models, updated detector sensitivities, and improved theoretical and observational constraints on mode amplitudes. In this study, I compute the gravitational response of solar oscillation modes using standard solar models generated with \texttt{MESA}, and mode eigenfrequencies and eigenfunctions calculated with \texttt{GYRE}. I focus primarily on solar $g$ modes, evaluating their responses for degree $l=2$ and azimuthal orders $m=0$ and $m=2$. The analysis incorporates both the earlier proposed and the current updated LISA sensitivity curves, and I perform a comparative assessment with the TianQin mission in the relevant low-frequency band. To assess the robustness of the predicted signals, I estimate the gravitational responses using two different standard solar models based on the GS98 and AGSS09 abundance compilations. I find that the resulting signal responses are nearly identical for the two models, indicating that uncertainties in solar metallicity have a negligible impact on the detectability of solar $g$ modes by space-based interferometers. | [üîó Paper](https://arxiv.org/abs/2602.18385v1) |
## üîπ Fine-Tuning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394v1) | Stefan Becker, Simon Weiss, Wolfgang H√ºbner, Michael Arens | 2026-02-20 | Fine-Tuning, Prompt Engineering | Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.   We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.   To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.   Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation. | [üîó Paper](https://arxiv.org/abs/2602.18394v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Quenched path limits and periodization stability for tilted Brownian motion in Poissonian potentials on $\mathbb{H}^d$](https://arxiv.org/abs/2602.18433v1) | Miklos Abert, Adam Arras, Jaelin Kim | 2026-02-20 | General AI | We analyze the existence of Brownian motion tilted by a potential of full support on hyperbolic spaces $\mathbb{H}^d$. On compact spaces, it is classical that these path limits, called Q-processes, exist and can be directly defined using the ground state of the corresponding Schr√∂dinger operator. On non-compact spaces like $\mathbb{H}^d$, the existence fails in general.   We show that for \emph{stationary random} potentials on $\mathbb{H}^d$ with suitable spectral and sup norm bounds, the Q-processes exist a.s. For potentials that are factors of a Poisson point process, the method works up to sup norm $(d-1)^2/8$. In this case, we also show that the path limit can be approximated by periodic potentials.   As a tool, we use the foliated space defined by the point process. It turns out that the global ground state of this foliated space serves as a substitute for the non-existing $L^2$ ground states on the leaves of the foliation. Restricting the global ground state to a leaf gives a generalized eigenwave that can be plugged into the usual machinery to get the Q-process. | [üîó Paper](https://arxiv.org/abs/2602.18433v1) |
| [SMaRT: Online Reusable Resource Assignment and an Application to Mediation in the Kenyan Judiciary](https://arxiv.org/abs/2602.18431v1) | Shafkat Farabi, Didac Marti Pinto, Wei Lu, Manuel Ramos-Maqueda, Sanmay Das, Antoine Deeb, Anja Sautmann | 2026-02-20 | General AI | Motivated by the problem of assigning mediators to cases in the Kenyan judicial, we study an online resource allocation problem where incoming tasks (cases) must be immediately assigned to available, capacity-constrained resources (mediators). The resources differ in their quality, which may need to be learned. In addition, resources can only be assigned to a subset of tasks that overlaps to varying degrees with the subset of tasks other resources can be assigned to. The objective is to maximize task completion while satisfying soft capacity constraints across all the resources. The scale of the real-world problem poses substantial challenges, since there are over 2000 mediators and a multitude of combinations of geographic locations (87) and case types (12) that each mediator is qualified to work on. Together, these features, unknown quality of new resources, soft capacity constraints, and a high-dimensional state space, make existing scheduling and resource allocation algorithms either inapplicable or inefficient. We formalize the problem in a tractable manner using a quadratic program formulation for assignment and a multi-agent bandit-style framework for learning. We demonstrate the key properties and advantages of our new algorithm, SMaRT (Selecting Mediators that are Right for the Task), compared with baselines on stylized instances of the mediator allocation problem. We then consider its application to real-world data on cases and mediators from the Kenyan judiciary. SMaRT outperforms baselines and allows control over the tradeoff between the strictness of capacity constraints and overall case resolution rates, both in settings where mediator quality is known beforehand and in bandit-like settings where learning is part of the problem definition. On the strength of these results, we plan to run a randomized controlled trial with SMaRT in the judiciary in the near future. | [üîó Paper](https://arxiv.org/abs/2602.18431v1) |
| [Phase-field simulations of nucleation, growth, and coarsening of $Œ≤_1$ precipitates in Mg-Nd alloys](https://arxiv.org/abs/2602.18430v1) | Lingxia Shi, Stephen DeWitt, David Montiel, Qianying Shi, John Allison, Katsuyo Thornton | 2026-02-20 | General AI | The spatial distribution and morphology of precipitates formed during aging are key factors that determine the precipitation hardening response of various magnesium-rare earth alloys. In recent years, the use of high-performance computing clusters and massively parallel frameworks has enabled quantitative simulations of the evolution of individual and multiple precipitates at relevant length and time scales. However, predictive modeling of precipitate evolution remains challenging, in part because many key thermodynamic and kinetic parameters governing the underlying physics are either unknown or have a high degree of uncertainty. In this work, we developed a workflow in which experimental data were used to parameterize a phase-field model to perform two-dimensional (2D) simulations of concurrent nucleation and evolution of $Œ≤_1$ precipitates in magnesium-neodymium alloy during aging. Matrix composition and precipitate number density at different aging times were obtained from atom probe tomography and transmission electron microscopy measurements, respectively. We applied a stereological method to estimate the three-dimensional (3D) number densities from experimental cross-sectional transmission electron micrographs. The estimated 3D number density data were then converted to effective 2D number densities. The effective 2D number density and composition data were used to determine the required model parameters by minimizing the discrepancy between simulation and experimental results. The parameterized model allows for quantitative phase-field simulations of nucleation and growth of $Œ≤_1$ precipitates, which can be employed to optimize aging time to achieve a target number density of precipitates. This work highlights an approach to overcome the challenges associated with parameterizing a coupled phase-field and nucleation model. | [üîó Paper](https://arxiv.org/abs/2602.18430v1) |
| [Spatio-Spectroscopic Representation Learning using Unsupervised Convolutional Long-Short Term Memory Networks](https://arxiv.org/abs/2602.18426v1) | Kameswara Bharadwaj Mantha, Lucy Fortson, Ramanakumar Sankar, Claudia Scarlata, Chris Lintott, Sandor Kruk, Mike Walmsley, Hugh Dickinson, Karen Masters, Brooke Simmons, Rebecca Smethurst | 2026-02-20 | General AI | Integral Field Spectroscopy (IFS) surveys offer a unique new landscape in which to learn in both spatial and spectroscopic dimensions and could help uncover previously unknown insights into galaxy evolution. In this work, we demonstrate a new unsupervised deep learning framework using Convolutional Long-Short Term Memory Network Autoencoders to encode generalized feature representations across both spatial and spectroscopic dimensions spanning $19$ optical emission lines (3800A $< Œª<$ 8000A) among a sample of $\sim 9000$ galaxies from the MaNGA IFS survey. As a demonstrative exercise, we assess our model on a sample of $290$ Active Galactic Nuclei (AGN) and highlight scientifically interesting characteristics of some highly anomalous AGN. | [üîó Paper](https://arxiv.org/abs/2602.18426v1) |
| [Leading singularities of Wilson loop correlators from twistor Wilson loop diagrams](https://arxiv.org/abs/2602.18423v1) | James Drummond, Matthew Rochford, Rowan Wright | 2026-02-20 | General AI | The leading singularities of one-loop scattering amplitudes in planar $\mathcal{N}=4$ super Yang-Mills theory are known to factorise into products of tree-level amplitudes, and this can be seen from a number of different perspectives e.g. generalised unitarity or on-shell diagrams. Here we investigate the leading singularities from the perspective of the Wilson loop expectation values to which these amplitudes are dual, in particular making use of the twistor Wilson loop formalism. We show that the factorisation of one-loop leading singularities of a null Wilson loop's expectation value into a product of tree-level objects is manifest at the level of twistor Wilson loop diagrams, and is a simple consequence of planarity, without appeal to e.g. unitarity on the amplitude side of the duality. We then use the same approach to derive compact formulae for the one-loop leading singularities of correlators of multiple light-like Wilson loop operators in terms of tree-level objects. Via the chiral box expansion, these formulae provide a simple route to writing down the $O(g^2)$ correlation function of any number of Wilson loops at any MHV degree. | [üîó Paper](https://arxiv.org/abs/2602.18423v1) |
| [Snapping Actuators with Asymmetric and Sequenced Motion](https://arxiv.org/abs/2602.18421v1) | Xin Li, Ye Jin, Mohsen Jafarpour, Hugo de Souza Oliveira, Edoardo Milana | 2026-02-20 | General AI | Snapping instabilities in soft structures offer a powerful pathway to achieve rapid and energy-efficient actuation. In this study, an eccentric dome-shaped snapping actuator is developed to generate controllable asymmetric motion through geometry-induced instability. Finite element simulations and experiments reveal consistent asymmetric deformation and the corresponding pressure characteristics. By coupling four snapping actuators in a pneumatic network, a compact quadrupedal robot achieves coordinated wavelike locomotion using only a single pressure input. The robot exhibits frequency-dependent performance with a maximum speed of 72.78~mm/s at 7.5~Hz. These findings demonstrate the potential of asymmetric snapping mechanisms for physically controlled actuation and lay the groundwork for fully untethered and efficient soft robotic systems. | [üîó Paper](https://arxiv.org/abs/2602.18421v1) |
| [Reconfigurable Geometric Phase Matching by Multilayered Nonlinear Thin-Film Crystals](https://arxiv.org/abs/2602.18418v1) | Danielle Ben-Haim, Mai Tal, Xiaoxi Xu, Tal Ellenbogen | 2026-02-20 | General AI | Phase matching is essential for efficient energy transfer in nonlinear wave-mixing processes. Traditional methods, such as birefringent and quasi-phase matching, have remained conceptually unchanged since their discovery over 60 years ago, each posing inherent constraints and limitations. Here, we demonstrate the concept of geometric phase matching as a new paradigm for tunable nonlinear wave mixing, based on a multilayered platform of nonlinear thin-film crystals. We leverage this concept to experimentally show reconfigurable and spin-controlled phase matching for second-harmonic generation (SHG), opening new avenues for real-time manipulation of nonlinear interactions in photonic devices. We specifically demonstrate full modulation of SHG from a bilayer structure, nearly perfect and tunable geometric phase matching from an eight-layer structure, and polarization tomography that reveals the evolution of the spin dependent interaction. This approach not only expands the design space for nonlinear optical processes but also paves the way for highly robust, tunable and efficient frequency conversion, for next-generation adaptive nonlinear photonic, quantum photonic and nonlinear optical metamaterial technologies based on thin-film crystals. | [üîó Paper](https://arxiv.org/abs/2602.18418v1) |
| [Weak approximation of kinetic SDEs: closing the criticality gap](https://arxiv.org/abs/2602.18411v1) | Zimo Hao, Khoa L√™, Chengcheng Ling | 2026-02-20 | General AI | We study the weak convergence of a generic tamed Euler-Maruyama scheme for kinetic stochastic differential equations (SDEs) with integrable drifts. We show that the marginal density of the considered scheme converges at rate 1/2 to the corresponding marginal density of the SDE. The convergence rate is independent from the criticality gap, which is new compared to previous results. | [üîó Paper](https://arxiv.org/abs/2602.18411v1) |
| [Reconstruction algorithms for the fractional Laplacian and applications to inverse problems](https://arxiv.org/abs/2602.18407v1) | Ethan Rinaldo, Mahamadi Warma | 2026-02-20 | General AI | We introduce two reconstruction schemes that enable the recovery of a function in the entire Euclidean space $\mathbb{R}^n$ from local data $(u _W, [(-Œî)^s u] _W)$, where $W$ is an arbitrarily small nonempty open subset of $\mathbb R^n$ and $(-Œî)^s$ denotes the fractional Laplace operator of order $s\in (0,1)$. These procedures rely crucially on the weak Unique Continuation Property (UCP) for the fractional Laplacian. We apply these schemes to two distinct inverse problems. Following the seminal work from Ghosh et al., the first one concerns the recovery of a potential (Calder√≥n-type problem) from the fractional Schr√∂dinger equation under nonlocal Robin-type exterior conditions. The second one involves recovering the solution of the space-fractional heat equation in $\mathbb{R}^n$ from localized time-dependent measurements within a ball. To tackle these problems, we introduce new analytical tools such as a generalized weak Kelvin transform and a fractional Robin-to-Robin map. Finally, we provide numerical simulations for one of the reconstruction methods, illustrating the stability issues and the severe ill-posedness inherent to such inverse problems. | [üîó Paper](https://arxiv.org/abs/2602.18407v1) |
| [Well-posedness and time stepping adaptivity for a class of collocation discretisations of time-fractional subdiffusion equations](https://arxiv.org/abs/2602.18404v1) | Sebastian Franz, Natalia Kopteva | 2026-02-20 | General AI | Time-fractional parabolic equations with a Caputo time derivative of order $Œ±\in(0,1)$ are discretised in time using collocation methods, which assume that the Caputo derivative of the computed solution is piecewise-polynomial. For such discretisations of any order $m\ge 0$, with any choice of collocation points, we give sufficient conditions for existence and uniqueness of collocation solutions. Furthermore, we investigate the applicability and performance of such schemes in the context of the a-posteriori error estimation and adaptive time stepping algorithms. | [üîó Paper](https://arxiv.org/abs/2602.18404v1) |
| [Domination and packing in graphs](https://arxiv.org/abs/2602.18402v1) | √Åkos D√∫cz, Anna Gujgiczer | 2026-02-20 | General AI | The dominating number $Œ≥(G)$ of a graph $G$ is the minimum size of a vertex set whose closed neighborhoods cover all vertices of $G$, while the packing number $œÅ(G)$ is the maximum size of a vertex set whose closed neighborhoods are pairwise disjoint. In this paper we investigate graph classes $\mathcal{G}$ for which the ratio $Œ≥(G)/œÅ(G)$ is bounded by a constant $c_{\mathcal{G}}$ for every $G \in \mathcal{G}$. Our main result is an improved upper bound on this ratio for planar graphs. We also extend the list of graph classes admitting a bounded ratio by showing this for chordal bipartite graphs and for homogeneously orderable graphs. In addition, we provide a simple, direct proof for trees. | [üîó Paper](https://arxiv.org/abs/2602.18402v1) |
| [Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay](https://arxiv.org/abs/2602.18401v1) | Josue Casco-Rodriguez, Nanda H. Krishna, Richard G. Baraniuk | 2026-02-20 | General AI | Biological neural networks (like the hippocampus) can internally generate "replay" resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity. | [üîó Paper](https://arxiv.org/abs/2602.18401v1) |
| [Overlap locking and non-perturbative effects in spin glasses](https://arxiv.org/abs/2602.18399v1) | Silvio Franz, Giorgio Parisi, Federico Ricci-Tersenghi | 2026-02-20 | General AI | We study the phenomenon of the locking of the order parameter (or synchronization) in spin glasses at low temperatures. When two systems with independent disorders are coupled, their overlaps become similar. A crucial question is how this effect depends on the strength of the coupling between the two systems. Non-perturbative phenomena are present when $1 \ll ŒîH \ll N$, being $ŒîH$ the coupling Hamiltonian and $N$ the size of the system. In this intermediate-coupling region, the effect is related to finite-size free-energy corrections and to the correlations in the Dyson hierarchical spin glass, a model that mimics the physics of finite-dimensional systems. We study this phenomenon in the mean-field approach, both analytically and numerically, and we finally compute the critical exponents for finite-volume corrections in mean-field theory and for the decay of correlations in the Dyson hierarchical model. | [üîó Paper](https://arxiv.org/abs/2602.18399v1) |
| [A Jump in the Codegree Tur√°n Densities of Long Tight Cycles](https://arxiv.org/abs/2602.18398v1) | J√≥zsef Balogh, Haoran Luo, Maya Sankar | 2026-02-20 | General AI | We study the codegree Tur√°n density of $\mathcal{C}_\ell^r$, the $r$-uniform hypergraph tight cycle of length $\ell$. A result of Han, Lo, and Sanhueza-Matamala states that if $\ell$ is sufficiently large and $r/\gcd(r,\ell)$ is even, then the codegree Tur√°n density of $\mathcal{C}_\ell^r$ is $1/2$. We prove that whenever the latter assumption is not satisfied, there is a significant drop in the codegree Tur√°n density. That is, if $\ell$ is sufficiently large and $r/\gcd(r,\ell)$ is odd, then the codegree Tur√°n density of $\mathcal{C}_\ell^r$ can be at most $1/3$. Moreover, this bound is tight for infinitely many uniformities $r$ and all sufficiently large $\ell$ in the corresponding residue classes modulo $r$. Our proof makes use of a group-theoretic connection between Tur√°n-type theorems for tight cycles and ``oriented colorings'' of the edge set of a hypergraph. | [üîó Paper](https://arxiv.org/abs/2602.18398v1) |
| [Cartography of LNV dim-9 SMEFT: Implications for Radiative Neutrino Masses and $0ŒΩŒ≤Œ≤$](https://arxiv.org/abs/2602.18395v1) | Fabian Esser, Luk√°≈° Gr√°f, Chandan Hati | 2026-02-20 | General AI | We perform a systematic study of lepton-number-violating (LNV) dimension-9 operators in the Standard Model Effective Field Theory (SMEFT) that can mediate neutrinoless double beta decay ($0ŒΩŒ≤Œ≤$) at tree level, and map them to their possible tree-level ultraviolet completions. Using a diagram-based classification, we enumerate all such completions and isolate minimal two-particle models that avoid generating the dimension-5 Weinberg operator or dimension-7 LNV operators at tree level. We then chart how these minimal models populate the operator landscape and organise them by the loop order at which they radiatively induce lower-dimensional LNV operators, highlighting scenarios in which the tree-level dimension-9 contribution can compete with or dominate loop-suppressed neutrino-mass (dimension-5) effects. Representative one-loop and two-loop classes are matched onto the SMEFT, and their implications for neutrino masses, charged-lepton flavour violation, and the relative size of dimension-9 versus dimension-5 contributions to $0ŒΩŒ≤Œ≤$ are analysed, delineating regions of parameter space where upcoming experiments can be sensitive to genuinely short-range LNV dynamics. | [üîó Paper](https://arxiv.org/abs/2602.18395v1) |
| [Two-over-Two Lattice Flavor from a Single Flavon with Three Messenger Chains](https://arxiv.org/abs/2602.18393v1) | Vernon Barger | 2026-02-20 | General AI | Flavor hierarchies are organized by a single parameter $B\simeq 5.357$ in a single-flavon Froggatt--Nielsen (FN) framework, in which each effective Yukawa entry arises from the sum of \emph{three} unit-magnitude messenger chains. We present benchmark complex $O(1)$ Yukawa matrices that reproduce quark and charged-lepton masses at $M_Z$ as powers of $Œµ\equiv 1/B$. The organizing principle is a two-over-two (2/2) lattice of quadrilateral mass ratios, which maps directly to a rational lattice of FN exponents. Sequential dominance preserves the leading-power exponent matrices, while subleading messenger chains generate entry-dependent complex $O(1)$ coefficients and provide a UV-friendly origin for CP violation. Neutrino masses are discussed at the level of eigenvalues within the same $B^n$ counting. | [üîó Paper](https://arxiv.org/abs/2602.18393v1) |
| [The coherent-state transformation in quantum electrodynamics coupled cluster theory](https://arxiv.org/abs/2602.18391v1) | Eric W. Fischer | 2026-02-20 | General AI | We analyse the coherent-state (CS) transformation in quantum electrodynamics coupled cluster (QED-CC) theory from the perspective of its non-vanishing commutator with the polaritonic cluster operator. Specifically, we show that a QED Hartree-Fock (QED-HF) reference state parametrized by the CS-transformation leads to a QED-CC Lagrangian formally determined by CS-representations of polaritonic Hamiltonian, polaritonic cluster and polaritonic deexcitation operators. This observation augments the original formulation of QED-CC theory where the CS-representation is restricted to the polaritonic Hamiltonian. We consequently find a renormalization of both QED-CC correlation energy and QED-CC ground state induced by the CS-transformation, which depends on the mean-field expectation value of the molecular dipole operator and therefore breaks origin invariance for charged systems. Electronic contributions to correlation energy and QED-CC ground state are renormalized by CS-transformed mixed excitation and deexcitation operators. In contrast, the CS-transformed single-photon excitation affects only the QED-CC ground state but not directly the correlation energy. The fully CS-transformed QED-CC ansatz is well approximated by the original QED-CC formulation for large cavity frequencies leading to small renormalization corrections. However, it exhibits a divergent zero-frequency limit absent in the original QED-CC ansatz for molecules with a non-vanishing molecular dipole moment in agreement with the asymptotic behaviour of the CS-parametrized QED-HF reference state. | [üîó Paper](https://arxiv.org/abs/2602.18391v1) |
| [Dichotomy for Axiomatising Inclusion Dependencies on K-Databases](https://arxiv.org/abs/2602.18390v1) | Miika Hannula, Teymur Ismikhanov, Jonni Virtema | 2026-02-20 | General AI | A relation consisting of tuples annotated by an element of a monoid K is called a K-relation. A K-database is a collection of K-relations. In this paper, we study entailment of inclusion dependencies over K-databases, where K is a positive commutative monoid. We establish a dichotomy regarding the axiomatisation of the entailment of inclusion dependencies over K-databases, based on whether the monoid K is weakly absorptive or weakly cancellative. We establish that, if the monoid is weakly cancellative then the standard axioms of inclusion dependencies are sound and complete for the implication problem. If the monoid is not weakly cancellative, it is weakly absorptive and the standard axioms of inclusion dependencies together with the weak symmetry axiom are sound and complete for the implication problem. In addition, we establish that the so-called balance axiom is further required, if one stipulates that the joint weights of each K-relation of a K-database need to be the same; this generalises the notion of a K-relation being a distribution. In conjunction with the balance axiom, weak symmetry axiom boils down to symmetry. | [üîó Paper](https://arxiv.org/abs/2602.18390v1) |
| [Improved Algorithms for Clustering with Noisy Distance Oracles](https://arxiv.org/abs/2602.18389v1) | Pinki Pradhan, Anup Bhattacharya, Ragesh Jaiswal | 2026-02-20 | General AI | Bateni et al. has recently introduced the weak-strong distance oracle model to study clustering problems in settings with limited distance information. Given query access to the strong-oracle and weak-oracle in the weak-strong oracle model, the authors design approximation algorithms for $k$-means and $k$-center clustering problems. In this work, we design algorithms with improved guarantees for $k$-means and $k$-center clustering problems in the weak-strong oracle model. The $k$-means++ algorithm is routinely used to solve $k$-means in settings where complete distance information is available. One of the main contributions of this work is to show that $k$-means++ algorithm can be adapted to work in the weak-strong oracle model using only a small number of strong-oracle queries, which is the critical resource in this model. In particular, our $k$-means++ based algorithm gives a constant approximation for $k$-means and uses $O(k^2 \log^2{n})$ strong-oracle queries. This improves on the algorithm of Bateni et al. that uses $O(k^2 \log^4n \log^2 \log n)$ strong-oracle queries for a constant factor approximation of $k$-means. For the $k$-center problem, we give a simple ball-carving based $6(1 + Œµ)$-approximation algorithm that uses $O(k^3 \log^2{n} \log{\frac{\log{n}}Œµ})$ strong-oracle queries. This is an improvement over the $14(1 + Œµ)$-approximation algorithm of Bateni et al. that uses $O(k^2 \log^4{n} \log^2{\frac{\log{n}}Œµ})$ strong-oracle queries. To show the effectiveness of our algorithms, we perform empirical evaluations on real-world datasets and show that our algorithms significantly outperform the algorithms of Bateni et al. | [üîó Paper](https://arxiv.org/abs/2602.18389v1) |
| [Limiting Absorption Principle and Radiation Condition for the Fractional Helmholtz Equation](https://arxiv.org/abs/2602.18387v1) | Dana Zilberberg, Fioralba Cakoni, Michael S. Vogelius | 2026-02-20 | General AI | We investigate elliptic fractional equations in the whole space, involving zero order perturbations of the fractional Laplacian $(-Œî)^s$, $0<s<1$. Our main objective is to determine appropriate radiation conditions at infinity that ensure existence and uniqueness of solutions to the fractional type Helmholtz equation. Extending classical scattering theory for the Helmholtz equation, we introduce and analyze suitable Sommerfeld type radiation conditions for fractional orders. A central contribution is the explicit computation of the outgoing free space Greens function for the operator $(-Œî)^s-k^{2s}$, for all $0<s<1$, any dimension and $k>0$, obtained via contour integration and a limiting absorption principle. We show that its asymptotic behavior at infinity coincides with a rescaled version of the classical Helmholtz fundamental solution, thereby justifying the standard Sommerfeld radiation condition for compactly supported sources. In addition, using resolvent estimates and a limiting absorption framework, we establish existence and uniqueness of outgoing solutions for compactly supported data, and for weighted sources. We further derive a convolution representation of the solution in terms of the outgoing fundamental solution. For inhomogeneous media with compactly supported perturbations, we reformulate the problem as a Lippmann Schwinger integral equation of Fredholm type and prove unique solvability away from a discrete set of frequencies. Our analysis provides a rigorous foundation for scattering theory of fractional Helmholtz operators and offers a framework suitable for numerical implementation of these nonlocal wave propagation models. | [üîó Paper](https://arxiv.org/abs/2602.18387v1) |
