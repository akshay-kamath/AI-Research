#  AI Research Papers (January05 to January11)

##  LLM

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/abs/2601.06016v1) | 贸r Sverrisson, Steinn Gu冒mundsson | 2026-01-09 | LLM, Training & Evaluation | Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions. | [ Paper](https://arxiv.org/abs/2601.06016v1) |
| [Don't Break the Cache: An Evaluation of Prompt Caching for Long-Horizon Agentic Tasks](https://arxiv.org/abs/2601.06007v1) | Elias Lumer, Faheem Nizar, Akshaya Jangiti, Kevin Frank, Anmol Gulati, Mandar Phadate, Vamse Kumar Subbiah | 2026-01-09 | LLM, Production and Deployment, Training & Evaluation, Prompt Engineering | Recent advancements in Large Language Model (LLM) agents have enabled complex multi-turn agentic tasks requiring extensive tool calling, where conversations can span dozens of API calls with increasingly large context windows. However, although major LLM providers offer prompt caching to reduce cost and latency, its benefits for agentic workloads remain underexplored in the research literature. To our knowledge, no prior work quantifies these cost savings or compares caching strategies for multi-turn agentic tasks. We present a comprehensive evaluation of prompt caching across three major LLM providers (OpenAI, Anthropic, and Google) and compare three caching strategies, including full context caching, system prompt only caching, and caching that excludes dynamic tool results. We evaluate on DeepResearchBench, a multi-turn agentic benchmark where agents autonomously execute real-world web search tool calls to answer complex research questions, measuring both API cost and time to first token (TTFT) across over 500 agent sessions with 10,000-token system prompts. Our results demonstrate that prompt caching reduces API costs by 45-80% and improves time to first token by 13-31% across providers. We find that strategic prompt cache block control, such as placing dynamic content at the end of the system prompt, avoiding dynamic traditional function calling, and excluding dynamic tool results, provides more consistent benefits than naive full-context caching, which can paradoxically increase latency. Our analysis reveals nuanced variations in caching behavior across providers, and we provide practical guidance for implementing prompt caching in production agentic systems. | [ Paper](https://arxiv.org/abs/2601.06007v1) |
| [CyberGFM: Graph Foundation Models for Lateral Movement Detection in Enterprise Networks](https://arxiv.org/abs/2601.05988v1) | Isaiah J. King, Bernardo Trindade, Benjamin Bowman, H. Howie Huang | 2026-01-09 | LLM, Graph AI | Representing networks as a graph and training a link prediction model using benign connections is an effective method of anomaly-based intrusion detection. Existing works using this technique have shown great success using temporal graph neural networks and skip-gram-based approaches on random walks. However, random walk-based approaches are unable to incorporate rich edge data, while the GNN-based approaches require large amounts of memory to train. In this work, we propose extending the original insight from random walk-based skip-grams--that random walks through a graph are analogous to sentences in a corpus--to the more modern transformer-based foundation models. Using language models that take advantage of GPU optimizations, we can quickly train a graph foundation model to predict missing tokens in random walks through a network of computers. The graph foundation model is then finetuned for link prediction and used as a network anomaly detector. This new approach allows us to combine the efficiency of random walk-based methods and the rich semantic representation of deep learning methods. This system, which we call CyberGFM, achieved state-of-the-art results on three widely used network anomaly detection datasets, delivering a up to 2$\times$ improvement in average precision. We found that CyberGFM outperforms all prior works in unsupervised link prediction for network anomaly detection, using the same number of parameters, and with equal or better efficiency than the previous best approaches. | [ Paper](https://arxiv.org/abs/2601.05988v1) |
| [DeePM: Regime-Robust Deep Learning for Systematic Macro Portfolio Management](https://arxiv.org/abs/2601.05975v1) | Kieran Wood, Stephen J. Roberts, Stefan Zohren | 2026-01-09 | LLM, Optimization | We propose DeePM (Deep Portfolio Manager), a structured deep-learning macro portfolio manager trained end-to-end to maximize a robust, risk-adjusted utility. DeePM addresses three fundamental challenges in financial learning: (1) it resolves the asynchronous "ragged filtration" problem via a Directed Delay (Causal Sieve) mechanism that prioritizes causal impulse-response learning over information freshness; (2) it combats low signal-to-noise ratios via a Macroeconomic Graph Prior, regularizing cross-asset dependence according to economic first principles; and (3) it optimizes a distributionally robust objective where a smooth worst-window penalty serves as a differentiable proxy for Entropic Value-at-Risk (EVaR) - a window-robust utility encouraging strong performance in the most adverse historical subperiods. In large-scale backtests from 2010-2025 on 50 diversified futures with highly realistic transaction costs, DeePM attains net risk-adjusted returns that are roughly twice those of classical trend-following strategies and passive benchmarks, solely using daily closing prices. Furthermore, DeePM improves upon the state-of-the-art Momentum Transformer architecture by roughly fifty percent. The model demonstrates structural resilience across the 2010s "CTA (Commodity Trading Advisor) Winter" and the post-2020 volatility regime shift, maintaining consistent performance through the pandemic, inflation shocks, and the subsequent higher-for-longer environment. Ablation studies confirm that strictly lagged cross-sectional attention, graph prior, principled treatment of transaction costs, and robust minimax optimization are the primary drivers of this generalization capability. | [ Paper](https://arxiv.org/abs/2601.05975v1) |
##  Diffusion Models

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Detecting Stochasticity in Discrete Signals via Nonparametric Excursion Theorem](https://arxiv.org/abs/2601.06009v1) | Sunia Tanweer, Firas A. Khasawneh | 2026-01-09 | Diffusion Models, Scaling Laws | We develop a practical framework for distinguishing diffusive stochastic processes from deterministic signals using only a single discrete time series. Our approach is based on classical excursion and crossing theorems for continuous semimartingales, which correlates number $N_\varepsilon$ of excursions of magnitude at least $\varepsilon$ with the quadratic variation $[X]_T$ of the process. The scaling law holds universally for all continuous semimartingales with finite quadratic variation, including general Ito diffusions with nonlinear or state-dependent volatility, but fails sharply for deterministic systems -- thereby providing a theoretically-certfied method of distinguishing between these dynamics, as opposed to the subjective entropy or recurrence based state of the art methods. We construct a robust data-driven diffusion test. The method compares the empirical excursion counts against the theoretical expectation. The resulting ratio $K(\varepsilon)=N_{\varepsilon}^{\mathrm{emp}}/N_{\varepsilon}^{\mathrm{theory}}$ is then summarized by a log-log slope deviation measuring the $\varepsilon^{-2}$ law that provides a classification into diffusion-like or not. We demonstrate the method on canonical stochastic systems, some periodic and chaotic maps and systems with additive white noise, as well as the stochastic Duffing system. The approach is nonparametric, model-free, and relies only on the universal small-scale structure of continuous semimartingales. | [ Paper](https://arxiv.org/abs/2601.06009v1) |
##  RLHF

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs](https://arxiv.org/abs/2601.06022v1) | Chengming Cui, Tianxin Wei, Ziyi Chen, Ruizhong Qiu, Zhichen Zeng, Zhining Liu, Xuying Ning, Duo Zhou, Jingrui He | 2026-01-09 | RLHF, Scaling Laws | Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse. | [ Paper](https://arxiv.org/abs/2601.06022v1) |
| [Categorical Foundations for CuTe Layouts](https://arxiv.org/abs/2601.05972v1) | Jack Carlisle, Jay Shah, Reuben Stern, Paul VanKoughnett | 2026-01-09 | RLHF | NVIDIA's CUTLASS library provides a robust and expressive set of methods for describing and manipulating multi-dimensional tensor data on the GPU. These methods are conceptually grounded in the abstract notion of a CuTe layout and a rich algebra of such layouts, including operations such as composition, logical product, and logical division. In this paper, we present a categorical framework for understanding this layout algebra by focusing on a naturally occurring class of tractable layouts. To this end, we define two categories Tuple and Nest whose morphisms give rise to layouts. We define a suite of operations on morphisms in these categories and prove their compatibility with the corresponding layout operations. Moreover, we give a complete characterization of the layouts which arise from our construction. Finally, we provide a Python implementation of our categorical constructions, along with tests that demonstrate alignment with CUTLASS behavior. This implementation can be found at our git repository https://github.com/ColfaxResearch/layout-categories. | [ Paper](https://arxiv.org/abs/2601.05972v1) |
##  Multimodal AI

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Open-Vocabulary 3D Instruction Ambiguity Detection](https://arxiv.org/abs/2601.05991v1) | Jiayu Ding, Haoran Tang, Ge Li | 2026-01-09 | Multimodal AI | In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like "Pass me the vial" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/. | [ Paper](https://arxiv.org/abs/2601.05991v1) |
##  Optimization

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.06002v1) | Qiguang Chen, Yantao Du, Ziniu Li, Jinhao Liu, Songyao Duan, Jiarui Guo, Minghao Liu, Jiaheng Liu, Tong Yang, Ge Zhang, Libo Qin, Wanxiang Che, Wenhao Huang | 2026-01-09 | Optimization, Prompt Engineering | Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks. | [ Paper](https://arxiv.org/abs/2601.06002v1) |
| [Terahertz metasurface sensor with graphene microstrips for biosensing: modeling and application](https://arxiv.org/abs/2601.05990v1) | K. S. Kuznetsova, V. A. Pashynska, Z. E. Eremenko | 2026-01-09 | Optimization | The study is devoted to development and optimization of a metasurface-based sensor with graphene constituents for potential biosensing applications. A unit cell of the proposed metasurface consists of a thin flexible dielectric substrate layer with a centrally positioned graphene microstrip. As a result of numerical modeling of spectral properties of the metasurface by COMSOL Multiphysics software in terahertz range from 5 to 35 THz the absorption spectrum maxima (resonance modes) are revealed. The following stages of the study demonstrate that placement of a layer of tested liquid sample (water or Bovine Serum Albumin (BSA) solution) on the metasurface causes a low frequency shift of the plasmonic resonance mode chosen for biosensing measurements. This frequency shift, along with the change in the amplitude of the absorption peak, are highly sensitive to the refractive index of the tested liquid sample. The obtained results demonstrate the potential of the developed metasurface-based sensor with graphene microstrips for application as a sensing structure to determine proteins and other biomolecules in liquid samples. | [ Paper](https://arxiv.org/abs/2601.05990v1) |
| [Community-Based Model Sharing and Generalisation: Anomaly Detection in IoT Temperature Sensor Networks](https://arxiv.org/abs/2601.05984v1) | Sahibzada Saadoon Hammad, Joaqu铆n Huerta Guijarro, Francisco Ramos, Michael Gould Carlson, Sergio Trilles Oliver | 2026-01-09 | Optimization | The rapid deployment of Internet of Things (IoT) devices has led to large-scale sensor networks that monitor environmental and urban phenomena in real time. Communities of Interest (CoIs) provide a promising paradigm for organising heterogeneous IoT sensor networks by grouping devices with similar operational and environmental characteristics. This work presents an anomaly detection framework based on the CoI paradigm by grouping sensors into communities using a fused similarity matrix that incorporates temporal correlations via Spearman coefficients, spatial proximity using Gaussian distance decay, and elevation similarities. For each community, representative stations based on the best silhouette are selected and three autoencoder architectures (BiLSTM, LSTM, and MLP) are trained using Bayesian hyperparameter optimization with expanding window cross-validation and tested on stations from the same cluster and the best representative stations of other clusters. The models are trained on normal temperature patterns of the data and anomalies are detected through reconstruction error analysis. Experimental results show a robust within-community performance across the evaluated configurations, while variations across communities are observed. Overall, the results support the applicability of community-based model sharing in reducing computational overhead and to analyse model generalisability across IoT sensor networks. | [ Paper](https://arxiv.org/abs/2601.05984v1) |
| [Optimization of the metal-dielectric metasurface unit cell for sensitivity enhancement in determination of IgG concentration in solutions](https://arxiv.org/abs/2601.05979v1) | K. S. Kuznetsova, V. A. Pashynska, Z. E. Eremenko | 2026-01-09 | Optimization | This study focuses on developing a metal-dielectric sensor structure with optimized unit cell geometry for determination of protein Immunoglobulin G (IgG) concentration in aqueous solutions. The research combines both experimental and theoretical investigations, utilizing the differential microwave dielectrometry method and numerical modeling with COMSOL software. Complex permittivity (CP) values dependence of IgG water solutions on the protein concentration was experimentally obtained at the microwaves using original microwave dielectrometer setup. It was shown that increase of IgG concentration resulted in the CP values of the solutions studied decrease. The experimentally obtained CP data for the IgG water solutions were used as a basis for microwave metal-dielectric metasurface unit cell numerical modeling. The metal-dielectric metasurface consisting of Teflon substrate and plane copper microresonators was combined with a standard 96-well microplate used in clinical laboratories. Optimization of the obtained metasurface unit cell revealed that the size and position of the copper microresonators within the unit cell significantly impact the sensor sensitivity for determining the IgG concentration in aqueous solutions. The metasurface with the unit cell containing four copper microresonators provided the most sensitive platform for detecting variations in the IgG concentration in the sample. The frequency shift of the reflection coefficient was directly related to changes in the protein concentration. The calibration graph was developed for effective determination of IgG concentrations in the aqueous solutions. | [ Paper](https://arxiv.org/abs/2601.05979v1) |
| [A Framework for Optimizing Human-Machine Interaction in Classification Systems](https://arxiv.org/abs/2601.05974v1) | Goran Muric, Steven Minton | 2026-01-09 | Optimization | Automated decision systems increasingly rely on human oversight to ensure accuracy in uncertain cases. This paper presents a practical framework for optimizing such human-in-the-loop classification systems using a double-threshold policy. Instead of relying on a single decision cutoff, the system defines two thresholds (a lower and an upper) to automatically accept or reject confident cases while routing ambiguous ones for human review. We formalize this problem as an optimization task that balances system accuracy against human review workload and demonstrate its behavior through extensive Monte Carlo simulations. Our results quantify how different probability score distributions affect the efficiency of human intervention and identify the regions of diminishing returns where additional review yields minimal benefit. The framework provides a general, reproducible method for improving reliability in any decision pipeline requiring selective human validation, including applications in entity resolution, fraud detection, medical triage, and content moderation. | [ Paper](https://arxiv.org/abs/2601.05974v1) |
##  Scaling Laws

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Slow mixing and emergent one-form symmetries in three-dimensional $\mathbb{Z}_2$ gauge theory](https://arxiv.org/abs/2601.06010v1) | Charles Stahl, Benedikt Placke, Vedika Khemani, Yaodong Li | 2026-01-09 | Scaling Laws | Symmetry-breaking order at low temperatures is often accompanied by slow relaxation dynamics, due to diverging free-energy barriers arising from interfaces between different ordered states. Here, we extend this correspondence to classical topological order, where the ordered states are locally indistinguishable, so there is no notion of interfaces between them. We study the relaxation dynamics of the three-dimensional (3D) classical $\mathbb{Z}_2$ lattice gauge theory (LGT) as a canonical example. We prove a lower bound on the mixing time in the deconfined phase, $t_{\text{mix}} = \exp [惟(L)]$, where L is the linear system size. This bound applies even in the presence of perturbations that explicitly break the one-form symmetry between different long-lived states. This perturbation destroys the energy barriers between ordered states, but we show that entropic effects nevertheless lead to diverging free-energy barriers at nonzero temperature. Our proof establishes the LGT as a robust finite-temperature classical memory. We further prove that entropic effects lead to an emergent one-form symmetry, via a notion that we make precise. We argue that the exponential mixing time follows from universal properties of the deconfined phase, and numerically corroborate this expectation by exploring mixing time scales at the Higgs and confinement transitions out of the deconfined phase. These transitions are found to exhibit markedly different dynamic scaling, even though both have the static critical exponents of the 3D Ising model. We expect this novel entropic mechanism for memory and emergent symmetry to also bring insight into self-correcting quantum memories. | [ Paper](https://arxiv.org/abs/2601.06010v1) |
| [From Superradiance to Superabsorption: An Exact Treatment of Non-Markovian Cooperative Radiation](https://arxiv.org/abs/2601.05989v1) | Ignacio Gonz谩lez, ngel Rivas | 2026-01-09 | Scaling Laws | We investigate the emergence of cooperative radiation phenomena in ensembles of two-level atoms coupled to a lossy resonant cavity beyond the Markovian and mean-field approximations. By deriving a complete analytical solution for the two-emitter case and employing a numerically exact method for larger ensembles, we characterize the full transition from Markovian to non-Markovian collective dynamics for systems of up to $10^3$ emitters. Our results reveal three distinct regimes: a Markovian phase exhibiting the standard superradiant burst, a non-Markovian phase featuring spontaneous superabsorption of the emitted field, and a critical regime marked by pulsed collective emission. We show that the critical spectral width separating these behaviors increases monotonically with the number of emitters, demonstrating that environmental memory effects can be enhanced by cooperativity. Finally, we find that the superradiant scaling of the peak intensity progressively degrades with increasing system size, approaching a subquadratic law in the limit of a perfect cavity. In this regime, spontaneous superabsorption emerges as a distinct manifestation of non-Markovian cooperativity. | [ Paper](https://arxiv.org/abs/2601.05989v1) |
| [Age of Gossip With Cellular Drone Mobility](https://arxiv.org/abs/2601.05983v1) | Arunabh Srivastava, Sennur Ulukus | 2026-01-09 | Scaling Laws | We consider a cellular network containing $n$ nodes where nodes within a cell gossip with each other in a fully-connected fashion and a source shares updates with these nodes via a mobile drone. The mobile drone receives updates directly from the source and shares them with nodes in the cell where it currently resides. The drone moves between cells according to an underlying continuous-time Markov chain (CTMC). In this work, we evaluate the impact of the number of cells $f(n)$, drone speed $位_m(n)$ and drone dissemination rate $位_d(n)$ on the freshness of information of nodes in the network. We utilize the version age of information metric to quantify the freshness of information. We observe that the expected duration between two drone-to-cell service times depends on the stationary distribution of the underlying CTMC and $位_d(n)$, but not on $位_m(n)$. However, the version age instability in slow moving CTMCs makes high probability analysis for a general underlying CTMC difficult. Therefore, next we focus on the fully-connected drone mobility model. Under this model, we uncover a dual-bottleneck between drone mobility and drone dissemination speed: the version age is constrained by the slower of these two processes. If $位_d(n) \gg 位_m(n)$, then the version age scaling of nodes is dominated by the inverse of $位_m(n)$ and is independent of $位_d(n)$. If $位_m(n) \gg 位_d(n)$, then the version age scaling of nodes is dominated by the inverse of $位_d(n)$ and is independent of $位_m(n)$. | [ Paper](https://arxiv.org/abs/2601.05983v1) |
| [Refined uniqueness results for 2D Euler and gSQG with rough Kraichnan noise](https://arxiv.org/abs/2601.05982v1) | Marco Bagnara, Lucio Galeati | 2026-01-09 | Scaling Laws | We prove strong well-posedness results for the stochastic 2D Euler equations in vorticity form and generalized SQG equations, with $L^p$ initial data and driven by a spatially rough, incompressible transport noise of Kraichnan type. Previous works addressed this problem with noise of spatial regularity $伪\in (0,1/2)$, in a setting where a rougher noise yields a stronger regularization. We remove this limitation by allowing any $伪\in (0,1)$, covering the same range of parameters for which anomalous regularization effects are known to occur in passive scalars. In particular, this covers the physically relevant case $伪=2/3$, associated with the Richardson-Kolmogorov scaling of energy cascade. | [ Paper](https://arxiv.org/abs/2601.05982v1) |
##  Training & Evaluation

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Constraining Hamiltonians from chiral effective field theory with neutron-star data](https://arxiv.org/abs/2601.05999v1) | Cassandra L. Armstrong, Brendan T. Reed, Tate Plohr, Henrik Rose, Soumi De, Rahul Somasundaram, Ingo Tews | 2026-01-09 | Training & Evaluation, Diffusion Models | Multi-messenger observations of neutron stars (NSs) and their mergers have placed strong constraints on the dense-matter equation of state (EOS). The EOS, in turn, depends on microscopic nuclear interactions that are described by nuclear Hamiltonians. These Hamiltonians are commonly derived within chiral effective field theory (EFT). Ideally, multi-messenger observations of NSs could be used to directly inform our understanding of EFT interactions, but such a direct inference necessitates millions of model evaluations. This is computationally prohibitive because each evaluation requires us to calculate the EOS from a Hamiltonian by solving the quantum many-body problem with methods such as auxiliary-field diffusion Monte Carlo (AFDMC), which provides very accurate and precise solutions but at a significant computational cost. Additionally, we need to solve the stellar structure equations for each EOS which further slows down each model evaluation by a few seconds. In this work, we combine emulators for AFDMC calculations of neutron matter, built using parametric matrix models, and for the stellar structure equations, built using multilayer perceptron neural networks, with the \texttt{PyCBC} data-analysis framework to enable a direct inference of coupling constants in an EFT Hamiltonian using multi-messenger observations of NSs. We find that astrophysical data can provide informative constraints on two-nucleon couplings despite the high densities probed in NS interiors. | [ Paper](https://arxiv.org/abs/2601.05999v1) |
##  Model Evaluation

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Manifold limit for the training of shallow graph convolutional neural networks](https://arxiv.org/abs/2601.06025v1) | Johanna Tengler, Christoph Brune, Jos茅 A. Iglesias | 2026-01-09 | Model Evaluation, Responsible AI | We study the discrete-to-continuum consistency of the training of shallow graph convolutional neural networks (GCNNs) on proximity graphs of sampled point clouds under a manifold assumption. Graph convolution is defined spectrally via the graph Laplacian, whose low-frequency spectrum approximates that of the Laplace-Beltrami operator of the underlying smooth manifold, and shallow GCNNs of possibly infinite width are linear functionals on the space of measures on the parameter space. From this functional-analytic perspective, graph signals are seen as spatial discretizations of functions on the manifold, which leads to a natural notion of training data consistent across graph resolutions. To enable convergence results, the continuum parameter space is chosen as a weakly compact product of unit balls, with Sobolev regularity imposed on the output weight and bias, but not on the convolutional parameter. The corresponding discrete parameter spaces inherit the corresponding spectral decay, and are additionally restricted by a frequency cutoff adapted to the informative spectral window of the graph Laplacians. Under these assumptions, we prove $$-convergence of regularized empirical risk minimization functionals and corresponding convergence of their global minimizers, in the sense of weak convergence of the parameter measures and uniform convergence of the functions over compact sets. This provides a formalization of mesh and sample independence for the training of such networks. | [ Paper](https://arxiv.org/abs/2601.06025v1) |
| [Discriminative-Generative Target Speaker Extraction with Decoder-Only Language Models](https://arxiv.org/abs/2601.06006v1) | Bang Zeng, Beilong Tang, Wang Xiang, Ming Li | 2026-01-09 | Model Evaluation, Responsible AI, Optimization, Multimodal AI | Target speaker extraction (TSE) aims to recover the speech signal of a desired speaker from a mixed audio recording, given a short enrollment utterance. Most existing TSE approaches are based on discriminative modeling paradigms. Although effective at suppressing interfering speakers, these methods often struggle to produce speech with high perceptual quality and naturalness. To address this limitation, we first propose LauraTSE, a generative TSE model built upon an auto-regressive decoder-only language model. However, purely generative approaches may suffer from hallucinations, content drift, and limited controllability, which may undermine their reliability in complex acoustic scenarios. To overcome these challenges, we further introduce a discriminative-generative TSE framework. In this framework, a discriminative front-end is employed to robustly extract the target speaker's speech, yielding stable and controllable intermediate representations. A generative back-end then operates in the neural audio codec representation space to reconstruct fine-grained speech details and enhance perceptual quality. This two-stage design effectively combines the robustness and controllability of discriminative models with the superior naturalness and quality enhancement capabilities of generative models. Moreover, we systematically investigate collaborative training strategies for the proposed framework, including freezing or fine-tuning the front-end, incorporating an auxiliary SI-SDR loss, and exploring both auto-regressive and non-auto-regressive inference mechanisms. Experimental results demonstrate that the proposed framework achieves a more favorable trade-off among speech quality, intelligibility, and speaker consistency. | [ Paper](https://arxiv.org/abs/2601.06006v1) |
| [The Causal Effect of First-Time Academic Failure on University Dropout: Evidence from a Regression Discontinuity Design](https://arxiv.org/abs/2601.05987v1) | H. R. Paz | 2026-01-09 | Model Evaluation, Responsible AI, Training & Evaluation | University dropout remains a persistent challenge in higher education systems, yet causal evidence on the mechanisms triggering early disengagement is limited. This study estimates the causal effect of first-time academic failure on subsequent university attrition. Exploiting a sharp institutional grading threshold on a 0-10 scale, we implement a regression discontinuity design (RDD) comparing students who narrowly fail to those who narrowly pass their first attempt. Using longitudinal administrative data spanning multiple cohorts and degree programmes, we estimate local average treatment effects (LATE) for students at the margin of success and examine dropout outcomes within 12 and 24 months following the initial evaluation. Contrary to conventional assumptions, the results indicate that marginal first-time failure is associated with a lower probability of subsequent dropout relative to marginal passing at both horizons. A comprehensive battery of robustness checks - including donut RDD specifications, placebo cutoffs, and formal density tests - supports the validity of the identification strategy. These findings suggest that early academic failure may function as a salient signal that prompts behavioural adjustment or reorientation, while marginal passing may sustain a state of "fragile persistence". The study provides causal evidence on the non-linear effects of early academic performance and highlights the importance of carefully designed institutional responses at critical evaluation thresholds. | [ Paper](https://arxiv.org/abs/2601.05987v1) |
| [Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints](https://arxiv.org/abs/2601.05986v1) | Adrian Serrano, Erwan Umlil, Ronan Thomas | 2026-01-09 | Model Evaluation, Responsible AI, Security & Adversarial ML, AI Safety | Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks. | [ Paper](https://arxiv.org/abs/2601.05986v1) |
| [Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation](https://arxiv.org/abs/2601.05981v1) | Yinsong Wang, Xinzhe Luo, Siyi Du, Chen Qin | 2026-01-09 | Model Evaluation, Optimization | Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR. | [ Paper](https://arxiv.org/abs/2601.05981v1) |
| [Counterdiabatic ADAPT-VQE for molecular simulation](https://arxiv.org/abs/2601.05973v1) | Diego Tancara, Herbert D铆az-Moraga, Dardo Goyeneche | 2026-01-09 | Model Evaluation, Responsible AI | Among variational quantum algorithms designed for NISQ devices, ADAPT-VQE stands out for its robustness against barren plateaus, particularly in estimating molecular ground states. On the other hand, counterdiabatic algorithms have shown advantages in both performance and circuit depth when compared to standard adiabatic approaches. In this work, we propose a hybrid method that integrates the ADAPT-VQE framework with counterdiabatic driving within an adiabatic evolution scheme. Specifically, we map the molecular Hamiltonian to a qubit representation and construct an adiabatic Hamiltonian, from which an approximate adiabatic gauge potential is computed using nested commutators. The resulting operator terms define the operator pool, and the ADAPT-VQE algorithm is applied to iteratively select the most relevant elements for the ansatz. Our results demonstrate improvements in performance and reductions in circuit depth compared to using either counterdiabatic algorithms or ADAPT-VQE with fermionic excitation operators, thus supporting the effectiveness of combining both paradigms in molecular simulations. | [ Paper](https://arxiv.org/abs/2601.05973v1) |
##  Responsible AI

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards](https://arxiv.org/abs/2601.06021v1) | Jiajie Zhang, Xin Lv, Ling Feng, Lei Hou, Juanzi Li | 2026-01-09 | Responsible AI, RLHF, Optimization | Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR. | [ Paper](https://arxiv.org/abs/2601.06021v1) |
##  General AI

|  Title |  Authors |  Date |  Tags |  Summary |  Link |
|---------|---------|---------|---------|---------|---------|
| [Primordial black holes: constraints, potential evidence and prospects](https://arxiv.org/abs/2601.06024v1) | Bernard Carr, Antonio J. Iovino, Gabriele Perna, Ville Vaskonen, Hardi Veerm盲e | 2026-01-09 | General AI | Primordial black holes (PBHs) may have formed in the early Universe and may account for all or part of the dark matter. In this review, we summarize the current observational constraints on PBHs across the full mass range, highlight potential evidence for their existence, and outline the prospects for future searches, particularly with gravitational-wave observatories. We also discuss different PBH formation scenarios, identify the corresponding mass functions, and present the observational constraints in each case. | [ Paper](https://arxiv.org/abs/2601.06024v1) |
| [Mobility Trajectories from Network-Driven Markov Dynamics](https://arxiv.org/abs/2601.06020v1) | David A. Meyer, Asif Shakeel | 2026-01-09 | General AI | We present a generative model of human mobility in which trajectories arise as realizations of a prescribed, time-dependent Markov dynamics defined on a spatial interaction network. The model constructs a hierarchical routing structure with hubs, corridors, feeder paths, and metro links, and specifies transition matrices using gravity-type distance decay combined with externally imposed temporal schedules and directional biases. Population mass evolves as indistinguishable, memoryless movers performing a single transition per time step.   When aggregated, the resulting trajectories reproduce structured origin-destination flows that reflect network geometry, temporal modulation, and connectivity constraints. By applying the Perron-Frobenius theorem to the daily evolution operator, we identify a unique periodic invariant population distribution that serves as a natural non-transient reference state. We verify consistency between trajectory-level realizations and multi-step Markov dynamics, showing that discrepancies are entirely attributable to finite-population sampling. The framework provides a network-centric, privacy-preserving approach to generating mobility trajectories and studying time-elapsed flow structure without invoking individual-level behavioral assumptions. | [ Paper](https://arxiv.org/abs/2601.06020v1) |
| [A Hal谩sz-type theorem for permutation anticoncentration](https://arxiv.org/abs/2601.06019v1) | Zach Hunter, Cosmin Pohoata, Daniel G. Zhu | 2026-01-09 | General AI | Given a set $A=\{a_1,\ldots,a_n\}$ of real numbers and real coefficients $b_1,\ldots,b_n$, consider the distribution of the sum obtained by pairing the $a_i$'s with the $b_i$'s according to a uniformly random permutation. A recent theorem of Pawlowski shows that as soon as the coefficients are not all equal, this distribution is always spread out at scale $n^{-1}$: no single value can occur with probability larger than $\frac{1}{2\lceil n/2\rceil + 1}$, and this bound is sharp in general.   We show that stronger anticoncentration holds when the coefficients have additional diversity. We quantify the structure of the coefficient multiset by a simple statistic depending on its multiplicity profile, and prove that the maximum point mass of the permuted sum decays polynomially faster as this statistic grows. In particular, when the coefficients are all distinct we obtain a bound of $n^{-5/2+o(1)}$, which can be regarded as an analogue of a classical theorem of Erds and Moser. | [ Paper](https://arxiv.org/abs/2601.06019v1) |
| [Probing Cosmic Expansion and Early Universe with Einstein Telescope](https://arxiv.org/abs/2601.06017v1) | Angelo Ricciardone, Mairi Sakellariadou, Archisman Ghosh, Alessandro Agapito, M. Celeste Artale, Michael Bacchi, Tessa Baker, Marco Baldi, Nicola Bartolo, Andrea Begnoni, Enis Belgacem, Marek Biesiada, Jose J. Blanco-Pillado, Tomasz Bulik, Marica Branchesi, Gianluca Calcagni, Giulia Capurri, Carmelita Carbone, Roberto Casadio, J. A. R. Cembranos, Andrea Cozzumbo, Ivan De Martino, Jose M. Diego, Emanuela Dimastrogiovanni, Guillem Dom猫nech, Ulyana Dupletsa, Hannah Duval, Gabriele Franciolini, Andrea Giusti, Giuseppe Greco, Lavinia Heisenberg, Alexander C. Jenkins, Sumit Kumar, Gaetano Lambiase, Michele Maggiore, Michele Mancarella, Federico Marulli, Sabino Matarrese, Isabela Santiago de Matos, Michele Moresco, Riccardo Murgia, Ilia Musco, Gabriele Perna, Michele Punturo, Diego Rubiera-Garcia, Javier Rubio, Alexander Sevrin, Riccardo Sturani, Matteo Tagliazucchi, Nicola Tamanini, Alessandro Tronconi, Ville Vaskonen, Daniele Vernieri, Stoytcho Yazadjiev, Ivonne Zavala | 2026-01-09 | General AI | Over the next two decades, gravitational-wave (GW) observations are expected to evolve from a discovery-driven endeavour into a precision tool for astrophysics, cosmology, and fundamental physics. Current second-generation ground-based detectors have established the existence of compact-binary mergers and enabled GW multi-messenger astronomy, but they remain limited in sensitivity, redshift reach, frequency coverage, and duty cycle. These limitations prevent them from addressing many fundamental open questions in cosmology. By the 2040s, wide-field electromagnetic surveys will have mapped the luminous Universe with unprecedented depth and accuracy. Nevertheless, key problems including the nature of dark matter, the physical origin of cosmic acceleration, the properties of gravity on cosmological scales, and the physical conditions of the earliest moments after the Big Bang will remain only partially constrained by electromagnetic observations alone. Progress on these fronts requires access to physical processes and epochs that do not emit light. Gravitational waves provide a unique and complementary observational channel: they propagate over cosmological distances largely unaffected by intervening matter, probe extreme astrophysical environments, and respond directly to the geometry of spacetime. In this context, next-generation GW observatories such as the Einstein Telescope (ET) will be transformative for European astronomy. Operating at sensitivities and frequencies beyond existing detectors, ET will observe binary black holes and neutron stars out to previously inaccessible redshifts, enable continuous high signal-to-noise monitoring of compact sources, and detect gravitational-wave backgrounds of astrophysical and cosmological origin. Together with space-based detectors, ET will play a central role in advancing our understanding of cosmic evolution and fundamental physics. | [ Paper](https://arxiv.org/abs/2601.06017v1) |
| [On the Effect of Misspecifying the Embedding Dimension in Low-rank Network Models](https://arxiv.org/abs/2601.06014v1) | Roddy Taing, Keith Levin | 2026-01-09 | General AI | As network data has become ubiquitous in the sciences, there has been growing interest in network models whose structure is driven by latent node-level variables in a (typically low-dimensional) latent geometric space. These "latent positions" are often estimated via embeddings, whereby the nodes of a network are mapped to points in Euclidean space so that "similar" nodes are mapped to nearby points. Under certain model assumptions, these embeddings are consistent estimates of the latent positions, but most such results require that the embedding dimension be chosen correctly, typically equal to the dimension of the latent space. Methods for estimating this correct embedding dimension have been studied extensive in recent years, but there has been little work to date characterizing the behavior of embeddings when this embedding dimension is misspecified. In this work, we provide theoretical descriptions of the effects of misspecifying the embedding dimension of the adjacency spectral embedding under the random dot product graph, a class of latent space network models that includes a number of widely-used network models as special cases, including the stochastic blockmodel. We consider both the case in which the dimension is chosen too small, where we prove estimation error lower-bounds, and the case where the dimension is chosen too large, where we show that consistency still holds, albeit at a slower rate than when the embedding dimension is chosen correctly.A range of synthetic data experiments support our theoretical results. Our main technical result, which may be of independent interest, is a generalization of earlier work in random matrix theory, showing that all non-signal eigenvectors of a low-rank matrix subject to additive noise are delocalized. | [ Paper](https://arxiv.org/abs/2601.06014v1) |
| [Database Theory in Action: Direct Access to Query Answers](https://arxiv.org/abs/2601.06013v1) | Jiayin Hu, Nikolaos Tziavelis | 2026-01-09 | General AI | Direct access asks for the retrieval of query answers by their ranked position, given a query and a desired order. While the time complexity of data structures supporting such accesses has been studied in depth, and efficient algorithms for many queries and common orders are known, their practical performance has received little attention. We provide an implementation covering a wide range of queries and orders; it allows us to investigate intriguing practical aspects, including the comparative performance of database systems and the relationship between direct access and its single-access counterpart. | [ Paper](https://arxiv.org/abs/2601.06013v1) |
| [Cooperative Differential GNSS Positioning: Estimators and Bounds](https://arxiv.org/abs/2601.06012v1) | Helena Calatrava, Daniel Medina, Pau Closas | 2026-01-09 | General AI | In Differential GNSS (DGNSS) positioning, differencing measurements between a user and a reference station suppresses common-mode errors but also introduces reference-station noise, which fundamentally limits accuracy. This limitation is minor for high-grade stations but becomes significant when using reference infrastructure of mixed quality. This paper investigates how large-scale user cooperation can mitigate the impact of reference-station noise in conventional (non-cooperative) DGNSS systems. We develop a unified estimation framework for cooperative DGNSS (C-DGNSS) and cooperative real-time kinematic (C-RTK) positioning, and derive parameterized expressions for their Fisher information matrices as functions of network size, satellite geometry, and reference-station noise. This formulation enables theoretical analysis of estimation performance, identifying regimes where cooperation asymptotically restores the accuracy of DGNSS with an ideal (noise-free) reference. Simulations validate these theoretical findings. | [ Paper](https://arxiv.org/abs/2601.06012v1) |
| [Simulations of collision and sloshing in the galaxy group NGC 5098/5096](https://arxiv.org/abs/2601.06011v1) | Richards P. Albuquerque, Gast茫o B. Lima Neto, Rubens E. G. Machado, Hugo V. Capelato, Florence Durret | 2026-01-09 | General AI | The study of galaxy groups is essential to understanding the evolutionary history of large-scale structures in the Universe. These dense environments have a significant impact on galaxy evolution, influencing their gas content, morphology, and star formation activity. In this work we analyse in detail the system NGC~5098$/$5096 composed of two galaxy groups. We performed hydrodynamical $N$-body simulations of a galaxy group collision aimed at reproducing the gas sloshing and surface brightness distribution observed in X-ray data. We conducted a detailed X-ray analysis and generated mock image \textit{Chandra} observations from our simulations. The resulting corrected mock image surface brightness profiles show good agreement with the observed data. The relative line-of-sight velocity between NGC~5098 and NGC~5096 is $v_{\mathrm{los}} = 700$ km s$^{-1}$, with a projected separation of $d_{\mathrm{proj}} = 155$ kpc, suggesting that the collision occurs nearly in the line-of-sight. Our simulations were performed with an inclination angle of $80^\circ$ in order to reproduce the dynamical constraints. We also find a correlation between the dark matter and intragroup light distributions when comparing the residual dark matter map with the intragroup light morphology. Our best-fitting model is consistent with these observational constraints and provides a plausible dynamical scenario for the current state of the NGC~5098 group interaction with NGC 5096. | [ Paper](https://arxiv.org/abs/2601.06011v1) |
| [Scaleable LED-pumped Room-temperature Maser using a Multi-blade Optical Injector](https://arxiv.org/abs/2601.06008v1) | Mingyang Liu, Zike Cheng, Ziqiu Huang, Yifan Yu, Michael Newns, Mark Oxborrow | 2026-01-09 | General AI | Though the performance of room-temperature masers has improved over the last decade, relatively little attention has been paid to the optics used to pump the maser's gain medium. In this work, we investigate a novel multi-blade optical ``injector'' that permits more effective and more scaleable pumping. The reported work encompasses an interdisciplinary mix of conceptualization, simulation, crystal growth, fabrication, and microwave engineering. Our gain medium is pentacene dissolved as a solid solution with para-terphenyl (Pc:PTP) molecular crystal. We accurately determine this pentacene's molecular absorption cross-section as a function of wavelength. Ray-tracing is then used to assess how different designs of waveguide inject light into the Pc:PTP crystal. A multi-blade injector made of high-refractive-index glass (namely Ohara S-TIH6) is predicted to pump it more completely and uniformly than previous designs. Upon hand-fabricating such an injector and Bridgman-growing a crystal of 0.1% Pc:PTP over it, an experimental maser oscillator using this combined injector-crystal assembly is demonstrated. The performance and scaleability of multiblade injection vis-a-vis alternative strategies is analyzed. | [ Paper](https://arxiv.org/abs/2601.06008v1) |
| [Generalized Poincar茅 inequality for quantum Markov semigroups](https://arxiv.org/abs/2601.06005v1) | Marius Junge, Jia Wang | 2026-01-09 | General AI | We prove a noncommutative $(p,p)$-Poincar茅 inequality for trace-symmetric quantum Markov semigroups on tracial von Neumann algebras, assuming only the existence of a spectral gap. Extending semi-commutative results of Huang and Tropp, our argument uses Markov dilations to obtain chain-rule estimates for Dirichlet forms and employs amalgamated free products to define an appropriate noncommutative derivation. We further generalize the argument to non-tracial $$-finite von Neumann algebras under the weaker assumption of GNS-detailed balance, using Haagerup's reduction and Kosaki's interpolation theorem. As applications, we recover noncommutative Khintchine and sub-exponential concentration inequalities. | [ Paper](https://arxiv.org/abs/2601.06005v1) |
| [Exact Volterra series for mean field dynamics](https://arxiv.org/abs/2601.06004v1) | Ion Santra, Matthias Kr眉ger | 2026-01-09 | General AI | We derive an exact Volterra series expansion for a mean field of an interacting particle system subject to a potential perturbation, expressing the Volterra expansion kernels in terms of the field's response functions, to any order. Applying this formalism to the mean particle density of a simple fluid, we identify a form reminiscent of dynamical density functional theory, with, however, fundamental differences: A nonlocal mobility kernel appears, and forces derive from a functional of the {\it history} of mean density. The equilibrium density functional is shown to be recovered in the limit of slowly varying perturbation. We identify a freedom in deriving this expansion, which allows different forms of mobility kernels. These developments allow for a systematic improvement of established mean field formalisms. | [ Paper](https://arxiv.org/abs/2601.06004v1) |
| [Rotational Coherence Dominates Early-Time Dynamics and Produces Long-Time Revivals in the S2 State of Azulene](https://arxiv.org/abs/2601.06003v1) | Jie Zhan, Alexander K. Lemmens, Musahid Ahmed, Melanie A. R. Reber | 2026-01-09 | General AI | The ultrafast dynamics of azulene have been debated for decades, with reported picosecond decay constants variously attributed to intramolecular vibrational redistribution (IVR), internal conversion, or rotational dephasing. Using polarization and femtosecond time-resolved Resonance Enhanced Multi-photon Ionization Spectroscopy with a nanosecond delay window, we disentangle this long-standing inconsistency and show that the early 2-5 ps decay component arises entirely from rotational dephasing of an excited-state wavepacket. Identical time constants extracted from the decay of the parallel signal and rise of the perpendicular signal across multiple vibronic origins provide an unambiguous rotational anisotropy signature, eliminating the need for IVR-based interpretations. Extending the measurement window to 1.3 ns reveals well-structured J-type and C-type rotational coherence revivals in S2 azulene on top of the well-documented fluorescence decay, demonstrating that both the short- and long-time dynamics contain information about the coherent rotational dynamics. These results show that azulene, and by extension polycyclic aromatic hydrocarbons (PAH), can sustain structured rotational coherence deep into the nanosecond regime, positioning PAHs as model systems for quantum-coherent wavepacket dynamics and providing a framework for probing coherence, decoherence, and rotational control in electronically rich molecular systems. | [ Paper](https://arxiv.org/abs/2601.06003v1) |
| [The Importance of Parameters in Ranking Functions](https://arxiv.org/abs/2601.06001v1) | Christoph Standke, Nikolaos Tziavelis, Wolfgang Gatterbauer, Benny Kimelfeld | 2026-01-09 | General AI | How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.   For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight). | [ Paper](https://arxiv.org/abs/2601.06001v1) |
| [Resilient UAV Data Mule via Adaptive Sensor Association under Timing Constraints](https://arxiv.org/abs/2601.06000v1) | Md Sharif Hossen, Anil Gurses, Ozgur Ozdemir, Mihail Sichitiu, Ismail Guvenc | 2026-01-09 | General AI | Unmanned aerial vehicles (UAVs) can be critical for time-sensitive data collection missions, yet existing research often relies on simulations that fail to capture real-world complexities. Many studies assume ideal wireless conditions or focus only on path planning, neglecting the challenge of making real-time decisions in dynamic environments. To bridge this gap, we address the problem of adaptive sensor selection for a data-gathering UAV, considering both the buffered data at each sensor and realistic propagation conditions. We introduce the Hover-based Greedy Adaptive Download (HGAD) strategy, designed to maximize data transfer by intelligently hovering over sensors during periods of peak signal quality. We validate HGAD using both a digital twin (DT) and a real-world (RW) testbed at the NSF-funded AERPAW platform. Our experiments show that HGAD significantly improves download stability and successfully meets per-sensor data targets. When compared with the traditional Greedy approach that simply follows the strongest signal, HGAD is shown to outperform in the cumulative data download. This work demonstrates the importance of integrating signal-to-noise ratio (SNR)-aware and buffer-aware scheduling with DT and RW signal traces to design resilient UAV data-mule strategies for realistic deployments. | [ Paper](https://arxiv.org/abs/2601.06000v1) |
| [Curving Beam Reflections: Model and Experimental Validation](https://arxiv.org/abs/2601.05998v1) | Caroline Jane Spindel, Edward Knightly | 2026-01-09 | General AI | Curving beams are a promising new method for bypassing obstacles in future millimeter-wave to sub-terahertz (sub-THz) networks but lack a general predictive model for their reflections from arbitrary surfaces. We show that, unfortunately, attempting to "mirror" the incident beam trajectory across the normal of the reflector, as in ray optics, fails in general. Thus, we introduce the first geometric framework capable of modeling the reflections of arbitrary convex sub-THz curving beams from general reflectors with experimental verification. Rather than "mirroring" the trajectory, we decompose the beam into a family of tangents and demonstrate that this process is equivalent to the Legendre transform. This approach allows us to accurately account for reflectors of any shape, size, and position while preserving the underlying physics of wave propagation. Our model is validated through finite element method simulations and over-the-air experiments, demonstrating millimeter-scale accuracy in predicting reflections. Our model provides a foundation for future curving beam communication and sensing systems, enabling the design of reflected curved links and curving radar paths. | [ Paper](https://arxiv.org/abs/2601.05998v1) |
| [Increasing The Sensitivity of a Surface Plasmon Resonance Sensor using Ti3C2 Mxene](https://arxiv.org/abs/2601.05997v1) | Rostyslav Terekhov, Zoya Eremenko, Sergii Kulish | 2026-01-09 | General AI | Sensors based on the phenomenon of surface plasmon resonance have limited sensitivity, up to 123 degree/Refractive Index Unit, which restricts their applicability in detecting subtle changes gin biological media (around 10-5 RIU). To address this, a sensor dependent on the Kretschmann-Reather configuration was modified using Ti3C2 MXene material. The sensor was modeled using the finite element method (FEM), yielding the dependence of the wave reflection parameter on the angle of incidence. Founded on these results, the sensitivity of the sensor was calculated and demonstrated a 10% improvement compared to the conventional Kretschmann-Reather configuration. In addition, human biological real-world samples were modeled using refractive index data, and the error of the proposed approach was determined to be approximately 3%. | [ Paper](https://arxiv.org/abs/2601.05997v1) |
| [Self-organization of local streamline structures and energy transfer rate in compressible plasma turbulence](https://arxiv.org/abs/2601.05996v1) | Simone Benella, Virgilio Quattrociocchi, Emanuele Papini, Andrea Verdini, Simone Landi, Maria Federica Marcucci, Giuseppe Consolini | 2026-01-09 | General AI | We examine how local streamline topology and energy cascade rate self-organize in plasma turbulence for both compressible and incompressible regimes. Using a fully-compressible Hall-magnetohydrodynamic simulation, we quantify the subgrid-scale energy transfer and analyze its relationship to streamline structures by means of grandient tensor geometric invariants of the velocity field. Our results highlight how streamline topology is crucial for diagnosing turbulence: for nearly-incompressible fluctuations the energy is primarily transferred to smaller scales through strain-dominated and stable-vortical structures, while is back-transferred towards larger scales through unstable-vortical structures. Compressible fluctuations, on the contrary, do not show a clear topological selection of the energy transfer since the overall direction of the local cascade rate is found to be determined by the sign of $-\nabla\cdot u$ (plasma volumetric compression or expansion). | [ Paper](https://arxiv.org/abs/2601.05996v1) |
| [Investigating Active Galactic Nuclei variability with the Cherenkov Telescope Array Observatory](https://arxiv.org/abs/2601.05995v1) | G. Grolleron, J. Biteau, M. Cerruti, R. Grau, L. Gr茅aux, T. Hovatta, J. -P. Lenain, E. Lindfors, W. Max-Moerbeck, D. Miceli, A. Moralejo, K. Nilsson, E. Prandini, E. Pueschel, S. Kankkunen, J. Becerra Gonzalez, J. Finke, M. Joshi, P. Morris, M. Petropoulou, A. Sarkar, P. Romano, S. Vercellone, M. Zacharias | 2026-01-09 | General AI | Blazars, a type of active galactic nuclei (AGN) with relativistic jets pointed at the observer, exhibit flux variability across the electromagnetic spectrum due to particle acceleration in their jets. Power spectral density (PSD) studies show breaks at specific frequencies, particularly in X-rays, linked to the accretion regime and black hole mass. However, very-high-energy gamma-ray PSD breaks remain unexplored due to current instrument limitations. The Cherenkov Telescope Array Observatory (CTAO), with up to ten times greater sensitivity compared to current generation instruments, will allow precise PSD reconstruction and unprecedented study of blazar flares. These flares reveal key insights into particle acceleration, photon production, and jet properties. The AGN monitoring and flare programs in CTAO's Key Science Project aim to deepen our understanding of blazar emissions. | [ Paper](https://arxiv.org/abs/2601.05995v1) |
| [Setting up the physical principles of resilience in a model of the Earth System](https://arxiv.org/abs/2601.05994v1) | Orfeu Bertolami, Magnus Nystr枚m | 2026-01-09 | General AI | Resilience is a property of social, ecological, social-ecological and biophysical systems. It describes the capacity of a system to cope with, adapt to and innovate in response to a changing surrounding. Given the current climate change crisis, ensuring conditions for a sustainable future for the habitability on the planet is fundamentally dependent on Earth System (ES) resilience. It is thus particularly relevant to establish a model that captures and frames resilience of the ES, most particularly in physical terms that can be influenced by human policy\footnote{See page 4 for examples of strategies}. In this work we propose that resilience can serve as a theoretical foundation when unpacking and describing metastable states of equilibrium and energy dissipation in any dynamic description of the variables that characterise the ES. Since the impact of the human activities can be suitably gauged by the planetary boundaries (PBs) and the planet's temperature is the net result of the multiple PB variables, such as $\text{CO}_2$ concentration and radiative forcing, atmospheric aerosol loading, atmospheric ozone depletion, etc, then resilience features arise once conditions to avoid an ES runaway to a state where the average temperature is much higher than the current one. Our model shows that this runaway can be prevented by the presence of metastable states and dynamic friction built out of the interaction among the PB variables once suitable conditions are satisfied. In this work these conditions are specified. As humanity moves away from Holocene conditions, we argue that resilience features arising from metastable states might be crucial for the ES to follow sustainable trajectories in the Anthropocene that prevent it run into a much hotter potential equilibrium state. | [ Paper](https://arxiv.org/abs/2601.05994v1) |
| [Detecting Planted Structure in Circular Data](https://arxiv.org/abs/2601.05993v1) | Taha Ameen, Bruce Hajek | 2026-01-09 | General AI | Hypothesis testing problems for circular data are formulated, where observations take values on the unit circle and may contain a hidden, phase-coherent structure. Under the null, the data are independent uniform on the unit circle; under the alternative, either (i) a planted subset of size K concentrates around an unknown phase (the flat setting), or (ii) a planted community of size k induces coherence among the edges of a complete graph (the community setting). In each of the two settings, two circular signal distributions are considered: a hard-cluster distribution, where correlated planted observations lie in an arc of known length and unknown location, and a von Mises distribution, where correlated planted observations follow a von Mises distribution with a common unknown location parameter. For each of the four resulting models, nearly matching necessary and sufficient conditions are derived (up to constants and occasional logarithmic factors) for detectability, thereby establishing information-theoretic phase transitions. | [ Paper](https://arxiv.org/abs/2601.05993v1) |
| [Novel High-Radiopurity Doped Amorphous Silicon Resistors for Low-Background Detectors](https://arxiv.org/abs/2601.05985v1) | A. Anker, P. C. Rowson, K. Skarpaas, S. Tsitrin, I. J. Arnquist, L. Kenneth S. Horkley, L. Pagani, T. D. Schlieder, E. van Bruggen, P. Kachru, A. Pocar, N. Yazbek | 2026-01-09 | General AI | We present the results of a study of lightly doped amorphous silicon used as a resistive medium for high-radiopurity resistors in nuclear and particle physics research instrumentation. Prototypes are produced for a Time Projection Chamber design for the nEXO neutrinoless double-beta decay search experiment that meet requirements for ultra-high radiopurity, good mechanical, cryogenic and high voltage performance, as well as useful vacuum ultraviolet (VUV) reflectivity. Further study is warranted to refine production methods and to confirm that the technology used here is useful for more general applications. | [ Paper](https://arxiv.org/abs/2601.05985v1) |
| [Radial differential rotation leading to dipole collapse in pre-main-sequence stars](https://arxiv.org/abs/2601.05980v1) | A. Guseva, L. Manchon, L. Petitdemange, C. Pin莽on | 2026-01-09 | General AI | Despite progress in the observations of stellar magnetic fields, their physical mechanisms remain poorly understood. During the pre-main sequence (PMS) phase, the inner layers of stars contract and a radiative core gradually develops. In contrast, the convective envelope is gradually braked through magnetic interactions with the accretion disk and winds. With developing differential rotation inside the star, PMS phase is thus a critical period for magnetic properties of stars when strong initial dipoles can get perturbed, leading to the observed diversity in the magnetism on the main sequence (MS). In this work, we study the impact of differential rotation on such fields. We perform three-dimensional anelastic convective dynamo simulations of rotating spherical shells with an imposed differential rotation (shear) between the boundaries. Density, gravity profiles and convective zone thicknesses were set close to those predicted in PMS low-mass stars by one-dimensional stellar evolution code Cesam2k20. Our results show that radial differential rotation can induce dipole collapse leading to weaker, oscillatory magnetic fields. Differential rotation seems to perturb $伪^2$ dynamo mechanism, responsible for dipolar magnetic fields, by shearing poloidal field lines and by affecting turbulent magnetic transport processes. This collapse is moderated by the relative importance of shear compared to the vigor of convective motions, with exact stability criterion depending on the field strength and the size of the radiative core. Applying DNS-based stability criterion in PMS stellar evolution models, we qualitatively reproduce the trends observed in the magnetic topologies of low-mass stars when assuming an efficient internal angular momentum redistribution. This suggests that stellar magnetic properties are intimately related to the PMS angular momentum evolution. | [ Paper](https://arxiv.org/abs/2601.05980v1) |
| [AWaRe-SAC: Proactive Slice Admission Control under Weather-Induced Capacity Uncertainty](https://arxiv.org/abs/2601.05978v1) | Dror Jacoby, Yanzhi Li, Shuyue Yu, Nicola Di Cicco, Hagit Messer, Gil Zussman, Igor Kadota | 2026-01-09 | General AI | As emerging applications demand higher throughput and lower latencies, operators are increasingly deploying millimeter-wave (mmWave) links within x-haul transport networks, spanning fronthaul, midhaul, and backhaul segments. However, the inherent susceptibility of mmWave frequencies to weather-related attenuation, particularly rain fading, complicates the maintenance of stringent Quality of Service (QoS) requirements. This creates a critical challenge: making admission decisions under uncertainty regarding future network capacity. To address this, we develop a proactive slice admission control framework for mmWave x-haul networks subject to rain-induced fluctuations. Our objective is to improve network performance, ensure QoS, and optimize revenue, thereby surpassing the limitations of standard reactive approaches. The proposed framework integrates a deep learning predictor of future network conditions with a proactive Q-learning-based slice admission control mechanism. We validate our solution using real-world data from a mmWave x-haul deployment in a dense urban area, incorporating realistic models of link capacity attenuation and dynamic slice demands. Extensive evaluations demonstrate that our proactive solution achieves 2-3x higher long-term average revenue under dynamic link conditions, providing a scalable and resilient framework for adaptive admission control. | [ Paper](https://arxiv.org/abs/2601.05978v1) |
| [Comment on Nuclear Fusion 66, 016012 (2026) and arXiv:2508.03561 by Richard Fitzpatrick, A Simple Model of Current Ramp-Up and Ramp-Down in Tokamaks](https://arxiv.org/abs/2601.05977v1) | Allen H Boozer | 2026-01-09 | General AI | The article Nuclear Fusion \textbf{66}, 016012 (2026) by Richard Fitzpatrick is based on fundamental errors in the physics of the poloidal magnetic flux in tokamaks. His paper was inspired by an article that I posted on arXiv in various versions [arXiv:2507.05456]. The September 9, 2025 version was submitted to the Physics of Plasmas, which flatly rejected the article. Before I can resubmit, the Physics of Plasmas stated that the issues with the Fitzpatrick article must be explained. Not only did Fitzpatrick make numerous fundamental errors in science, he totally misrepresented my views as clearly stated in my article and even more explicitly in email exchanges, called ``private communication" in his paper. Enquiries were made to the journal Nuclear Fusion staring on November 24, 2025 of the consistency of Fitzpatrick's article with the scientific and ethical standards of the journal. On January 5, 2026, Nuclear Fusion said they had "no evidence of intentional misrepresentation," but others may disagree after reading the emails. Both grants and the publication of an important paper make the public availability of this Comment urgent. | [ Paper](https://arxiv.org/abs/2601.05977v1) |
| [Distinct Rotational Evolution of Giant Planets and Brown Dwarf Companions](https://arxiv.org/abs/2601.05976v1) | Chih-Chun Hsu, Jason J. Wang, Jerry W. Xuan, Yapeng Zhang, Jean-Baptiste Ruffio, Dimitri Mawet, Luke Finnerty, Katelyn Horstman, Julianne Cronin, Yinzi Xin, Ben Sappey, Daniel Echeverri, Nemanja Jovanovic, Ashley D. Baker, Randy Bartos, Geoffrey A. Blake, Benjamin Calvin, Sylvain Cetre, Jacques-Robert Delorme, Greg W. Doppmann, Michael P. Fitzgerald, Quinn M. Konopacky, Joshua Liberman, Ronald A. Lopez, Evan C. Morris, Jacklyn Pezzato, Tobias Schofield, Andrew Skemer, James K. Wallace, Ji Wang | 2026-01-09 | General AI | We present a rotational velocity (vsini) survey of 32 stellar/substellar objects and giant planets using Keck/KPIC high-resolution spectroscopy, including 6 giant planets (2-7 M$_\mathrm{Jup}$) and 25 substellar/stellar companions (12-88 M$_\mathrm{Jup}$). Adding companions with spin measurements from the literature, we construct a curated spin sample for 43 benchmark stellar/substellar companions and giant planets and 54 free-floating brown dwarfs and planetary mass objects. We compare their spins, parameterized as fractional breakup velocities at 10 Myr, assuming constant angular momentum evolution. We find the first clear evidence that giant planets exhibit distinct spins versus low-mass brown dwarf companions (10 to 40 M$_\mathrm{Jup}$) at 4-4.5 $$ significance assuming inclinations aligned with their orbits, while under randomly oriented inclinations the significance is at 1.6-2.1 $$. Our findings hold when considering various assumptions about planets, and the mass ratio below 0.8% gives a clean cut for rotation between giant planets and brown dwarf companions. The higher fractional breakup velocities of planets can be interpreted as less angular momentum loss through circumplanetary disk braking during the planet formation phase. Brown dwarf companions exhibit evidence of slower rotation compared to isolated brown dwarfs, while planets and planetary mass objects show similar spins. Finally, our analysis of specific angular momentum versus age of 221 stellar/substellar objects below 0.1 MSun with spin measurements in the literature indicates that the substellar objects of 5-40 M$_\mathrm{Jup}$ retain much higher angular momenta compared to stellar and substellar objects of 40-100 M$_\mathrm{Jup}$ after 10 Myr, when their initial angular momenta were set. | [ Paper](https://arxiv.org/abs/2601.05976v1) |
