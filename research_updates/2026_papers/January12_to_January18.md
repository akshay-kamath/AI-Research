# üìå AI Research Papers (January12 to January18)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Predictive autoencoder-transformer model of Cu oxidation state from EELS and XAS spectra](https://arxiv.org/abs/2601.11509v1) | Brian Lee, Linna Qiao, Samuel Gleason, Guangwen Zhou, Xiaohui Qu, Judith Yang, Jim Ciston, Deyu Lu | 2026-01-16 | LLM | X-ray absorption spectroscopy (XAS) and electron energy-loss spectroscopy (EELS) produce detailed information about oxidation state, bonding, and coordination, making them essential for quantitative studies of redox and structure in functional materials. However, high-throughput quantitative analysis of these spectra, especially for mixed valence materials, remains challenging as diverse experimental conditions introduce noise, misalignment, broadening of the spectral features. We address this challenge by training a machine learning model consisting of an autoencoder to standardize the spectra and a transformer model to predict both Cu oxidation state and Bader charge directly from L-edge spectra. The model is trained on a large dataset of FEFF-simulated spectra and evaluates model performance on both simulated and experimental data. The results of the machine learning model exhibit highly accurate prediction across the domains of simulated and experimental XAS as well as experimental EELS. These advances enable future quantitative analysis of Cu redox processes under in situ and operando conditions. | [üîó Paper](https://arxiv.org/abs/2601.11509v1) |
| [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479v1) | Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, St√©phane Verguet, Milind Tambe | 2026-01-16 | LLM, Optimization, RLHF | Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning. | [üîó Paper](https://arxiv.org/abs/2601.11479v1) |
| [Low-Rank Key Value Attention](https://arxiv.org/abs/2601.11471v1) | James O'Neill, Robert Clancy, Mariia Matskevichus, Fergal Reid | 2026-01-16 | LLM, Scaling Laws, Training & Evaluation | Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-level resolution. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, yielding a continuous trade-off between complete sharing and fully independent attention.   LRKV is a drop-in replacement for standard multi-head attention and directly subsumes query-sharing approaches such as multi-query and grouped-query attention, while remaining distinct from latent-compression methods such as multi-latent attention (MLA). Across large-scale pretraining experiments, LRKV consistently achieves faster loss reduction, lower validation perplexity, and stronger downstream task performance than standard attention, MQA/GQA, and MLA. At the 2.5B scale, LRKV outperforms standard attention while using roughly half the KV cache, and reaches equivalent model quality with up to \textbf{20-25\% less training compute} when measured in cumulative FLOPs. To explain these gains, we analyze attention head structure in operator space and show that LRKV preserves nearly all functional head diversity relative to standard attention, whereas more aggressive KV-sharing mechanisms rely on compensatory query specialization. Together, these results establish LRKV as a practical and effective attention mechanism for scaling Transformer pretraining under memory- and compute-constrained regimes. | [üîó Paper](https://arxiv.org/abs/2601.11471v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation](https://arxiv.org/abs/2601.11522v1) | Ruiheng Zhang, Jingfeng Yao, Huangxuan Zhao, Hao Yan, Xiao He, Lei Chen, Zhou Wei, Yong Luo, Zengmao Wang, Lefei Zhang, Dacheng Tao, Bo Du | 2026-01-16 | Diffusion Models | Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX. | [üîó Paper](https://arxiv.org/abs/2601.11522v1) |
| [Halide diffusion in mixed-halide perovskites and heterojunctions](https://arxiv.org/abs/2601.11503v1) | Viren Tyagi, Mike Pols, Geert Brocks, Shuxia Tao | 2026-01-16 | Diffusion Models | Migration of halide defects guides ion transport in metal halide perovskites and controls the kinetics of halide mixing and phase separation. We study the diffusion of halide vacancies and interstitials in \ce{CsPb(I_{x}Br_{1-x})_{3}} and \ce{CsPbI_{3}}/\ce{CsPbBr_{3}} heterojunctions by molecular dynamics simulations using neural network potentials trained on density functional theory calculations. We observe enhanced diffusion of both vacancies and interstitials in the mixed halide compounds compared to the single halide ones, as well as a difference in mobility between Br and I ions in the mixed compound. Diffusion across heterojunctions is governed by the interface structure, where a Br-rich interface blocks migration of vacancies in particular, but an I-rich interface is permeable. | [üîó Paper](https://arxiv.org/abs/2601.11503v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Generative Scenario Rollouts for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.11475v1) | Rajeev Yasarla, Deepti Hegde, Shizhong Han, Hsin-Pai Cheng, Yunxiao Shi, Meysam Sadeghigooghari, Shweta Mahajan, Apratim Bhattacharyya, Litian Liu, Risheek Garrepalli, Thomas Svantesson, Fatih Porikli, Hong Cai | 2026-01-16 | RLHF, Model Evaluation, Multimodal AI, Responsible AI, Prompt Engineering | Vision-Language-Action (VLA) models are emerging as highly effective planning models for end-to-end autonomous driving systems. However, current works mostly rely on imitation learning from sparse trajectory annotations and under-utilize their potential as generative models. We propose Generative Scenario Rollouts (GeRo), a plug-and-play framework for VLA models that jointly performs planning and generation of language-grounded future traffic scenes through an autoregressive rollout strategy. First, a VLA model is trained to encode ego vehicle and agent dynamics into latent tokens under supervision from planning, motion, and language tasks, facilitating text-aligned generation. Next, GeRo performs language-conditioned autoregressive generation. Given multi-view images, a scenario description, and ego-action questions, it generates future latent tokens and textual responses to guide long-horizon rollouts. A rollout-consistency loss stabilizes predictions using ground truth or pseudo-labels, mitigating drift and preserving text-action alignment. This design enables GeRo to perform temporally consistent, language-grounded rollouts that support long-horizon reasoning and multi-agent planning. On Bench2Drive, GeRo improves driving score and success rate by +15.7 and +26.2, respectively. By integrating reinforcement learning with generative rollouts, GeRo achieves state-of-the-art closed-loop and open-loop performance, demonstrating strong zero-shot robustness. These results highlight the promise of generative, language-conditioned reasoning as a foundation for safer and more interpretable end-to-end autonomous driving. | [üîó Paper](https://arxiv.org/abs/2601.11475v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492v1) | Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu | 2026-01-16 | Multimodal AI, Optimization | Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports. | [üîó Paper](https://arxiv.org/abs/2601.11492v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [A Probabilistic Approach to Trajectory-Based Optimal Experimental Design](https://arxiv.org/abs/2601.11473v1) | Ahmed Attia | 2026-01-16 | Optimization | We present a novel probabilistic approach for optimal path experimental design. In this approach a discrete path optimization problem is defined on a static navigation mesh, and trajectories are modeled as random variables governed by a parametric Markov policy. The discrete path optimization problem is then replaced with an equivalent stochastic optimization problem over the policy parameters, resulting in an optimal probability model that samples estimates of the optimal discrete path. This approach enables exploration of the utility function's distribution tail and treats the utility function of the design as a black box, making it applicable to linear and nonlinear inverse problems and beyond experimental design. Numerical verification and analysis are carried out by using a parameter identification problem widely used in model-based optimal experimental design. | [üîó Paper](https://arxiv.org/abs/2601.11473v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [ShapeR: Robust Conditional 3D Shape Generation from Casual Captures](https://arxiv.org/abs/2601.11514v1) | Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins, Daniel DeTone, Pierre Moulon, Qirui Wu, Zhengqin Li, Julian Straub, Richard Newcombe, Jakob Engel | 2026-01-16 | Training & Evaluation, Model Evaluation, Multimodal AI, Responsible AI, LLM | Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art. | [üîó Paper](https://arxiv.org/abs/2601.11514v1) |
| [Industry Influence in High-Profile Social Media Research](https://arxiv.org/abs/2601.11507v1) | Joseph Bak-Coleman, Jevin West, Cailin O'Connor, Carl T. Bergstrom | 2026-01-16 | Training & Evaluation | To what extent is social media research independent from industry influence? Leveraging openly available data, we show that half of the research published in top journals has disclosable ties to industry in the form of prior funding, collaboration, or employment. However, the majority of these ties go undisclosed in the published research. These trends do not arise from broad scientific engagement with industry, but rather from a select group of scientists who maintain long-lasting relationships with industry. Undisclosed ties to industry are common not just among authors, but among reviewers and academic editors during manuscript evaluation. Further, industry-tied research garners more attention within the academy, among policymakers, on social media, and in the news. Finally, we find evidence that industry ties are associated with a topical focus away from impacts of platform-scale features. Together, these findings suggest industry influence in social media research is extensive, impactful, and often opaque. Going forward there is a need to strengthen disclosure norms and implement policies to ensure the visibility of independent research, and the integrity of industry supported research. | [üîó Paper](https://arxiv.org/abs/2601.11507v1) |
| [On the Probability of First Success in Differential Evolution: Hazard Identities and Tail Bounds](https://arxiv.org/abs/2601.11499v1) | Dimitar Nedanovski, Svetoslav Nenov, Dimitar Pilev | 2026-01-16 | Training & Evaluation | We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\Prob(E_t\mid\mathcal F_{t-1})$. This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event.   For the L-SHADE algorithm with current-to-$p$best/1 mutation, we construct a checkable algorithmic witness event $\mathcal L_t$ under which the conditional hazard admits an explicit lower bound depending only on sampling rules, population size, and crossover statistics. This separates theoretical constants from empirical event frequencies and explains why worst-case constant-hazard bounds are typically conservative.   We complement the theory with a Kaplan--Meier survival analysis on the CEC2017 benchmark suite . Across functions and budgets, we identify three distinct empirical regimes: (i) strongly clustered success, where hitting times concentrate in short bursts; (ii) approximately geometric tails, where a constant-hazard model is accurate; and (iii) intractable cases with no observed hits within the evaluation horizon. The results show that while constant-hazard bounds provide valid tail envelopes, the practical behavior of L-SHADE is governed by burst-like transitions rather than homogeneous per-generati on success probabilities. | [üîó Paper](https://arxiv.org/abs/2601.11499v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Do explanations generalize across large reasoning models?](https://arxiv.org/abs/2601.11517v1) | Koyena Pal, David Bau, Chandan Singh | 2026-01-16 | Prompt Engineering, RLHF | Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization. | [üîó Paper](https://arxiv.org/abs/2601.11517v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Building Production-Ready Probes For Gemini](https://arxiv.org/abs/2601.11516v1) | J√°nos Kram√°r, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy | 2026-01-16 | Responsible AI, LLM, Model Evaluation | Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architecture that handle this long-context distribution shift.   We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant shifts, including multi-turn conversations, static jailbreaks, and adaptive red teaming. Our results demonstrate that while multimax addresses context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes.   These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google's frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible. | [üîó Paper](https://arxiv.org/abs/2601.11516v1) |
| [QUPID: A Partitioned Quantum Neural Network for Anomaly Detection in Smart Grid](https://arxiv.org/abs/2601.11500v1) | Hoang M. Ngo, Tre' R. Jeter, Jung Taek Seo, My T. Thai | 2026-01-16 | Responsible AI, Model Evaluation | Smart grid infrastructures have revolutionized energy distribution, but their day-to-day operations require robust anomaly detection methods to counter risks associated with cyber-physical threats and system faults potentially caused by natural disasters, equipment malfunctions, and cyber attacks. Conventional machine learning (ML) models are effective in several domains, yet they struggle to represent the complexities observed in smart grid systems. Furthermore, traditional ML models are highly susceptible to adversarial manipulations, making them increasingly unreliable for real-world deployment. Quantum ML (QML) provides a unique advantage, utilizing quantum-enhanced feature representations to model the intricacies of the high-dimensional nature of smart grid systems while demonstrating greater resilience to adversarial manipulation. In this work, we propose QUPID, a partitioned quantum neural network (PQNN) that outperforms traditional state-of-the-art ML models in anomaly detection. We extend our model to R-QUPID that even maintains its performance when including differential privacy (DP) for enhanced robustness. Moreover, our partitioning framework addresses a significant scalability problem in QML by efficiently distributing computational workloads, making quantum-enhanced anomaly detection practical in large-scale smart grid environments. Our experimental results across various scenarios exemplifies the efficacy of QUPID and R-QUPID to significantly improve anomaly detection capabilities and robustness compared to traditional ML approaches. | [üîó Paper](https://arxiv.org/abs/2601.11500v1) |
| [The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents](https://arxiv.org/abs/2601.11496v1) | Eilam Shapira, Roi Reichart, Moshe Tennenholtz | 2026-01-16 | Responsible AI, Autonomous Agents | The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the "Poisoned Apple" effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator's choice of market design in their favor. This strategic release improves the releaser's welfare at the expense of their opponent and the regulator's fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities. | [üîó Paper](https://arxiv.org/abs/2601.11496v1) |
| [Extractive summarization on a CMOS Ising machine](https://arxiv.org/abs/2601.11491v1) | Ziqing Zeng, Abhimanyu Kumar, Chris H. Kim, Ulya R. Karpuzcu, Sachin S. Sapatnekar | 2026-01-16 | Responsible AI, Model Evaluation, Optimization | Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices. | [üîó Paper](https://arxiv.org/abs/2601.11491v1) |
| [CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation](https://arxiv.org/abs/2601.11488v1) | Vanshali Sharma, Andrea Mia Bejar, Gorkem Durak, Ulas Bagci | 2026-01-16 | Responsible AI, Training & Evaluation, Model Evaluation, Multimodal AI | In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts. To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG. The modules test: (i) Writing Style Generalizability (WSG) via LLM-based rephrasing; (ii) Synthetic Error Injection (SEI) at graded severities; and (iii) Metrics-vs-Expert correlation (MvE) using clinician ratings on 175 "disagreement" cases. Eight widely used metrics (BLEU, ROUGE, METEOR, BERTScore-F1, F1-RadGraph, RaTEScore, GREEN Score, CRG) are studied across seven LLMs built on a CT-CLIP encoder. Using our novel framework, we found that lexical NLG metrics are highly sensitive to stylistic variations; GREEN Score aligns best with expert judgments (Spearman~0.70), while CRG shows negative correlation; and BERTScore-F1 is least sensitive to factual error injection. We will release the framework, code, and allowable portion of the anonymized evaluation data (rephrased/error-injected CT reports), to facilitate reproducible benchmarking and future metric development. | [üîó Paper](https://arxiv.org/abs/2601.11488v1) |
| [Fundamental Properties of Novae in M31](https://arxiv.org/abs/2601.11476v1) | Allen W. Shafter, Kamil Hornoch | 2026-01-16 | Responsible AI, Model Evaluation | The peak luminosities and rates of decline for a large sample of novae recently published by Clark et al. have been analyzed using the Yaron et al. nova models to estimate fundamental properties of the M31 nova population. The apparent white dwarf (WD) mass distribution is approximately Gaussian with a mean $\langle M_\mathrm{WD} \rangle = 1.16\pm0.14~M_{\odot}$. When corrected for recurrence-time bias, the mean drops to $\langle M_\mathrm{WD} \rangle = 1.07~M_\odot$. The average WD mass of the M31 nova sample is found to be remarkably similar to that found by Shara et al. in their study of 82 Galactic novae, but $\sim0.15~M_\odot$ more massive than the mean recently determined by Schaefer in his comprehensive study of more than 300 systems. As expected, the average WD mass for the recurrent novae included in the M31 sample, $\langle M_\mathrm{WD} \rangle = 1.33\pm0.08~M_{\odot}$, is significantly higher than that for novae generally. Other parameters of interest, such as the accretion rate, velocity of the ejecta, and the predicted recurrence time, are characterized by skewed distributions with large spreads about means of $\langle \log \dot M ~(M_\odot~\mathrm{yr}^{-1}) \rangle \simeq -9.27$, $\langle V_\mathrm{max} \rangle \simeq 1690~\mathrm{km~s}^{-1}$, and $\langle \log P_\mathrm{rec}~\mathrm{(yr)} \rangle \simeq 4.39$, respectively. The role of hibernation in affecting the $\dot M$ and $P_\mathrm{rec}$ distributions is briefly discussed. Finally, the nova properties were studied as a function of apparent position (isophotal radius) in M31, with the preponderance of evidence failing to establish any clear dependence on stellar population. | [üîó Paper](https://arxiv.org/abs/2601.11476v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [X-ray Polarization of the Intrabinary Shock in Redback Pulsar J1723$-$2837](https://arxiv.org/abs/2601.11521v1) | Andrew G. Sullivan, Jack T. Dinsmore, Roger W. Romani | 2026-01-16 | General AI | The intrabinary shocks (IBS) in spider pulsars emit non-thermal synchrotron X-rays from accelerated electrons and positrons in the shocked pulsar wind, likely energized by magnetic reconnection. The double-peaked X-ray light curves from these shocks have been well characterized in several spider systems. In this paper, we analyze Imaging X-ray Polarimetry Explorer (IXPE) observations of the redback pulsar J1723$-$2837 to examine the expected synchrotron polarization. Using advanced extraction methods that include spatial, temporal, and particle background weights, we constrain the polarization of the IBS. We compare different models for the magnetic field in the radiation zone and find that the best fit prefers a striped pulsar wind model over other polarized models, with maximum polarization degree of the IBS emission component $Œ†_{\rm IBS}=36^{+16}_{-15}\%$, in addition to an unpolarized non-IBS component. Since this is only 2.4$œÉ$, we cannot claim strong preference over an unpolarized model; we report a $99\%$ confidence level upper limit on the total polarization of both IBS and non-IBS components $Œ†_{99}<36\%$, which is improved over the $50\%$ limit obtained in previous work. The best-fit polarization of the IBS component is consistent with numerical simulations. Detailed tests of such models are accessible to future measurements. | [üîó Paper](https://arxiv.org/abs/2601.11521v1) |
| [Empirical Coordination over Markov Channel with Independent Source](https://arxiv.org/abs/2601.11520v1) | Mengyuan Zhao, Ma√´l Le Treust, Tobias J. Oechtering | 2026-01-16 | General AI | We study joint source-channel coding over Markov channels through the empirical coordination framework. More specifically, we aim at determining the empirical distributions of source and channel symbols that can be induced by a coding scheme. We consider strictly causal encoders that generate channel inputs, without access to the past channel states, henceforth driving the current Markov state evolution. Our main result is the single-letter inner and outer bounds of the set of achievable joint distributions, coordinating all the symbols in the network. To establish the inner bound, we introduce a new notion of typicality, the input-driven Markov typicality, and develop its fundamental properties. Contrary to the classical block-Markov coding schemes that rely on blockwise independence for discrete memoryless channels, our analysis directly exploits the Markov channel structure and improves beyond the independence-based arguments. | [üîó Paper](https://arxiv.org/abs/2601.11520v1) |
| [Vacuum-selected timescales in driven Josephson systems](https://arxiv.org/abs/2601.11519v1) | Sebastian Allende, David Galvez-Poblete | 2026-01-16 | General AI | In this work, we demonstrate that the intrinsic timescale of a Josephson junction can be controlled through dynamical vacuum selection. By applying a Kapitza-like high-frequency drive to the system, the effective Josephson potential is reshaped, allowing for the stabilization of inphase or antiphase configuration. As a result, the Josephson plasma frequency, that is, the clock frequency of the junction, becomes a tunable property of the selected vacuum. Our findings establish a vacuum-controlled Josephson clock principle, in which the dynamical vacuum acts as an internal reference that fixes the operational timescale of Josephson oscillations, rather than this scale being imposed externally. | [üîó Paper](https://arxiv.org/abs/2601.11519v1) |
| [How Long Is a Piece of String? A Brief Empirical Analysis of Tokenizers](https://arxiv.org/abs/2601.11518v1) | Jonathan Roberts, Kai Han, Samuel Albanie | 2026-01-16 | General AI | Frontier LLMs are increasingly utilised across academia, society and industry. A commonly used unit for comparing models, their inputs and outputs, and estimating inference pricing is the token. In general, tokens are used as a stable currency, assumed to be broadly consistent across tokenizers and contexts, enabling direct comparisons. However, tokenization varies significantly across models and domains of text, making naive interpretation of token counts problematic. We quantify this variation by providing a comprehensive empirical analysis of tokenization, exploring the compression of sequences to tokens across different distributions of textual data. Our analysis challenges commonly held heuristics about token lengths, finding them to be overly simplistic. We hope the insights of our study add clarity and intuition toward tokenization in contemporary LLMs. | [üîó Paper](https://arxiv.org/abs/2601.11518v1) |
| [Spectroscopic confirmation of a large and luminous galaxy with weak emission lines at $\mathbf{z = 13.53}$](https://arxiv.org/abs/2601.11515v1) | Callum T. Donnan, Derek J. McLeod, Ross J. McLure, James S. Dunlop, Fergus Cullen, Mark Dickinson, Pablo Arrabal Haro, Anthony J. Taylor, Cecilia Bondestam, Feng-Yuan Liu, Karla Z. Arellano-C√≥rdova, Laia Barrufet, Ryan Begley, Adam C. Carnall, Hanna Golawska, Ho-Hin Leung, Dirk Scholte, Thomas M. Stanton | 2026-01-16 | General AI | We present JWST/NIRSpec PRISM observations of a robust galaxy candidate at $z\simeq14$, selected from pure-parallel NIRCam imaging; PAN-z14-1. The NIRSpec spectrum allows confirmation of this source at $z_{\rm spec}=13.53^{+0.05}_{-0.06}$ through modeling of the Lyman-$Œ±$ break. PAN-z14-1 is the fourth most distant galaxy known to date and is extremely luminous ($M_{\rm UV}=-20.6\pm0.2$), with a blue UV-continuum slope ($Œ≤=-2.26\pm0.08$) and a large physical size ($r_{\rm c}=233\pm10\, \rm pc$). We fail to detect any rest-frame UV emission lines at $\geq 2œÉ$ significance, with upper limits sufficiently constraining to exclude the possibility of strong line emission. In terms of its physical properties, PAN-z14-1 is remarkably similar to the previously confirmed $z_{\rm spec}=14.18$ galaxy GS-z14-0. The lack of strong emission lines and large physical size is consistent with an emerging picture of two potentially distinct galaxy populations at $z>10$, distinguished by star-formation rate surface density. In this scenario, PAN-z14-1 is a second example of a ``normal'', extended, luminous, star-forming galaxy at $z \simeq 14$, and differs markedly from the other class of extremely compact galaxies with strong emission lines recently uncovered at extreme redshifts with JWST. These results highlight the importance of further spectroscopic confirmation of $z>10$ galaxy candidates in order to fully understand the diversity of properties displayed by the first galaxies. | [üîó Paper](https://arxiv.org/abs/2601.11515v1) |
| [Capacity Constraints Make Admissions Processes Less Predictable](https://arxiv.org/abs/2601.11513v1) | Evan Dong, Nikhil Garg, Sarah Dean | 2026-01-16 | General AI | Machine learning models are often used to make predictions about admissions process outcomes, such as for colleges or jobs. However, such decision processes differ substantially from the conventional machine learning paradigm. Because admissions decisions are capacity-constrained, whether a student is admitted depends on the other applicants who apply. We show how this dependence affects predictive performance even in otherwise ideal settings. Theoretically, we introduce two concepts that characterize the relationship between admission function properties, machine learning representation, and generalization to applicant pool distribution shifts: instability, which measures how many existing decisions can change when a single new applicant is introduced; and variability, which measures the number of unique students whose decisions can change. Empirically, we illustrate our theory on individual-level admissions data from the New York City high school matching system, showing that machine learning performance degrades as the applicant pool increasingly differs from the training data. Furthermore, there are larger performance drops for schools using decision rules that are more unstable and variable. Our work raises questions about the reliability of predicting individual admissions probabilities. | [üîó Paper](https://arxiv.org/abs/2601.11513v1) |
| [Krull-Gabriel dimension of Skew group algebras](https://arxiv.org/abs/2601.11512v1) | Shantanu Sardar | 2026-01-16 | General AI | For an algebraically closed field K, let G be a finite abelian group of K-linear automorphisms of a finite-dimensional algebra A and AG is the associated skew group algebra. The author with S. Trepode and A. G. Chaio introduced the notion of a Galois semi-covering functor to study the irreducible morphisms over skew group algebras. In this paper, we establish a Galois semi-covering functor between the morphism categories as well as the functor categories over the algebras A and AG and prove that their Krull-Gabriel dimension are equal. This computation confirms Prests conjecture on the finiteness of Krull-Gabriel dimension and Schroers conjecture on its connection with the stable rank (the least stabilized radical power) over skew gentle algebras. Moreover, we determine all posible stable ranks for (skew) Brauer graph algebras. | [üîó Paper](https://arxiv.org/abs/2601.11512v1) |
| [On a C*-Diagonal Generated by the Toric Code](https://arxiv.org/abs/2601.11511v1) | Danilo Polo Ojito, Emil Prodan | 2026-01-16 | General AI | We study the abelian sub-C*-algebra of the CAR algebra generated by the start and face opertors of Kitaev's toric code. We show that it is a C*-diagonal equivalent to the canonical diagonal of the CAR algebra. | [üîó Paper](https://arxiv.org/abs/2601.11511v1) |
| [Applying Formal Methods Tools to an Electronic Warfare Codebase (Experience report)](https://arxiv.org/abs/2601.11510v1) | Letitia W. Li, Denley Lam, Vu Le, Daniel Mitchell, Mark J. Gerken, Robert B. Ross | 2026-01-16 | General AI | While using formal methods offers advantages over unit testing, their steep learning curve can be daunting to developers and can be a major impediment to widespread adoption. To support integration into an industrial software engineering workflow, a tool must provide useful information and must be usable with relatively minimal user effort. In this paper, we discuss our experiences associated with identifying and applying formal methods tools on an electronic warfare (EW) system with stringent safety requirements and present perspectives on formal methods tools from EW software engineers who are proficient in development yet lack formal methods training. In addition to a difference in mindset between formal methods and unit testing approaches, some formal methods tools use terminology or annotations that differ from their target programming language, creating another barrier to adoption. Input/output contracts, objects in memory affected by a function, and loop invariants can be difficult to grasp and use. In addition to usability, our findings include a comparison of vulnerabilities detected by different tools. Finally, we present suggestions for improving formal methods usability including better documentation of capabilities, decreased manual effort, and improved handling of library code. | [üîó Paper](https://arxiv.org/abs/2601.11510v1) |
| [ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes](https://arxiv.org/abs/2601.11508v1) | Emily Steiner, Jianhao Zheng, Henry Howard-Jenkins, Chris Xie, Iro Armeni | 2026-01-16 | General AI | Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes. | [üîó Paper](https://arxiv.org/abs/2601.11508v1) |
| [MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management](https://arxiv.org/abs/2601.11505v1) | Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston | 2026-01-16 | General AI | Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets. | [üîó Paper](https://arxiv.org/abs/2601.11505v1) |
| [Visualization of Tunable Electronic Structure of Monolayer TaIrTe$_4$](https://arxiv.org/abs/2601.11504v1) | Sandy Adhitia Ekahana, Aalok Tiwari, Souvik Sasmal, Zefeng Cai, Ravi Kumar Bandapelli, I-Hsuan Kao, Jian Tang, Chenbo Min, Tiema Qian, Kenji Watanabe, Takashi Taniguchi, Ni Ni, Qiong Ma, Chris Jozwiak, Eli Rotenberg, Aaron Bostwick, Simranjeet Singh, Noa Marom, Jyoti Katoch | 2026-01-16 | General AI | Monolayer TaIrTe$_4$ has emerged as an attractive material platform to study intriguing phenomena related to topology and strong electron correlations. Recently, strong interactions have been demonstrated to induce strain and dielectric screening tunable topological phases such as quantum spin Hall insulator (QSHI), trivial insulator, higher-order topological insulator, and metallic phase, in the ground state of monolayer TaIrTe$_4$. Moreover, charge dosing has been demonstrated to convert the QSHI into a dual QSHI state. Although the band structure of monolayer TaIrTe$_4$ is central to interpreting its topological phases in transport experiments, direct experimental access to its intrinsic electronic structure has so far remained elusive. Here we report direct measurements of the monolayer TaIrTe$_4$ band structure using spatially resolved micro-angle-resolved photoemission spectroscopy (microARPES) with micrometre-scale resolution. The observed dispersions show quantitative agreement with density functional theory calculations using the Heyd-Scuseria-Ernzerhof hybrid functional, establishing the insulating ground state and revealing no evidence for strong electronic correlations. We further uncover a pronounced electron-hole asymmetry in the doping response. Whereas hole doping is readily induced by electrostatic gating, attempts to introduce electrons via gating or alkali metal deposition do not yield a rigid upward shift of the Fermi level. Fractional charge calculations demonstrate that added electrons instead drive band renormalization and shrink the band gap. Taken together, our experimental and theoretical results identify the microscopic mechanism by which induced charges reshape the band topology of monolayer TaIrTe$_4$, showing that doping can fundamentally alter the electronic structure beyond the rigid band behaviour that is typically assumed. | [üîó Paper](https://arxiv.org/abs/2601.11504v1) |
| [Coding Schemes for the Noisy Torn Paper Channel](https://arxiv.org/abs/2601.11501v1) | Frederik Walter, Maria Abu-Sini, Nils Weinhardt, Antonia Wachter-Zeh | 2026-01-16 | General AI | To make DNA a suitable medium for archival data storage, it is essential to consider the decay process of the strands observed in DNA storage systems. This paper studies the decay process as a probabilistic noisy torn paper channel (TPC), which first corrupts the bits of the transmitted sequence in a probabilistic manner by substitutions, then breaks the sequence into a set of noisy unordered substrings. The present work devises coding schemes for the noisy TPC by embedding markers in the transmitted sequence. We investigate the use of static markers and markers connected to the data in the form of hash functions. These two tools have also been recently exploited to tackle the noiseless TPC. Simulations show that static markers excel at higher substitution probabilities, while data-dependent markers are superior at lower noise levels. Both approaches achieve reconstruction rates exceeding $99\%$ with no false decodings observed, primarily limited by computational resources. | [üîó Paper](https://arxiv.org/abs/2601.11501v1) |
| [Convergence Properties of Good Quantum Codes for Classical Communication](https://arxiv.org/abs/2601.11498v1) | Alptug Aytekin, Mohamed Nomeir, Lei Hu, Sennur Ulukus | 2026-01-16 | General AI | An important part of the information theory folklore had been about the output statistics of codes that achieve the capacity and how the empirical distributions compare to the output distributions induced by the optimal input in the channel capacity problem. Results for a variety of such empirical output distributions of good codes have been known in the literature, such as the comparison of the output distribution of the code to the optimal output distribution in vanishing and non-vanishing error probability cases. Motivated by these, we aim to achieve similar results for the quantum codes that are used for classical communication, that is the setting in which the classical messages are communicated through quantum codewords that pass through a noisy quantum channel. We first show the uniqueness of the optimal output distribution, to be able to talk more concretely about the optimal output distribution. Then, we extend the vanishing error probability results to the quantum case, by using techniques that are close in spirit to the classical case. We also extend non-vanishing error probability results to the quantum case on block codes, by using the second-order converses for such codes based on hypercontractivity results for the quantum generalized depolarizing semi-groups. | [üîó Paper](https://arxiv.org/abs/2601.11498v1) |
| [Global $C^{1,Œ±}$-Regularity for Musielak-Orlicz Equations in Divergence Form](https://arxiv.org/abs/2601.11495v1) | Hlel Missaoui | 2026-01-16 | General AI | In this paper, we establish global $C^{1,Œ±}$-regularity for bounded generalized solutions of elliptic equations in divergence form with Musielak-Orlicz growth and subject to Dirichlet or Neumann boundary conditions. In fact, our findings extend and generalize several important regularity results in cases of special attention such as variable exponent spaces, Orlicz spaces, and some $(p,q)$ situations. We also point out new conditions in the analysis that focus on the interplay between non-standard growth conditions and the boundary behavior in such generalized examples. | [üîó Paper](https://arxiv.org/abs/2601.11495v1) |
| [Conformal Symmetry and the Thermal Effects of Acceleration in Classical Physic](https://arxiv.org/abs/2601.11494v1) | Timothy H Boyer | 2026-01-16 | General AI | An accelerating Rindler frame in Minkowski spacetime acting for a finite time interval is used to carry a box of particles or waves between two relativistic inertial frames. The finite spatial extent of the box allows treatment of the equations of motion for particles or for waves, while the Rindler acceleration provides a substitute for scattering to test for thermal equilibrium. In the case of equilibrium for relativist particles, the Juttner distribution is derived. For relativistic waves, a full derivation of the Planck spectrum including zero-point radiation is obtained within classical theory. For relativistic waves, relativistic behavior and conformal symmetry are crucial. It is emphasized that the classical two-point correlation function for classical zero-point radiation depends upon the geodesic separation between the spacetime points and is independent of the coordinate system choice. The classical point of view here does not give any support for the idea that a system in uniform acceleration through classical zero-point radiation finds a thermal system. | [üîó Paper](https://arxiv.org/abs/2601.11494v1) |
| [Efficient error estimators for Generalized Nystr√∂m](https://arxiv.org/abs/2601.11493v1) | Lorenzo Lazzarino, Katherine J. Pearce, Nathaniel Pritchard | 2026-01-16 | General AI | Randomized algorithms in numerical linear algebra have proven to be effective in ameliorating issues of scalability when working with large matrices, efficiently producing accurate low-rank approximations. A key remaining challenge, however, is to efficiently assess the approximation accuracy of randomized methods without additional expensive matrix accesses. Recent work has addressed this issue by deriving fast leave-one-out error estimators for the randomized SVD and Nystr√∂m decomposition, enabling accurate error estimation with no additional matrix accesses. In this work, we extend the leave-one-out framework to the generalized Nystr√∂m decomposition, an approach that can be applied to general rectangular matrices. We do this by deriving three new leave-one-out error estimators and validating their effectiveness through numerical experiments. | [üîó Paper](https://arxiv.org/abs/2601.11493v1) |
| [Quasi-unitial Inner Kan Spaces](https://arxiv.org/abs/2601.11489v1) | Trygve Poppe Oldervoll | 2026-01-16 | General AI | We show that semi-simplicial spaces that i) admit inner horn fillers up to homotopy and ii) possess units in a weak sense provide a viable model for $\infty$-categories. The existence of units can be expressed through various quasi-unitality conditions, and we compare the natural generalization of three such conditions found in the literature. This work is motivated by applications in Floer homotopy theory. | [üîó Paper](https://arxiv.org/abs/2601.11489v1) |
| [Space-Optimal, Computation-Optimal, Topology-Agnostic, Throughput-Scalable Causal Delivery through Hybrid Buffering](https://arxiv.org/abs/2601.11487v1) | Paulo S√©rgio Almeida | 2026-01-16 | General AI | Message delivery respecting causal ordering (causal delivery) is one of the most classic and widely useful abstraction for inter-process communication in a distributed system. Most approaches tag messages with causality information and buffer them at the receiver until they can be safely delivered. Except for specific approaches that exploit communication topology, therefore not generally applicable, they incur a metadata overhead which is prohibitive for a large number of processes. Much less used are the approaches that enforce causal order by buffering messages at the sender, until it is safe to release them to the network, as the classic algorithm has too many drawbacks. In this paper, first we discuss the limitations of sender-only buffering approaches and introduce the Sender Permission to Send (SPS) enforcement strategy, showing that SPS + FIFO implies Causal. We analyze a recent sender-buffering algorithm, Cykas, which follows SPS + FIFO, albeit very conservatively, pointing out throughput scalability and liveness issues. Then, we introduce a novel SPS + FIFO based algorithm, which adopts a new hybrid approach: enforcing causality by combining sender-buffering to enforce SPS and receiver-buffering to enforce FIFO. The algorithm overcomes limitations of sender-only buffering, and achieves effectively constant metadata size per message. By a careful choice of data-structures, the algorithm is also computationally-optimal, with amortized effectively constant processing overhead. As far as we know, there is no other topology-agnostic causal delivery algorithm with these properties. | [üîó Paper](https://arxiv.org/abs/2601.11487v1) |
| [Algorithmic aspects of Newman polynomials and their divisors](https://arxiv.org/abs/2601.11486v1) | Musbahu Idris, Jean-Marc Sac-√âp√©e | 2026-01-16 | General AI | We study the problem of determining which integer polynomials divide Newman polynomials. In this vein, we first give results concerning the $8438$ known polynomials with Mahler measure less than $1.3$. We then exhibit a list of polynomials that divide no Newman polynomial. In particular, we show that a degree-10 polynomial of Mahler measure \text{approximately} 1.419404632 divides no Newman polynomial, thereby improving the best known upper bound for any universal constant $œÉ$, if it exists, such that every integer polynomial of Mahler measure less than $œÉ$ divides a Newman polynomial. Finally, letting $l(x)$ denote Lehmer's polynomial, we explicitly construct Newman polynomials divisible by $l(x)^2$ with degrees up to $150$, and show that no Newman polynomial is divisible by $l(x)^3$ up to degree $160$. | [üîó Paper](https://arxiv.org/abs/2601.11486v1) |
| [Analytical approaches to the study of the phase of the visibility function](https://arxiv.org/abs/2601.11485v1) | S. V. Chernov | 2026-01-16 | General AI | In radio interferometric observations, the main source of information is the complex visibility function, which includes amplitude and phase. In this paper, the dependence of the phase of the visibility function on the base projection is investigated when used in radio interferometry with space bases up to six Earth diameters. The dependence of the phase of the visibility function on the projection of the base and direction is obtained. It is shown that for small values of the base projections, this dependence has a universal character and is consistent with the results of numerical magnetohydrodynamic models. | [üîó Paper](https://arxiv.org/abs/2601.11485v1) |
| [Source-Driven Tails in Kerr Spacetime: Nonlinear effects in Late-Time Behavior](https://arxiv.org/abs/2601.11484v1) | Som Dev Bishoyi, Subir Sabharwal, Gaurav Khanna | 2026-01-16 | General AI | We present the long-duration time-domain simulations of scalar-field tails in Kerr spacetimes driven by   \emph{outgoing} multipolar sources. Extending the recent work in the literature from Schwarzschild to rotating black holes, we evolve   sources with $\ell'=\{0,1,2,3,4\}$ on backgrounds with dimensionless spin $a/M=\{0.0, 0.8, 1.0\}$ and extract the late-time decay rates of   measured modes $\ell\le4$ for a nonlinearity-inspired outgoing source with a $1/r^2$ fall-off. In all cases we find the inverse   power-law index $p_{\ell\ell'}$ to be larger than the source-free Price law values by one unit, i.e. $p^{\text{sourced}}_{\ell\ell'} =   p^{\text{Price}}_{\ell\ell'} + 1$. We also include a power-law index value computation for a similar source-driven gravitational wave   case $(\ell,m)=(4,4)$ and confirm closely related results in the recent literature. | [üîó Paper](https://arxiv.org/abs/2601.11484v1) |
| [Tensor field tomography with attenuation and refraction: adjoint operators for the dynamic case and numerical experiments](https://arxiv.org/abs/2601.11483v1) | Lukas Vierus, Thomas Schuster, Bernadette Hahn | 2026-01-16 | General AI | This article is concerned with tensor field tomography in a fairly general setting, that takes refraction, attenuation and time-dependence of tensor fields into account. The mathematical model is given by attenuated ray transforms of the fields along geodesic curves corresponding to a Riemannian metric that is defined by the index of refraction. The data are given at the boundary tangent bundle of the domain and it is well-known that they can be characterized as boundary data of a transport equation turning tensor field tomography into an inverse source problem. This way the adjoint of the forward mapping can be computed using the integral representation or, equivalently, associated to a dual transport equation. The article offers and proves two different representations for the adjoint mappings both in the dynamic and static case. The numerical implementation is demonstrated and evaluated for static fields using the damped Landweber method with Nesterov acceleration applied to both, the integral and PDE-based formulations. The transport equations are solved using a viscosity approximation. The error analysis reveals that the integral representation significantly outperforms PDE-based methods in terms of computational efficiency while achieving comparable reconstruction accuracy. The impact of noise and deviations from straight-line trajectories are investigated confirming improved accuracy if refraction is taken into account. We conclude that the inclusion of refraction to the forward model pays in spite of increased numerical cost. | [üîó Paper](https://arxiv.org/abs/2601.11483v1) |
| [A Genetic Algorithm for Generating Extreme Examples in Arithmetic Dynamics](https://arxiv.org/abs/2601.11482v1) | Benjamin Hutz | 2026-01-16 | General AI | We describe a genetic algorithm to find extreme examples in the arithmetic of dynamical systems. The algorithm is applied to four problems: small (non-zero) canonical heights, many rational preperiodic points, long rational cycles, and long rational tails. Data is provided for extreme examples generated for polynomials up to degree 13 and rational functions up to degree 5. This work significantly expands the known examples of extreme behavior for several of the conjectured behaviors in arithmetic dynamics and provides a foundation from which to begin a more advanced application of machine learning techniques in the creation of extreme examples for arithmetic dynamics. | [üîó Paper](https://arxiv.org/abs/2601.11482v1) |
| [Entanglement complexity of spanning pairs of lattice polygons](https://arxiv.org/abs/2601.11481v1) | Ryan Blair, Puttipong Pongtanapaisan, Christine E. Soteros | 2026-01-16 | General AI | We study the entanglement complexity of a system consisting of two simple-closed curves (self-avoiding polygons) that span a lattice tube, referred to as a 2SAP. 2SAPs are of interest as the first known model of confined ring polymers where the linking probability goes to 1 exponentially with the size of the system. Atapour et al proved this in 2010 by showing that all but exponentially few sufficiently large 2SAPs contain a pattern that guarantees the 2SAP is non-split, provided that the requisite pattern fits in the tube. This result was recently extended to all tubes sizes that admit non-trivial links. Here we develop and apply knot theory results to answer more general questions about the entanglement complexity of 2SAPs.   We first extend the 1992 concept of a good measure of knot complexity to a good measure, $F$, of spanning-link complexity for $k$-component links. Using tangle products, we show, for example, that the more complex the prime knot decomposition of any component of a given link type, the greater its $F$-measure. We then prove that all but exponentially few size $m$ 2SAPs have $F$ complexity that grows at least linearly in $m$ as $m\to \infty$. We establish that good measures of knot complexity yield good measures of spanning-link complexity. We also establish conditions whereby more general link invariants can yield good measures. In particular, we establish that measures based on several classical invariants are good measures by our definition, eg bridge number or the number of $p$-colourings.   Finally, we consider how the tube dimensions affect which links are embeddable as 2SAPs as well as geometric restrictions on the entanglement complexity of the embeddings. For example, we establish that there are two-component links that occur as 2SAPs in a given tube size only when one of the components is forced into a non-minimal bridge number conformation. | [üîó Paper](https://arxiv.org/abs/2601.11481v1) |
| [Heat, work, and fluctuations in a driven quantum resonator](https://arxiv.org/abs/2601.11480v1) | Riya Baruah, Pedro Portugal, Jun-Zhe Chen, Joachim Wabnig, Christian Flindt | 2026-01-16 | General AI | A central building block of a heat engine is the working fluid, which mediates the conversion of heat into work. In nanoscale heat engines, the working fluid can be a quantum system whose behavior and dynamics are non-classical. A particularly versatile realization is a quantum resonator, which allows for precise control and coupling to thermal reservoirs, making it an ideal platform for exploring quantum thermodynamic processes. Here, we investigate the thermodynamic properties of a driven quantum resonator whose temperature is controlled by modulating its natural frequency. We evaluate the work performed by the external drive and the resulting heat flow between the resonator and its environment, both within linear response and beyond. To further elucidate these processes, we determine the full distribution of photon exchanges between the resonator and its environment, characterized by its first few cumulants. Our results provide quantitative insights into the interplay between heat, work, and fluctuations, and may help in designing future heat engines. | [üîó Paper](https://arxiv.org/abs/2601.11480v1) |
| [Temporal Complexity and Self-Organization in an Exponential Dense Associative Memory Model](https://arxiv.org/abs/2601.11478v1) | Marco Cafiso, Paolo Paradisi | 2026-01-16 | General AI | Dense Associative Memory (DAM) models generalize the classical Hopfield model by incorporating n-body or exponential interactions that greatly enhance storage capacity. While the criticality of DAM models has been largely investigated, mainly within a statistical equilibrium picture, little attention has been devoted to the temporal self-organizing behavior induced by learning. In this work, we investigate the behavior of a stochastic exponential DAM (SEDAM) model through the lens of Temporal Complexity (TC), a framework that characterizes complex systems by intermittent transition events between order and disorder and by scale-free temporal statistics. Transition events associated with birth-death of neural avalanche structures are exploited for the TC analyses and compared with analogous transition events based on coincidence structures. We systematically explore how TC indicators depend on control parameters, i.e., noise intensity and memory load. Our results reveal that the SEDAM model exhibits regimes of complex intermittency characterized by nontrivial temporal correlations and scale-free behavior, indicating the spontaneous emergence of self-organizing dynamics. These regimes emerge in small intervals of noise intensity values, which, in agreement with the extended criticality concept, never shrink to a single critical point. Further, the noise intensity range needed to reach the critical region, where self-organizing behavior emerges, slightly decreases as the memory load increases. This study highlights the relevance of TC as a complementary framework for understanding learning and information processing in artificial and biological neural systems, revealing the link between the memory load and the self-organizing capacity of the network. | [üîó Paper](https://arxiv.org/abs/2601.11478v1) |
| [Galactic core-tail structure in BEC dark matter with Kapitza potential](https://arxiv.org/abs/2601.11477v1) | Itauany do Nascimento Barroso, Hermano Velten | 2026-01-16 | General AI | Recently, the experimental realization of a Kapitza potential in a Bose-Einstein Condensate (BEC) has been reported for the first time in literature, motivating further theoretical investigations of such system. At the same time, in the astrophysical context, BEC dark matter models have been widely studied as a possible phenomenological explanation for the dark matter phenomena. We model the galactic structure with an inner cored profile obtained from the ground state equilibrium solution of the Schroedinger-Poisson together with a Kapitza-BEC like interaction for the tail region. We find reasonable agreement of the model with representative galaxy rotation curves available in the SPARC catalogue. | [üîó Paper](https://arxiv.org/abs/2601.11477v1) |
| [Comonadic approach to pretorsion theories](https://arxiv.org/abs/2601.11472v1) | Elena Caviglia, Zurab Janelidze, Luca Mesiti | 2026-01-16 | General AI | We present a comonadic approach to pretorsion theories on semiexact categories, i.e. categories equipped with a closed ideal of null morphisms that admits all kernels and all cokernels. We first prove that bihereditary pretorsion theories are comonadic in a 2-dimensional sense over the 2-category of semiexact categories with naturally chosen 1-cells. We then extend the built pseudo-comonad to guarantee that all pretorsion theories are pseudo-coalgebras. But interestingly, not all pseudo-coalgebras are pretorsion theories. Rather, pseudo-coalgebras give a generalized notion of pretorsion theory. | [üîó Paper](https://arxiv.org/abs/2601.11472v1) |
| [Dvoretzky covering problem for general measures](https://arxiv.org/abs/2601.11470v1) | Roope Anttila, Markus Myllyoja | 2026-01-16 | General AI | We study the Dvoretzky covering problem for random covering sets driven by general Borel probability measures. As our main result, we solve the problem of covering analytic sets by random covering sets generated by arbitrary Borel probability measures on the real line. Prior to this work, a complete solution was not known for any singular measure. Our solution is potential theoretic and involves a generalisation of a notion of capacity in the work of Kahane, who solved the problem of covering compact sets in the classical setting where the random covering process is driven by the Lebesgue measure on the unit circle. One of our key innovations is a simple but powerful application of the Jankov-von Neumann uniformisation theorem, which we believe to have interest outside of this work.   In addition, we determine the critical exponent for the covering problem for polynomially decreasing sequences $(cn^{-t})_n$ for random covering sets driven by Borel probability measures on $\mathbb{R}^d$. At exactly the critical exponent, the covering property generally depends on the constant $c>0$, and as an application of our main result, we determine the critical constant for random covering sets driven by natural measures on strongly separated self-conformal sets on the line. The critical constant depends on the multifractal structure of the average densities of the measure, and the result is new even for the simplest case of the Hausdorff measure on the Cantor set. | [üîó Paper](https://arxiv.org/abs/2601.11470v1) |
| [KMT-2025-BLG-1616Lb: First Microlensing Bound Planet From DREAMS](https://arxiv.org/abs/2601.11469v1) | Hongjing Yang, Weicheng Zang, Yoon-Hyun Ryu, Takahiro Sumi, Jiyuan Zhang, Hongyu Li, Cheongho Han, Yuchen Tang, Qiyue Qian, Zhixing Li, Yuxin Shang, Xikai Shan, Shude Mao, Guillermo Damke, Alfredo Zenteno, Steve Heathcote, Konstantina Boutsia, Przemek Mr√≥z, Xiurui Zhao, Matthew Penny, Sean Terry, Patrick Tamburo, Timothy Cunningham, Quanzhi Ye, Eric W. Peng, Rachel Street, Katarzyna Kruszy≈Ñska, Etienne Bachelet, Yiannis Tsapras, Markus Hundertmark, Michael D. Albrow, Sun-Ju Chung, Andrew Gould, Kyu-Ha Hwang, Youn Kil Jung, In-Gu Shin, Yossi Shvartzvald, Jennifer C. Yee, Dong-Jin Kim, Chung-Uk Lee, Byeong-Gon Park, David P. Bennett, Ian A. Bond, Giuseppe Cataldo, Ryusei Hamada, Yuki Hirao, Asahi Idei, Shuma Makida, Shota Miyazaki, Tutumi Nagai, Togo Nagano, Seiya Nakayama, Mayu Nishio, Kansuke Nunota, Ryo Ogawa, Ryunosuke Oishi, Yui Okumoto, Nicholas J. Rattenbury, Yuki K. Satoh, Daisuke Suzuki, Motohide Tamura, Takuto Tamaoki, Hibiki Yama | 2026-01-16 | General AI | We present observations and analysis of the bound planetary microlensing event KMT-2025-BLG-1616. The planetary signal was captured by the Korea Microlensing Telescope Network (KMTNet) and the DECam Rogue Earths and Mars Survey (DREAMS). DREAMS's minute-cadence observations break the central/resonant degeneracy in the binary-lens models. The color of the faint source star ($I=22$) is measured from the DREAMS's $r - z$ color. The planetary system has a planet-host mass ratio of $q \sim 5 \times 10^{-4}$. A Bayesian analysis yields a host-star mass of $\sim 0.3\,M_\odot$, a planetary mass of $\sim 40\,M_{\oplus}$, a projected planet-host separation of $\sim 1.6~\mathrm{au}$, and a lens distance of $\sim 7.5~\mathrm{kpc}$. Based on the photometric precision achieved by DREAMS for this event, we simulate free-floating planet (FFP) detections and find that DREAMS is sensitive to Mars-mass FFPs in the Galactic bulge and Moon-mass FFPs in the Galactic disk. | [üîó Paper](https://arxiv.org/abs/2601.11469v1) |
| [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468v1) | Alessandro Padella, Massimiliano de Leoni, Marlon Dumas | 2026-01-16 | General AI | Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions. | [üîó Paper](https://arxiv.org/abs/2601.11468v1) |
