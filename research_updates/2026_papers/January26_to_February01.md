# üìå AI Research Papers (January26 to February01)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Exploring Sidewalk Sheds in New York City through Chatbot Surveys and Human Computer Interaction](https://arxiv.org/abs/2601.23095v1) | Junyi Li, Zhaoxi Zhang, Tamir Mendel, Takahiro Yabe | 2026-01-30 | LLM | Sidewalk sheds are a common feature of the streetscape in New York City, reflecting ongoing construction and maintenance activities. However, policymakers and local business owners have raised concerns about reduced storefront visibility and altered pedestrian navigation. Although sidewalk sheds are widely used for safety, their effects on pedestrian visibility and movement are not directly measured in current planning practices. To address this, we developed an AI-based chatbot survey that collects image-based annotations and route choices from pedestrians, linking these responses to specific shed design features, including clearance height, post spacing, and color. This AI chatbot survey integrates a large language model (e.g., Google's Gemini-1.5-flash-001 model) with an image-annotation interface, allowing users to interact with street images, mark visual elements, and provide structured feedback through guided dialogue. To explore pedestrian perceptions and behaviors, this paper conducts a grid-based analysis of entrance annotations and applies logistic mixed-effects modeling to assess sidewalk choice patterns. Analysis of the dataset (n = 25) shows that: (1) the presence of scaffolding significantly reduces pedestrians' ability to identify ground-floor retail entrances, and (2) variations in weather conditions and shed design features significantly influence sidewalk selection behavior. By integrating generative AI into urban research, this study demonstrates a novel method for evaluating sidewalk shed designs and provides empirical evidence to support adjustments to shed guidelines that improve the pedestrian experience without compromising safety. | [üîó Paper](https://arxiv.org/abs/2601.23095v1) |
| [OrLog: Resolving Complex Queries with LLMs and Probabilistic Reasoning](https://arxiv.org/abs/2601.23085v1) | Mohanna Hoveyda, Jelle Piepenbrock, Arjen P de Vries, Maarten de Rijke, Faegheh Hasibi | 2026-01-30 | LLM | Resolving complex information needs that come with multiple constraints should consider enforcing the logical operators encoded in the query (i.e., conjunction, disjunction, negation) on the candidate answer set. Current retrieval systems either ignore these constraints in neural embeddings or approximate them in a generative reasoning process that can be inconsistent and unreliable. Although well-suited to structured reasoning, existing neuro-symbolic approaches remain confined to formal logic or mathematics problems as they often assume unambiguous queries and access to complete evidence, conditions rarely met in information retrieval. To bridge this gap, we introduce OrLog, a neuro-symbolic retrieval framework that decouples predicate-level plausibility estimation from logical reasoning: a large language model (LLM) provides plausibility scores for atomic predicates in one decoding-free forward pass, from which a probabilistic reasoning engine derives the posterior probability of query satisfaction. We evaluate OrLog across multiple backbone LLMs, varying levels of access to external knowledge, and a range of logical constraints, and compare it against base retrievers and LLM-as-reasoner methods. Provided with entity descriptions, OrLog can significantly boost top-rank precision compared to LLM reasoning with larger gains on disjunctive queries. OrLog is also more efficient, cutting mean tokens by $\sim$90\% per query-entity pair. These results demonstrate that generation-free predicate plausibility estimation combined with probabilistic reasoning enables constraint-aware retrieval that outperforms monolithic reasoning while using far fewer tokens. | [üîó Paper](https://arxiv.org/abs/2601.23085v1) |
| [Evaluating the Effectiveness of OpenAI's Parental Control System](https://arxiv.org/abs/2601.23062v1) | Kerem Ersoz, Saleh Afroogh, David Atkinson, Junfeng Jiao | 2026-01-30 | LLM | We evaluate how effectively platform-level parental controls moderate a mainstream conversational assistant used by minors. Our two-phase protocol first builds a category-balanced conversation corpus via PAIR-style iterative prompt refinement over API, then has trained human agents replay/refine those prompts in the consumer UI using a designated child account while monitoring the linked parent inbox for alerts. We focus on seven risk areas -- physical harm, pornography, privacy violence, health consultation, fraud, hate speech, and malware and quantify four outcomes: Notification Rate (NR), Leak-Through (LR), Overblocking (OBR), and UI Intervention Rate (UIR). Using an automated judge (with targeted human audit) and comparing the current backend to legacy variants (GPT-4.1/4o), we find that notifications are selective rather than comprehensive: privacy violence, fraud, hate speech, and malware triggered no parental alerts in our runs, whereas physical harm (highest), pornography, and some health queries produced intermittent alerts. The current backend shows lower leak-through than legacy models, yet overblocking of benign, educational queries near sensitive topics remains common and is not surfaced to parents, revealing a policy-product gap between on-screen safeguards and parent-facing telemetry. We propose actionable fixes: broaden/configure the notification taxonomy, couple visible safeguards to privacy-preserving parent summaries, and prefer calibrated, age-appropriate safe rewrites over blanket refusals. | [üîó Paper](https://arxiv.org/abs/2601.23062v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Learning-Based Signal Recovery in Nonlinear Systems with Spectrally Separated Interference](https://arxiv.org/abs/2601.23076v1) | Jayadev Joy, Sundeep Rangan | 2026-01-30 | Diffusion Models, Optimization | Upper Mid-Band (FR3, 7-24 GHz) receivers for 6G must operate over wide bandwidths in dense spectral environments, making them particularly vulnerable to strong adjacent-band interference and front-end nonlinearities. While conventional linear receivers can suppress spectrally separated interferers under ideal hardware assumptions, receiver saturation and finite-resolution quantization cause nonlinear spectral leakage that severely degrades performance in practical wideband radios. We study the recovery of a desired signal from nonlinear receiver observations corrupted by a high-power out-of-band interferer. The receiver front-end is modeled as a smooth, memoryless nonlinearity followed by additive noise and optional quantization. To mitigate these nonlinear and quantization-induced distortions, we propose a learned multi-layer Vector Approximate Message Passing (LMLVAMP) algorithm that incorporates spectral priors with neural network based denoising. Simulation results demonstrate significant performance gains over conventional methods, particularly in high-interference regimes representative of FR3 coexistence scenarios. | [üîó Paper](https://arxiv.org/abs/2601.23076v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087v1) | Wu Songwei, Jiang Zhiduo, Xie Guanghu, Liu Yang, Liu Hong | 2026-01-30 | Multimodal AI, Production and Deployment, Diffusion Models | Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.   We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.   LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies. | [üîó Paper](https://arxiv.org/abs/2601.23087v1) |
| [One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs](https://arxiv.org/abs/2601.23041v1) | Youxu Shi, Suorong Yang, Dong Liu | 2026-01-30 | Multimodal AI, Optimization, Model Evaluation | Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe that steering vectors can generalize across inputs when tasks share aligned semantic intent. Based on this insight, we propose \textbf{OSGA} (\textbf{O}ne-shot \textbf{S}teering with \textbf{G}enerative \textbf{A}nchor), an input-independent framework that improves model performance with a single optimization instance. OSGA first selects an informative sample via a variance-based data selection strategy and learns a single steering vector with a contrastive objective with generative anchor regularization. The resulting vector can be universally applied at a certain layer during inference time without modifying model parameters. Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead, highlighting one-shot steering as a practical and scalable solution for reliable VLMs. | [üîó Paper](https://arxiv.org/abs/2601.23041v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Existence of Traveling Waves in Infinite Range FPUT Lattices](https://arxiv.org/abs/2601.23091v1) | Michael Herrmann, Karsten Matthies, Jan-Patrick Meyer | 2026-01-30 | Optimization | We prove the existence of solitary waves in a lattice where all particles interact with each other by pair-wise repulsive forces that decay with distance. The variational existence proof is based on constrained optimization and provides a one-parameter family of unimodal solutions. We also describe the asymptotic behavior of large, fast, high-energy waves. | [üîó Paper](https://arxiv.org/abs/2601.23091v1) |
| [RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning](https://arxiv.org/abs/2601.23075v1) | Yuexin Bian, Jie Feng, Tao Wang, Yijiang Li, Sicun Gao, Yuanyuan Shi | 2026-01-30 | Optimization, RLHF | On-policy deep reinforcement learning remains a dominant paradigm for continuous control, yet standard implementations rely on Gaussian actors and relatively shallow MLP policies, often leading to brittle optimization when gradients are noisy and policy updates must be conservative. In this paper, we revisit policy representation as a first-class design choice for on-policy optimization. We study discretized categorical actors that represent each action dimension with a distribution over bins, yielding a policy objective that resembles a cross-entropy loss. Building on architectural advances from supervised learning, we further propose regularized actor networks, while keeping critic design fixed. Our results show that simply replacing the standard actor network with our discretized regularized actor yields consistent gains and achieve the state-of-the-art performance across diverse continuous-control benchmarks. | [üîó Paper](https://arxiv.org/abs/2601.23075v1) |
| [EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing](https://arxiv.org/abs/2601.23065v1) | Xijie Yang, Mulin Yu, Changjian Jiang, Kerui Ren, Tao Lu, Jiangmiao Pang, Dahua Lin, Bo Dai, Linning Xu | 2026-01-30 | Optimization | Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation. Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using efficient single-bounce optimization and high-quality multi-bounce path tracing after scene editing. Experiments on synthetic and real indoor scenes show that EAG-PT produces more natural and physically consistent renders after editing than radiant scene reconstructions, while preserving finer geometric detail and avoiding mesh-induced artifacts compared to mesh-based inverse path tracing. These results suggest promising directions for future use in interior design, XR content creation, and embodied AI. | [üîó Paper](https://arxiv.org/abs/2601.23065v1) |
| [From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning](https://arxiv.org/abs/2601.23058v1) | Wenzhe Niu, Wei He, Zongxia Xie, Jinpeng Ou, Huichuan Fan, Yuchen Ge, Yanru Sun, Ziyin Wang, Yizhao Sun, Chengshun Shi, Jiuchong Gao, Jinghua Hao, Renqing He | 2026-01-30 | Optimization, Fine-Tuning, RLHF | Reinforcement learning has become a cornerstone for enhancing the reasoning capabilities of Large Language Models, where group-based approaches such as GRPO have emerged as efficient paradigms that optimize policies by leveraging intra-group performance differences. However, these methods typically rely on absolute numerical rewards, introducing intrinsic limitations. In verifiable tasks, identical group evaluations often result in sparse supervision, while in open-ended scenarios, the score range instability of reward models undermines advantage estimation based on group means. To address these limitations, we propose Reinforcement Learning with Relative Rewards (RLRR), a framework that shifts reward shaping from absolute scoring to relative ranking. Complementing this framework, we introduce the Ranking Reward Model, a listwise preference model tailored for group-based optimization to directly generate relative rankings. By transforming raw evaluations into robust relative signals, RLRR effectively mitigates signal sparsity and reward instability. Experimental results demonstrate that RLRR yields consistent performance improvements over standard group-based baselines across reasoning benchmarks and open-ended generation tasks. | [üîó Paper](https://arxiv.org/abs/2601.23058v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [CATTO: Balancing Preferences and Confidence in Language Models](https://arxiv.org/abs/2601.23096v1) | Nisarg Parikh, Kunjal Panchal, Ananya Sai, Pannaga Shivaswamy, Andrew Lan | 2026-01-30 | Scaling Laws, Optimization, Ongoing Learning, RLHF | Large language models (LLMs) often make accurate next token predictions but their confidence in these predictions can be poorly calibrated: high-confidence predictions are frequently wrong, and low-confidence predictions may be correct. This miscalibration is exacerbated by preference-based alignment methods breaking the link between predictive probability and correctness. We introduce a Calibration Aware Token-level Training Objective (CATTO), a calibration-aware objective that aligns predicted confidence with empirical prediction correctness, which can be combined with the original preference optimization objectives. Empirically, CATTO reduces Expected Calibration Error (ECE) by 2.22%-7.61% in-distribution and 1.46%-10.44% out-of-distribution compared to direct preference optimization (DPO), and by 0.22%-1.24% in-distribution and 1.23%-5.07% out-of-distribution compared to the strongest DPO baseline. This improvement in confidence does not come at a cost of losing task accuracy, where CATTO maintains or slightly improves multiple-choice question-answering accuracy on five datasets. We also introduce Confidence@k, a test-time scaling mechanism leveraging calibrated token probabilities for Bayes-optimal selection of output tokens. | [üîó Paper](https://arxiv.org/abs/2601.23096v1) |
| [From Similarity to Vulnerability: Key Collision Attack on LLM Semantic Caching](https://arxiv.org/abs/2601.23088v1) | Zhixiang Zhang, Zesen Liu, Yuchong Xie, Quanfeng Huang, Dongdong She | 2026-01-30 | Scaling Laws, Production and Deployment, Security & Adversarial ML | Semantic caching has emerged as a pivotal technique for scaling LLM applications, widely adopted by major providers including AWS and Microsoft. By utilizing semantic embedding vectors as cache keys, this mechanism effectively minimizes latency and redundant computation for semantically similar queries. In this work, we conceptualize semantic cache keys as a form of fuzzy hashes. We demonstrate that the locality required to maximize cache hit rates fundamentally conflicts with the cryptographic avalanche effect necessary for collision resistance. Our conceptual analysis formalizes this inherent trade-off between performance (locality) and security (collision resilience), revealing that semantic caching is naturally vulnerable to key collision attacks.   While prior research has focused on side-channel and privacy risks, we present the first systematic study of integrity risks arising from cache collisions. We introduce CacheAttack, an automated framework for launching black-box collision attacks. We evaluate CacheAttack in security-critical tasks and agentic workflows. It achieves a hit rate of 86\% in LLM response hijacking and can induce malicious behaviors in LLM agent, while preserving strong transferability across different embedding models. A case study on a financial agent further illustrates the real-world impact of these vulnerabilities. Finally, we discuss mitigation strategies. | [üîó Paper](https://arxiv.org/abs/2601.23088v1) |
| [From Abstract to Contextual: What LLMs Still Cannot Do in Mathematics](https://arxiv.org/abs/2601.23048v1) | Bowen Cao, Dongdong Zhang, Yixia Li, Junpeng Liu, Shijue Huang, Chufan Shi, Hongyuan Lu, Yaokang Wu, Guanhua Chen, Wai Lam, Furu Wei | 2026-01-30 | Scaling Laws, Optimization | Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice. Evaluating 61 proprietary and open-source models, we observe sharp drops: on average, open-source models decline by 13 and 34 points on SG and CS, while proprietary models drop by 13 and 20. Error analysis shows that errors are dominated by incorrect problem formulation, with formulation accuracy declining as original problem difficulty increases. Correct formulation emerges as a prerequisite for success, and its sufficiency improves with model scale, indicating that larger models advance in both understanding and reasoning. Nevertheless, formulation and reasoning remain two complementary bottlenecks that limit contextual mathematical problem solving. Finally, we find that fine-tuning with scenario data improves performance, whereas formulation-only training is ineffective. However, performance gaps are only partially alleviated, highlighting contextual mathematical reasoning as a central unsolved challenge for LLMs. | [üîó Paper](https://arxiv.org/abs/2601.23048v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080v1) | Yubiao Ma, Han Yu, Jiayin Xie, Changtai Lv, Qiang Luo, Chi Zhang, Yunpeng Yin, Boyang Xing, Xuemei Ren, Dongdong Zheng | 2026-01-30 | Model Evaluation, Responsible AI, Optimization, Prompt Engineering, Memory & Context Length | Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot. | [üîó Paper](https://arxiv.org/abs/2601.23080v1) |
| [Towards Explicit Acoustic Evidence Perception in Audio LLMs for Speech Deepfake Detection](https://arxiv.org/abs/2601.23066v1) | Xiaoxuan Guo, Yuankun Xie, Haonan Cheng, Jiayi Zhou, Jian Liu, Hengyan Huang, Long Ye, Qin Zhang | 2026-01-30 | Model Evaluation, Multimodal AI, Responsible AI, LLM | Speech deepfake detection (SDD) focuses on identifying whether a given speech signal is genuine or has been synthetically generated. Existing audio large language model (LLM)-based methods excel in content understanding; however, their predictions are often biased toward semantically correlated cues, which results in fine-grained acoustic artifacts being overlooked during the decisionmaking process. Consequently, fake speech with natural semantics can bypass detectors despite harboring subtle acoustic anomalies; this suggests that the challenge stems not from the absence of acoustic data, but from its inadequate accessibility when semantic-dominant reasoning prevails. To address this issue, we investigate SDD within the audio LLM paradigm and introduce SDD with Auditory Perception-enhanced Audio Large Language Model (SDD-APALLM), an acoustically enhanced framework designed to explicitly expose fine-grained time-frequency evidence as accessible acoustic cues. By combining raw audio with structured spectrograms, the proposed framework empowers audio LLMs to more effectively capture subtle acoustic inconsistencies without compromising their semantic understanding. Experimental results indicate consistent gains in detection accuracy and robustness, especially in cases where semantic cues are misleading. Further analysis reveals that these improvements stem from a coordinated utilization of semantic and acoustic information, as opposed to simple modality aggregation. | [üîó Paper](https://arxiv.org/abs/2601.23066v1) |
| [MedMCP-Calc: Benchmarking LLMs for Realistic Medical Calculator Scenarios via MCP Integration](https://arxiv.org/abs/2601.23049v1) | Yakun Zhu, Yutong Huang, Shengqian Qin, Zhongzhen Huang, Shaoting Zhang, Xiaofan Zhang | 2026-01-30 | Model Evaluation, Training & Evaluation | Medical calculators are fundamental to quantitative, evidence-based clinical practice. However, their real-world use is an adaptive, multi-stage process, requiring proactive EHR data acquisition, scenario-dependent calculator selection, and multi-step computation, whereas current benchmarks focus only on static single-step calculations with explicit instructions. To address these limitations, we introduce MedMCP-Calc, the first benchmark for evaluating LLMs in realistic medical calculator scenarios through Model Context Protocol (MCP) integration. MedMCP-Calc comprises 118 scenario tasks across 4 clinical domains, featuring fuzzy task descriptions mimicking natural queries, structured EHR database interaction, external reference retrieval, and process-level evaluation. Our evaluation of 23 leading models reveals critical limitations: even top performers like Claude Opus 4.5 exhibit substantial gaps, including difficulty selecting appropriate calculators for end-to-end workflows given fuzzy queries, poor performance in iterative SQL-based database interactions, and marked reluctance to leverage external tools for numerical computation. Performance also varies considerably across clinical domains. Building on these findings, we develop CalcMate, a fine-tuned model incorporating scenario planning and tool augmentation, achieving state-of-the-art performance among open-source models. Benchmark and Codes are available in https://github.com/SPIRAL-MED/MedMCP-Calc. | [üîó Paper](https://arxiv.org/abs/2601.23049v1) |
## üîπ Production and Deployment

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [A Universal Convolution-Based Pre-processor to Correct the Prevalence-Incidence Gap in SIR, SEIR, and SIRS Modeling](https://arxiv.org/abs/2601.23077v1) | Jose de Jesus Bernal-Alvarado, David Delepine | 2026-01-30 | Production and Deployment | Traditional compartmental models, including SIR, SEIR, and SIRS frameworks, remain the analytical standard for epidemic forecasting. However, real-world data validation consistently reveals significant predictive failures, such as peak underestimations of up to 50%. This research identifies a persistent fundamental methodological error: the calibration of prevalence-based (stock) models using raw daily incidence (flow) data without proper transformation. We propose an integrated protocol utilizing an exponentially weighted convolution to reconstruct active cases from reported incidence: $I(t) \approx \frac{1}{p} \int_{0}^{t} NDC(œÑ) e^{-Œ≥(t-œÑ)} dœÑ$. This transformation accounts for the recovery rate $Œ≥$ and the ascertainment rate $p$. We demonstrate that increasing structural complexity, such as adding latency (SEIR) or waning immunity (SIRS), fails to resolve the incidence-prevalence gap. Simulation results show that without the proposed universal pre-processor, these advanced models inherit the systematic biases of misaligned data types, leading to significant errors in estimating latent periods and the "heavy tail" of endemicity. The proposed convolution transformation must serve as a universal prerequisite for any compartmental framework, bridging the gap between clinical reporting and mechanistic modeling. | [üîó Paper](https://arxiv.org/abs/2601.23077v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Chain-of-thought obfuscation learned from output supervision can generalise to unseen tasks](https://arxiv.org/abs/2601.23086v1) | Nathaniel Mitrani Hadida, Sassan Bhanji, Cameron Tice, Puria Radmard | 2026-01-30 | Prompt Engineering | Chain-of-thought (CoT) reasoning provides a significant performance uplift to LLMs by enabling planning, exploration, and deliberation of their actions. CoT is also a powerful tool for monitoring the behaviours of these agents: when faithful, they offer interpretations of the model's decision making process, and an early warning sign for dangerous behaviours. However, optimisation pressures placed on the CoT may cause the model to obfuscate reasoning traces, losing this beneficial property. We show that obfuscation can generalise across tasks; models that learn to obfuscate reasoning involving reward hacking (e.g. accessing and utilising leaked information) generalise both the reward hacking behaviour and its obfuscation in CoT to unseen reward hacking settings. Most worryingly, we show that obfuscation of CoT reasoning, and its generalisation across tasks, also follows when we penalise only the model's final actions after closing its CoT. Our findings suggest that current practices of penalising harmful generations may inadvertently lead to a reduction in the broader monitorability of LLMs in unpredictable ways. | [üîó Paper](https://arxiv.org/abs/2601.23086v1) |
## üîπ AI Safety

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [ExplainerPFN: Towards tabular foundation models for model-free zero-shot feature importance estimations](https://arxiv.org/abs/2601.23068v1) | Joao Fonseca, Julia Stoyanovich | 2026-01-30 | AI Safety, Prompt Engineering, Ongoing Learning | Computing the importance of features in supervised classification tasks is critical for model interpretability. Shapley values are a widely used approach for explaining model predictions, but require direct access to the underlying model, an assumption frequently violated in real-world deployments. Further, even when model access is possible, their exact computation may be prohibitively expensive. We investigate whether meaningful Shapley value estimations can be obtained in a zero-shot setting, using only the input data distribution and no evaluations of the target model. To this end, we introduce ExplainerPFN, a tabular foundation model built on TabPFN that is pretrained on synthetic datasets generated from random structural causal models and supervised using exact or near-exact Shapley values. Once trained, ExplainerPFN predicts feature attributions for unseen tabular datasets without model access, gradients, or example explanations.   Our contributions are fourfold: (1) we show that few-shot learning-based explanations can achieve high fidelity to SHAP values with as few as two reference observations; (2) we propose ExplainerPFN, the first zero-shot method for estimating Shapley values without access to the underlying model or reference explanations; (3) we provide an open-source implementation of ExplainerPFN, including the full training pipeline and synthetic data generator; and (4) through extensive experiments on real and synthetic datasets, we show that ExplainerPFN achieves performance competitive with few-shot surrogate explainers that rely on 2-10 SHAP examples. | [üîó Paper](https://arxiv.org/abs/2601.23068v1) |
| [On the Impact of Code Comments for Automated Bug-Fixing: An Empirical Study](https://arxiv.org/abs/2601.23059v1) | Antonio Vitale, Emanuela Guglielmi, Simone Scalabrino, Rocco Oliveto | 2026-01-30 | AI Safety, Training & Evaluation | Large Language Models (LLMs) are increasingly relevant in Software Engineering research and practice, with Automated Bug Fixing (ABF) being one of their key applications. ABF involves transforming a buggy method into its fixed equivalent. A common preprocessing step in ABF involves removing comments from code prior to training. However, we hypothesize that comments may play a critical role in fixing certain types of bugs by providing valuable design and implementation insights. In this study, we investigate how the presence or absence of comments, both during training and at inference time, impacts the bug-fixing capabilities of LLMs. We conduct an empirical evaluation comparing two model families, each evaluated under all combinations of training and inference conditions (with and without comments), and thereby revisiting the common practice of removing comments during training. To address the limited availability of comments in state-of-the-art datasets, we use an LLM to automatically generate comments for methods lacking them. Our findings show that comments improve ABF accuracy by up to threefold when present in both phases, while training with comments does not degrade performance when instances lack them. Additionally, an interpretability analysis identifies that comments detailing method implementation are particularly effective in aiding LLMs to fix bugs accurately. | [üîó Paper](https://arxiv.org/abs/2601.23059v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Safer Policy Compliance with Dynamic Epistemic Fallback](https://arxiv.org/abs/2601.23094v1) | Joseph Marvin Imperial, Harish Tayyar Madabushi | 2026-01-30 | Responsible AI, Model Evaluation | Humans develop a series of cognitive defenses, known as epistemic vigilance, to combat risks of deception and misinformation from everyday interactions. Developing safeguards for LLMs inspired by this mechanism might be particularly helpful for their application in high-stakes tasks such as automating compliance with data privacy laws. In this paper, we introduce Dynamic Epistemic Fallback (DEF), a dynamic safety protocol for improving an LLM's inference-time defenses against deceptive attacks that make use of maliciously perturbed policy texts. Through various levels of one-sentence textual cues, DEF nudges LLMs to flag inconsistencies, refuse compliance, and fallback to their parametric knowledge upon encountering perturbed policy texts. Using globally recognized legal policies such as HIPAA and GDPR, our empirical evaluations report that DEF effectively improves the capability of frontier LLMs to detect and refuse perturbed versions of policies, with DeepSeek-R1 achieving a 100% detection rate in one setting. This work encourages further efforts to develop cognitively inspired defenses to improve LLM robustness against forms of harm and deception that exploit legal artifacts. | [üîó Paper](https://arxiv.org/abs/2601.23094v1) |
| [WiFiPenTester: Advancing Wireless Ethical Hacking with Governed GenAI](https://arxiv.org/abs/2601.23092v1) | Haitham S. Al-Sinani, Chris J. Mitchell | 2026-01-30 | Responsible AI, Security & Adversarial ML | Wireless ethical hacking relies heavily on skilled practitioners manually interpreting reconnaissance results and executing complex, time-sensitive sequences of commands to identify vulnerable targets, capture authentication handshakes, and assess password resilience; a process that is inherently labour-intensive, difficult to scale, and prone to subjective judgement and human error. To help address these limitations, we propose WiFiPenTester, an experimental, governed, and reproducible system for GenAI-enabled wireless ethical hacking. The system integrates large language models into the reconnaissance and decision-support phases of wireless security assessment, enabling intelligent target ranking, attack feasibility estimation, and strategy recommendation, while preserving strict human-in-the-loop control and budget-aware execution. We describe the system architecture, threat model, governance mechanisms, and prompt-engineering methodology, and empirical experiments conducted across multiple wireless environments. The results demonstrate that GenAI assistance improves target selection accuracy and overall assessment efficiency, while maintaining auditability and ethical safeguards. This indicates that WiFiPenTester is a meaningful step toward practical, safe, and scalable GenAI-assisted wireless penetration testing, while reinforcing the necessity of bounded autonomy, human oversight, and rigorous governance mechanisms when deploying GenAI in ethical hacking. | [üîó Paper](https://arxiv.org/abs/2601.23092v1) |
| [Gender Disparities in StackOverflow's Community-Based Question Answering: A Matter of Quantity versus Quality](https://arxiv.org/abs/2601.23063v1) | Maddalena Amendola, Cosimo Rulli, Carlos Castillo, Andrea Passarella, Raffaele Perego | 2026-01-30 | Responsible AI, Model Evaluation | Community Question-Answering platforms, such as Stack Overflow (SO), are valuable knowledge exchange and problem-solving resources. These platforms incorporate mechanisms to assess the quality of answers and participants' expertise, ideally free from discriminatory biases. However, prior research has highlighted persistent gender biases, raising concerns about the inclusivity and fairness of these systems. Addressing such biases is crucial for fostering equitable online communities. While previous studies focus on detecting gender bias by comparing male and female user characteristics, they often overlook the interaction between genders, inherent answer quality, and the selection of ``best answers'' by question askers. In this study, we investigate whether answer quality is influenced by gender using a combination of human evaluations and automated assessments powered by Large Language Models. Our findings reveal no significant gender differences in answer quality, nor any substantial influence of gender bias on the selection of ``best answers." Instead, we find that the significant gender disparities in SO's reputation scores are primarily attributable to differences in users' activity levels, e.g., the number of questions and answers they write. Our results have important implications for the design of scoring systems in community question-answering platforms. In particular, reputation systems that heavily emphasize activity volume risk amplifying gender disparities that do not reflect actual differences in answer quality, calling for more equitable design strategies. | [üîó Paper](https://arxiv.org/abs/2601.23063v1) |
| [The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?](https://arxiv.org/abs/2601.23045v1) | Alexander H√§gele, Aryo Pradipta Gema, Henry Sleight, Ethan Perez, Jascha Sohl-Dickstein | 2026-01-30 | Responsible AI, Model Evaluation, RLHF | As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome. Across all tasks and frontier models we measure, the longer models spend reasoning and taking actions, \emph{the more incoherent} their failures become. Incoherence changes with model scale in a way that is experiment dependent. However, in several settings, larger, more capable models are more incoherent than smaller models. Consequently, scale alone seems unlikely to eliminate incoherence. Instead, as more capable AIs pursue harder tasks, requiring more sequential action and thought, our results predict failures to be accompanied by more incoherent behavior. This suggests a future where AIs sometimes cause industrial accidents (due to unpredictable misbehavior), but are less likely to exhibit consistent pursuit of a misaligned goal. This increases the relative importance of alignment research targeting reward hacking or goal misspecification. | [üîó Paper](https://arxiv.org/abs/2601.23045v1) |
| [Dicke superposition probes for noise-resilient Heisenberg and super-Heisenberg Metrology](https://arxiv.org/abs/2601.23043v1) | Sudha, B. N. Karthik, K. S. Akhilesh, A. R. Usha Devi | 2026-01-30 | Responsible AI, Scaling Laws, Model Evaluation | Phase sensing with entangled multiqubit states in the presence of noise is a central theme of modern quantum metrology. The present work investigates Dicke state superposition probes for quantum phase sensing under parameter encoding generated by one- and two-body interaction Hamiltonians. A class of N-qubit Dicke superposition states that exhibit near-Heisenberg scaling, of the quantum Fisher information, while maintaining significantly enhanced robustness to dephasing noise compared to GHZ, W-superposition, and balanced Dicke states, under unitary encodings generated by one-body interaction Hamiltonians are identified. For two-body interactions, Dicke superposition probes optimizing the quantum Fisher information are identified, and their performance under phase-damping, amplitude-damping, and global depolarizing noise is explored. Within this family, certain Dicke superpositions are found to combine super-Heisenberg scaling with improved resilience to phase damping relative to Fisher information optimal probes. These results establish tailored near-optimal Dicke-state superposition probes as versatile and noise-resilient resources for Heisenberg and super-Heisenberg quantum phase sensing governed by one- and two-body interactions. | [üîó Paper](https://arxiv.org/abs/2601.23043v1) |
## üîπ Security & Adversarial ML

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures](https://arxiv.org/abs/2601.23081v1) | Yanghao Su, Wenbo Zhou, Tianwei Zhang, Qiu Han, Weiming Zhang, Nenghai Yu, Jie Zhang | 2026-01-30 | Security & Adversarial ML, Optimization, RLHF | Emergent Misalignment refers to a failure mode in which fine-tuning large language models (LLMs) on narrowly scoped data induces broadly misaligned behavior. Prior explanations mainly attribute this phenomenon to the generalization of erroneous or unsafe content. In this work, we show that this view is incomplete. Across multiple domains and model families, we find that fine-tuning models on data exhibiting specific character-level dispositions induces substantially stronger and more transferable misalignment than incorrect-advice fine-tuning, while largely preserving general capabilities. This indicates that emergent misalignment arises from stable shifts in model behavior rather than from capability degradation or corrupted knowledge. We further show that such behavioral dispositions can be conditionally activated by both training-time triggers and inference-time persona-aligned prompts, revealing shared structure across emergent misalignment, backdoor activation, and jailbreak susceptibility. Overall, our results identify character formation as a central and underexplored alignment risk, suggesting that robust alignment must address behavioral dispositions rather than isolated errors or prompt-level defenses. | [üîó Paper](https://arxiv.org/abs/2601.23081v1) |
| [Digital Twin Synchronization: towards a data-centric architecture](https://arxiv.org/abs/2601.23051v1) | Eduardo Freitas, Assis T. de Oliveira Filho, Pedro R. X. do Carmo, Djamel Sadok, Judith Kelner | 2026-01-30 | Security & Adversarial ML | Digital Twin (DT) technology revolutionizes industrial processes by enabling the representation of physical entities and their dynamics to enhance productivity and operational efficiency. It has emerged as a vital enabling technology in the Industry 4.0 context. The present article examines the particular issue of synchronizing a digital twin while ensuring an accurate reflection of its physical counterpart. Despite the reported recent advances in the design of middleware and low delay communication technologies, effective synchronization between both worlds remains challenging. This paper reviews currently adopted synchronization technologies and architectures, identifies vital outstanding technical challenges, and proposes a unified synchronization architecture for use by various industrial applications while addressing security and interoperability requirements. As such, this study aims to bridges gaps and advance robust synchronization in DT environments, emphasizing the need for a standardized architecture to ensure seamless operation and continuous improvement of industrial systems. | [üîó Paper](https://arxiv.org/abs/2601.23051v1) |
## üîπ Fine-Tuning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation](https://arxiv.org/abs/2601.23064v1) | Hari Krishna Gadi, Daniel Matos, Hongyi Luo, Lu Liu, Yongliang Wang, Yanfeng Zhang, Liqiu Meng | 2026-01-30 | Fine-Tuning | Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over space but struggle with fine detail. We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space. Images are aligned directly to country, region, subregion, and city entities through Geo-Weighted Hyperbolic contrastive learning by directly incorporating haversine distance into the contrastive objective. This hierarchical design enables interpretable predictions and efficient inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M benchmark, on which our method establishes a new state-of-the-art performance. Compared to the current methods in the literature, it reduces mean geodesic error by 19.5\%, while improving the fine-grained subregion accuracy by 43%. These results demonstrate that geometry-aware hierarchical embeddings provide a scalable and conceptually new alternative for global image geolocation. | [üîó Paper](https://arxiv.org/abs/2601.23064v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Exploring Long-Range Interactions in the Atmospheric Neutrino Oscillations at IceCube DeepCore](https://arxiv.org/abs/2601.23093v1) | Gopal Garg | 2026-01-30 | General AI | The IceCube neutrino observatory consists of an array of Digital Optical Modules (DOMs) instrumenting one cubic-kilometer of deep glacial ice at the South Pole. DeepCore, a densely-spaced sub-array of DOMs at the bottom central region of IceCube, enables the detection of atmospheric neutrinos with an energy threshold in the GeV range. The high statistics data of DeepCore provides a unique opportunity to perform neutrino oscillation studies as well as explore various sub-leading Beyond the Standard Model (BSM) physics signatures. We consider a well-motivated minimal extension of the Standard Model by an additional anomaly-free, gauged lepton-number symmetry, such as $L_e - L_Œº$ or $L_e - L_œÑ$. These symmetries give rise to flavor-dependent long-range interaction mediated through a very light neutral gauge boson. In this contribution, we present the sensitivity of the IceCube DeepCore detector to search for this flavor-dependent long-range interaction potential with a runtime of 9.3 years. | [üîó Paper](https://arxiv.org/abs/2601.23093v1) |
| [Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model](https://arxiv.org/abs/2601.23090v1) | Mo Wang, Wenhao Ye, Junfeng Xia, Junxiang Zhang, Xuanye Pan, Minghao Xu, Haotian Deng, Hongkai Wen, Quanying Liu | 2026-01-30 | General AI | Self-supervised fMRI foundation models have shown promising transfer performance, yet most rely on predefined region-level parcellations that discard fine-grained voxel information and introduce atlas-dependent biases. We propose Omni-fMRI, an atlas-free foundation model that operates directly on voxel-level signals. To enable scalable pretraining on 49,497 fMRI sessions across nine datasets, Omni-fMRI introduces a dynamic patching mechanism that substantially reduces computational cost while preserving informative spatial structure. To support reproducibility and fair comparison, we establish a comprehensive benchmark suite spanning 11 datasets and a diverse set of resting-state and task-based fMRI tasks. Experimental results demonstrate that Omni-fMRI consistently outperforms existing foundation models, providing a scalable and reproducible framework for atlas-free brain representation learning. Code and logs are available. | [üîó Paper](https://arxiv.org/abs/2601.23090v1) |
| [Margin-Based Generalisation Bounds for Quantum Kernel Methods under Local Depolarising Noise](https://arxiv.org/abs/2601.23084v1) | Saarisha Govender, Ilya Sinayskiy | 2026-01-30 | General AI | Generalisation refers to the ability of a machine learning (ML) model to successfully apply patterns learned from training data to new, unseen data. Quantum devices in the current Noisy Intermediate-Scale Quantum (NISQ) era are inherently affected by noise, which degrades generalisation performance. In this work, we derive upper and lower margin-based generalisation bounds for Quantum Kernel-Assisted Support Vector Machines (QSVMs) under local depolarising noise. These theoretical bounds characterise noise-induced margin decay and are validated via numerical simulations across multiple datasets, as well as experiments on real quantum hardware. We further justify the focus on margin-based measures by empirically establishing margins as a reliable indicator of generalisation performance for QSVMs. Additionally, we motivate the study of local depolarising noise by presenting empirical evidence demonstrating that the commonly used global depolarising noise model is overly optimistic and fails to accurately capture the degradation of generalisation performance observed in the NISQ era. | [üîó Paper](https://arxiv.org/abs/2601.23084v1) |
| [Solving 4-Block Integer Linear Programs Faster Using Affine Decompositions of the Right-Hand Sides](https://arxiv.org/abs/2601.23083v1) | Alexandra Lassota, Koen Ligthart | 2026-01-30 | General AI | We present a new and faster algorithm for the 4-block integer linear programming problem, overcoming the long-standing runtime barrier faced by previous algorithms that rely on Graver complexity or proximity bounds. The 4-block integer linear programming problem asks to compute $\min\{c_0^\top x_0+c_1^\top x_1+\dots+c_n^\top x_n\ \vert\ Ax_0+Bx_1+\dots+Bx_n=b_0,\ Cx_0+Dx_i=b_i\ \forall i\in[n],\ (x_0,x_1,\dots,x_n)\in\mathbb Z_{\ge0}^{(1+n)k}\}$ for some $k\times k$ matrices $A,B,C,D$ with coefficients bounded by $\overlineŒî$ in absolute value. Our algorithm runs in time $f(k,\overlineŒî)\cdot n^{k+\mathcal O(1)}$, improving upon the previous best running time of $f(k,\overlineŒî)\cdot n^{k^2+\mathcal O(1)}$ [Oertel, Paat, and Weismantel (Math. Prog. 2024), Chen, Kouteck√Ω, Xu, and Shi (ESA 2020)]. Further, we give the first algorithm that can handle large coefficients in $A, B$ and $C$, that is, it has a running time that depends only polynomially on the encoding length of these coefficients. We obtain these results by extending the $n$-fold integer linear programming algorithm of Cslovjecsek, Kouteck√Ω, Lassota, Pilipczuk, and Polak (SODA 2024) to incorporate additional global variables $x_0$. The central technical result is showing that the exhaustive use of the vector rearrangement lemma of Cslovjecsek, Eisenbrand, Pilipczuk, Venzin, and Weismantel (ESA 2021) can be made \emph{affine} by carefully guessing both the residue of the global variables modulo a large modulus and a face in a suitable hyperplane arrangement among a sufficiently small number of candidates. This facilitates a dynamic high-multiplicy encoding of a \emph{faithfully decomposed} $n$-fold ILP with bounded right-hand sides, which we can solve efficiently for each such guess. | [üîó Paper](https://arxiv.org/abs/2601.23083v1) |
| [A Complete Finitary Refinement Type System for Scott-Open Properties](https://arxiv.org/abs/2601.23082v1) | Colin Riba, Adam Donadille | 2026-01-30 | General AI | We are interested in proving input-output properties of functions that handle infinite data such as streams or non-wellfounded trees. We provide a finitary refinement type system which is sound and complete for Scott-open properties defined in a fixpoint-like logic. Working on top of Abramsky's Domain Theory in Logical Form, we build from the well-known fact that the Scott domains interpreting recursive types are spectral spaces. The usual symmetry between Scott-open and compact-saturated sets is reflected in logical polarities: positive formulae allow for least fixpoints and define Scott-open properties, while negative formulae allow for greatest fixpoints and define compact-saturated properties. A realizability implication with the usual (contra)variance on polarities allows for non-trivial input-output properties to be formulated as positive formulae on function types. | [üîó Paper](https://arxiv.org/abs/2601.23082v1) |
| [Computing braids from approximate data](https://arxiv.org/abs/2601.23073v1) | Alexandre Guillemot, Pierre Lairez | 2026-01-30 | General AI | We study the theoretical and practical aspects of computing braids described by approximate descriptions of paths in the plane. Exact algorithms rely on the lexicographic ordering of the points in the plane, which is unstable under numerical uncertainty. Instead, we formalize an input model for approximate data, based on a separation predicate. It applies, for example, to paths obtained by tracking the roots of a parametrized polynomial with complex coefficients, thereby connecting certified path tracking outputs to exact braid computation. | [üîó Paper](https://arxiv.org/abs/2601.23073v1) |
| [SplineFlow: Flow Matching for Dynamical Systems with B-Spline Interpolants](https://arxiv.org/abs/2601.23072v1) | Santanu Subhash Rathod, Pietro Li√≤, Xiao Zhang | 2026-01-30 | General AI | Flow matching is a scalable generative framework for characterizing continuous normalizing flows with wide-range applications. However, current state-of-the-art methods are not well-suited for modeling dynamical systems, as they construct conditional paths using linear interpolants that may not capture the underlying state evolution, especially when learning higher-order dynamics from irregular sampled observations. Constructing unified paths that satisfy multi-marginal constraints across observations is challenging, since na√Øve higher-order polynomials tend to be unstable and oscillatory. We introduce SplineFlow, a theoretically grounded flow matching algorithm that jointly models conditional paths across observations via B-spline interpolation. Specifically, SplineFlow exploits the smoothness and stability of B-spline bases to learn the complex underlying dynamics in a structured manner while ensuring the multi-marginal requirements are met. Comprehensive experiments across various deterministic and stochastic dynamical systems of varying complexity, as well as on cellular trajectory inference tasks, demonstrate the strong improvement of SplineFlow over existing baselines. Our code is available at: https://github.com/santanurathod/SplineFlow. | [üîó Paper](https://arxiv.org/abs/2601.23072v1) |
| [Some notes on plump ordinals](https://arxiv.org/abs/2601.23070v1) | Shuwei Wang | 2026-01-30 | General AI | In this exposition, we attempt to formalise a treatment of Paul Taylor's notion of plump ordinals in weak intuitionistic axiomatic set theories such as IKP. We will explore basic properties of plump ordinals, especially in relation to G√∂del's constructible universe $L$ and incomparable codings. As a quick application, we explain at the end how plump ordinals can be used to build a Heyting-valued model $V^\mathbb{H}$ from a classical $V \vDash \mathrm{ZFC}$ such that for some arbitrary, fixed $x \in V$ we have $V^\mathbb{H} \vDash \mathcal{P}{\left(\check{x}\right)} \in L$. | [üîó Paper](https://arxiv.org/abs/2601.23070v1) |
| [Quantifying the C/O ratio in the planet-forming environments around very-low-mass stars](https://arxiv.org/abs/2601.23069v1) | Javiera K. D√≠az-Berr√≠os, Catherine Walsh, Ewine F. van Dishoeck | 2026-01-30 | General AI | The material in planet-forming disks determines the composition of planets; hence, it is crucial to understand the physical and chemical processes that set the abundance and distribution of key volatiles. James Webb Space Telescope observations of disks around very-low-mass ($\sim0.1~M\odot$) stars (VLMS) have revealed their hydrocarbon-rich inner regions (e.g., $\mathrm{C_2H_2}$), with column densities significantly higher than predicted. We employ chemical kinetics models using the physical structure of the inner disk around an M~Dwarf star with an X-ray luminosity of $L_X\sim10^{29}~\mathrm{erg~s^{-1}}$. We adopt initial abundances that mimic the effects of carbon enhancement and oxygen depletion (C/O from 0.44 to 87.47) and quantify how the abundances and distributions of key volatiles respond. The column density and number of molecules ($\mathcal{N}$) of hydrocarbons and oxygen-bearing species are highly sensitive to the C/O ratio, with the largest increases in hydrocarbons occurring when carbon increases by a factor of 2, and/or oxygen decreases by a factor of 10, relative to solar. In the IR-emitting region ($T_\mathrm{gas}>200$~K), a range of C/O ratios can reproduce the observed $\mathcal{N}$ and ratios relative to $\mathrm{CO_2}$. The disk-integrated molecular ratio with respect to $\mathrm{CO_2}$ is highly sensitive to the underlying C/O ratio. However, our results apply only to a source with a single X-ray luminosity value at the middle of that observed for VLMS; hence, a degeneracy between the stellar $L_X$ and the C/O ratio cannot be discarded. Nonetheless, our findings support that an enhanced C/O is required to drive the hydrocarbon-rich chemistry observed in the inner disks around VLMS. | [üîó Paper](https://arxiv.org/abs/2601.23069v1) |
| [Missing links prediction: comparing machine learning with physics-rooted approaches](https://arxiv.org/abs/2601.23061v1) | Francesca Santucci, Giulio Cimini, Tiziano Squartini | 2026-01-30 | General AI | An active research line within the broader field of network science is the one concerning link prediction. Close in scope to network reconstruction, link prediction targets specific connections with the aim of uncovering the missing ones, as well as predicting those most likely to emerge in the future, from the available information. In this paper, we consider two families of methods, i.e. those rooted in statistical physics and those based upon machine learning: the members of the first family identify missing links as the most probable non-observed ones, the probability coefficients being determined by solving maximum-entropy benchmarks over the accessible network structure; the members of the second family, instead, associate the presence of single edges to explanatory node-specific variables. Running likelihood-based models such as the Configuration Model, or one of its many fitness-based variants, in parallel with the Gradient Boosting Decision Tree algorithm reveals that the former's accuracy is comparable to (and sometimes slightly higher than) the latter's. Such a result confirms that white-box algorithms are viable competitors to the currently available black-box ones, being computationally faster and more interpretable than the latter. | [üîó Paper](https://arxiv.org/abs/2601.23061v1) |
| [Complete Operator Basis for the modular invariant SMEFT](https://arxiv.org/abs/2601.23060v1) | Luo-Jia Kang, Hao Sun, Jiang-Hao Yu | 2026-01-30 | General AI | We implement modular flavor symmetries within the Standard Model Effective Field Theory (SMEFT) framework, using the flavor group $A_4^{(q)} \times A_4^{(e)}$ with distinct moduli $œÑ_q$ and $œÑ_e$, and assigning different modular weights to right-handed quarks using simplest weight assignment. By treating the moduli as non-dynamical spurions, adopting the MFV-like assumption, and neglecting effects associated with $\mathrm{Im}\,œÑ$, we systematically construct a finite set of independent modular-invariant higher-dimensional operators via the Hilbert-series techniques. In the holomorphic $A_4$ scenario, where all modular forms derive from the weight-2 triplet $Y^{(2)}_{\mathbf{3}}$, we present two equivalent Hilbert-series bases. This establishes that higher-dimensional operators can be formally organized as $[Y_{\mathbf{r}}^{(k_Y)},{Y_{\mathbf{r}'}^{(k_Y')}}^{*},\mathcal{O}]_{\mathbf{1}}$ singlets. We subsequently enumerate all independent operators up to dimension 7 under this assumption and provide explicit constructions for all dimension-5 operators as well as baryon- and lepton-number conserving dimension-6 operators. Relaxing holomorphicity to the non-holomorphic case of polyharmonic Maas forms, considering that non-holomorphic modular forms are not closed under multiplication, adopting the holomorphic organizing idea would generically lead to an infinite proliferation of modular-invariant structures. To retain a finite and complete operator basis, we therefore impose the same minimal formal organizing principle, which reproduces the benchmark Weinberg operator and the corresponding dimension-$6$ operators. | [üîó Paper](https://arxiv.org/abs/2601.23060v1) |
| [Exploring Layered Structure Inside Earth Using Atmospheric Neutrino Oscillation at IceCube DeepCore](https://arxiv.org/abs/2601.23057v1) | J Krishnamoorthi | 2026-01-30 | General AI | The IceCube detector, using its densely instrumented center, called DeepCore, can detect multi-GeV atmospheric neutrinos. The oscillation pattern of neutrinos is altered due to interactions with ambient electrons as they pass through Earth. The changes in these patterns are influenced by the amount of matter and its specific arrangement. As neutrinos propagate, they retain information about the densities they encounter. Our study demonstrates that IceCube DeepCore can utilize the Earth's matter effects to distinguish between a homogeneous matter density profile and a layered structure density profile of Earth. In this contribution, we present that IceCube DeepCore data equivalent to 9.3 years of observation can reject the homogeneous matter density profile with a confidence level of 1.4$œÉ$. | [üîó Paper](https://arxiv.org/abs/2601.23057v1) |
| [Some elementary amenable subgroups of interval exchange transformations](https://arxiv.org/abs/2601.23054v1) | Nancy Guelman, Isabelle Liousse | 2026-01-30 | General AI | In this paper, we study a family of finitely generated elementary amenable iet-groups. These groups are generated by finitely many rationals iets and rotations. For them, we state criteria for not virtual nilpotency or solvability, and we give conditions to ensure that they are not virtually solvable. We precise their abelianizations, we determine when they are isomorphic to certain lamplighter groups and we provide non isomorphic cases among them. As consequences, in the class of infinite finitely generated subgroups of iets up to isomorphism, we exhibit infinitely many non virtually solvable and non linear groups, and infinitely many solvable groups of arbitrary derived length. | [üîó Paper](https://arxiv.org/abs/2601.23054v1) |
| [On two-dimensional Dirac operators with critical delta-shell interactions](https://arxiv.org/abs/2601.23053v1) | William Borrelli, Pietro Carimati, Davide Fermi | 2026-01-30 | General AI | We study two-dimensional Dirac operators with singular interactions of electrostatic and Lorentzscalar type, supported either on a straight line or a circle. For certain critical values of the interaction strengths, the essential spectrum of such operators comprises an isolated point lying within the mass gap. We clarify the nature of this point in both geometries. For the straight line model, this point is known to be an eigenvalue of infinite multiplicity, and we provide a detailed analysis of the corresponding eigenfunctions. By contrast, in the case of a circle, we show that the said point is not itself an eigenvalue, but rather an accumulation point of a double sequence of simple eigenvalues. In view of the high degree of symmetry of the configurations under analysis, this behavior is unexpected and our findings lead us to formulate some conjectures concerning critical singular interactions supported on generic smooth curves. | [üîó Paper](https://arxiv.org/abs/2601.23053v1) |
| [Adaptive Edge Learning for Density-Aware Graph Generation](https://arxiv.org/abs/2601.23052v1) | Seyedeh Ava Razi Razavi, James Sargant, Sheridan Houghten, Renata Dividino | 2026-01-30 | General AI | Generating realistic graph-structured data is challenging due to discrete structures, variable sizes, and class-specific connectivity patterns that resist conventional generative modelling. While recent graph generation methods employ generative adversarial network (GAN) frameworks to handle permutation invariance and irregular topologies, they typically rely on random edge sampling with fixed probabilities, limiting their capacity to capture complex structural dependencies between nodes. We propose a density-aware conditional graph generation framework using Wasserstein GANs (WGAN) that replaces random sampling with a learnable distance-based edge predictor. Our approach embeds nodes into a latent space where proximity correlates with edge likelihood, enabling the generator to learn meaningful connectivity patterns. A differentiable edge predictor determines pairwise relationships directly from node embeddings, while a density-aware selection mechanism adaptively controls edge density to match class-specific sparsity distributions observed in real graphs. We train the model using a WGAN with gradient penalty, employing a GCN-based critic to ensure generated graphs exhibit realistic topology and align with target class distributions. Experiments on benchmark datasets demonstrate that our method produces graphs with superior structural coherence and class-consistent connectivity compared to existing baselines. The learned edge predictor captures complex relational patterns beyond simple heuristics, generating graphs whose density and topology closely match real structural distributions. Our results show improved training stability and controllable synthesis, making the framework effective for realistic graph generation and data augmentation. Source code is publicly available at https://github.com/ava-12/Density_Aware_WGAN.git. | [üîó Paper](https://arxiv.org/abs/2601.23052v1) |
| [Theory of Little-Parks oscillations by vortices in two-dimensional superconductors](https://arxiv.org/abs/2601.23050v1) | Ying-Ming Xie, Naoto Nagaosa | 2026-01-30 | General AI | The Little-Parks (LP) effect is a quantum phenomenon in which the superconducting transition temperature of a superconducting cylinder (or ring) oscillates periodically as a function of the magnetic flux threading the loop. Recently, multiple experiments have observed half-quantum flux shifts in measurements of LP oscillations, where the oscillations are globally shifted by half a flux quantum compared to conventional cases, a behavior referred to as a $œÄ$-ring. Such observations are commonly linked to unconventional pairing symmetries. In this work, we demonstrate that half-quantum flux shifts can arise in two-dimensional (2D) superconducting rings without invoking unconventional pairing symmetry, provided that vortices near the Berezinskii-Kosterlitz-Thouless (BKT) transition are taken into account. Specifically, based on the vortex-charge duality theory near the BKT transition, we map the problem onto a Coulomb gas model, in which the magnetic flux is represented as a pair of opposite boundary charges (or vortices) at the two edges. The screening of these boundary charges by thermally excited vortex-antivortex pairs is investigated through explicit Monte Carlo simulations. Importantly, we demonstrate that the oscillation of the free-vortex density as a function of magnetic flux can exhibit an anomalous half-quantum flux shift, depending on the geometry of the sample. Our work thus predicts the LP oscillations induced by vortices in 2D superconducting rings near the BKT transition, which provides a new mechanism for generating $œÄ$-rings. | [üîó Paper](https://arxiv.org/abs/2601.23050v1) |
| [Establishing Earth's Matter Effect in Atmospheric Neutrino Oscillations at IceCube DeepCore](https://arxiv.org/abs/2601.23047v1) | Anuj Kumar Upadhyay | 2026-01-30 | General AI | The discovery of the non-zero value of $Œ∏_{13}$ has opened an exciting opportunity to probe the Earth's matter effects in three-flavor oscillations of atmospheric neutrinos. These matter effects depend on both neutrino energy and the electron density distributions encountered during their propagation through Earth. In this contribution, we present preliminary sensitivities from the DeepCore detector, a densely instrumented sub-array of the IceCube neutrino observatory at the South Pole, demonstrating its ability to observe these matter effects in atmospheric neutrino oscillations. Using simulated data equivalent to 9.3 years of observations at IceCube DeepCore, we show the sensitivity of the DeepCore to reject the vacuum oscillation hypothesis and align with the Preliminary Reference Earth Model. Additionally, we present the expected improvement in sensitivity for rejecting the vacuum oscillations using the upcoming IceCube Upgrade, a low-energy extension of the IceCube detector. | [üîó Paper](https://arxiv.org/abs/2601.23047v1) |
| [Stereoscopic Observations of Solar X-ray Sources Explained by a Data-Constrained Magnetohydrodynamic Simulation](https://arxiv.org/abs/2601.23046v1) | Keitarou Matsumoto, Satoshi Inoue, Meiqi Wang, S√§m Krucker, Satoshi Masuda, Muriel Zo√´ Stiefel, Jeongwoo Lee, Bin Chen, Haimin Wang | 2026-01-30 | General AI | We investigated the three-dimensional (3D) magnetic structures and dynamics responsible for particle acceleration in an X7.1-class flare that occurred on October 1, 2024, in NOAA active region 13842. We combined stereoscopic hard X-ray (HXR) observations from the Advanced Space-based Solar Observatory/Hard X-ray Imager (HXI) and the Solar Orbiter/Spectrometer Telescope for Imaging X-rays (STIX) with a 3D magnetohydrodynamic (MHD) simulation constrained by observed photospheric magnetic fields. During the two main peaks of the impulsive phase, HXR footpoints appeared at different locations, indicating a migration of the primary reconnection site in the corona. Our data-constrained MHD simulation successfully reproduced the reconnected field lines linking the observed conjugate HXR footpoints. Furthermore, the simulation shows that these primary reconnections occur along a single quasi-separatrix layer (QSL) system. Therefore, the two main peaks of HXR can be interpreted as episodic energy release within the single QSL system. This study demonstrates that the data-constrained MHD model provides a realistic 3D magnetic context for interpreting HXR emission. Notably, STIX observations revealed a vertically distributed thermal HXR source, extending from the footpoints to the looptop, with its centroid migrating between the two peaks. This marks a first step toward understanding the particle acceleration processes in solar flares. | [üîó Paper](https://arxiv.org/abs/2601.23046v1) |
| [Scalable Memory Sharing in Photonic Quantum Memristors for Reservoir Computing](https://arxiv.org/abs/2601.23044v1) | Chaehyeon Lim, Hyungchul Park, Beomjoon Chae, Jeonghun Kwak, Soo-Yeon Lee, Namkyoo Park, Sunkyu Yu | 2026-01-30 | General AI | Although photons are robust, room-temperature carriers well suited to quantum machine learning, the absence of photon-photon interactions hinder the realization of memory functionalities that are critical for capturing long-range context. Recently, measurement-based implementations of photonic quantum memristors (PQMRs) have enabled tunable non-Markovian responses. However, their memory remains confined to local elements, in contrast to biological or artificial networks where memory is shared across the system. Here, we propose a scalable PQMR network that enables measurement-based memory sharing. Each memristive node updates its internal state using the history of its own and neighbouring quantum states, thereby realizing distributed memory. By modelling each node as a photonic quantum memtransistor, we demonstrate pronounced enhancements in both classical and quantum hysteresis at the device level, as well as enhanced network-level quantum hysteresis. Implemented as a quantum reservoir, the architecture achieves improved Fashion-MNIST classification accuracy and confidence via increased data separability. Our approach paves the way toward high-capacity quantum machine learning using memristive devices compatible with linear-optical quantum computing. | [üîó Paper](https://arxiv.org/abs/2601.23044v1) |
| [Charging energy effects on a single-edge anyon braiding detector](https://arxiv.org/abs/2601.23042v1) | No√© Demazure, Flavio Ronetti, Beno√Æt Gr√©maud, Laurent Raymond, Masayuki Hashisaka, Takeo Kato, Thierry Martin | 2026-01-30 | General AI | We investigate the influence of capacitive coupling on the detection of anyon braiding in a single-edge interferometer realized in the fractional quantum Hall regime. In this setup, a quantum point contact bends a single edge into a loop, where tunneling occurs at the open end and is controlled by the QPC voltage. In contrast with previously studied two-edge geometries, the weak backscattering regime is dominated by the first-order perturbative term, allowing quantum transport quantities to factorize into a non-universal prefactor and a braiding-induced contribution that provides direct access to the universal statistical angle $œÄŒª$. While previous analyses neglected edge-to-edge capacitance, we show that capacitive effects, which are known to play a crucial role in mesoscopic capacitors, modify both the current and the current cross-correlations. Using a two-point Green's function formalism augmented by Dyson's equation to include the charging energy, we quantify how the fluctuations of the cross-correlations depend simultaneously on $Œª$ and on the capacitance of the loop. Our results indicate that a reliable extraction of the statistical angle requires a parallel measurement of the loop capacitance, which can be implemented via a charged gate coupled to the junction. | [üîó Paper](https://arxiv.org/abs/2601.23042v1) |
| [Instability of two-dimensional Taylor-Green Vortices](https://arxiv.org/abs/2601.23040v1) | Gonzalo Cao-Labora, Maria Colombo, Michele Dolce, Paolo Ventura | 2026-01-30 | General AI | For a wide class of linear Hamiltonian operators we develop a general criterion that characterizes the unstable eigenvalues as the zeros of a holomorphic function given by the determinant of a finite-dimensional matrix. We apply the latter result to prove the spectral instability of the Taylor-Green vortex in two-dimensional ideal fluids. The linearized Euler operator at this steady state possesses different invariant subspaces, within which we apply our criterion to rule out or detect instabilities. We show linear stability of odd perturbations, for which the unstable spectrum can appear only on the real axis. We exclude this possibility by applying our stability criterion. Real instabilities, instead, exist and can be detected with the same criterion if we consider suitable rescalings of the Taylor-Green vortex. In the subspace of functions even in both variables, the problem is reduced to finding a single complex root of our stability function. We successfully locate this value by combining our general criterion with a rigorous computer-assisted argument. As a consequence, we fully characterize the unstable spectrum of the Taylor-Green vortex. | [üîó Paper](https://arxiv.org/abs/2601.23040v1) |
| [Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference](https://arxiv.org/abs/2601.23039v1) | Yizhi Liu | 2026-01-30 | General AI | Differentiable matching layers, often implemented via entropy-regularized Optimal Transport, serve as a critical approximate inference mechanism in structural prediction. However, recovering discrete permutations via annealing $Œµ\to 0$ is notoriously unstable. We identify a fundamental mechanism for this failure: \textbf{Premature Mode Collapse}. By analyzing the non-normal dynamics of the Sinkhorn fixed-point map, we reveal a theoretical \textbf{thermodynamic speed limit}. Under standard exponential cooling, the shift in the target posterior ($O(1)$) outpaces the contraction rate of the inference operator, which degrades as $O(1/Œµ)$. This mismatch inevitably forces the inference trajectory into spurious local basins. To address this, we propose \textbf{Efficient PH-ASC}, an adaptive scheduling algorithm that monitors the stability of the inference process. By enforcing a linear stability law, we decouple expensive spectral diagnostics from the training loop, reducing overhead from $O(N^3)$ to amortized $O(1)$. Our implementation and interactive demo are available at https://github.com/xxx0438/torch-sinkhorn-asc and https://huggingface.co/spaces/leon0923/torch-sinkhorn-asc-demo. bounded away from zero in generic training dynamics unless the feature extractor converges unrealistically fast. | [üîó Paper](https://arxiv.org/abs/2601.23039v1) |
