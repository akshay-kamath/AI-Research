# üìå AI Research Papers (August04 to August10)

## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [GAP: Gaussianize Any Point Clouds with Text Guidance](http://arxiv.org/abs/2508.05631v1) | Weiqi Zhang, Junsheng Zhou, Haotian Geng, Wenyuan Zhang, Yu-Shen Liu | 2025-08-07 | Diffusion Models, Optimization | 3D Gaussian Splatting (3DGS) has demonstrated its advantages in achieving fast and high-quality rendering. As point clouds serve as a widely-used and easily accessible form of 3D representation, bridging the gap between point clouds and Gaussians becomes increasingly important. Recent studies have explored how to convert the colored points into Gaussians, but directly generating Gaussians from colorless 3D point clouds remains an unsolved challenge. In this paper, we propose GAP, a novel approach that gaussianizes raw point clouds into high-fidelity 3D Gaussians with text guidance. Our key idea is to design a multi-view optimization framework that leverages a depth-aware image diffusion model to synthesize consistent appearances across different viewpoints. To ensure geometric accuracy, we introduce a surface-anchoring mechanism that effectively constrains Gaussians to lie on the surfaces of 3D shapes during optimization. Furthermore, GAP incorporates a diffuse-based inpainting strategy that specifically targets at completing hard-to-observe regions. We evaluate GAP on the Point-to-Gaussian generation task across varying complexity levels, from synthetic point clouds to challenging real-world scans, and even large-scale scenes. Project Page: https://weiqi-zhang.github.io/GAP. | [üîó Paper](http://arxiv.org/abs/2508.05631v1) |
| [Latent Space Diffusion for Topology Optimization](http://arxiv.org/abs/2508.05624v1) | Aaron Lutheran, Srijan Das, Alireza Tabarraei | 2025-08-07 | Diffusion Models, Optimization | Topology optimization enables the automated design of efficient structures by optimally distributing material within a defined domain. However, traditional gradient-based methods often scale poorly with increasing resolution and dimensionality due to the need for repeated finite element analyses and sensitivity evaluations. In this work, we propose a novel framework that combines latent diffusion models (LDMs) with variational autoencoders (VAEs) to enable fast, conditional generation of optimized topologies. Unlike prior approaches, our method conditions the generative process on physically meaningful fields, specifically von Mises stress, strain energy density, volume fraction, and loading information, embedded as dense input channels. To further guide the generation process, we introduce auxiliary loss functions that penalize floating material, load imbalance, and volume fraction deviation, thereby encouraging physically realistic and manufacturable designs. Numerical experiments on a large synthetic dataset demonstrate that our VAE-LDM framework outperforms existing diffusion-based methods in compliance accuracy, volume control, and structural connectivity, providing a robust and scalable alternative to conventional | [üîó Paper](http://arxiv.org/abs/2508.05624v1) |
| [Unveiling the Lithium-Ion Transport Mechanism in Li2ZrCl6 Solid-State
  Electrolyte via Deep Learning-Accelerated Molecular Dynamics Simulations](http://arxiv.org/abs/2508.05598v1) | Hanzeng Guo, Volodymyr Koverga, Selva Chandrasekaran Selvaraj, Anh T. Ngo | 2025-08-07 | Diffusion Models | Lithium zirconium chlorides (LZCs) present a promising class of cost-effective solid electrolyte for next-generation all-solid-state batteries. The unique crystal structure of LZCs plays a crucial role in facilitating lithium-ion mobility, which is central to their electrochemical performance. To understand the underlying mechanism governing ion transport, we employed deep learning-accelerated molecular dynamics simulation on Li2ZrCl6 (trigonal {\alpha}- and monoclinic \b{eta}-LZC), focusing specifically on the zirconium coordination environment. Our results reveal that disordered {\alpha}-LZC exhibits the highest ionic conductivity, while \b{eta}-LZC demonstrates significantly lower conductivity, closely aligning with experimental findings. Detailed analysis shows substantial differences in lithium-ion dynamics: {\alpha}-LZC phases display pronounced collective diffusion driven anisotropic interlayer transport, whereas lithium mobility in \b{eta}-LZC is largely determined by isotropic translations and individual diffusion dominated by intralayer migration. Across all phases, lithium migration proceeds via site-to-site hopping mechanism, where variations in site residence times critically impact the overall ionic conductivity. Local structure organizations analysis confirms that particular zirconium arrangements in LZC phases create varied ion channel energy barriers, influencing dynamic behaviors: In {\alpha}-LZC phases, the interlayer hopping barrier is lower than the intralayer barrier, facilitating faster ion transport. Disordered {\alpha}-LZC, with its loose zirconium arrangement, presents the lowest energy barrier, enhancing conductivity. Conversely, \b{eta}-LZC features a higher overall barrier, with intralayer hopping favored over interlayer, resulting in slower ion migration. | [üîó Paper](http://arxiv.org/abs/2508.05598v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Genie Envisioner: A Unified World Foundation Platform for Robotic
  Manipulation](http://arxiv.org/abs/2508.05635v1) | Yue Liao, Pengfei Zhou, Siyuan Huang, Donglin Yang, Shengcong Chen, Yuxin Jiang, Yue Hu, Jingbin Cai, Si Liu, Jianlan Luo, Liliang Chen, Shuicheng Yan, Maoqing Yao, Guanghui Ren | 2025-08-07 | RLHF, Diffusion Models, Multimodal AI, Training & Evaluation | We introduce Genie Envisioner (GE), a unified world foundation platform for robotic manipulation that integrates policy learning, evaluation, and simulation within a single video-generative framework. At its core, GE-Base is a large-scale, instruction-conditioned video diffusion model that captures the spatial, temporal, and semantic dynamics of real-world robotic interactions in a structured latent space. Built upon this foundation, GE-Act maps latent representations to executable action trajectories through a lightweight, flow-matching decoder, enabling precise and generalizable policy inference across diverse embodiments with minimal supervision. To support scalable evaluation and training, GE-Sim serves as an action-conditioned neural simulator, producing high-fidelity rollouts for closed-loop policy development. The platform is further equipped with EWMBench, a standardized benchmark suite measuring visual fidelity, physical consistency, and instruction-action alignment. Together, these components establish Genie Envisioner as a scalable and practical foundation for instruction-driven, general-purpose embodied intelligence. All code, models, and benchmarks will be released publicly. | [üîó Paper](http://arxiv.org/abs/2508.05635v1) |
| [Towards Generalizable Safety in Crowd Navigation via Conformal
  Uncertainty Handling](http://arxiv.org/abs/2508.05634v1) | Jianpeng Yao, Xiaopan Zhang, Yu Xia, Zejin Wang, Amit K. Roy-Chowdhury, Jiachen Li | 2025-08-07 | RLHF, Responsible AI, Ongoing Learning, Model Evaluation | Mobile robots navigating in crowds trained using reinforcement learning are known to suffer performance degradation when faced with out-of-distribution scenarios. We propose that by properly accounting for the uncertainties of pedestrians, a robot can learn safe navigation policies that are robust to distribution shifts. Our method augments agent observations with prediction uncertainty estimates generated by adaptive conformal inference, and it uses these estimates to guide the agent's behavior through constrained reinforcement learning. The system helps regulate the agent's actions and enables it to adapt to distribution shifts. In the in-distribution setting, our approach achieves a 96.93% success rate, which is over 8.80% higher than the previous state-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times fewer intrusions into ground-truth human future trajectories. In three out-of-distribution scenarios, our method shows much stronger robustness when facing distribution shifts in velocity variations, policy changes, and transitions from individual to group dynamics. We deploy our method on a real robot, and experiments show that the robot makes safe and robust decisions when interacting with both sparse and dense crowds. Our code and videos are available on https://gen-safe-nav.github.io/. | [üîó Paper](http://arxiv.org/abs/2508.05634v1) |
| [On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification](http://arxiv.org/abs/2508.05629v1) | Yongliang Wu, Yizhou Zhou, Zhou Ziheng, Yingzhe Peng, Xinyu Ye, Xinting Hu, Wenbo Zhu, Lu Qi, Ming-Hsuan Yang, Xu Yang | 2025-08-07 | RLHF, Optimization, LLM | We present a simple yet theoretically motivated improvement to Supervised Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited generalization compared to reinforcement learning (RL). Through mathematical analysis, we reveal that standard SFT gradients implicitly encode a problematic reward structure that may severely restrict the generalization capabilities of model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing gradient updates for each token by dynamically rescaling the objective function with the probability of this token. Remarkably, this single-line code change significantly outperforms standard SFT across multiple challenging benchmarks and base models, demonstrating greatly improved generalization. Additionally, our approach shows competitive results in offline RL settings, offering an effective yet simpler alternative. This work bridges theoretical insight and practical solutions, substantially advancing SFT performance. The code will be available at https://github.com/yongliang-wu/DFT. | [üîó Paper](http://arxiv.org/abs/2508.05629v1) |
| [Learning to Reason for Factuality](http://arxiv.org/abs/2508.05618v1) | Xilun Chen, Ilia Kulikov, Vincent-Pierre Berges, Barlas Oƒüuz, Rulin Shao, Gargi Ghosh, Jason Weston, Wen-tau Yih | 2025-08-07 | RLHF, Responsible AI, Training & Evaluation, Model Evaluation | Reasoning Large Language Models (R-LLMs) have significantly advanced complex reasoning tasks but often struggle with factuality, generating substantially more hallucinations than their non-reasoning counterparts on long-form factuality benchmarks. However, extending online Reinforcement Learning (RL), a key component in recent R-LLM advancements, to the long-form factuality setting poses several unique challenges due to the lack of reliable verification methods. Previous work has utilized automatic factuality evaluation frameworks such as FActScore to curate preference data in the offline RL setting, yet we find that directly leveraging such methods as the reward in online RL leads to reward hacking in multiple ways, such as producing less detailed or relevant responses. We propose a novel reward function that simultaneously considers the factual precision, response detail level, and answer relevance, and applies online RL to learn high quality factual reasoning. Evaluated on six long-form factuality benchmarks, our factual reasoning model achieves an average reduction of 23.1 percentage points in hallucination rate, a 23% increase in answer detail level, and no degradation in the overall response helpfulness. | [üîó Paper](http://arxiv.org/abs/2508.05618v1) |
| [Test-Time Reinforcement Learning for GUI Grounding via Region
  Consistency](http://arxiv.org/abs/2508.05615v1) | Yong Du, Yuchen Yan, Fei Tang, Zhengxi Lu, Chang Zong, Weiming Lu, Shengpei Jiang, Yongliang Shen | 2025-08-07 | RLHF, Scaling Laws, Optimization | Graphical User Interface (GUI) grounding, the task of mapping natural language instructions to precise screen coordinates, is fundamental to autonomous GUI agents. While existing methods achieve strong performance through extensive supervised training or reinforcement learning with labeled rewards, they remain constrained by the cost and availability of pixel-level annotations. We observe that when models generate multiple predictions for the same GUI element, the spatial overlap patterns reveal implicit confidence signals that can guide more accurate localization. Leveraging this insight, we propose GUI-RC (Region Consistency), a test-time scaling method that constructs spatial voting grids from multiple sampled predictions to identify consensus regions where models show highest agreement. Without any training, GUI-RC improves accuracy by 2-3% across various architectures on ScreenSpot benchmarks. We further introduce GUI-RCPO (Region Consistency Policy Optimization), which transforms these consistency patterns into rewards for test-time reinforcement learning. By computing how well each prediction aligns with the collective consensus, GUI-RCPO enables models to iteratively refine their outputs on unlabeled data during inference. Extensive experiments demonstrate the generality of our approach: GUI-RC boosts Qwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO further improves it to 85.14% through self-supervised optimization. Our approach reveals the untapped potential of test-time scaling and test-time reinforcement learning for GUI grounding, offering a promising path toward more robust and data-efficient GUI agents. | [üîó Paper](http://arxiv.org/abs/2508.05615v1) |
| [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models
  via Data-centric Dynamic Shuffle](http://arxiv.org/abs/2508.05612v1) | Linghao Zhu, Yiran Guan, Dingkang Liang, Jianzhong Ju, Zhenbo Luo, Bin Qin, Jian Luan, Yuliang Liu, Xiang Bai | 2025-08-07 | RLHF, Multimodal AI, Optimization | Reinforcement learning (RL) has emerged as an effective post-training paradigm for enhancing the reasoning capabilities of multimodal large language model (MLLM). However, current RL pipelines often suffer from training inefficiencies caused by two underexplored issues: Advantage Collapsing, where most advantages in a batch concentrate near zero, and Rollout Silencing, where the proportion of rollouts contributing non-zero gradients diminishes over time. These issues lead to suboptimal gradient updates and hinder long-term learning efficiency. To address these issues, we propose Shuffle-R1, a simple yet principled framework that improves RL fine-tuning efficiency by dynamically restructuring trajectory sampling and batch composition. It introduces (1) Pairwise Trajectory Sampling, which selects high-contrast trajectories with large advantages to improve gradient signal quality, and (2) Advantage-based Trajectory Shuffle, which increases exposure of valuable rollouts through informed batch reshuffling. Experiments across multiple reasoning benchmarks show that our framework consistently outperforms strong RL baselines with minimal overhead. These results highlight the importance of data-centric adaptations for more efficient RL training in MLLM. | [üîó Paper](http://arxiv.org/abs/2508.05612v1) |
| [Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity](http://arxiv.org/abs/2508.05609v1) | Yuhan Zhang, Long Zhuo, Ziyang Chu, Tong Wu, Zhibing Li, Liang Pan, Dahua Lin, Ziwei Liu | 2025-08-07 | RLHF, Multimodal AI, Training & Evaluation | Despite rapid advances in 3D content generation, quality assessment for the generated 3D assets remains challenging. Existing methods mainly rely on image-based metrics and operate solely at the object level, limiting their ability to capture spatial coherence, material authenticity, and high-fidelity local details. 1) To address these challenges, we introduce Hi3DEval, a hierarchical evaluation framework tailored for 3D generative content. It combines both object-level and part-level evaluation, enabling holistic assessments across multiple dimensions as well as fine-grained quality analysis. Additionally, we extend texture evaluation beyond aesthetic appearance by explicitly assessing material realism, focusing on attributes such as albedo, saturation, and metallicness. 2) To support this framework, we construct Hi3DBench, a large-scale dataset comprising diverse 3D assets and high-quality annotations, accompanied by a reliable multi-agent annotation pipeline. We further propose a 3D-aware automated scoring system based on hybrid 3D representations. Specifically, we leverage video-based representations for object-level and material-subject evaluations to enhance modeling of spatio-temporal consistency and employ pretrained 3D features for part-level perception. Extensive experiments demonstrate that our approach outperforms existing image-based metrics in modeling 3D characteristics and achieves superior alignment with human preference, providing a scalable alternative to manual evaluations. The project page is available at https://zyh482.github.io/Hi3DEval/. | [üîó Paper](http://arxiv.org/abs/2508.05609v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [MOSEv2: A More Challenging Dataset for Video Object Segmentation in
  Complex Scenes](http://arxiv.org/abs/2508.05630v1) | Henghui Ding, Kaining Ying, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H. S. Torr, Song Bai | 2025-08-07 | Multimodal AI | Video object segmentation (VOS) aims to segment specified target objects throughout a video. Although state-of-the-art methods have achieved impressive performance (e.g., 90+% J&F) on existing benchmarks such as DAVIS and YouTube-VOS, these datasets primarily contain salient, dominant, and isolated objects, limiting their generalization to real-world scenarios. To advance VOS toward more realistic environments, coMplex video Object SEgmentation (MOSEv1) was introduced to facilitate VOS research in complex scenes. Building on the strengths and limitations of MOSEv1, we present MOSEv2, a significantly more challenging dataset designed to further advance VOS methods under real-world conditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks for 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2 introduces significantly greater scene complexity, including more frequent object disappearance and reappearance, severe occlusions and crowding, smaller objects, as well as a range of new challenges such as adverse weather (e.g., rain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot sequences, camouflaged objects, non-physical targets (e.g., shadows, reflections), scenarios requiring external knowledge, etc. We benchmark 20 representative VOS methods under 5 different settings and observe consistent performance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9% on MOSEv2. We further evaluate 9 video object tracking methods and find similar declines, demonstrating that MOSEv2 presents challenges across tasks. These results highlight that despite high accuracy on existing datasets, current VOS methods still struggle under real-world complexities. MOSEv2 is publicly available at https://MOSE.video. | [üîó Paper](http://arxiv.org/abs/2508.05630v1) |
| [LLaVA-RE: Binary Image-Text Relevancy Evaluation with Multimodal Large
  Language Model](http://arxiv.org/abs/2508.05602v1) | Tao Sun, Oliver Liu, JinJin Li, Lan Ma | 2025-08-07 | Multimodal AI, Training & Evaluation | Multimodal generative AI usually involves generating image or text responses given inputs in another modality. The evaluation of image-text relevancy is essential for measuring response quality or ranking candidate responses. In particular, binary relevancy evaluation, i.e., ``Relevant'' vs. ``Not Relevant'', is a fundamental problem. However, this is a challenging task considering that texts have diverse formats and the definition of relevancy varies in different scenarios. We find that Multimodal Large Language Models (MLLMs) are an ideal choice to build such evaluators, as they can flexibly handle complex text formats and take in additional task information. In this paper, we present LLaVA-RE, a first attempt for binary image-text relevancy evaluation with MLLM. It follows the LLaVA architecture and adopts detailed task instructions and multimodal in-context samples. In addition, we propose a novel binary relevancy data set that covers various tasks. Experimental results validate the effectiveness of our framework. | [üîó Paper](http://arxiv.org/abs/2508.05602v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Error Bounds for Radial Network Topology Learning from Quantized
  Measurements](http://arxiv.org/abs/2508.05620v1) | Samuel Talkington, Aditya Rangarajan, Pedro A. de Alc√¢ntara, Line Roald, Daniel K. Molzahn, Daniel R. Fuhrmann | 2025-08-07 | Optimization | We probabilistically bound the error of a solution to a radial network topology learning problem where both connectivity and line parameters are estimated. In our model, data errors are introduced by the precision of the sensors, i.e., quantization. This produces a nonlinear measurement model that embeds the operation of the sensor communication network into the learning problem, expanding beyond the additive noise models typically seen in power system estimation algorithms. We show that the error of a learned radial network topology is proportional to the quantization bin width and grows sublinearly in the number of nodes, provided that the number of samples per node is logarithmic in the number of nodes. | [üîó Paper](http://arxiv.org/abs/2508.05620v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language
  Modelling in Morphologically-Rich Languages](http://arxiv.org/abs/2508.05628v1) | Mehrdad Zakershahrak, Samira Ghodratnama | 2025-08-07 | Model Evaluation, Responsible AI, LLM | Byte-level language models eliminate fragile tokenizers but face computational challenges in morphologically-rich languages (MRLs), where words span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that learns linguistically-informed segmentation through end-to-end training. Key innovations include: (1) a lightweight Transformer context-mixer (1.9M parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for document-level consistency, (3) specialized handling of orthographic artifacts (e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks align with Persian morphology without explicit supervision, demonstrating that hierarchical dynamic chunking provides an effective tokenizer-free solution for MRLs while maintaining computational efficiency. | [üîó Paper](http://arxiv.org/abs/2508.05628v1) |
| [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](http://arxiv.org/abs/2508.05614v1) | Zixuan Wang, Dingming Li, Hongxing Li, Shuo Chen, Yuchen Yan, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang | 2025-08-07 | Model Evaluation, Optimization, Training & Evaluation | Large language models excel at abstract reasoning but their capacity for embodied agent reasoning remains largely unexplored. We present OmniEAR, a comprehensive framework for evaluating how language models reason about physical interactions, tool usage, and multi-agent coordination in embodied tasks. Unlike existing benchmarks that provide predefined tool sets or explicit collaboration directives, OmniEAR requires agents to dynamically acquire capabilities and autonomously determine coordination strategies based on task demands. Through text-based environment representation, we model continuous physical properties and complex spatial relationships across 1,500 scenarios spanning household and industrial domains. Our systematic evaluation reveals severe performance degradation when models must reason from constraints: while achieving 85-96% success with explicit instructions, performance drops to 56-85% for tool reasoning and 63-85% for implicit collaboration, with compound tasks showing over 50% failure rates. Surprisingly, complete environmental information degrades coordination performance, indicating models cannot filter task-relevant constraints. Fine-tuning improves single-agent tasks dramatically (0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing fundamental architectural limitations. These findings demonstrate that embodied reasoning poses fundamentally different challenges than current models can address, establishing OmniEAR as a rigorous benchmark for evaluating and advancing embodied AI systems. Our code and data are included in the supplementary materials and will be open-sourced upon acceptance. | [üîó Paper](http://arxiv.org/abs/2508.05614v1) |
| [Thin-Film Solar Photovoltaics: Trends and Future Directions](http://arxiv.org/abs/2508.05589v1) | Donald Intal, Abasifreke U. Ebong | 2025-08-07 | Model Evaluation | Thin-film photovoltaic (PV) technologies address crucial challenges in solar energy applications, including scalability, cost-effectiveness, and environmental sustainability. This paper reviews critically, thin-film technologies such as amorphous silicon (a-Si), cadmium telluride (CdTe), and copper indium gallium selenide (CIGS). It also discusses emerging technologies, including perovskites, copper zinc tin sulfide (CZTS), quantum dots (QDs), organic photovoltaics (OPV), and dye-sensitized solar cells (DSSC). Among these, CdTe and CIGS currently dominate commercial viability, achieving laboratory-scale efficiencies of 23.1% and 23.6%, respectively. Perovskites have notably advanced, reaching a laboratory efficiency of 26.7%. Thin-film PV technologies significantly reduce material use and manufacturing costs, offering distinct advantages such as flexibility and lightweight structures, thereby enabling diverse applications from building-integrated systems to portable electronic devices. Despite these benefits, broader adoption remains limited by challenges including long-term stability, toxicity concerns, and material scarcity. Addressing these challenges through advancements in tandem architectures, improved encapsulation strategies, and sustainable material sourcing is essential for thin-film PV technologies to substantially contribute to the global renewable energy transition. | [üîó Paper](http://arxiv.org/abs/2508.05589v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and
  Vision](http://arxiv.org/abs/2508.05606v1) | Luozheng Qin, Jia Gong, Yuqing Sun, Tianjiao Li, Mengping Yang, Xiaomeng Yang, Chao Qu, Zhiyu Tan, Hao Li | 2025-08-07 | Prompt Engineering, Diffusion Models, Multimodal AI | Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large Language Models (LLMs) by decomposing complex tasks into simpler, sequential subtasks. However, extending CoT to vision-language reasoning tasks remains challenging, as it often requires interpreting transitions of visual states to support reasoning. Existing methods often struggle with this due to limited capacity of modeling visual state transitions or incoherent visual trajectories caused by fragmented architectures.   To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought framework that enables coherent and grounded multimodal reasoning within a single unified model. The key idea is to leverage a model capable of both image understanding and generation to reason over visual content and model evolving visual states. However, empowering a unified model to achieve that is non-trivial, given the high computational cost and the burden of training. To address this, Uni-CoT introduces a novel two-level reasoning paradigm: A Macro-Level CoT for high-level task planning and A Micro-Level CoT for subtask execution. This design significantly reduces the computational overhead. Furthermore, we introduce a structured training paradigm that combines interleaved image-text supervision for macro-level CoT with multi-task objectives for micro-level CoT. Together, these innovations allow Uni-CoT to perform scalable and coherent multi-modal reasoning. Furthermore, thanks to our design, all experiments can be efficiently completed using only 8 A100 GPUs with 80GB VRAM each. Experimental results on reasoning-driven image generation benchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT demonstrates SOTA performance and strong generalization, establishing Uni-CoT as a promising solution for multi-modal reasoning. Project Page and Code: https://sais-fuxi.github.io/projects/uni-cot/ | [üîó Paper](http://arxiv.org/abs/2508.05606v1) |
| [WeTok: Powerful Discrete Tokenization for High-Fidelity Visual
  Reconstruction](http://arxiv.org/abs/2508.05599v1) | Shaobin Zhuang, Yiwei Guo, Canmiao Fu, Zhipeng Huang, Zeyue Tian, Ying Zhang, Chen Li, Yali Wang | 2025-08-07 | Prompt Engineering, Optimization | Visual tokenizer is a critical component for vision generation. However, the existing tokenizers often face unsatisfactory trade-off between compression ratios and reconstruction fidelity. To fill this gap, we introduce a powerful and concise WeTok tokenizer, which surpasses the previous leading tokenizers via two core innovations. (1) Group-wise lookup-free Quantization (GQ). We partition the latent features into groups, and perform lookup-free quantization for each group. As a result, GQ can efficiently overcome memory and computation limitations of prior tokenizers, while achieving a reconstruction breakthrough with more scalable codebooks. (2) Generative Decoding (GD). Different from prior tokenizers, we introduce a generative decoder with a prior of extra noise variable. In this case, GD can probabilistically model the distribution of visual data conditioned on discrete tokens, allowing WeTok to reconstruct visual details, especially at high compression ratios. Extensive experiments on mainstream benchmarks show superior performance of our WeTok. On the ImageNet 50k validation set, WeTok achieves a record-low zero-shot rFID (WeTok: 0.12 vs. FLUX-VAE: 0.18 vs. SD-VAE 3.5: 0.19). Furthermore, our highest compression model achieves a zero-shot rFID of 3.49 with a compression ratio of 768, outperforming Cosmos (384) 4.57 which has only 50% compression rate of ours. Code and models are available: https://github.com/zhuangshaobin/WeTok. | [üîó Paper](http://arxiv.org/abs/2508.05599v1) |
| [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging
  Synthetic Problems with a Reinforced Policy](http://arxiv.org/abs/2508.05592v1) | Shaoxiong Zhan, Yanlin Lai, Ziyu Lu, Dahua Lin, Ziqing Yang, Fei Tang | 2025-08-07 | Prompt Engineering, RLHF | Large language models have achieved substantial progress in mathematical reasoning, yet their advancement is limited by the scarcity of high-quality, high-difficulty training data. Existing synthesis methods largely rely on transforming human-written templates, limiting both diversity and scalability. We propose MathSmith, a novel framework for synthesizing challenging mathematical problems to enhance LLM reasoning. Rather than modifying existing problems, MathSmith constructs new ones from scratch by randomly sampling concept-explanation pairs from PlanetMath, ensuring data independence and avoiding contamination. To increase difficulty, we design nine predefined strategies as soft constraints during rationales. We further adopts reinforcement learning to jointly optimize structural validity, reasoning complexity, and answer consistency. The length of the reasoning trace generated under autoregressive prompting is used to reflect cognitive complexity, encouraging the creation of more demanding problems aligned with long-chain-of-thought reasoning. Experiments across five benchmarks, categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025, OlympiadBench), show that MathSmith consistently outperforms existing baselines under both short and long CoT settings. Additionally, a weakness-focused variant generation module enables targeted improvement on specific concepts. Overall, MathSmith exhibits strong scalability, generalization, and transferability, highlighting the promise of high-difficulty synthetic data in advancing LLM reasoning capabilities. | [üîó Paper](http://arxiv.org/abs/2508.05592v1) |
## üîπ Graph AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge
  Graph Embedding Models](http://arxiv.org/abs/2508.05587v1) | Claudia d'Amato, Ivan Diliso, Nicola Fanizzi, Zafar Saeed | 2025-08-07 | Graph AI | Embedding methods have become popular due to their scalability on link prediction and/or triple classification tasks on Knowledge Graphs. Embedding models are trained relying on both positive and negative samples of triples. However, in the absence of negative assertions, these must be usually artificially generated using various negative sampling strategies, ranging from random corruption to more sophisticated techniques which have an impact on the overall performance. Most of the popular libraries for knowledge graph embedding, support only basic such strategies and lack advanced solutions. To address this gap, we deliver an extension for the popular KGE framework PyKEEN that integrates a suite of several advanced negative samplers (including both static and dynamic corruption strategies), within a consistent modular architecture, to generate meaningful negative samples, while remaining compatible with existing PyKEEN -based workflows and pipelines. The developed extension not only enhancesPyKEEN itself but also allows for easier and comprehensive development of embedding methods and/or for their customization. As a proof of concept, we present a comprehensive empirical study of the developed extensions and their impact on the performance (link prediction tasks) of different embedding methods, which also provides useful insights for the design of more effective strategies | [üîó Paper](http://arxiv.org/abs/2508.05587v1) |
## üîπ Ongoing Learning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven
  Evolution](http://arxiv.org/abs/2508.05616v1) | Zhikai Zhao, Chuanbo Hua, Federico Berto, Kanghoon Lee, Zihan Ma, Jiachen Li, Jinkyoo Park | 2025-08-07 | Ongoing Learning | Trajectory prediction is a critical task in modeling human behavior, especially in safety-critical domains such as social robotics and autonomous vehicle navigation. Traditional heuristics based on handcrafted rules often lack accuracy and generalizability. Although deep learning approaches offer improved performance, they typically suffer from high computational cost, limited explainability, and, importantly, poor generalization to out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a framework that leverages Large Language Models (LLMs) to automatically design trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data. We propose two key innovations: Cross-Generation Elite Sampling to encourage population diversity, and a Statistics Feedback Loop that enables the LLM to analyze and improve alternative predictions. Our evaluations demonstrate that TrajEvo outperforms existing heuristic methods across multiple real-world datasets, and notably surpasses both heuristic and deep learning methods in generalizing to an unseen OOD real-world dataset. TrajEvo marks a promising step toward the automated design of fast, explainable, and generalizable trajectory prediction heuristics. We release our source code to facilitate future research at https://github.com/ai4co/trajevo. | [üîó Paper](http://arxiv.org/abs/2508.05616v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [KuaiLive: A Real-time Interactive Dataset for Live Streaming
  Recommendation](http://arxiv.org/abs/2508.05633v1) | Changle Qu, Sunhao Dai, Ke Guo, Liqin Zhao, Yanan Niu, Xiao Zhang, Jun Xu | 2025-08-07 | Responsible AI | Live streaming platforms have become a dominant form of online content consumption, offering dynamically evolving content, real-time interactions, and highly engaging user experiences. These unique characteristics introduce new challenges that differentiate live streaming recommendation from traditional recommendation settings and have garnered increasing attention from industry in recent years. However, research progress in academia has been hindered by the lack of publicly available datasets that accurately reflect the dynamic nature of live streaming environments. To address this gap, we introduce KuaiLive, the first real-time, interactive dataset collected from Kuaishou, a leading live streaming platform in China with over 400 million daily active users. The dataset records the interaction logs of 23,772 users and 452,621 streamers over a 21-day period. Compared to existing datasets, KuaiLive offers several advantages: it includes precise live room start and end timestamps, multiple types of real-time user interactions (click, comment, like, gift), and rich side information features for both users and streamers. These features enable more realistic simulation of dynamic candidate items and better modeling of user and streamer behaviors. We conduct a thorough analysis of KuaiLive from multiple perspectives and evaluate several representative recommendation methods on it, establishing a strong benchmark for future research. KuaiLive can support a wide range of tasks in the live streaming domain, such as top-K recommendation, click-through rate prediction, watch time prediction, and gift price prediction. Moreover, its fine-grained behavioral data also enables research on multi-behavior modeling, multi-task learning, and fairness-aware recommendation. The dataset and related resources are publicly available at https://imgkkk574.github.io/KuaiLive. | [üîó Paper](http://arxiv.org/abs/2508.05633v1) |
## üîπ Autonomous Agents

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [The Missing Reward: Active Inference in the Era of Experience](http://arxiv.org/abs/2508.05619v1) | Bo Wen | 2025-08-07 | Autonomous Agents | This paper argues that Active Inference (AIF) provides a crucial foundation for developing autonomous AI agents capable of learning from experience without continuous human reward engineering. As AI systems begin to exhaust high-quality training data and rely on increasingly large human workforces for reward design, the current paradigm faces significant scalability challenges that could impede progress toward genuinely autonomous intelligence. The proposal for an ``Era of Experience,'' where agents learn from self-generated data, is a promising step forward. However, this vision still depends on extensive human engineering of reward functions, effectively shifting the bottleneck from data curation to reward curation. This highlights what we identify as the \textbf{grounded-agency gap}: the inability of contemporary AI systems to autonomously formulate, adapt, and pursue objectives in response to changing circumstances. We propose that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, allowing agents to naturally balance exploration and exploitation through a unified Bayesian objective. By integrating Large Language Models as generative world models with AIF's principled decision-making framework, we can create agents that learn efficiently from experience while remaining aligned with human values. This synthesis offers a compelling path toward AI systems that can develop autonomously while adhering to both computational and physical constraints. | [üîó Paper](http://arxiv.org/abs/2508.05619v1) |
## üîπ Security & Adversarial ML

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Secure Quantum Key Distribution via Entangled Quantum Walkers](http://arxiv.org/abs/2508.05593v1) | Chia-Tso Lai | 2025-08-07 | Security & Adversarial ML | Quantum Key Distribution (QKD) is an emerging cryptographic method designed for secure key sharing. Its security is theoretically guaranteed by fundamental principles of quantum mechanics, making it a leading candidate for future communication protocols. Quantum Random Walks (QRWs), on the other hand, are quantum processes that exhibit intriguing phenomena such as interference and superposition, enabling the generation of decentralized and asymmetric probability distributions. Inspired by both fields of study, we propose a novel QKD protocol based on two entangled quantum walkers. Our protocol exploits the unique correlations between the walkers at extremal positions of the walk to establish secret keys shared exclusively by the two parties. The security of the protocol is augmented by analyzing the joint probability distributions of the walkers' measured positions and their associated coin states. | [üîó Paper](http://arxiv.org/abs/2508.05593v1) |
| [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](http://arxiv.org/abs/2508.05591v1) | Natalia Emelianova, Carlos Kamienski, Ronaldo C. Prati | 2025-08-07 | Security & Adversarial ML, AI Safety | The exponential growth of the Internet of Things (IoT) has led to the emergence of substantial security concerns, with IoT networks becoming the primary target for cyberattacks. This study examines the potential of Kolmogorov-Arnold Networks (KANs) as an alternative to conventional machine learning models for intrusion detection in IoT networks. The study demonstrates that KANs, which employ learnable activation functions, outperform traditional MLPs and achieve competitive accuracy compared to state-of-the-art models such as Random Forest and XGBoost, while offering superior interpretability for intrusion detection in IoT networks. | [üîó Paper](http://arxiv.org/abs/2508.05591v1) |
## üîπ Fine-Tuning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning
  for Large Language Models](http://arxiv.org/abs/2508.05613v1) | Haitao Hong, Yuchen Yan, Xingyu Wu, Guiyang Hou, Wenqi Zhang, Weiming Lu, Yongliang Shen, Jun Xiao | 2025-08-07 | Fine-Tuning, RLHF, Responsible AI, Model Evaluation | Large language models (LLMs) have demonstrated remarkable performance in reasoning tasks, where reinforcement learning (RL) serves as a key algorithm for enhancing their reasoning capabilities. Currently, there are two mainstream reward paradigms: model-based rewards and rule-based rewards. However, both approaches suffer from limitations: rule-based rewards lack robustness, while model-based rewards are vulnerable to reward hacking. To address these issues, we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework that jointly optimizes both the policy model and the reward model. Cooper leverages the high precision of rule-based rewards when identifying correct responses, and dynamically constructs and selects positive-negative sample pairs for continued training the reward model. This design enhances robustness and mitigates the risk of reward hacking. To further support Cooper, we introduce a hybrid annotation strategy that efficiently and accurately generates training data for the reward model. We also propose a reference-based reward modeling paradigm, where the reward model takes a reference answer as input. Based on this design, we train a reward model named VerifyRM, which achieves higher accuracy on VerifyBench compared to other models of the same size. We conduct reinforcement learning using both VerifyRM and Cooper. Our experiments show that Cooper not only alleviates reward hacking but also improves end-to-end RL performance, for instance, achieving a 0.54% gain in average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that dynamically updating reward model is an effective way to combat reward hacking, providing a reference for better integrating reward models into RL. | [üîó Paper](http://arxiv.org/abs/2508.05613v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [FaceAnonyMixer: Cancelable Faces via Identity Consistent Latent Space
  Mixing](http://arxiv.org/abs/2508.05636v1) | Mohammed Talha Alam, Fahad Shamshad, Fakhri Karray, Karthik Nandakumar | 2025-08-07 | General AI | Advancements in face recognition (FR) technologies have amplified privacy concerns, necessitating methods that protect identity while maintaining recognition utility. Existing face anonymization methods typically focus on obscuring identity but fail to meet the requirements of biometric template protection, including revocability, unlinkability, and irreversibility. We propose FaceAnonyMixer, a cancelable face generation framework that leverages the latent space of a pre-trained generative model to synthesize privacy-preserving face images. The core idea of FaceAnonyMixer is to irreversibly mix the latent code of a real face image with a synthetic code derived from a revocable key. The mixed latent code is further refined through a carefully designed multi-objective loss to satisfy all cancelable biometric requirements. FaceAnonyMixer is capable of generating high-quality cancelable faces that can be directly matched using existing FR systems without requiring any modifications. Extensive experiments on benchmark datasets demonstrate that FaceAnonyMixer delivers superior recognition accuracy while providing significantly stronger privacy protection, achieving over an 11% gain on commercial API compared to recent cancelable biometric methods. Code is available at: https://github.com/talha-alam/faceanonymixer. | [üîó Paper](http://arxiv.org/abs/2508.05636v1) |
| [Partial projected ensembles and spatiotemporal structure of information
  scrambling](http://arxiv.org/abs/2508.05632v1) | Saptarshi Mandal, Pieter W. Claeys, Sthitadhi Roy | 2025-08-07 | General AI | Thermalisation and information scrambling in out-of-equilibrium quantum many-body systems are deeply intertwined: local subsystems dynamically approach thermal density matrices while their entropies track information spreading. Projected ensembles--ensembles of pure states conditioned on measurement outcomes of complementary subsystems--provide higher-order probes of thermalisation, converging at late times to universal maximum-entropy ensembles. In this work, we introduce the partial projected ensemble (PPE) as a framework to study how the spatiotemporal structure of scrambling is imprinted on projected ensembles. The PPE consists of an ensemble of mixed states induced on a subsystem by measurements on a spatially separated part of its complement, tracing out the remainder, naturally capturing scenarios involving discarded outcomes or noise-induced losses. We show that statistical fluctuations of the PPE faithfully track the causal lightcone of information spreading, revealing how scrambling dynamics are encoded in ensemble structure. In addition, we demonstrate that the probabilities of bit-string probabilities (PoPs) associated with the PPE exhibit distinct dynamical regimes and provide an experimentally accessible probe of scrambling. Both PPE fluctuations and PoPs display exponential sensitivity to the size of the discarded region, reflecting exponential degradation of quantum correlations under erasure. We substantiate these findings using the non-integrable kicked Ising chain, combining numerics in the ergodic regime with exact results at its self-dual point. We extend our analysis to a many-body localised (MBL) regime numerically, along with analytic results for the $\ell$-bit model. The linear and logarithmic lightcones characteristic of ergodic and MBL regimes emerge naturally from PPE dynamics, establishing it as a powerful tool for probing scrambling and deep thermalisation. | [üîó Paper](http://arxiv.org/abs/2508.05632v1) |
| [LiDO: Discovery of a 10:1 Resonator with a Novel Libration State](http://arxiv.org/abs/2508.05627v1) | Rosemary E. Pike, Ruth Murray-Clay, Kathryn Volk, Mike Alexandersen, Mark Comte, Samantha M. Lawler, Ying-Tung Chen, Arcelia Hermosillo Ruiz, Cameron Semenchuck, Cameron Collyer, J. J. Kavelaars, Lowell Peltier | 2025-08-07 | General AI | The Large inclination Distant Objects LiDO survey has discovered the first securely classified object in the 10:1 mean motion resonance of Neptune. This object, 2020 VN40, is short-term stable in the 10:1 resonance, but not stable on Gyr timescales. 2020 VN40 is likely part of the scattering sticking population, and temporarily resides in the 10:1 resonance at ~139.5 au. This discovery confirms that this distant resonance is populated, as a single detection is likely to be indicative of a large population that is difficult to detect due to observational biases. This object has an inclination of 33.4 degrees, and n-body integrations of orbital clones of 2020 VN40 have revealed some unexpected evolutions. While clones of 2020 VN40 show resonant libration around the expected resonance centers of approximately 90, 180, and 270 degrees, for a restricted range of inclination and eccentricity values some clones librate around a resonant argument of 0 degrees. As this occurs for the slightly lower-eccentricity portions of the evolution, this behavior can also be quite stable. Our initial exploration suggests that this libration around a center of 0 degrees is a generic effect for highly inclined objects in n:1 resonances because the nature of their resonant interaction with Neptune becomes a strong function of their argument of pericenter, omega. At large inclination, the resonant islands shift as omega precesses, switching the center of symmetric libration to 0 degrees for omega=90 degrees and omega=270 degrees. 2020 VN40 provides interesting insight into the evolution of the large-inclination resonators, which become more common at increasing semi-major axis. | [üîó Paper](http://arxiv.org/abs/2508.05627v1) |
| [Physically Controllable Relighting of Photographs](http://arxiv.org/abs/2508.05626v1) | Chris Careaga, Yaƒüƒ±z Aksoy | 2025-08-07 | General AI | We present a self-supervised approach to in-the-wild image relighting that enables fully controllable, physically based illumination editing. We achieve this by combining the physical accuracy of traditional rendering with the photorealistic appearance made possible by neural rendering. Our pipeline works by inferring a colored mesh representation of a given scene using monocular estimates of geometry and intrinsic components. This representation allows users to define their desired illumination configuration in 3D. The scene under the new lighting can then be rendered using a path-tracing engine. We send this approximate rendering of the scene through a feed-forward neural renderer to predict the final photorealistic relighting result. We develop a differentiable rendering process to reconstruct in-the-wild scene illumination, enabling self-supervised training of our neural renderer on raw image collections. Our method represents a significant step in bringing the explicit physical control over lights available in typical 3D computer graphics tools, such as Blender, to in-the-wild relighting. | [üîó Paper](http://arxiv.org/abs/2508.05626v1) |
| [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in
  Multi-Turn Conversations](http://arxiv.org/abs/2508.05625v1) | Brandon Jaipersaud, David Krueger, Ekdeep Singh Lubana | 2025-08-07 | General AI | Large Language Models (LLMs) have started to demonstrate the ability to persuade humans, yet our understanding of how this dynamic transpires is limited. Recent work has used linear probes, lightweight tools for analyzing model representations, to study various LLM skills such as the ability to model user sentiment and political perspective. Motivated by this, we apply probes to study persuasion dynamics in natural, multi-turn conversations. We leverage insights from cognitive science to train probes on distinct aspects of persuasion: persuasion success, persuadee personality, and persuasion strategy. Despite their simplicity, we show that they capture various aspects of persuasion at both the sample and dataset levels. For instance, probes can identify the point in a conversation where the persuadee was persuaded or where persuasive success generally occurs across the entire dataset. We also show that in addition to being faster than expensive prompting-based approaches, probes can do just as well and even outperform prompting in some settings, such as when uncovering persuasion strategy. This suggests probes as a plausible avenue for studying other complex behaviours such as deception and manipulation, especially in multi-turn settings and large-scale dataset analysis where prompting-based methods would be computationally inefficient. | [üîó Paper](http://arxiv.org/abs/2508.05625v1) |
| [Five points for the Polyakov Bootstrap](http://arxiv.org/abs/2508.05623v1) | Ant√≥nio Antunes, Sebastian Harris, Apratim Kaviraj | 2025-08-07 | General AI | Higher-point correlation functions encode the data of infinitely many 4-point correlators in conformal field theory (CFT). In this paper, we develop new tools to efficiently extract this data from multi-point crossing equations. Concretely, we generalize the functionals constituting the so-called Polyakov bootstrap of 4-point correlators to the case of 5-point functions in one-dimensional CFTs. We first construct the crossing symmetric Polyakov blocks, and then derive sum-rules by requiring consistency with the operator product expansion (OPE). This procedure leads to two classes of functionals controlling OPE coefficients of double- and triple-twist families. After extensively checking the validity of the associated sum-rules, we apply our functionals to the truncated 5-point bootstrap where we find several advantages with respect to more standard derivative functionals. | [üîó Paper](http://arxiv.org/abs/2508.05623v1) |
| [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](http://arxiv.org/abs/2508.05622v1) | Yu Yuan, Lili Zhao, Wei Chen, Guangting Zheng, Kai Zhang, Mengdi Zhang, Qi Liu | 2025-08-07 | General AI | Capturing human learning behavior based on deep learning methods has become a major research focus in both psychology and intelligent systems. Recent approaches rely on controlled experiments or rule-based models to explore cognitive processes. However, they struggle to capture learning dynamics, track progress over time, or provide explainability. To address these challenges, we introduce LearnerAgent, a novel multi-agent framework based on Large Language Models (LLMs) to simulate a realistic teaching environment. To explore human-like learning dynamics, we construct learners with psychologically grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free General Learner to inspect the base LLM's default behavior. Through weekly knowledge acquisition, monthly strategic choices, periodic tests, and peer interaction, we can track the dynamic learning progress of individual learners over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis reveals that only Deep Learner achieves sustained cognitive growth. Our specially designed "trap questions" effectively diagnose Surface Learner's shallow knowledge. 2) The behavioral and cognitive patterns of distinct learners align closely with their psychological profiles. 3) Learners' self-concept scores evolve realistically, with the General Learner developing surprisingly high self-efficacy despite its cognitive limitations. 4) Critically, the default profile of base LLM is a "diligent but brittle Surface Learner"-an agent that mimics the behaviors of a good student but lacks true, generalizable understanding. Extensive simulation experiments demonstrate that LearnerAgent aligns well with real scenarios, yielding more insightful findings about LLMs' behavior. | [üîó Paper](http://arxiv.org/abs/2508.05622v1) |
| [Back to Bits: Extending Shannon's communication performance framework to
  computing](http://arxiv.org/abs/2508.05621v1) | Max Hawkins, Richard Vuduc | 2025-08-07 | General AI | This work proposes a novel computing performance unit grounded in information theory. Modern computing systems are increasingly diverse, supporting low-precision formats, hardware specialization, and emerging paradigms such as analog, quantum, and reversible logic. Traditional metrics like floating-point operations (flops) no longer accurately capture this complexity. We frame computing as the transformation of information through a channel and define performance in terms of the mutual information between a system's inputs and outputs. This approach measures not just the quantity of data processed, but the amount of meaningful information encoded, manipulated, and retained through computation. Our framework provides a principled, implementation-agnostic foundation for evaluating performance. | [üîó Paper](http://arxiv.org/abs/2508.05621v1) |
| [Pressure-induced decomposition of Bi14WO24](http://arxiv.org/abs/2508.05617v1) | E. Karaca, D. Santamaria-Perez, A. Otero-de-la-Roza, R. Oliva, K. S. Rao, S. N. Achary, C. Popescu, D. Errandonea | 2025-08-07 | General AI | We present a study of the high-pressure behaviour Bi14WO24, a high oxide ion conductor member of the Bi2O3-WO3 binary system. The tetragonal polymorph of Bi14WO24 was studied under high-pressure conditions using synchrotron powder X-ray diffraction. It was found that in contrast to isostructural Bi14CrO24 and Bi14MoO24 which experience a phase transition around 5 GPa, in our study Bi14WO24 undergoes an irreversible chemical decomposition into Bi2O3 and WO3 at 2.85(5) GPa. The pressure dependence of the unit-cell parameters of Bi14WO24 was also determined, and hence the linear compressibility along different axes and room-temperature pressure-volume equation of state were derived. Bulk modulus of tetragonal Bi14WO24 was found to be 49.8(2.6) GPa, and the linear compressibility of the two crystallographic axes, \k{appa}a and \k{appa}c were 6.94(2) 10-3 GPa-1 and = 3.73(1) 10-3 GPa-1, respectively. The pressure induced decomposition can be attributed to the favourable increasing density of the system to accommodate the pressure induced stress. | [üîó Paper](http://arxiv.org/abs/2508.05617v1) |
| [Mind the Gap: From Resolving Theoretical Foundations of
  Chiral(ity)-Induced Spin Selectivity to Pioneering Implementations in Quantum
  Sensing](http://arxiv.org/abs/2508.05611v1) | Yan Xi Foo, Aisha Kermiche, Farhan T. Chowdhury, Clarice D. Aiello, Luke D. Smith | 2025-08-07 | General AI | The chiral(ity)-induced spin selectivity (CISS) effect, where electrons passing through a chiral medium acquire significant spin-polarization at ambient temperatures, has been widely observed experimentally, yet its theoretical foundations remain actively debated. Open questions persist regarding whether CISS originates from helical geometry or more general chirality, and whether a unified mechanism can account for phenomena across solid-state and soft-matter systems, mesoscopic films, and single molecules. Clarifying the interrelations between existing models is essential to determine if a universal picture of CISS can be found or whether system-specific models are required, and if so, where their common starting point should lie for a workable classification of CISS manifestations. Despite this theoretical fragmentation, recent studies of CISS effects in electron transfer systems, magnetic field sensitivity and coherence of radical pair reactions, polarized electroluminescence in chiral hybrid perovskites, DNA-based biosensors, and enantioselective detection, highlight its broad conceptual relevance and potential applications in spintronics, molecular sensors, and quantum information processing. In this review, we help bridge the gap between theory, experiment, and implementation, with a particular focus on prospects for quantum sensing and metrology. We outline fundamental frameworks of CISS, clarifying what constitutes the `chiral', the `induced', and the `spin-selectivity' that makes up CISS, before going on to survey key model realizations and their assumptions. We examine some of the emerging quantum sensing applications and assess the model-specific implications, in particular exemplifying these in the context of spin-correlated radical pairs, which offer a promising, tunable, and biomimetic platform for emerging molecular quantum technologies. | [üîó Paper](http://arxiv.org/abs/2508.05611v1) |
| [On a 5D UV completion of Argyres-Douglas theories](http://arxiv.org/abs/2508.05610v1) | Giulio Bonelli, Pavlo Gavrylenko, Ideal Majtara, Alessandro Tanzini | 2025-08-07 | General AI | We discuss a novel UV completion of a class of Argyres-Douglas (AD) theories by its embedding into the renormalisation group flow from five dimensional $\mathcal{N}=1$ superconformal field theories (SCFT) on $S^1$. This is obtained via analysing these theories in the light of ($q$-)Painlev\'e/gauge theory correspondence, which allows to compute the five dimensional BPS partition functions as an expansion in the Wilson loop vev with integer $q$-polynomials coefficients. These are derived formulating the gauge theory on a blown-up geometry and using a five-dimensional lift of (topological) operator/state correspondence. We discuss in detail the phase diagram of the four dimensional limits, pinpointing the special AD loci. Explicit computations are reported for $\tilde E_1$ SCFT and its limit to H$_0=(A_1,A_2)$ AD theory. | [üîó Paper](http://arxiv.org/abs/2508.05610v1) |
| [Ultra-Large-Scale Compilation and Manipulation of Quantum Circuits with
  Pandora](http://arxiv.org/abs/2508.05608v1) | Ioana Moflic, Alexandru Paler | 2025-08-07 | General AI | There is an enormous gap between what quantum circuit sizes can be compiled and manipulated with the current generation of quantum software and the sizes required by practical applications such as quantum chemistry or Shor's algorithm. We present Pandora, an efficient, open-source, multithreaded, high-performance-computing-enabled tool based on circuit rewrites. Pandora can be used for quantum circuit equivalence checking, full compilations of large circuits, and scalable, streaming quantum resource estimation frameworks. Pandora can easily handle billions of gates and can stream circuit partitions in resource estimation pipelines at very high rates. We utilized Pandora for full compilations of Fermi-Hubbard 100x100 and 1024-bit Shor's algorithm circuits. Compared to TKET and Qiskit, we determine a performance advantage for manipulating circuits of more than 10000 gates. For equivalence checking tasks, Pandora outperforms MQT.QCEC on specific circuits that have more than 32 qubits. The performance and versatility of Pandora open novel paths in quantum software. | [üîó Paper](http://arxiv.org/abs/2508.05608v1) |
| [The Mpemba Effect in Pure Water Has a Stochastic Origin. Experimental
  and Theoretical Resolution of the Paradox](http://arxiv.org/abs/2508.05607v1) | Andrei A. Klimov, Alexei V. Finkelstein | 2025-08-07 | General AI | The "Mpemba effect" is the name given to the assertion that hot water freezes quicker than cold water1 or, in a modern and more general form, that the system that is initially more distant from its equilibrium state comes to this state earlier2. This counterintuitive statement seems to breach fundamental thermodynamic and kinetic laws; however, numerous experiments3-10 with classical and quantum systems demonstrate this paradoxical Mpemba effect, leading to extensive discssions in prominent scientific jornals2,5,9,12-14. However, the fundamental physical mechanisms behind this effect have remained elusive14. Here we performed the water freezing experiments under carefully controlled conditions, and found that the Mpemba effect only occurred when the freezer temperature was very close to the temperature of ice nucleation. In this case, the range of freezing times for both hot and cold water was so great that it exceeded the delayed cooling of the initially hotter liquid, and therefore sometimes the hot water froze before the cold water. Our theoretical analysis of this fact shows that the Mpemba paradox associated with water freezing is rooted in the stochastic nature of ice nucleation, typical of first-order phase transitions. We anticipate our assay to be a starting point for reconsidering the famous Mpemba paradox in water and other systems undergoing similar phase transitions. | [üîó Paper](http://arxiv.org/abs/2508.05607v1) |
| [Annular SL(2) and SL(3) web algebras](http://arxiv.org/abs/2508.05605v1) | Rostislav Akhmechet, Mikhail Khovanov, Melissa Zhang | 2025-08-07 | General AI | We use annular foam TQFTs introduced by the first two authors to define equivariant $SL(2)$ and $SL(3)$ web algebras in the annulus. To a diagram of a tangle in the thickened annulus we assign a complex of bimodules over these algebras whose chain homotopy type is an invariant of the tangle. Several properties of algebras and bimodules are established. An essential technical part of the paper provides a bijective correspondence between non-elliptic annular $SL(3)$ webs and closed paths in the $SL(3)$ weight lattice. This generalizes an analogous bijection in the planar setting. | [üîó Paper](http://arxiv.org/abs/2508.05605v1) |
| [Consistency of an Intercept-Shifted Synthetic-Control Estimator under
  Weighted Parallel Trends](http://arxiv.org/abs/2508.05604v1) | Michael Guggisberg | 2025-08-07 | General AI | The average treatment effect on the treated (ATT) in a staggered-adoption panel is estimated using an intercept-augmented synthetic-control (SCM) estimator. A weighted parallel trends plus an intercept shift, together with mild regularity on the weight vectors (non-degenerate dispersion) and expanding pre-treatment length, are sufficient for consistency allowing for heavy-tailed shocks. These conditions can be more interpretable than the autoregressive or low-rank factor models with light tails assumed by Ben-Michael, Feller, and Rothstein (2022) and expand the valid DGP pool from the same paper. Practical diagnostics to support the assumptions are discussed and situate these results within the recent literature on SC + DiD hybrids. | [üîó Paper](http://arxiv.org/abs/2508.05604v1) |
| [The discrete periodic Pitman transform: invariances, braid relations,
  and Burke properties](http://arxiv.org/abs/2508.05603v1) | Eva R. Engel, Benjamin Jasper Kra-Caskey, Oleksandr Lazorenko, Caio Hermano Maia de Oliveira, Evan Sorensen, Ivan Wong, Ryan Xu, Xinyi Zhang | 2025-08-07 | General AI | We develop the theory of the discrete periodic Pitman transform, first introduced by Corwin, Gu, and the fifth author. We prove that, for polymers in a periodic environment, single-path and multi-path partition functions are preserved under the action of this transform on the weights in the polymer model. As a corollary, we prove that the discrete periodic Pitman transform satisfies the same braid relations that are satisfied for the full-line Pitman transform, shown by Biane, Bougerol, and O'Connell. Combined with a new inhomogeneous Burke property for the periodic Pitman transform, we prove a multi-path invariance result for the periodic inverse-gamma polymer under permutations of the column parameters. In the limit to the full-line case, we obtain a multi-path extension of a recent invariance result of Bates, Emrah, Martin, Sepp\"al\"ainen, and the fifth author, in both positive and zero-temperature. Additionally, we give a combinatorial description of the distribution of the $2$-component jointly invariant measures for a discrete-time Markov chain. | [üîó Paper](http://arxiv.org/abs/2508.05603v1) |
| [Asymptotically-tight packing and covering with transversal bases in
  Rota's basis conjecture](http://arxiv.org/abs/2508.05601v1) | Richard Montgomery, Lisa Sauermann | 2025-08-07 | General AI | In 1989, Rota conjectured that, given any $n$ bases $B_1,\dots,B_n$ of a vector space of dimension $n$, or more generally a matroid of rank $n$, it is possible to rearrange these into $n$ disjoint transversal bases. Here, a transversal basis is a basis consisting of exactly one element from each of the original bases $B_1,\dots,B_n$. Two natural approaches to this conjecture are, to ask in this setting a) how many disjoint transversal bases can we find and b) how few transversal bases do we need to cover all the elements of $B_1,\dots,B_n$? In this paper, we give asymptotically-tight answers to both of these questions.   For a), we show that there are always $(1-o(1))n$ disjoint transversal bases, improving a result of Buci\'c, Kwan, Pokrovskiy, and Sudakov that $(1/2-o(1))n$ disjoint transversal bases always exist. For b), we show that $B_1\cup\dots \cup B_n$ can be covered by $(1+o(1))n$ transversal bases, improving a result of Aharoni and Berger using instead $2n$ transversal bases, and a subsequent result of the Polymath project on Rota's basis conjecture using $2n-2$ transversal bases. | [üîó Paper](http://arxiv.org/abs/2508.05601v1) |
| [Non-omniscient backdoor injection with a single poison sample: Proving
  the one-poison hypothesis for linear regression and linear classification](http://arxiv.org/abs/2508.05600v1) | Thorsten Peinemann, Paula Arnold, Sebastian Berndt, Thomas Eisenbarth, Esfandiar Mohammadi | 2025-08-07 | General AI | Backdoor injection attacks are a threat to machine learning models that are trained on large data collected from untrusted sources; these attacks enable attackers to inject malicious behavior into the model that can be triggered by specially crafted inputs. Prior work has established bounds on the success of backdoor attacks and their impact on the benign learning task, however, an open question is what amount of poison data is needed for a successful backdoor attack. Typical attacks either use few samples, but need much information about the data points or need to poison many data points.   In this paper, we formulate the one-poison hypothesis: An adversary with one poison sample and limited background knowledge can inject a backdoor with zero backdooring-error and without significantly impacting the benign learning task performance. Moreover, we prove the one-poison hypothesis for linear regression and linear classification. For adversaries that utilize a direction that is unused by the benign data distribution for the poison sample, we show that the resulting model is functionally equivalent to a model where the poison was excluded from training. We build on prior work on statistical backdoor learning to show that in all other cases, the impact on the benign learning task is still limited. We also validate our theoretical results experimentally with realistic benchmark data sets. | [üîó Paper](http://arxiv.org/abs/2508.05600v1) |
| [NP-Hardness and ETH-Based Inapproximability of Communication Complexity
  via Relaxed Interlacing](http://arxiv.org/abs/2508.05597v1) | Serge Gaspers, Zixu He, Simon Mackenzie | 2025-08-07 | General AI | We prove that computing the deterministic communication complexity D(f) of a Boolean function is NP-hard, even when protocols are limited to a constant number of alternations, resolving a question first posed by Yao (1979). Our reduction builds and expands on a suite of structural "interlacing" lemmas introduced by Mackenzie and Saffidine (arXiv:2411.19003); these lemmas can be reused as black boxes in future lower-bound constructions.   The instances produced by our reduction admit optimal protocols that use only constant alternations, so NP-hardness holds under stronger restrictions than those considered in concurrent and independent work by Hirahara, Ilango, and Loff (arXiv:2507.10426), whose proof requires unbounded alternations.   Because the gadgets in our construction are self-similar, they can be recursively embedded. We sketch how this yields, under the Exponential-Time Hypothesis, an additive inapproximability gap that grows without bound, and we outline a route toward NP-hardness of approximating D(f) within a fixed constant additive error. Full details of the ETH-based inapproximability results will appear in a future version.   Beyond settling the complexity of deterministic communication complexity itself, the modular framework we develop opens the door to a wider class of reductions and, we believe, will prove useful in tackling other long-standing questions in communication complexity. | [üîó Paper](http://arxiv.org/abs/2508.05597v1) |
| [Long-period variable stars in NGC 147 and NGC 185-II. Their dust
  production](http://arxiv.org/abs/2508.05596v1) | Hamidreza Mahani, Atefeh Javadi, Jacco van Loon, Francisca Kemper, Roya Hamedani Golshan, Iain McDonald, Habib Khosroshahi, Hedieh Abdollahi, Sajjad Mahdizadeh | 2025-08-07 | General AI | This study presents a comparative analysis of mass-loss and dust-production rates in the dwarf galaxies NGC 147 and NGC 185, focusing on long-period variables (LPVs) and pulsating asymptotic giant branch (AGB) stars as primary indicators of dust feedback into the interstellar medium. For NGC 147, the total mass-loss rate is calculated as $(9.44 \pm 3.78) \times 10^{-4} M_{sun} yr^{-1}$, with LPV luminosities ranging from $(6.20 \pm 0.25) \times 10^{2} L_\odot$ to $( 7.87 \pm 0.32) \times 10^{3} L_\odot $. In NGC 185, the total mass-loss rate is higher, at $(1.58 \pm 0.63) \times 10^{-3} M_{sun} yr^{-1}$, with LPV luminosities spanning $ (5.68 \pm 0.23) \times 10^{2} L_\odot $ to $(1.54 \pm 0.66) \times 10^{4} L_\odot$. A positive correlation is observed between stellar luminosity, intrinsic reddening due to circumstellar dust self-extinction, and elevated mass-loss rates. Additionally, comparisons of calculated dust injection rates, two-dimensional dust distribution maps, and observed dust masses provide evidence for a gravitational interaction between NGC 147 and the Andromeda galaxy, which influences the dust distribution within the system. | [üîó Paper](http://arxiv.org/abs/2508.05596v1) |
| [Gradient and Hessian-Based Temperature Estimator in Lattice Gauge
  Theories: A Diagnostic Tool for Stability and Consistency in Numerical
  Simulations](http://arxiv.org/abs/2508.05595v1) | Navdeep Singh Dhindsa, Anosh Joseph, Vamika Longia | 2025-08-07 | General AI | We present a field configuration-based temperature estimator in lattice gauge theories. It is constructed from the gradient and Hessian of the Euclidean action of the theory. Adapted from geometric formulations of entropy in classical statistical mechanics, this estimator provides a gauge-invariant, non-kinetic diagnostic of thermodynamic consistency in Monte Carlo simulations of lattice gauge theories. We validate the method in compact U(1) lattice gauge theories across one, two, and four dimensions, comparing the estimated temperature to the input temperature. Our results show that the estimator accurately reproduces the input temperature and remains robust across a range of lattice volumes and coupling strengths. The temperature estimator offers a general-purpose diagnostic for lattice field theory simulations, with potential applications to non-Abelian theories, anisotropic lattices, and real-time monitoring in hybrid Monte Carlo algorithms. | [üîó Paper](http://arxiv.org/abs/2508.05595v1) |
| [Data Analysis and Modeling for Transitioning Between Laboratory Methods
  for Detecting SARS-CoV-2 in Wastewater](http://arxiv.org/abs/2508.05594v1) | Maria M. Warns, Leah Mrowiec, Christopher Owen, Adam Horton, Chi-Yu Lin, Modou Lamin Jarju, Niall M. Mangan, Aaron Packman, Katelyn Plaisier Leisman, Abhilasha Shrestha, Rachel Poretsky | 2025-08-07 | General AI | Wastewater surveillance has proven to be a useful tool to monitor pathogens such as SARS-CoV-2 as it is a nonintrusive way to survey the potential disease burden of the population contributing to a sewershed. With the expansion of this field since the beginning of the COVID-19 pandemic, laboratory methods to process wastewater and quantify pathogen nucleic acid levels have improved as technologies changed, efforts expanded in size and scope, and supply chain issues were resolved. Maintaining data continuity is crucial for labs undergoing method transitions to accurately assess infectious disease levels over time and compare measured RNA concentrations to public health data. Despite the dynamic nature of laboratory methods and the necessity to ensure uninterrupted data, to our knowledge there has not been a study that unites two datasets from different lab methods for pathogen quantification from environmental samples. Here, we describe a lab transition from SARS-CoV-2 RNA quantification using a low-throughput, manual filtration-based wastewater concentration and RNA extraction followed by qPCR to a high-throughput, automated magnetic bead-based concentration and extraction followed by dPCR. During the two-month transition period, wastewater samples from across the Chicago metropolitan area were processed with both methods in parallel. We evaluated a variety of regression models to relate the RNA measurements from both methods and found a log-log model was most appropriate after removing outliers and discrepancy points to improve model performance. We also evaluated the consequences of assigning values to samples that were below the detection limit. Our study demonstrates that data continuity can be maintained throughout a transition of laboratory methods if there is a sufficient period of overlap between the methods for an appropriate model to be constructed to relate the datasets. | [üîó Paper](http://arxiv.org/abs/2508.05594v1) |
| [Design and Analysis of a Vanadium Dioxide-Based Ultra-Broadband
  Terahertz Metamaterial Absorber](http://arxiv.org/abs/2508.05590v1) | Robiul Hasan, Nafisa Anjum | 2025-08-07 | General AI | This paper presents a VO2-based metamaterial absorber optimized for ultra-broadband, polarization-insensitive performance in the terahertz (THz) frequency range. The absorber consists of a patterned VO2 metasurface, a low-loss MF2 dielectric spacer, and a gold ground plane. Exploiting the phase transition of VO2, the design enables dynamic control of electromagnetic absorption. Full-wave simulations show an average absorptance of 98.15% across a 5.38THz bandwidth (5.72-11.11THz) and over 99% absorption sustained across 3.35THz. The absorber maintains stable performance for varying polarization angles and both TE and TM modes under oblique incidence. Impedance analysis confirms strong matching to free space, reducing reflection and eliminating transmission. Parametric analysis investigates the influence of VO2 conductivity, MF2 thickness, and unit cell periodicity on performance. Compared to recent THz metamaterial absorbers, the proposed design achieves broader bandwidth, higher efficiency, and simpler implementation. These characteristics make it suitable for THz sensing, imaging, wireless communication, and adaptive photonic systems, and position it as a promising platform for tunable and reconfigurable THz modules. | [üîó Paper](http://arxiv.org/abs/2508.05590v1) |
| [Quench dynamics of entanglement entropy under projective charge
  measurements: the free fermion case](http://arxiv.org/abs/2508.05588v1) | Riccardo Travaglino, Colin Rylands, Pasquale Calabrese | 2025-08-07 | General AI | We consider the effect of projective measurements on the quench dynamics of the bipartite entanglement entropy in one dimensional free fermionic systems. In our protocol, we consider projective measurements of a $U(1)$ conserved charge, the particle number, on some large subsystem, and study the entanglement entropies between the same subsystem and its complement. We compare the dynamics emanating from two classes of initial states, one which is an eigenstate of the charge and another which is not. Moreover, we consider the effects of a single measurement as well as multiple which are periodically performed. Using the quasiparticle picture, we obtain analytic expressions for the behaviour of the entanglement which admit a transparent physical interpretation. In general, we find that measurements introduce two distinct types of corrections to the entanglement, which can be interpreted separately as classical and quantum contributions. The classical contribution is independent of the measurement outcome and scales logarithmically with variance of the charge distribution. In contrast, the quantum contribution depends on the specific measurement outcome and can be significant for individual realizations; however, it becomes negligible when averaged over all possible outcomes. Our expressions reduce to previously known results for symmetry resolved entanglement and full counting statistics in some relevant limits, and are confirmed by an exact calculation performed on the N\'eel initial state. | [üîó Paper](http://arxiv.org/abs/2508.05588v1) |
