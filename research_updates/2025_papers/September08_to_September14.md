# 📌 AI Research Papers (September08 to September14)

## 🔹 Diffusion Models

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning
  Dataset and Comprehensive Benchmark](http://arxiv.org/abs/2509.09680v1) | Rongyao Fang, Aldrich Yu, Chengqi Duan, Linjiang Huang, Shuai Bai, Yuxuan Cai, Kun Wang, Si Liu, Xihui Liu, Hongsheng Li | 2025-09-11 | Diffusion Models, Prompt Engineering, RLHF, Training & Evaluation, Multimodal AI | The advancement of open-source text-to-image (T2I) models has been hindered by the absence of large-scale, reasoning-focused datasets and comprehensive evaluation benchmarks, resulting in a performance gap compared to leading closed-source systems. To address this challenge, We introduce FLUX-Reason-6M and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark). FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality FLUX-generated images and 20 million bilingual (English and Chinese) descriptions specifically designed to teach complex reasoning. The image are organized according to six key characteristics: Imagination, Entity, Text rendering, Style, Affection, and Composition, and design explicit Generation Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation steps. The whole data curation takes 15,000 A100 GPU days, providing the community with a resource previously unattainable outside of large industrial labs. PRISM-Bench offers a novel evaluation standard with seven distinct tracks, including a formidable Long Text challenge using GCoT. Through carefully designed prompts, it utilizes advanced vision-language models for nuanced human-aligned assessment of prompt-image alignment and image aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench reveals critical performance gaps and highlights specific areas requiring improvement. Our dataset, benchmark, and evaluation code are released to catalyze the next wave of reasoning-oriented T2I generation. Project page: https://flux-reason-6m.github.io/ . | [🔗 Paper](http://arxiv.org/abs/2509.09680v1) |
## 🔹 Multimodal AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [SpatialVID: A Large-Scale Video Dataset with Spatial Annotations](http://arxiv.org/abs/2509.09676v1) | Jiahao Wang, Yufeng Yuan, Rujie Zheng, Youtian Lin, Jian Gao, Lin-Zhuo Chen, Yajie Bao, Yi Zhang, Chang Zeng, Yanxi Zhou, Xiaoxiao Long, Hao Zhu, Zhaoxiang Zhang, Xun Cao, Yao Yao | 2025-09-11 | Multimodal AI | Significant progress has been made in spatial intelligence, spanning both spatial reconstruction and world exploration. However, the scalability and real-world fidelity of current models remain severely constrained by the scarcity of large-scale, high-quality training data. While several datasets provide camera pose information, they are typically limited in scale, diversity, and annotation richness, particularly for real-world dynamic scenes with ground-truth camera motion. To this end, we collect \textbf{SpatialVID}, a dataset consists of a large corpus of in-the-wild videos with diverse scenes, camera movements and dense 3D annotations such as per-frame camera poses, depth, and motion instructions. Specifically, we collect more than 21,000 hours of raw video, and process them into 2.7 million clips through a hierarchical filtering pipeline, totaling 7,089 hours of dynamic content. A subsequent annotation pipeline enriches these clips with detailed spatial and semantic information, including camera poses, depth maps, dynamic masks, structured captions, and serialized motion instructions. Analysis of SpatialVID's data statistics reveals a richness and diversity that directly foster improved model generalization and performance, establishing it as a key asset for the video and 3D vision research community. | [🔗 Paper](http://arxiv.org/abs/2509.09676v1) |
## 🔹 Optimization

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable
  Orthogonal Butterfly Transforms](http://arxiv.org/abs/2509.09679v1) | Bingxin Xu, Zhen Dong, Oussama Elachqar, Yuzhang Shang | 2025-09-11 | Optimization, LLM, Training & Evaluation | Large language models require massive memory footprints, severely limiting deployment on consumer hardware. Quantization reduces memory through lower numerical precision, but extreme 2-bit quantization suffers from catastrophic performance loss due to outliers in activations. Rotation-based methods such as QuIP and QuaRot apply orthogonal transforms to eliminate outliers before quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} = (\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these methods use fixed transforms--Hadamard matrices achieving optimal worst-case coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight distributions. We identify that different transformer layers exhibit distinct outlier patterns, motivating layer-adaptive rotations rather than one-size-fits-all approaches. We propose ButterflyQuant, which replaces Hadamard rotations with learnable butterfly transforms parameterized by continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$ entries that are non-differentiable and prohibit gradient-based learning, butterfly transforms' continuous parameterization enables smooth optimization while guaranteeing orthogonality by construction. This orthogonal constraint ensures theoretical guarantees in outlier suppression while achieving $O(n \log n)$ computational complexity with only $\frac{n \log n}{2}$ learnable parameters. We further introduce a uniformity regularization on post-transformation activations to promote smoother distributions amenable to quantization. Learning requires only 128 calibration samples and converges in minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot. | [🔗 Paper](http://arxiv.org/abs/2509.09679v1) |
## 🔹 Scaling Laws

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [The Illusion of Diminishing Returns: Measuring Long Horizon Execution in
  LLMs](http://arxiv.org/abs/2509.09677v1) | Akshit Sinha, Arvindh Arun, Shashwat Goel, Steffen Staab, Jonas Geiping | 2025-09-11 | Scaling Laws, Training & Evaluation, Model Evaluation | Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks. | [🔗 Paper](http://arxiv.org/abs/2509.09677v1) |
## 🔹 General AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Cosmic $τ$ensions Indirectly Correlate with Reionization Optical
  Depth](http://arxiv.org/abs/2509.09678v1) | Itamar J. Allali, Lingfeng Li, Praniti Singh, JiJi Fan | 2025-09-11 | General AI | The reionization optical depth $\tau_{\rm reio}$ has interesting connections to existing cosmological anomalies. As first studied in the context of the Hubble tension in our previous paper, a larger $\tau_{\rm reio}$, which could be achieved by removing the Planck low-$\ell$ polarization data, could boost $H_0$ slightly, resulting in a mild reduction of the tension between the early- and late-universe determinations of $H_0$. It has been shown later that a larger $\tau_{\rm reio}$ could also relieve other anomalies including: the tension between BAO and CMB data, the neutrino mass tension, and the latest DESI plus supernovae data's tension with the standard cosmological constant scenario. In this paper, we systematically analyze the correlations between $\tau_{\rm reio}$ and relevant cosmological parameters in the existing cosmic observation anomalies. In addition to Pearson correlation coefficients extracted directly from the covariance matrix, we also study partial correlation coefficients which measure intrinsic relationships between pairs of parameters removing the influence of other parameters. We show that $\tau_{\rm reio}$ has weak intrinsic correlations with the parameters responsible for the tensions and anomalies discussed. The large direct Pearson correlations that allow larger $\tau_{\rm reio}$ inferences to alleviate the cosmological tensions each arise from complicated networks through multiple parameters. As a result, the relationships between $\tau_{\rm reio}$ and each anomaly are not independent of each other. We also employ our method of computing correlations to clarify the impact of large scale polarization data, and comment also on the effects of CMB observations from ACT and SPT. | [🔗 Paper](http://arxiv.org/abs/2509.09678v1) |
