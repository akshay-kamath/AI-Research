# 📌 AI Research Papers (July07 to July13)

## 🔹 LLM

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [PyVision: Agentic Vision with Dynamic Tooling](http://arxiv.org/abs/2507.07998v1) | Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei | 2025-07-10 | LLM | LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning. | [🔗 Paper](http://arxiv.org/abs/2507.07998v1) |
| [Finding sparse induced subgraphs on graphs of bounded induced matching
  treewidth](http://arxiv.org/abs/2507.07975v1) | Hans L. Bodlaender, Fedor V. Fomin, Tuukka Korhonen | 2025-07-10 | LLM | The induced matching width of a tree decomposition of a graph $G$ is the cardinality of a largest induced matching $M$ of $G$, such that there exists a bag that intersects every edge in $M$. The induced matching treewidth of a graph $G$, denoted by $\mathsf{tree-}\mu(G)$, is the minimum induced matching width of a tree decomposition of $G$. The parameter $\mathsf{tree-}\mu$ was introduced by Yolov [SODA '18], who showed that, for example, Maximum-Weight Independent Set can be solved in polynomial-time on graphs of bounded $\mathsf{tree-}\mu$. Lima, Milani\v{c}, Mur\v{s}i\v{c}, Okrasa, Rz\k{a}\.zewski, and \v{S}torgel [ESA '24] conjectured that this algorithm can be generalized to a meta-problem called Maximum-Weight Induced Subgraph of Bounded Treewidth, where we are given a vertex-weighted graph $G$, an integer $w$, and a $\mathsf{CMSO}_2$-sentence $\Phi$, and are asked to find a maximum-weight set $X \subseteq V(G)$ so that $G[X]$ has treewidth at most $w$ and satisfies $\Phi$. They proved the conjecture for some special cases, such as for the problem Maximum-Weight Induced Forest.   In this paper, we prove the general case of the conjecture. In particular, we show that Maximum-Weight Induced Subgraph of Bounded Treewidth is polynomial-time solvable when $\mathsf{tree-}\mu(G)$, $w$, and $ \Phi $ are bounded. The running time of our algorithm for $n$-vertex graphs $G$ with $\mathsf{tree} - \mu(G) \le k$ is $f(k, w,  \Phi ) \cdot n^{O(k w^2)}$ for a computable function $f$. | [🔗 Paper](http://arxiv.org/abs/2507.07975v1) |
## 🔹 Diffusion Models

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [EXPO: Stable Reinforcement Learning with Expressive Policies](http://arxiv.org/abs/2507.07986v1) | Perry Dong, Qiyang Li, Dorsa Sadigh, Chelsea Finn | 2025-07-10 | Diffusion Models, Optimization, RLHF | We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online. | [🔗 Paper](http://arxiv.org/abs/2507.07986v1) |
| [Geometry Forcing: Marrying Video Diffusion and 3D Representation for
  Consistent World Modeling](http://arxiv.org/abs/2507.07982v1) | Haoyu Wu, Diankun Wu, Tianyu He, Junliang Guo, Yang Ye, Yueqi Duan, Jiang Bian | 2025-07-10 | Diffusion Models, Multimodal AI, RLHF | Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: https://GeometryForcing.github.io. | [🔗 Paper](http://arxiv.org/abs/2507.07982v1) |
| [A Semi-Analytic model for Effects of Fuzzy Dark Matter Granule
  Perturbations on Orbital Motion](http://arxiv.org/abs/2507.07963v1) | Yu Zhao, Andrew Benson, Xiaolong Du | 2025-07-10 | Diffusion Models | In fuzzy dark matter scenarios, the quantum wave nature of ultralight axion-like particles generates stochastic density fluctuations inside dark matter halos. These fluctuations, known as granules, perturb the orbits of subhalos and other orbiting bodies. While previous studies have simulated these effects using N-body techniques or modeled them statistically using diffusion approximations, we propose an alternative framework based on representing the perturbations as a Fourier series with random coefficients, which can be applied to individual orbits, not just populations. We extend the model to finite-size subhalos, identifying a critical length scale below which subhalos behave as point-mass particles. In contrast, larger subhalos exhibit suppressed perturbations from granules due to their extended mass profiles. Using FDM-Simulator, we validate our finite-size model by isolating granule accelerations and confirming their statistical effects on subhalo dynamics. | [🔗 Paper](http://arxiv.org/abs/2507.07963v1) |
## 🔹 RLHF

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and
  Methodology](http://arxiv.org/abs/2507.07999v1) | Haochen Wang, Xiangtai Li, Zilong Huang, Anran Wang, Jiacong Wang, Tao Zhang, Jiani Zheng, Sule Bai, Zijian Kang, Jiashi Feng, Zhuochen Wang, Zhaoxiang Zhang | 2025-07-10 | RLHF, Training & Evaluation | Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human "thinking with images". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR. | [🔗 Paper](http://arxiv.org/abs/2507.07999v1) |
| [Reinforcement Learning with Action Chunking](http://arxiv.org/abs/2507.07969v1) | Qiyang Li, Zhiyuan Zhou, Sergey Levine | 2025-07-10 | RLHF | We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks. | [🔗 Paper](http://arxiv.org/abs/2507.07969v1) |
## 🔹 Multimodal AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Multigranular Evaluation for Brain Visual Decoding](http://arxiv.org/abs/2507.07993v1) | Weihao Xia, Cengiz Oztireli | 2025-07-10 | Multimodal AI, RLHF, Training & Evaluation | Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods. | [🔗 Paper](http://arxiv.org/abs/2507.07993v1) |
| [OST-Bench: Evaluating the Capabilities of MLLMs in Online
  Spatio-temporal Scene Understanding](http://arxiv.org/abs/2507.07984v1) | JingLi Lin, Chenming Zhu, Runsen Xu, Xiaohan Mao, Xihui Liu, Tai Wang, Jiangmiao Pang | 2025-07-10 | Multimodal AI | Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is: https://rbler1234.github.io/OSTBench.github.io/ | [🔗 Paper](http://arxiv.org/abs/2507.07984v1) |
| [Martian World Models: Controllable Video Synthesis with Physically
  Accurate 3D Reconstructions](http://arxiv.org/abs/2507.07978v1) | Longfei Li, Zhiwen Fan, Wenyan Cong, Xinhang Liu, Yuyang Yin, Matt Foutter, Panwang Pan, Chenyu You, Yue Wang, Zhangyang Wang, Yao Zhao, Marco Pavone, Yunchao Wei | 2025-07-10 | Multimodal AI | Synthesizing realistic Martian landscape videos is crucial for mission rehearsal and robotic simulation. However, this task poses unique challenges due to the scarcity of high-quality Martian data and the significant domain gap between Martian and terrestrial imagery. To address these challenges, we propose a holistic solution composed of two key components: 1) A data curation pipeline Multimodal Mars Synthesis (M3arsSynth), which reconstructs 3D Martian environments from real stereo navigation images, sourced from NASA's Planetary Data System (PDS), and renders high-fidelity multiview 3D video sequences. 2) A Martian terrain video generator, MarsGen, which synthesizes novel videos visually realistic and geometrically consistent with the 3D structure encoded in the data. Our M3arsSynth engine spans a wide range of Martian terrains and acquisition dates, enabling the generation of physically accurate 3D surface models at metric-scale resolution. MarsGen, fine-tuned on M3arsSynth data, synthesizes videos conditioned on an initial image frame and, optionally, camera trajectories or textual prompts, allowing for video generation in novel environments. Experimental results show that our approach outperforms video synthesis models trained on terrestrial datasets, achieving superior visual fidelity and 3D structural consistency. | [🔗 Paper](http://arxiv.org/abs/2507.07978v1) |
| [MIRIX: Multi-Agent Memory System for LLM-Based Agents](http://arxiv.org/abs/2507.07957v1) | Yu Wang, Xi Chen | 2025-07-10 | Multimodal AI, Autonomous Agents | Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy. | [🔗 Paper](http://arxiv.org/abs/2507.07957v1) |
| [Input Conditioned Layer Dropping in Speech Foundation Models](http://arxiv.org/abs/2507.07954v1) | Abdul Hannan, Daniele Falavigna, Alessio Brutti | 2025-07-10 | Multimodal AI | Curating foundation speech models for edge and IoT settings, where computational resources vary over time, requires dynamic architectures featuring adaptable reduction strategies. One emerging approach is layer dropping ($\mathcal{LD}$) which skips fraction of the layers of a backbone network during inference to reduce the computational load. This allows transforming static models into dynamic ones. However, existing approaches exhibit limitations either in the mode of selecting layers or by significantly modifying the neural architecture. To this end, we propose input-driven $\mathcal{LD}$ that employs the network's input features and a lightweight layer selecting network to determine the optimum combination of processing layers. Extensive experimentation on 4 speech and audio public benchmarks, using two different pre-trained foundation models, demonstrates the effectiveness of our approach, thoroughly outperforming random dropping and producing on-par (or better) results to early exit. | [🔗 Paper](http://arxiv.org/abs/2507.07954v1) |
## 🔹 Optimization

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group
  Quantization](http://arxiv.org/abs/2507.07997v1) | Mingkai Jia, Wei Yin, Xiaotao Hu, Jiaxin Guo, Xiaoyang Guo, Qian Zhang, Xiao-Xiao Long, Ping Tan | 2025-07-10 | Optimization, Prompt Engineering | Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental models that compress continuous visual data into discrete tokens. Existing methods have tried to improve the quantization strategy for better reconstruction quality, however, there still exists a large gap between VQ-VAEs and VAEs. To narrow this gap, we propose \NickName, a novel method to augment the representation capability of discrete codebooks, facilitating easier optimization for codebooks and minimizing information loss, thereby enhancing reconstruction quality. Specifically, we propose to retain the latent dimension to preserve encoded features and incorporate a set of sub-codebooks for quantization. Furthermore, we construct comprehensive zero-shot benchmarks featuring resolutions of 512p and 2k to evaluate the reconstruction performance of existing methods rigorously. \NickName~achieves the \textbf{state-of-the-art performance on both ImageNet and $8$ zero-shot benchmarks} across all VQ-VAEs. Notably, compared with SD-VAE, we outperform them on ImageNet significantly, with rFID $\textbf{0.49}$ v.s. $\textbf{0.91}$, and achieve superior PSNR on all zero-shot benchmarks. These results highlight the superiority of \NickName~in reconstruction and pave the way for preserving fidelity in HD image processing tasks. Code will be publicly available at https://github.com/MKJia/MGVQ. | [🔗 Paper](http://arxiv.org/abs/2507.07997v1) |
| [Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs](http://arxiv.org/abs/2507.07996v1) | Ziyue Li, Yang Li, Tianyi Zhou | 2025-07-10 | Optimization | Can a pretrained neural network adapt its architecture to different inputs without any finetuning? Do we need all layers for simple tasks, and are they adequate for challenging tasks? We found that the layers of a pretrained large language model (LLM) can be manipulated as separate modules to build a better and even shallower model customized for each test sample. In particular, each layer from the pretrained model can be skipped/pruned or repeated multiple times as recurrent neural networks (RNN), and stacked with others in arbitrary orders, yielding a chain-of-layers (CoLa) per sample. This compositional space greatly expands the scope of existing works on looped/recurrent pretrained modules, layer pruning, or early-exit networks. We develop a Monte Carlo Tree Search (MCTS) protocol to explore and identify the optimal CoLa for each sample from math and commonsense reasoning benchmarks. Compared to a static model of a fixed depth, CoLa allows shortcut paths (fast thinking), recurrence of the same layer(s) (slow thinking), and combining both, offering more flexible, dynamic architectures for different inputs. We conduct an extensive analysis of the MCTS-optimized CoLa, which leads to two key findings: (1) For >75% of samples with correct predictions by the original LLM, we can find shorter CoLa, suggesting a large space for improving inference efficiency; (2) For >60% of samples with originally incorrect predictions, we can identify CoLa achieving correct predictions, suggesting a large space of performance enhancement. Our results highlight the shortcomings of using a fixed architecture of pre-trained LLMs for inference on different samples and pave the way to unlock the generalization power of test-time depth adaptation. | [🔗 Paper](http://arxiv.org/abs/2507.07996v1) |
| [Multiple Axions Save High-Scale Inflation](http://arxiv.org/abs/2507.07973v1) | Dan Kondo, Hitoshi Murayama | 2025-07-10 | Optimization | Many models of dark matter QCD axion requires inflation at a scale $H_{\text{inf}} \lesssim 10^{6}$~GeV and hence does not allow for a detectable tensor mode fluctuation. This is because the domain wall problem forces the Peccei--Quinn symmetry to be broken during the inflation and the axions to be produced by the misalignment mechanism. We point out that theories with multiple axions can evade this constraint and allow for a high-scale inflation with detectable tensor mode. It only requires a condition on the anomaly coefficients so that there is a unique minimum for the axion potential without a fine-tuning or small parameters. | [🔗 Paper](http://arxiv.org/abs/2507.07973v1) |
## 🔹 Scaling Laws

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Impact of Pretraining Word Co-occurrence on Compositional Generalization
  in Multimodal Models](http://arxiv.org/abs/2507.08000v1) | Helen Qu, Sang Michael Xie | 2025-07-10 | Scaling Laws, Multimodal AI, Prompt Engineering | CLIP and large multimodal models (LMMs) have better accuracy on examples involving concepts that are highly represented in the training data. However, the role of concept combinations in the training data on compositional generalization is largely unclear -- for instance, how does accuracy vary when a common object appears in an uncommon pairing with another object? In this paper, we investigate how word co-occurrence statistics in the pretraining dataset (a proxy for co-occurrence of visual concepts) impacts CLIP/LMM performance. To disentangle the effects of word co-occurrence frequencies from single-word frequencies, we measure co-occurrence with pointwise mutual information (PMI), which normalizes the joint probability of two words co-occurring by the probability of co-occurring independently. Using synthetically generated images with a variety of concept pairs, we show a strong correlation between PMI in the CLIP pretraining data and zero-shot accuracy in CLIP models trained on LAION-400M (r=0.97 and 14% accuracy gap between images in the top and bottom 5% of PMI values), demonstrating that even accuracy on common concepts is affected by the combination of concepts in the image. Leveraging this finding, we reproduce this effect in natural images by editing them to contain pairs with varying PMI, resulting in a correlation of r=0.75. Finally, we demonstrate that this behavior in CLIP transfers to LMMs built on top of CLIP (r=0.70 for TextVQA, r=0.62 for VQAv2). Our findings highlight the need for algorithms and architectures that improve compositional generalization in multimodal models without scaling the training data combinatorially. Our code is available at https://github.com/helenqu/multimodal-pretraining-pmi. | [🔗 Paper](http://arxiv.org/abs/2507.08000v1) |
| [Single-pass Adaptive Image Tokenization for Minimum Program Search](http://arxiv.org/abs/2507.07995v1) | Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola | 2025-07-10 | Scaling Laws, Ongoing Learning, RLHF | According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition. | [🔗 Paper](http://arxiv.org/abs/2507.07995v1) |
| [Multi-Granular Spatio-Temporal Token Merging for Training-Free
  Acceleration of Video LLMs](http://arxiv.org/abs/2507.07990v1) | Jeongseok Hyun, Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim | 2025-07-10 | Scaling Laws, Multimodal AI | Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at https://www.jshyun.me/projects/sttm. | [🔗 Paper](http://arxiv.org/abs/2507.07990v1) |
| [CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is
  Why](http://arxiv.org/abs/2507.07985v1) | Bijay Gurung, David T. Hoffmann, Thomas Brox | 2025-07-10 | Scaling Laws, Multimodal AI, Responsible AI, Prompt Engineering, Model Evaluation | Contrastive vision-language models like CLIP are used for a large variety of applications, such as zero-shot classification or as vision encoder for multi-modal models. Despite their popularity, their representations show major limitations. For instance, CLIP models learn bag-of-words representations and, as a consequence, fail to distinguish whether an image is of "a yellow submarine and a blue bus" or "a blue submarine and a yellow bus". Previous attempts to fix this issue added hard negatives during training or modified the architecture, but failed to resolve the problem in its entirety. We suspect that the missing insights to solve the binding problem for CLIP are hidden in the arguably most important part of learning algorithms: the data. In this work, we fill this gap by rigorously identifying the influence of data properties on CLIP's ability to learn binding using a synthetic dataset. We find that common properties of natural data such as low attribute density, incomplete captions, and the saliency bias, a tendency of human captioners to describe the object that is "most salient" to them have a detrimental effect on binding performance. In contrast to common belief, we find that neither scaling the batch size, i.e., implicitly adding more hard negatives, nor explicitly creating hard negatives enables CLIP to learn reliable binding. Only when the data expresses our identified data properties CLIP learns almost perfect binding. | [🔗 Paper](http://arxiv.org/abs/2507.07985v1) |
| [Scaling RL to Long Videos](http://arxiv.org/abs/2507.07966v1) | Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han | 2025-07-10 | Scaling Laws, Multimodal AI, RLHF, Fine-Tuning, Prompt Engineering, Optimization, LLM | We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 52K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves strong performance on long video QA benchmarks such as VideoMME. It also outperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal reasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on our LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent performance gains as the number of input video frames scales. LongVILA-R1 marks a firm step towards long video reasoning in VLMs. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens). | [🔗 Paper](http://arxiv.org/abs/2507.07966v1) |
| [A c-theorem for the effective central charge in the R=1 replica limit,
  and applications to systems with measurement-induced randomness](http://arxiv.org/abs/2507.07959v1) | Rushikesh A. Patil, Andreas W. W. Ludwig | 2025-07-10 | Scaling Laws | We present a general theorem demonstrating non-perturbatively the decrease of the "effective central charge" $c_{\text{eff}}=(d c/dR) _{R=1}$ under renormalization group (RG) flow in the $R\rightarrow1$ replica limit of a $R$-copy $2D$ conformal field theory (CFT) action $S_{*}$ perturbed by a replica interaction of the form $$-\mathbb{S}=-\sum_{a=1}^{R}S_{*}^{(a)}+\Delta\int d^2 x \sum_{\substack{a,b=1\\ a\neq b}}^{R}\varphi^{(a)}(x)\varphi^{(b)}(x).$$ Here $\varphi$ is a scaling field belonging to the CFT with action $S_*$ and the coupling $\Delta$ is relevant in the RG sense. We show that the infrared value of $c_{\text{eff}}$ is always $\textit{less}$ than the central charge $c$ of the unperturbed CFT $S_{*}$. We refer to this result as the "$c$-effective theorem". As an application of this theorem, we consider replica field theories in the limit of $R \to 1$ replicas of the form above, shown by Nahum and Jacobsen [arXiv:2504.01264] to describe $2D$ classical monitored systems, where measurements introduce a form of quenched randomness via Bayes' theorem. Lastly, we discuss a possible relationship of our theorem with the effective central charge $c_{\text{eff}}^{(R\rightarrow0)}=(dc/dR) _{R=0}$ for the above replica action in the different $R\rightarrow0$ replica limit, which is of relevance to systems with generic uncorrelated impurity-type quenched disorder, as opposed to measurements. | [🔗 Paper](http://arxiv.org/abs/2507.07959v1) |
| [Dynamic Chunking for End-to-End Hierarchical Sequence Modeling](http://arxiv.org/abs/2507.07955v1) | Sukjun Hwang, Brandon Wang, Albert Gu | 2025-07-10 | Scaling Laws, Model Evaluation, Responsible AI, LLM | Despite incredible progress in language models (LMs) in recent years, largely resulting from moving away from specialized models designed for specific tasks to general models based on powerful architectures (e.g. the Transformer) that learn everything from raw data, pre-processing steps such as tokenization remain a barrier to true end-to-end foundation models. We introduce a collection of new techniques that enable a dynamic chunking mechanism which automatically learns content -- and context -- dependent segmentation strategies learned jointly with the rest of the model. Incorporating this into an explicit hierarchical network (H-Net) allows replacing the (implicitly hierarchical) tokenization-LM-detokenization pipeline with a single model learned fully end-to-end. When compute- and data- matched, an H-Net with one stage of hierarchy operating at the byte level outperforms a strong Transformer language model operating over BPE tokens. Iterating the hierarchy to multiple stages further increases its performance by modeling multiple levels of abstraction, demonstrating significantly better scaling with data and matching a token-based Transformer of twice its size. H-Nets pretrained on English show significantly increased character-level robustness, and qualitatively learn meaningful data-dependent chunking strategies without any heuristics or explicit supervision. Finally, the H-Net's improvement over tokenized pipelines is further increased in languages and modalities with weaker tokenization heuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement in data efficiency over baselines), showing the potential of true end-to-end models that learn and scale better from unprocessed data. | [🔗 Paper](http://arxiv.org/abs/2507.07955v1) |
## 🔹 Training & Evaluation

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Performance and Practical Considerations of Large and Small Language
  Models in Clinical Decision Support in Rheumatology](http://arxiv.org/abs/2507.07983v1) | Sabine Felde, Rüdiger Buchkremer, Gamal Chehab, Christian Thielscher, Jörg HW Distler, Matthias Schneider, Jutta G. Richter | 2025-07-10 | Training & Evaluation | Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology. | [🔗 Paper](http://arxiv.org/abs/2507.07983v1) |
## 🔹 Model Evaluation

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Baryonification II: Constraining feedback with X-ray and kinematic
  Sunyaev-Zel'dovich observations](http://arxiv.org/abs/2507.07991v1) | Michael Kovač, Andrina Nicola, Jozef Bucko, Aurel Schneider, Robert Reischke, Sambit K. Giri, Romain Teyssier, Matthieu Schaller, Joop Schaye | 2025-07-10 | Model Evaluation, Responsible AI | Baryonic feedback alters the matter distribution on small and intermediate scales, posing a challenge for precision cosmology. The new, component-wise baryonification (BFC) approach provides a self-consistent framework to model feedback effects for different observables. In this paper we use this framework to fit kinematic Sunyaev-Zel'dovich (kSZ) observations from the Atacama Cosmology Telescope (ACT) alongside halo X-ray gas fractions from eROSITA, investigating baryonic feedback in a cosmological context. We first show that the kSZ data from ACT is consistent with the gas fractions from eROSITA, both suggesting a feedback model that is stronger than what is assumed in most hydrodynamical simulations. This finding is in contrast to older, pre-eROSITA gas fraction measurements that point towards weaker feedback in tension with the kSZ results. We suspect these discrepancies to be due to selection bias in the pre-eROSITA sample, or differences in halo mass estimation between the two data sets. In a further step, we use the BFC model to predict the baryonic suppression of the matter power spectrum. Based on our combined fit to data from ACT and eROSITA, we find a power spectrum suppression that exceeds the percent-level at modes above $k=0.3-0.6 \,h\,\mathrm{Mpc}^{-1}$, growing to 2-8 percent at $k=1\,h\,\mathrm{Mpc}^{-1}$, and to 20-25 percent at $k=5\,h\,\mathrm{Mpc}^{-1}$, consistent with strong-feedback hydrodynamical simulations. Finally, we compare our best-fitting model to the observed gas density and pressure profiles of massive galaxy clusters from the X-COP sample, finding excellent agreement. These results show that BFC provides a self-consistent picture of feedback across mass- and length scales as well as different cosmological observables, thus making it promising for applications to multiwavelength studies to jointly constrain cosmology and baryonic effects. | [🔗 Paper](http://arxiv.org/abs/2507.07991v1) |
| [Automating Expert-Level Medical Reasoning Evaluation of Large Language
  Models](http://arxiv.org/abs/2507.07988v1) | Shuang Zhou, Wenya Xie, Jiaxi Li, Zaifu Zhan, Meijia Song, Han Yang, Cheyenna Espinoza, Lindsay Welton, Xinnie Mai, Yanwei Jin, Zidu Xu, Yuen-Hei Chung, Yiyun Xing, Meng-Han Tsai, Emma Schaffer, Yucheng Shi, Ninghao Liu, Zirui Liu, Rui Zhang | 2025-07-10 | Model Evaluation, Training & Evaluation | As large language models (LLMs) become increasingly integrated into clinical decision-making, ensuring transparent and trustworthy reasoning is essential. However, existing evaluation strategies of LLMs' medical reasoning capability either suffer from unsatisfactory assessment or poor scalability, and a rigorous benchmark remains lacking. To address this, we introduce MedThink-Bench, a benchmark designed for rigorous, explainable, and scalable assessment of LLMs' medical reasoning. MedThink-Bench comprises 500 challenging questions across ten medical domains, each annotated with expert-crafted step-by-step rationales. Building on this, we propose LLM-w-Ref, a novel evaluation framework that leverages fine-grained rationales and LLM-as-a-Judge mechanisms to assess intermediate reasoning with expert-level fidelity while maintaining scalability. Experiments show that LLM-w-Ref exhibits a strong positive correlation with expert judgments. Benchmarking twelve state-of-the-art LLMs, we find that smaller models (e.g., MedGemma-27B) can surpass larger proprietary counterparts (e.g., OpenAI-o3). Overall, MedThink-Bench offers a foundational tool for evaluating LLMs' medical reasoning, advancing their safe and responsible deployment in clinical practice. | [🔗 Paper](http://arxiv.org/abs/2507.07988v1) |
| [Purcell enhancement of photogalvanic currents in a van der Waals
  plasmonic self-cavity](http://arxiv.org/abs/2507.07987v1) | Xinyu Li, Jesse Hagelstein, Gunda Kipp, Felix Sturm, Kateryna Kusyak, Yunfei Huang, Benedikt F. Schulte, Alexander M. Potts, Jonathan Stensberg, Victoria Quirós-Cordero, Chiara Trovatello, Zhi Hao Peng, Chaowei Hu, Jonathan M. DeStefano, Michael Fechner, Takashi Taniguchi, Kenji Watanabe, P. James Schuck, Xiaodong Xu, Jiun-Haw Chu, Xiaoyang Zhu, Angel Rubio, Marios H. Michael, Matthew W. Day, Hope M. Bretscher, James W. McIver | 2025-07-10 | Model Evaluation, Responsible AI | Cavities provide a means to manipulate the optical and electronic responses of quantum materials by selectively enhancing light-matter interaction at specific frequencies and momenta. While cavities typically involve external structures, exfoliated flakes of van der Waals (vdW) materials can form intrinsic self-cavities due to their small finite dimensions, confining electromagnetic fields into plasmonic cavity modes, characterized by standing-wave current distributions. While cavity-enhanced phenomena are well-studied at optical frequencies, the impact of self-cavities on nonlinear electronic responses--such as photogalvanic currents--remains largely unexplored, particularly in the terahertz regime, critical for emerging ultrafast optoelectronic technologies. Here, we report a self-cavity-induced Purcell enhancement of photogalvanic currents in the vdW semimetal WTe$_2$. Using ultrafast optoelectronic circuitry, we measured coherent near-field THz emission resulting from nonlinear photocurrents excited at the sample edges. We observed enhanced emission at finite frequencies, tunable via excitation fluence and sample geometry, which we attribute to plasmonic interference effects controlled by the cavity boundaries. We developed an analytical theory that captures the cavity resonance conditions and spectral response across multiple devices. Our findings establish WTe$_2$ as a bias-free, geometry-tunable THz emitter and demonstrate the potential of self-cavity engineering for controlling nonlinear, nonequilibrium dynamics in quantum materials. | [🔗 Paper](http://arxiv.org/abs/2507.07987v1) |
| [Defending Against Prompt Injection With a Few DefensiveTokens](http://arxiv.org/abs/2507.07974v1) | Sizhe Chen, Yizhu Wang, Nicholas Carlini, Chawin Sitawarin, David Wagner | 2025-07-10 | Model Evaluation, Security & Adversarial ML, Responsible AI, LLM | When large language model (LLM) systems interact with external data to perform complex tasks, a new attack, namely prompt injection, becomes a significant threat. By injecting instructions into the data accessed by the system, the attacker is able to override the initial user task with an arbitrary task directed by the attacker. To secure the system, test-time defenses, e.g., defensive prompting, have been proposed for system developers to attain security only when needed in a flexible manner. However, they are much less effective than training-time defenses that change the model parameters. Motivated by this, we propose DefensiveToken, a test-time defense with prompt injection robustness comparable to training-time alternatives. DefensiveTokens are newly inserted as special tokens, whose embeddings are optimized for security. In security-sensitive cases, system developers can append a few DefensiveTokens before the LLM input to achieve security with a minimal utility drop. In scenarios where security is less of a concern, developers can simply skip DefensiveTokens; the LLM system remains the same as there is no defense, generating high-quality responses. Thus, DefensiveTokens, if released alongside the model, allow a flexible switch between the state-of-the-art (SOTA) utility and almost-SOTA security at test time. The code is available at https://github.com/Sizhe-Chen/DefensiveToken. | [🔗 Paper](http://arxiv.org/abs/2507.07974v1) |
| [Constraints from CMB lensing tomography with projected bispectra](http://arxiv.org/abs/2507.07968v1) | Lea Harscouet, David Alonso, Andrina Nicola, Anže Slosar | 2025-07-10 | Model Evaluation, Responsible AI | We measure the angular power spectrum and bispectrum of the projected overdensity of photometric DESI luminous red galaxies, and its cross-correlation with maps of the Cosmic Microwave Background lensing convergence from \planck. This analysis is enabled by the use of the ``filtered-squared bispectrum'' approach, introduced in previous work, which we generalise here to the case of cross-correlations between multiple fields. The projected galaxy bispectrum is detected at very high significance (above $30\sigma$ in all redshift bins), and the galaxy-galaxy-convergence bispectrum is detected above $5\sigma$ in the three highest-redshift bins. We find that the bispectrum is reasonably well described over a broad range of scales by a tree-level prediction using the linear galaxy bias measured from the power spectrum. We carry out the first cosmological analysis combining projected power spectra and bispectra under a relatively simple model, and show that the galaxy bispectrum can be used in combination with the power spectrum to place a constraint on the amplitude of matter fluctuations, $\sigma_8$, an on the non-relativistic matter fraction $\Omega_m$. We find that data combinations involving the galaxy bispectrum recover constraints on these parameters that are in good agreement with those found from the traditional ``2$\times$2-point'' combination of galaxy-galaxy and galaxy-convergence power spectra, across all redshift bins. | [🔗 Paper](http://arxiv.org/abs/2507.07968v1) |
## 🔹 Ongoing Learning

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](http://arxiv.org/abs/2507.07994v2) | Subhajit Maity, Ayan Kumar Bhunia, Subhadeep Koley, Pinaki Nath Chowdhury, Aneeshan Sain, Yi-Zhe Song | 2025-07-10 | Ongoing Learning, Prompt Engineering | Keypoint detection, integral to modern machine perception, faces challenges in few-shot learning, particularly when source data from the same distribution as the query is unavailable. This gap is addressed by leveraging sketches, a popular form of human expression, providing a source-free alternative. However, challenges arise in mastering cross-modal embeddings and handling user-specific sketch styles. Our proposed framework overcomes these hurdles with a prototypical setup, combined with a grid-based locator and prototypical domain adaptation. We also demonstrate success in few-shot convergence across novel keypoints and classes through extensive experiments. | [🔗 Paper](http://arxiv.org/abs/2507.07994v2) |
| [Why is Your Language Model a Poor Implicit Reward Model?](http://arxiv.org/abs/2507.07981v1) | Noam Razin, Yong Lin, Jiarui Yao, Sanjeev Arora | 2025-07-10 | Ongoing Learning, RLHF, Fine-Tuning, Training & Evaluation | Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Towards a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models. | [🔗 Paper](http://arxiv.org/abs/2507.07981v1) |
## 🔹 General AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Correlations and quantum circuits with dynamical causal order](http://arxiv.org/abs/2507.07992v1) | Raphaël Mothe, Alastair A. Abbott, Cyril Branciard | 2025-07-10 | General AI | Requiring that the causal structure between different parties is well-defined imposes constraints on the correlations they can establish, which define so-called causal correlations. Some of these are known to have a "dynamical" causal order in the sense that their causal structure is not fixed a priori but is instead established on the fly, with for instance the causal order between future parties depending on some choice of action of parties in the past. Here we identify a new way that the causal order between the parties can be dynamical: with at least four parties, there can be some dynamical order which can nevertheless not be influenced by the actions of past parties. This leads us to introduce an intermediate class of correlations with what we call non-influenceable causal order, in between the set of correlations with static (non-dynamical) causal order and the set of general causal correlations. We then define analogous classes of quantum processes, considering recently introduced classes of quantum circuits with classical or quantum control of causal order - the latter being the largest class within the process matrix formalism known to have a clear interpretation in terms of coherent superpositions of causal orders. This allows us to formalise precisely in which sense certain quantum processes can have both indefinite and dynamical causal order. | [🔗 Paper](http://arxiv.org/abs/2507.07992v1) |
| [Strong converse rate for asymptotic hypothesis testing in type III](http://arxiv.org/abs/2507.07989v1) | Nicholas Laracuente, Marius Junge | 2025-07-10 | General AI | We extend from the hyperfinite setting to general von Neumann algebras Mosonyi and Ogawa's (2015) and Mosonyi and Hiai's (2023) results showing the operational interpretation of sandwiched relative R\'enyi entropy in the strong converse of hypothesis testing. The specific task is to distinguish between two quantum states given many copies. We use a reduction method of Haagerup, Junge, and Xu (2010) to approximate relative entropy inequalities in an arbitrary von Neumann algebra by those in finite von Neumann algebras. Within these finite von Neumann algebras, it is possible to approximate densities via finite spectrum operators, after which the quantum method of types reduces them to effectively commuting subalgebras. Generalizing beyond the hyperfinite setting shows that the operational meaning of sandwiched R\'enyi entropy is not restricted to the matrices but is a more fundamental property of quantum information. Furthermore, applicability in general von Neumann algebras opens potential new connections to random matrix theory and the quantum information theory of fundamental physics. | [🔗 Paper](http://arxiv.org/abs/2507.07989v1) |
| [UniTac: Whole-Robot Touch Sensing Without Tactile Sensors](http://arxiv.org/abs/2507.07980v1) | Wanjia Fu, Hongyu Li, Ivy X. He, Stefanie Tellex, Srinath Sridhar | 2025-07-10 | General AI | Robots can better interact with humans and unstructured environments through touch sensing. However, most commercial robots are not equipped with tactile skins, making it challenging to achieve even basic touch-sensing functions, such as contact localization. We present UniTac, a data-driven whole-body touch-sensing approach that uses only proprioceptive joint sensors and does not require the installation of additional sensors. Our approach enables a robot equipped solely with joint sensors to localize contacts. Our goal is to democratize touch sensing and provide an off-the-shelf tool for HRI researchers to provide their robots with touch-sensing capabilities. We validate our approach on two platforms: the Franka robot arm and the Spot quadruped. On Franka, we can localize contact to within 8.0 centimeters, and on Spot, we can localize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU without adding any additional sensors to the robot. Project website: https://ivl.cs.brown.edu/research/unitac. | [🔗 Paper](http://arxiv.org/abs/2507.07980v1) |
| [A Service Architecture for Dataspaces](http://arxiv.org/abs/2507.07979v1) | Benedikt T. Arnold, Christoph Lange, Christina Gillmann, Stefan Decker | 2025-07-10 | General AI | Dataspaces are designed to support sovereign, trusted and decentralized data exchange between participants forming an ecosystem. They are standardized by initiatives such as the International Data Spaces Association or Gaia-X and have gained adoption in several domains such as mobility, manufacturing, tourism or culture. In dataspaces, participants use connectors to communicate peer-to-peer. The Eclipse Dataspace Components (EDC) Connector is a broadly adopted, open-source implementation that adheres to the standards and is supported by a large community. As dataspaces in general, it focuses on the exchange of data assets with associated usage policies and does not support services. In practice, however, there is demand for dataspace-based services and conceptual arguments support their inclusion in dataspaces. In this paper, we propose an abstraction layer for providing generic services within dataspaces. Adopters can use this layer to easily develop own services, seamlessly integrated with the existing dataspace technology. Besides, we present an initial implementation of this service architecture for the EDC Connector and demonstrate its practical applicability. | [🔗 Paper](http://arxiv.org/abs/2507.07979v1) |
| [From spatial to null infinity: Connecting initial data to peeling](http://arxiv.org/abs/2507.07977v1) | Berend Schneider, Neev Khera | 2025-07-10 | General AI | The asymptotic structure of space-time is studied by imposing conditions on the asymptotics of the metric. These conditions are weak enough to include large classes of physically relevant isolated space-times, but have a rich enough structure to be able to define important physically meaningful quantities like mass, angular momentum, and gravitational waves.   By using a unified expansion of the metric in a neighborhood of spatial infinity that includes a piece of null infinity, we connect the asymptotic expansions of solutions to Einstein's equations in the different asymptotic regimes. Within the class of space-times under consideration, we find a connection between the peeling properties of the Weyl scalars and symmetries of initial data near spatial infinity. In particular, we show that for initial data that to leading order is symmetric under parity + time reversal, $\Psi_2$ has the usual $1/r^3$ fall-off rate at null infinity. If, in addition, the subleading part of the data is antisymmetric under parity + time reversal, then $\Psi_1$ has the usual $1/r^4$ fall-off rate at future null infinity. | [🔗 Paper](http://arxiv.org/abs/2507.07977v1) |
| [Pierce-Birkhoff conjecture is true for splines](http://arxiv.org/abs/2507.07976v1) | Zehua Lai, Lek-Heng Lim | 2025-07-10 | General AI | We prove the Pierce--Birkhoff conjecture for splines, i.e., continuous piecewise polynomials of degree $d$ in $n$ variables on a hyperplane partition of $\mathbb{R}^n$, can be written as a finite lattice combination of polynomials. We will provide a purely existential proof, followed by a more in-depth analysis that yields effective bounds. | [🔗 Paper](http://arxiv.org/abs/2507.07976v1) |
| [EinHops: Einsum Notation for Expressive Homomorphic Operations on
  RNS-CKKS Tensors](http://arxiv.org/abs/2507.07972v1) | Karthik Garimella, Austin Ebel, Brandon Reagen | 2025-07-10 | General AI | Fully Homomorphic Encryption (FHE) is an encryption scheme that allows for computation to be performed directly on encrypted data, effectively closing the loop on secure and outsourced computing. Data is encrypted not only during rest and transit, but also during processing. However, FHE provides a limited instruction set: SIMD addition, SIMD multiplication, and cyclic rotation of 1-D vectors. This restriction makes performing multi-dimensional tensor operations challenging. Practitioners must pack these tensors into 1-D vectors and map tensor operations onto this one-dimensional layout rather than their traditional nested structure. And while prior systems have made significant strides in automating this process, they often hide critical packing decisions behind layers of abstraction, making debugging, optimizing, and building on top of these systems difficult.   In this work, we approach multi-dimensional tensor operations in FHE through Einstein summation (einsum) notation. Einsum notation explicitly encodes dimensional structure and operations in its syntax, naturally exposing how tensors should be packed and transformed. We decompose einsum expressions into a fixed set of FHE-friendly operations. We implement our design and present EinHops, a minimalist system that factors einsum expressions into a fixed sequence of FHE operations. EinHops enables developers to perform encrypted tensor operations using FHE while maintaining full visibility into the underlying packing strategy. We evaluate EinHops on a range of tensor operations from a simple transpose to complex multi-dimensional contractions. We show that the explicit nature of einsum notation allows us to build an FHE tensor system that is simple, general, and interpretable. We open-source EinHops at the following repository: https://github.com/baahl-nyu/einhops. | [🔗 Paper](http://arxiv.org/abs/2507.07972v1) |
| [Spectral networks for polynomial cubic differentials](http://arxiv.org/abs/2507.07971v1) | Omar Kidwai, Guillaume Tahar | 2025-07-10 | General AI | We study cubic differentials and their spectral networks on Riemann surfaces, focusing on the polynomial case on the Riemann sphere. We introduce the notion of spectral core as the primary tool for our study, refining the classical notion of core in the theory of flat surfaces, and show that it controls the birthing process of spectral network trajectories. As an application, we completely characterize the polynomial cubic differentials having saddle connections or critical tripods when the degree $d$ is at most $3$; in particular, we obtain the relevant degenerations as the phase is varied and determine explicitly the wall-and-chamber structure. In this case, we obtain the BPS structure according to Gaiotto-Moore-Neitzke's algorithm, and verify that it satisfies the Kontsevich-Soibelman wall-crossing formula. In physics language, this corresponds to computing the BPS spectrum of a certain four-dimensional $\mathcal{N}=2$ quantum field theory, known as the $(A_{2},A_{d-1})$ generalized Argyres-Douglas theory. | [🔗 Paper](http://arxiv.org/abs/2507.07971v1) |
| [Non-holomorphic Contributions in GMSB with Adjoint Messengers](http://arxiv.org/abs/2507.07970v1) | Busra Nis, Cem Salih Un | 2025-07-10 | General AI | We consider models of gauge mediated supersymmetry breaking, in which the breaking is transmitted to the visible sector by the messenger fields from the adjoint representation of MSSM's gauge group. We include the non-holomorphic terms induced by the supersymmetry breaking and involve them in the renormalization group evolution. The main impact from the non-holomorphic terms arises in the right-handed stau mass, which requires large hypercharge interactions with the messengers to accommodate non-tachyonic staus. With the non-holomorphic terms, the stau mass-square can remain positive in the renormalization group evolution, even if the hypercharge interactions are small. Although the radiative non-holomorphic contributions enhance the mass spectrum, their effects in the sparticle mixing rather reduce their overall contributions such that we realize about 25 GeV difference in the right-handed stau mass, while the difference is lowered by about 5 TeV in the lightest mass-eigenstate of staus. We realize 6-7 TeV difference in the sbottom mass, and about 15 TeV in the stop mass. These contributions in the sparticle masses also affect the SM-like Higgs boson mass, and we find that the SM-like Higgs boson can be enhanced as much as about 80 GeV. In a small region of the parameter space we also observe negative non-holomorphic contributions which do not exceed about 1 TeV for the sparticles, and 20 GeV for the SM-like Higgs boson. An interesting impact from the non-holomorphic terms happens in the muon g-2 results. We find that the non-holomorphic contributions can provide a significant decreasing in supersymmetric contributions to muon g-2. We realize that the muon g-2 results can be decreased as much as about -50 x 10^-10 by the non-holomorphic contributions, and consequently one can still accommodate light sleptons and gauginos in the spectrum. | [🔗 Paper](http://arxiv.org/abs/2507.07970v1) |
| [Synthesizing Sun-as-a-star flare spectra from high-resolution solar
  observations](http://arxiv.org/abs/2507.07967v1) | M. De Wilde, A. G. M. Pietrow, M. K. Druett, A. Pastor Yabar, J. Koza, I. Kontogiannis, O. Andriienko, A. Berlicki, A. R. Brunvoll, J. de la Cruz Rodríguez, J. T. Faber, R. Joshi, D. Kuridze, D. Nóbrega-Siverio, L. H. M. Rouppe van der Voort, J. Rybák, E. Scullion, A. M. Silva, Z. Vashalomidze, A. Vicente Arévalo, A. Wiśniewska, R. Yadav, T. V. Zaqarashvili, J. Zbinden, E. S. Øyre | 2025-07-10 | General AI | Spatially resolved observations of the Sun and the astronomical sample size of stellar bodies are the respective key strengths of solar and stellar observations. However, the large difference in object brightness between the Sun and other stars has led to distinctly different instrumentation and methodologies between the two fields. We produce and analyze synthetic full-disk spectra derived from 19 small area field-of-view optical observations of solar flares acquired by the Swedish 1-m Solar Telescope (SST) between 2011 and 2024. These are used to investigate what can and cannot be inferred about physical processes on the Sun from Sun-as-a-star observations. The recently released Numerical Empirical Sun-as-a-Star Integrator (NESSI) code provides synthetic full-disk integrated spectral line emission based on smaller field-of-view input, accounting for center-to-limb variations and differential rotation. We use this code to generate pseudo-Sun-as-a-star spectra from the SST observations. ... | [🔗 Paper](http://arxiv.org/abs/2507.07967v1) |
| [Prospective Learning in Retrospect](http://arxiv.org/abs/2507.07965v1) | Yuxin Bai, Cecelia Shuai, Ashwin De Silva, Siyu Yu, Pratik Chaudhari, Joshua T. Vogelstein | 2025-07-10 | General AI | In most real-world applications of artificial intelligence, the distributions of the data and the goals of the learners tend to change over time. The Probably Approximately Correct (PAC) learning framework, which underpins most machine learning algorithms, fails to account for dynamic data distributions and evolving objectives, often resulting in suboptimal performance. Prospective learning is a recently introduced mathematical framework that overcomes some of these limitations. We build on this framework to present preliminary results that improve the algorithm and numerical results, and extend prospective learning to sequential decision-making scenarios, specifically foraging. Code is available at: https://github.com/neurodata/prolearn2. | [🔗 Paper](http://arxiv.org/abs/2507.07965v1) |
| [Gravitational lensing rarely produces high-mass outliers to the compact
  binary population](http://arxiv.org/abs/2507.07964v1) | Amanda Farah, Jose María Ezquiaga, Maya Fishbach, Daniel Holz | 2025-07-10 | General AI | All gravitational-wave signals are inevitably gravitationally lensed by intervening matter as they propagate through the Universe. When a gravitational-wave signal is magnified, it appears to have originated from a closer, more massive system. Thus, high-mass outliers to the gravitational-wave source population are often proposed as natural candidates for strongly lensed events. However, when using a data-driven method for identifying population outliers, we find that high-mass outliers are not necessarily strongly lensed, nor will the majority of strongly-lensed signals appear as high-mass outliers. This is both because statistical fluctuations produce a larger effect on observed binary parameters than does lensing magnification, and because lensing-induced outliers must originate from intrinsically high-mass sources, which are rare. Thus, the appearance of a single lensing-induced outlier implies the existence of many other lensed events within the catalog. We additionally show that it is possible to constrain the strong lensing optical depth, which is a fundamental quantity of our Universe, with the detection or absence of high-mass outliers. However, constraints using the latest gravitational-wave catalog are weak$\unicode{x2014}$we obtain an upper limit on the optical depth of sources at redshift $1$ magnified by a factor of $5$ or more of $\tau(\mu\geq5,z=1)\leq 0.035 \unicode{x2014}$and future observing runs will not make an outlier-based method competitive with other probes of the optical depth. Future work will investigate the ability of the full inferred population of compact binaries to inform the distribution of lenses in the Universe, opening a unique opportunity to access the high-redshift Universe and constrain cosmic structures. | [🔗 Paper](http://arxiv.org/abs/2507.07964v1) |
| [Cohomology and Extensions of $C_p$-Green Functors of Lie Type](http://arxiv.org/abs/2507.07962v1) | Tarik Anowar, Satyendra Kumar Mishra, Ripan Saha | 2025-07-10 | General AI | We develop a theory of $C_p$-Green functors of Lie type, unifying the axiomatic framework of Green functors with the structure of Lie algebras under the action of a cyclic group $C_p$ of prime order. Extending classical notions from representation theory and topology, we define tensor and exterior products, introduce an equivariant Chevalley-Eilenberg cohomology, and construct cup products that endow the cohomology with a graded Green functor of Lie type structure. A key result establishes a correspondence between equivalence classes of singular extensions and second cohomology groups, generalizing classical Lie algebra extension theory to the equivariant setting. This framework enriches the toolkit for studying equivariant algebraic structures and paves the way for further applications in deformation theory, homotopical algebra, and representation theory. | [🔗 Paper](http://arxiv.org/abs/2507.07962v1) |
| [Sharp estimates of quantum covering problems via a novel trace
  inequality](http://arxiv.org/abs/2507.07961v1) | Hao-Chung Cheng, Li Gao, Christoph Hirche, Hao-Wei Huang, Po-Chieh Liu | 2025-07-10 | General AI | In this paper, we prove a novel trace inequality involving two operators. As applications, we sharpen the one-shot achievability bound on the relative entropy error in a wealth of quantum covering-type problems, such as soft covering, privacy amplification, convex splitting, quantum information decoupling, and quantum channel simulation by removing some dimension-dependent factors. Moreover, the established one-shot bounds extend to infinite-dimensional separable Hilbert spaces as well. The proof techniques are based on the recently developed operator layer cake theorem and an operator change-of-variable argument, which are of independent interest. | [🔗 Paper](http://arxiv.org/abs/2507.07961v1) |
| [Spin-only dynamics of the multi-species nonreciprocal Dicke model](http://arxiv.org/abs/2507.07960v1) | Joseph Jachinowski, Peter B. Littlewood | 2025-07-10 | General AI | The Hepp-Lieb-Dicke model is ubiquitous in cavity quantum electrodynamics, describing spin-cavity coupling which does not conserve excitation number. Coupling the closed spin-cavity system to an environment realizes the open Dicke model, and by tuning the structure of the environment or the system-environment coupling, interesting spin-only models can be engineered. In this work, we focus on a variation of the multi-species open Dicke model which realizes mediated nonreciprocal interactions between the spin species and, consequently, an interesting dynamical limit-cycle phase. In particular, we improve upon adiabatic elimination and, instead, employ a Redfield master equation in order to describe the effective dynamics of the spin-only system. We assess this approach at the mean-field level, comparing it both to adiabatic elimination and the full spin-cavity model, and find that the predictions are sensitive to the presence of single-particle incoherent decay. Additionally, we clarify the symmetries of the model and explore the dynamical limit-cycle phase in the case of explicit parity-time-symmetry breaking, finding a region of phase coexistence terminating at an codimension-two exceptional point. Lastly, we go beyond mean-field theory by exact numerical diagonalization of the master equation, appealing to permutation symmetry in order to increase the size of accessible systems. We find signatures of phase transitions even for small system sizes. | [🔗 Paper](http://arxiv.org/abs/2507.07960v1) |
| [Invariants of twisted current algebras and related Poisson-commutative
  subalgebras](http://arxiv.org/abs/2507.07958v1) | Dmitri Panyushev, Oksana Yakimova | 2025-07-10 | General AI | Let q be a finite-dimensional Lie algebra and $\theta$ an automorphism of q of order m. We extend $\theta$ to an automorphism of the loop algebra of q and consider the fixed-point subalgebra $q[t,t^{-1}]^{\theta}$. Using a splitting of $q[t,t^{-1}]^{\theta}$, we construct $\theta$-twisted Poisson-commutative versions of the Feigin--Frenkel centre and the universal Gaudin subalgebra introduced by Ilin and Rybnikov in 2021. | [🔗 Paper](http://arxiv.org/abs/2507.07958v1) |
| [Macroscopic dynamics of oscillator ensembles with communities,
  higher-order interactions, and phase lags](http://arxiv.org/abs/2507.07956v1) | Sabina Adhikari, Juan G. Restrepo, Per Sebastian Skardal | 2025-07-10 | General AI | We study the effects of phase-frustrated, higher-order interactions in a system of coupled phase oscillators with two communities. We use dimensionality reduction techniques to derive a low-dimensional system of ODEs to describe the macroscopic behavior of the system. By analyzing this system we show that, in addition to the fixed point solutions present in a system of oscillators with higher order interactions and community structure only, the system also exhibits oscillatory or chaotic synchronization behavior for some phase lag values. Moreover, some phase lag values give rise to multistability of solutions, where both fixed point solutions and oscillatory or chaotic behavior of the order parameters can be observed, depending on initial conditions. | [🔗 Paper](http://arxiv.org/abs/2507.07956v1) |
| [Incremental Collision Laws Based on the Bouc-Wen Model: External Forces
  and Corner Cases](http://arxiv.org/abs/2507.07953v1) | Mihails Milehins, Dan Marghitu | 2025-07-10 | General AI | In the article titled "The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies" and published in the Journal of Computational and Nonlinear Dynamics, the authors studied mathematical models of binary direct collinear collisions of convex viscoplastic bodies that employed two incremental collision laws based on the Bouc-Wen differential model of hysteresis. It was shown that the models possess favorable analytical properties, and several model parameter identification studies were conducted in an attempt to validate the models. In this article, these models are augmented by taking into account the effects of external forces that are modeled as time-dependent inputs that belong to a certain function space. Furthermore, the range of the parameters under which the models possess favorable analytical properties is extended to several corner cases that were not considered in the prior publication. Finally, the previously conducted model parameter identification studies are extended, and an additional model parameter identification study is provided in an attempt to validate the ability of the augmented models to represent the effects of external forces. | [🔗 Paper](http://arxiv.org/abs/2507.07953v1) |
| [Intraseasonal Equatorial Kelvin and Rossby Waves in Modern AI-ML Models](http://arxiv.org/abs/2507.07952v1) | Shrutee Jalan, Jai Sukhatme | 2025-07-10 | General AI | We examine the structure of large-scale convectively coupled Kelvin and Rossby waves in a suite of modern AI-ML models. In particular, multiple runs of PanguWeather, GraphCast, FourCastNet and Aurora are performed to assess the structure of the aforementioned waves. Wavenumber-frequency diagrams of zonal winds from all models show a clear signature of Rossby and Kelvin waves with equivalent depths that are in accord with observations and reanalysis. Composites of Kelvin waves show correct lower and upper troposphere horizontal convergence patterns, vertical tilts in temperature, humidity and vertical velocity as well as the phase relation between temperature and vertical velocity anomalies. Though, differences between models are notable such as smaller vertical tilts and incorrect surface temperature anomalies in GraphCast and relatively weak convergent flows in PanguWeather. The models had much more difficulty with Rossby waves; while the horizontal gyres were captured, the vertical structure of temperature and divergence was incorrect. Apart from unexpected tilts in various fields, the temperature anomaly was inconsistent with the nature of the vertical velocity in all four models. Curiously, moisture and vertical velocity anomalies were much closer to observations. Further, only two models (GraphCast and FourCastNet) captured the simultaneous generation of deep vertical motion with moisture anomalies. In all, while the representation of these large-scale waves is encouraging, issues with the structure of Rossby waves and especially the inconsistency among fields require further investigation. | [🔗 Paper](http://arxiv.org/abs/2507.07952v1) |
| [Constructing Optimal Kobon Triangle Arrangements via Table Encoding, SAT
  Solving, and Heuristic Straightening](http://arxiv.org/abs/2507.07951v1) | Pavlo Savchuk | 2025-07-10 | General AI | We present new methods and results for constructing optimal Kobon triangle arrangements. First, we introduce a compact table notation for describing arrangements of pseudolines, enabling the representation and analysis of complex cases, including symmetrical arrangements, arrangements with parallel lines, and arrangements with multiple-line intersection points. Building on this, we provide a simple heuristic method and tools for recovering straight-line arrangements from a given table, with the ability to enforce additional properties such as symmetries. The tool successfully recovers arrangements for many previously known optimal solutions. Additionally, we develop a tool that transforms the search for optimal Kobon arrangement tables into a SAT problem, allowing us to leverage modern SAT solvers (specifically Kissat) to efficiently find new solutions or to show that no other solutions exist (for example, confirming that no optimal solution exists in the 11-line case). Using these techniques, we find new optimal Kobon arrangements for 23 and 27 lines, along with several other new results. | [🔗 Paper](http://arxiv.org/abs/2507.07951v1) |
