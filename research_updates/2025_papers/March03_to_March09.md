# üìå AI Research Papers (March03 to March09)

## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video](http://arxiv.org/abs/2503.04720v1) | Yue Gao, Hong-Xing Yu, Bo Zhu, Jiajun Wu | 2025-03-06 | Diffusion Models, Multimodal AI | We study reconstructing and predicting 3D fluid appearance and velocity from a single video. Current methods require multi-view videos for fluid reconstruction. We present FluidNexus, a novel framework that bridges video generation and physics simulation to tackle this task. Our key insight is to synthesize multiple novel-view videos as references for reconstruction. FluidNexus consists of two key components: (1) a novel-view video synthesizer that combines frame-wise view synthesis with video diffusion refinement for generating realistic videos, and (2) a physics-integrated particle representation coupling differentiable simulation and rendering to simultaneously facilitate 3D fluid reconstruction and prediction. To evaluate our approach, we collect two new real-world fluid datasets featuring textured backgrounds and object interactions. Our method enables dynamic novel view synthesis, future prediction, and interaction simulation from a single fluid video. Project website: https://yuegao.me/FluidNexus. | [üîó Paper](http://arxiv.org/abs/2503.04720v1) |
| [Coarse graining and reduced order models for plume ejection dynamics](http://arxiv.org/abs/2503.04690v1) | Ike Griss Salas, Megan R. Ebers, Jake Stevens-Haas, J. Nathan Kutz | 2025-03-06 | Diffusion Models, Multimodal AI, Training & Evaluation | Monitoring the atmospheric dispersion of pollutants is increasingly critical for environmental impact assessments. High-fidelity computational models are often employed to simulate plume dynamics, guiding decision-making and prioritizing resource deployment. However, such models can be prohibitively expensive to simulate, as they require resolving turbulent flows at fine spatial and temporal resolutions. Moreover, there are at least two distinct dynamical regimes of interest in the plume: (i) the initial ejection of the plume where turbulent mixing is generated by the shear-driven Kelvin-Helmholtz instability, and (ii) the ensuing turbulent diffusion and advection which is often modeled by the Gaussian plume model. We address the challenge of modeling the initial plume generation. Specifically, we propose a data-driven framework that identifies a reduced-order analytical model for plume dynamics -- directly from video data. We extract a time series of plume center and edge points from video snapshots and evaluate different regressions based to their extrapolation performance to generate a time series of coefficients that characterize the plume's overall direction and spread. We regress to a sinusoidal model inspired by the Kelvin-Helmholtz instability for the edge points in order to identify the plume's dispersion and vorticity. Overall, this reduced-order modeling framework provides a data-driven and lightweight approach to capture the dominant features of the initial nonlinear point-source plume dynamics, agnostic to plume type and starting only from video. The resulting model is a pre-cursor to standard models such as the Gaussian plume model and has the potential to enable rapid assessment and evaluation of critical environmental hazards, such as methane leaks, chemical spills, and pollutant dispersal from smokestacks. | [üîó Paper](http://arxiv.org/abs/2503.04690v1) |
| [Compositional World Knowledge leads to High Utility Synthetic data](http://arxiv.org/abs/2503.04687v1) | Sachit Gaudi, Gautam Sreekumar, Vishnu Boddeti | 2025-03-06 | Diffusion Models, Model Evaluation, Responsible AI | Machine learning systems struggle with robustness, under subpopulation shifts. This problem becomes especially pronounced in scenarios where only a subset of attribute combinations is observed during training -a severe form of subpopulation shift, referred as compositional shift. To address this problem, we ask the following question: Can we improve the robustness by training on synthetic data, spanning all possible attribute combinations? We first show that training of conditional diffusion models on limited data lead to incorrect underlying distribution. Therefore, synthetic data sampled from such models will result in unfaithful samples and does not lead to improve performance of downstream machine learning systems. To address this problem, we propose CoInD to reflect the compositional nature of the world by enforcing conditional independence through minimizing Fisher's divergence between joint and marginal distributions. We demonstrate that synthetic data generated by CoInD is faithful and this translates to state-of-the-art worst-group accuracy on compositional shift tasks on CelebA. | [üîó Paper](http://arxiv.org/abs/2503.04687v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Sample-Optimal Agnostic Boosting with Unlabeled Data](http://arxiv.org/abs/2503.04706v1) | Udaya Ghai, Karan Singh | 2025-03-06 | RLHF | Boosting provides a practical and provably effective framework for constructing accurate learning algorithms from inaccurate rules of thumb. It extends the promise of sample-efficient learning to settings where direct Empirical Risk Minimization (ERM) may not be implementable efficiently. In the realizable setting, boosting is known to offer this computational reprieve without compromising on sample efficiency. However, in the agnostic case, existing boosting algorithms fall short of achieving the optimal sample complexity.   This paper highlights an unexpected and previously unexplored avenue of improvement: unlabeled samples. We design a computationally efficient agnostic boosting algorithm that matches the sample complexity of ERM, given polynomially many additional unlabeled samples. In fact, we show that the total number of samples needed, unlabeled and labeled inclusive, is never more than that for the best known agnostic boosting algorithm -- so this result is never worse -- while only a vanishing fraction of these need to be labeled for the algorithm to succeed. This is particularly fortuitous for learning-theoretic applications of agnostic boosting, which often take place in the distribution-specific setting, where unlabeled samples can be availed for free. We detail other applications of this result in reinforcement learning. | [üîó Paper](http://arxiv.org/abs/2503.04706v1) |
| [L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning](http://arxiv.org/abs/2503.04697v1) | Pranjal Aggarwal, Sean Welleck | 2025-03-06 | RLHF, Optimization, Prompt Engineering, LLM | Reasoning language models have shown an uncanny ability to improve performance at test-time by ``thinking longer''-that is, by generating longer chain-of-thought sequences and hence using more compute. However, the length of their chain-of-thought reasoning is not controllable, making it impossible to allocate test-time compute to achieve a desired level of performance. We introduce Length Controlled Policy Optimization (LCPO), a simple reinforcement learning method that optimizes for accuracy and adherence to user-specified length constraints. We use LCPO to train L1, a reasoning language model that produces outputs satisfying a length constraint given in its prompt. L1's length control allows for smoothly trading off computational cost and accuracy on a wide range of tasks, and outperforms the state-of-the-art S1 method for length control. Furthermore, we uncover an unexpected short chain-of-thought capability in models trained with LCPO. For instance, our 1.5B L1 model surpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise control over reasoning length, allowing for fine-grained allocation of test-time compute and accuracy. We release code and models at https://www.cmu-l3.github.io/l1 | [üîó Paper](http://arxiv.org/abs/2503.04697v1) |
| [Multi-Agent Inverse Q-Learning from Demonstrations](http://arxiv.org/abs/2503.04679v1) | Nathaniel Haynam, Adam Khoja, Dhruv Kumar, Vivek Myers, Erdem Bƒ±yƒ±k | 2025-03-06 | RLHF, Optimization | When reward functions are hand-designed, deep reinforcement learning algorithms often suffer from reward misspecification, causing them to learn suboptimal policies in terms of the intended task objectives. In the single-agent case, inverse reinforcement learning (IRL) techniques attempt to address this issue by inferring the reward function from expert demonstrations. However, in multi-agent problems, misalignment between the learned and true objectives is exacerbated due to increased environment non-stationarity and variance that scales with multiple agents. As such, in multi-agent general-sum games, multi-agent IRL algorithms have difficulty balancing cooperative and competitive objectives. To address these issues, we propose Multi-Agent Marginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient framework for multi-agent IRL. For each agent, MAMQL learns a critic marginalized over the other agents' policies, allowing for a well-motivated use of Boltzmann policies in the multi-agent context. We identify a connection between optimal marginalized critics and single-agent soft-Q IRL, allowing us to apply a direct, simple optimization criterion from the single-agent domain. Across our experiments on three different simulated domains, MAMQL significantly outperforms previous multi-agent methods in average reward, sample efficiency, and reward recovery by often more than 2-5x. We make our code available at https://sites.google.com/view/mamql . | [üîó Paper](http://arxiv.org/abs/2503.04679v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM](http://arxiv.org/abs/2503.04724v1) | Sambal Shikhar, Mohammed Irfan Kurpath, Sahal Shaji Mullappilly, Jean Lahoud, Fahad Khan, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal | 2025-03-06 | Multimodal AI, Optimization, Production and Deployment | Recent advancements in speech-to-speech dialogue systems leverage LLMs for multimodal interactions, yet they remain hindered by fine-tuning requirements, high computational overhead, and text-speech misalignment. Existing speech-enabled LLMs often degrade conversational quality by modifying the LLM, thereby compromising its linguistic capabilities. In contrast, we propose LLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS system that generates high-quality speech with low latency, while fully preserving the capabilities of the base LLM. Our approach achieves a significantly lower Word Error Rate compared to speech-enabled LLMs, while operating at comparable latency and UTMOS score. By decoupling speech synthesis from LLM processing via a multi-queue token streaming system, LLMVoX supports seamless, infinite-length dialogues. Its plug-and-play design also facilitates extension to various tasks with different backbones. Furthermore, LLMVoX generalizes to new languages with only dataset adaptation, attaining a low Character Error Rate on an Arabic speech task. Additionally, we have integrated LLMVoX with a Vision-Language Model to create an omni-model with speech, text, and vision capabilities, without requiring additional multimodal training. Our code base and project page is available at https://mbzuai-oryx.github.io/LLMVoX . | [üîó Paper](http://arxiv.org/abs/2503.04724v1) |
| [Scaling Rich Style-Prompted Text-to-Speech Datasets](http://arxiv.org/abs/2503.04713v1) | Anuj Diwan, Zhisheng Zheng, David Harwath, Eunsol Choi | 2025-03-06 | Multimodal AI, Scaling Laws | We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale dataset that annotates speech utterances with rich style captions. While rich abstract tags (e.g. guttural, nasal, pained) have been explored in small-scale human-annotated datasets, existing large-scale datasets only cover basic tags (e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech embedders, classifiers and an audio language model to automatically scale rich tag annotations for the first time. ParaSpeechCaps covers a total of 59 style tags, including both speaker-level intrinsic tags and utterance-level situational tags. It consists of 342 hours of human-labelled data (PSC-Base) and 2427 hours of automatically annotated data (PSC-Scaled). We finetune Parler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and achieve improved style consistency (+7.9% Consistency MOS) and speech quality (+15.5% Naturalness MOS) over the best performing baseline that combines existing rich style tag datasets. We ablate several of our dataset design choices to lay the foundation for future work in this space. Our dataset, models and code are released at https://github.com/ajd12342/paraspeechcaps . | [üîó Paper](http://arxiv.org/abs/2503.04713v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation](http://arxiv.org/abs/2503.04718v1) | David T. Hoffmann, Syed Haseeb Raza, Hanqiu Jiang, Denis Tananaev, Steffen Klingenhoefer, Martin Meinke | 2025-03-06 | Optimization | Scene flow estimation is a foundational task for many robotic applications, including robust dynamic object detection, automatic labeling, and sensor synchronization. Two types of approaches to the problem have evolved: 1) Supervised and 2) optimization-based methods. Supervised methods are fast during inference and achieve high-quality results, however, they are limited by the need for large amounts of labeled training data and are susceptible to domain gaps. In contrast, unsupervised test-time optimization methods do not face the problem of domain gaps but usually suffer from substantial runtime, exhibit artifacts, or fail to converge to the right solution. In this work, we mitigate several limitations of existing optimization-based methods. To this end, we 1) introduce a simple voxel grid-based model that improves over the standard MLP-based formulation in multiple dimensions and 2) introduce a new multiframe loss formulation. 3) We combine both contributions in our new method, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only by EulerFlow among unsupervised methods while achieving comparable performance at a fraction of the computational cost. Floxels achieves a massive speedup of more than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10 minutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels achieves a speedup of ~14x. | [üîó Paper](http://arxiv.org/abs/2503.04718v1) |
| [Efficiently Escaping Saddle Points under Generalized Smoothness via Self-Bounding Regularity](http://arxiv.org/abs/2503.04712v1) | Daniel Yiming Cao, August Y. Chen, Karthik Sridharan, Benjamin Tang | 2025-03-06 | Optimization | In this paper, we study the problem of non-convex optimization on functions that are not necessarily smooth using first order methods. Smoothness (functions whose gradient and/or Hessian are Lipschitz) is not satisfied by many machine learning problems in both theory and practice, motivating a recent line of work studying the convergence of first order methods to first order stationary points under appropriate generalizations of smoothness.   We develop a novel framework to study convergence of first order methods to first and \textit{second} order stationary points under generalized smoothness, under more general smoothness assumptions than the literature. Using our framework, we show appropriate variants of GD and SGD (e.g. with appropriate perturbations) can converge not just to first order but also \textit{second order stationary points} in runtime polylogarithmic in the dimension. To our knowledge, our work contains the first such result, as well as the first 'non-textbook' rate for non-convex optimization under generalized smoothness. We demonstrate that several canonical non-convex optimization problems fall under our setting and framework. | [üîó Paper](http://arxiv.org/abs/2503.04712v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Scalable and Site-Specific Frequency Tuning of Two-Level System Defects in Superconducting Qubit Arrays](http://arxiv.org/abs/2503.04702v1) | Larry Chen, Kan-Heng Lee, Chuan-Hong Liu, Brian Marinelli, Ravi K. Naik, Ziqi Kang, Noah Goss, Hyunseong Kim, David I. Santiago, Irfan Siddiqi | 2025-03-06 | Scaling Laws | State-of-the-art superconducting quantum processors containing tens to hundreds of qubits have demonstrated the building blocks for realizing fault-tolerant quantum computation. Nonetheless, a fundamental barrier to scaling further is the prevalence of fluctuating quantum two-level system (TLS) defects that can couple resonantly to qubits, causing excess decoherence and enhanced gate errors. Here we introduce a scalable architecture for site-specific and in-situ manipulation of TLS frequencies out of the spectral vicinity of our qubits. Our method is resource efficient, combining TLS frequency tuning and universal single qubit control into a single on-chip control line per qubit. We independently control each qubit's dissipative environment to dynamically improve both qubit coherence times and single qubit gate fidelities -- with a constant time overhead that does not scale with the device size. Over a period of 40 hours across 6 qubits, we demonstrate a $36\%$ improvement in average single qubit error rates and a $17\%$ improvement in average energy relaxation times. Critically, we realize a 4-fold suppression in the occurrence of TLS-induced performance outliers, and a complete reduction of simultaneous outlier events. These results mark a significant step toward overcoming the challenges that TLS defects pose to scaling superconducting quantum processors. | [üîó Paper](http://arxiv.org/abs/2503.04702v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities](http://arxiv.org/abs/2503.04721v1) | Guan-Ting Lin, Jiachen Lian, Tingle Li, Qirui Wang, Gopala Anumanchipalli, Alexander H. Liu, Hung-yi Lee | 2025-03-06 | Training & Evaluation | Spoken dialogue modeling introduces unique challenges beyond text-based language modeling, demanding robust turn-taking, backchanneling, and real-time interaction. Although most Spoken Dialogue Models (SDMs) rely on half-duplex processing (handling speech one turn at a time), emerging full-duplex SDMs can listen and speak simultaneously, enabling more natural and engaging conversations. However, current evaluations of such models remain limited, often focusing on turn-based metrics or high-level corpus analyses (e.g., turn gaps, pauses). To address this gap, we present Full-Duplex-Bench, a new benchmark that systematically evaluates key conversational behaviors: pause handling, backchanneling, turn-taking, and interruption management. Our framework uses automatic metrics for consistent and reproducible assessments of SDMs' interactive performance. By offering an open and standardized evaluation benchmark, we aim to advance spoken dialogue modeling and encourage the development of more interactive and natural dialogue systems. | [üîó Paper](http://arxiv.org/abs/2503.04721v1) |
| [Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size](http://arxiv.org/abs/2503.04704v2) | Alireza Behtash, Marijan Fofonjka, Ethan Baird, Tyler Mauer, Hossein Moghimifam, David Stout, Joel Dennison | 2025-03-06 | Training & Evaluation, Optimization, LLM | We present a novel approach to selective model quantization that transcends the limitations of architecture-specific and size-dependent compression methods for Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By analyzing the entropy distribution across transformer blocks, EWQ determines which blocks can be safely quantized without causing significant performance degradation, independent of model architecture or size. Our method outperforms uniform quantization approaches, maintaining Massive Multitask Language Understanding (MMLU) accuracy scores within 0.5% of unquantized models while reducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ across multiple architectures -- from 1.6B to 70B parameters -- and showcase consistent improvements in the quality-compression trade-off regardless of model scale or architectural design. A surprising finding of EWQ is its ability to reduce perplexity compared to unquantized models, suggesting the presence of beneficial regularization through selective precision reduction. This improvement holds across different model families, indicating a fundamental relationship between layer-level entropy and optimal precision requirements. Additionally, we introduce FastEWQ, a rapid method for entropy distribution analysis that eliminates the need for loading model weights. This technique leverages universal characteristics of entropy distribution that persist across various architectures and scales, enabling near-instantaneous quantization decisions while maintaining 80% classification accuracy with full entropy analysis. Our results demonstrate that effective quantization strategies can be developed independently of specific architectural choices or model sizes, opening new possibilities for efficient LLM deployment. | [üîó Paper](http://arxiv.org/abs/2503.04704v2) |
| [Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases](http://arxiv.org/abs/2503.04691v1) | Pengcheng Qiu, Chaoyi Wu, Shuyu Liu, Weike Zhao, Ya Zhang, Yanfeng Wang, Weidi Xie | 2025-03-06 | Training & Evaluation | The latest reasoning-enhanced large language models (reasoning LLMs), such as DeepSeek-R1 and OpenAI-o3, have demonstrated remarkable success. However, the application of such reasoning enhancements to the highly professional medical domain has not been clearly evaluated, particularly regarding with not only assessing the final generation but also examining the quality of their reasoning processes. In this study, we present MedR-Bench, a reasoning-focused medical evaluation benchmark comprising 1,453 structured patient cases with reasoning references mined from case reports. Our benchmark spans 13 body systems and 10 specialty disorders, encompassing both common and rare diseases. In our evaluation, we introduce a versatile framework consisting of three critical clinical stages: assessment recommendation, diagnostic decision-making, and treatment planning, comprehensively capturing the LLMs' performance across the entire patient journey in healthcare. For metrics, we propose a novel agentic system, Reasoning Evaluator, designed to automate and objectively quantify free-text reasoning responses in a scalable manner from the perspectives of efficiency, factuality, and completeness by dynamically searching and performing cross-referencing checks. As a result, we assess five state-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and others. Our results reveal that current LLMs can handle relatively simple diagnostic tasks with sufficient critical assessment results, achieving accuracy generally over 85%. However, they still struggle with more complex tasks, such as assessment recommendation and treatment planning. In reasoning, their reasoning processes are generally reliable, with factuality scores exceeding 90%, though they often omit critical reasoning steps. Our study clearly reveals further development directions for current clinical LLMs. | [üîó Paper](http://arxiv.org/abs/2503.04691v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Enough Coin Flips Can Make LLMs Act Bayesian](http://arxiv.org/abs/2503.04722v1) | Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan | 2025-03-06 | Model Evaluation, Responsible AI, Prompt Engineering | Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs utilize ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner. | [üîó Paper](http://arxiv.org/abs/2503.04722v1) |
| [Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining](http://arxiv.org/abs/2503.04715v1) | Houyi Li, Wenzheng Zheng, Jingcheng Hu, Qiufeng Wang, Hanshan Zhang, Zili Wang, Yangshijie Xu, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang | 2025-03-06 | Model Evaluation, Responsible AI, Optimization, Scaling Laws | The impressive capabilities of Large Language Models (LLMs) across diverse tasks are now well-established, yet their effective deployment necessitates careful hyperparameter optimization. Through extensive empirical studies involving grid searches across diverse configurations, we discover universal scaling laws governing these hyperparameters: optimal learning rate follows a power-law relationship with both model parameters and data sizes, while optimal batch size scales primarily with data sizes. Our analysis reveals a convex optimization landscape for hyperparameters under fixed models and data size conditions. This convexity implies an optimal hyperparameter plateau. We contribute a universal, plug-and-play optimal hyperparameter tool for the community. Its estimated values on the test set are merely 0.07\% away from the globally optimal LLM performance found via an exhaustive search. These laws demonstrate remarkable robustness across variations in model sparsity, training data distribution, and model shape. To our best known, this is the first work that unifies different model shapes and structures, such as Mixture-of-Experts models and dense transformers, as well as establishes optimal hyperparameter scaling laws across diverse data distributions. This exhaustive optimization process demands substantial computational resources, utilizing nearly one million NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and hyperparameters from scratch and consuming approximately 100 trillion tokens in total. To facilitate reproducibility and further research, we will progressively release all loss measurements and model checkpoints through our designated repository https://step-law.github.io/ | [üîó Paper](http://arxiv.org/abs/2503.04715v1) |
| [Ultrahigh free-electron Kerr nonlinearity in all-semiconductor waveguides for all-optical nonlinear modulation of mid-infrared light](http://arxiv.org/abs/2503.04711v1) | Gonzalo √Ålvarez-P√©rez, Huatian Hu, Fangcheng Huang, Tadele Orbula Otomalo, Michele Ortolani, Cristian Cirac√¨ | 2025-03-06 | Model Evaluation, Responsible AI | Nonlinear optical waveguides, particularly those harnessing the optical Kerr effect, are promising for advancing next-generation photonic technologies. Despite the Kerr effect`s ultrafast response, its inherently weak nonlinearity has hindered practical applications. Here, we explore free-electron-induced Kerr nonlinearities in all-semiconductor waveguides, revealing that longitudinal bulk plasmons (inherently nonlocal excitations) can generate exceptionally strong Kerr nonlinearities. We specifically develop a nonlinear eigenmode analysis integrated with semiclassical hydrodynamic theory to compute the linear and nonlinear optical responses originating from the quantum behavior of free electrons in heavily doped semiconductors. These waveguides achieve ultrahigh nonlinear coefficients exceeding 10$^7$ W$^{-1}$km$^{-1}$ and support long-propagating modes with propagation distances over 100 $\mu$m. Additionally, we confirm the robustness of the nonlinear response under realistic conditions by considering viscoelastic and nonlinear damping mechanisms. Finally, we implement our all-semiconductor waveguides in a Mach-Zehnder interferometer, demonstrating efficient nonlinear modulation of the transmittance spectrum via the free-electron Kerr effect. This work evidences the transformative potential of free-electron nonlinearities in heavily doped semiconductors for photonic integrated circuits, paving the way for scalable on-chip nonlinear nanophotonic systems. | [üîó Paper](http://arxiv.org/abs/2503.04711v1) |
| [Improving Cosmic Birefringence Constraints via Delensing](http://arxiv.org/abs/2503.04708v1) | Anto Idicherian Lonappan | 2025-03-06 | Model Evaluation, Responsible AI | We present a study on using delensing to enhance cosmic birefringence measurements based on full-sky, map-based simulations. In our analysis, we neglect foreground contamination and instrumental systematics to isolate the intrinsic impact of delensing on both isotropic and anisotropic birefringence. For the isotropic case, assuming a constant rotation angle of $\beta = 0.35^\circ$, delensing reduces the lensing-induced variance in the EB power spectrum, yielding an improvement in sensitivity of approximately 10% at 6 $\mu$K-arcmin noise and 25-40% at lower noise levels. For the anisotropic case, using simulations at 1 $\mu$K-arcmin noise, we reconstruct the birefringence angle for a scale-invariant spectrum and mitigate lensing bias by delensing, achieving a 50% reduction in the leading $N_{(0)}$ bias and a 30% improvement in the constraints on the amplitude $A_{CB}$. Our results demonstrate that delensing is an effective tool for enhancing the detectability of subtle parity-violating signals in the cosmic microwave background with forthcoming experiments such as the Simons Observatory, CMB-S4, and LiteBIRD. | [üîó Paper](http://arxiv.org/abs/2503.04708v1) |
| [DEAL-YOLO: Drone-based Efficient Animal Localization using YOLO](http://arxiv.org/abs/2503.04698v1) | Aditya Prashant Naidu, Hem Gosalia, Ishaan Gakhar, Shaurya Singh Rathore, Krish Didwania, Ujjwal Verma | 2025-03-06 | Model Evaluation, Responsible AI | Although advances in deep learning and aerial surveillance technology are improving wildlife conservation efforts, complex and erratic environmental conditions still pose a problem, requiring innovative solutions for cost-effective small animal detection. This work introduces DEAL-YOLO, a novel approach that improves small object detection in Unmanned Aerial Vehicle (UAV) images by using multi-objective loss functions like Wise IoU (WIoU) and Normalized Wasserstein Distance (NWD), which prioritize pixels near the centre of the bounding box, ensuring smoother localization and reducing abrupt deviations. Additionally, the model is optimized through efficient feature extraction with Linear Deformable (LD) convolutions, enhancing accuracy while maintaining computational efficiency. The Scaled Sequence Feature Fusion (SSFF) module enhances object detection by effectively capturing inter-scale relationships, improving feature representation, and boosting metrics through optimized multiscale fusion. Comparison with baseline models reveals high efficacy with up to 69.5\% fewer parameters compared to vanilla Yolov8-N, highlighting the robustness of the proposed modifications. Through this approach, our paper aims to facilitate the detection of endangered species, animal population analysis, habitat monitoring, biodiversity research, and various other applications that enrich wildlife conservation efforts. DEAL-YOLO employs a two-stage inference paradigm for object detection, refining selected regions to improve localization and confidence. This approach enhances performance, especially for small instances with low objectness scores. | [üîó Paper](http://arxiv.org/abs/2503.04698v1) |
| [The Influence of Prior Discourse on Conversational Agent-Driven Decision-Making](http://arxiv.org/abs/2503.04692v1) | Stephen Pilli, Vivek Nallur | 2025-03-06 | Model Evaluation, Responsible AI | Persuasion through conversation has been the focus of much research. Nudging is a popular strategy to influence decision-making in physical and digital settings. However, conversational agents employing "nudging" have not received significant attention. We explore the manifestation of cognitive biases-the underlying psychological mechanisms of nudging-and investigate how the complexity of prior dialogue tasks impacts decision-making facilitated by conversational agents. Our research used a between-group experimental design, involving 756 participants randomly assigned to either a simple or complex task before encountering a decision-making scenario. Three scenarios were adapted from Samuelson's classic experiments on status-quo bias, the underlying mechanism of default nudges. Our results aligned with previous studies in two out of three simple-task scenarios. Increasing task complexity consistently shifted effect-sizes toward our hypothesis, though bias was significant in only one case. These findings inform conversational nudging strategies and highlight inherent biases relevant to behavioural economics. | [üîó Paper](http://arxiv.org/abs/2503.04692v1) |
| [Origin and emergent features of many-body dynamical localization](http://arxiv.org/abs/2503.04683v1) | Ang Yang, Zekai Chen, Yanliang Guo, Manuele Landini, Hanns-Christoph N√§gerl, Lei Ying | 2025-03-06 | Model Evaluation, Responsible AI | The question of whether interactions can break dynamical localization in quantum kicked rotor systems has been the subject of a long-standing debate. Here, we introduce an extended mapping from the kicked Lieb-Liniger model to an effective lattice model with long-range couplings and reveal two universal features: on-site pseudorandomness and rapidly decaying couplings in the center-of-mass momentum. For finite contact interactions, the long-range coupling between relative momenta obeys an algebraic decay behavior with a crossover of its decay exponent as the interaction increases. Similar behavior occurs in the Fock basis, underscoring the robustness and distinct many-body characteristics of dynamical localization. Analysis of the generalized fractal dimension and level-spacing ratio also supports these findings, highlighting the presence of near integrability and multifractality in different regions of parameter space. Our results offer an explanation for the occurrence of many-body dynamical localization, particularly in strongly correlated quantum gases, and are anticipated to generalize to systems of many particles. | [üîó Paper](http://arxiv.org/abs/2503.04683v1) |
## üîπ Ongoing Learning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Teach YOLO to Remember: A Self-Distillation Approach for Continual Object Detection](http://arxiv.org/abs/2503.04688v1) | Riccardo De Monte, Davide Dalle Pezze, Gian Antonio Susto | 2025-03-06 | Ongoing Learning, Optimization | Real-time object detectors like YOLO achieve exceptional performance when trained on large datasets for multiple epochs. However, in real-world scenarios where data arrives incrementally, neural networks suffer from catastrophic forgetting, leading to a loss of previously learned knowledge. To address this, prior research has explored strategies for Class Incremental Learning (CIL) in Continual Learning for Object Detection (CLOD), with most approaches focusing on two-stage object detectors. However, existing work suggests that Learning without Forgetting (LwF) may be ineffective for one-stage anchor-free detectors like YOLO due to noisy regression outputs, which risk transferring corrupted knowledge. In this work, we introduce YOLO LwF, a self-distillation approach tailored for YOLO-based continual object detection. We demonstrate that when coupled with a replay memory, YOLO LwF significantly mitigates forgetting. Compared to previous approaches, it achieves state-of-the-art performance, improving mAP by +2.1% and +2.9% on the VOC and COCO benchmarks, respectively. | [üîó Paper](http://arxiv.org/abs/2503.04688v1) |
## üîπ Memory & Context Length

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling](http://arxiv.org/abs/2503.04725v1) | Zhuo Chen, Oriol Mayn√© i Comas, Zhuotao Jin, Di Luo, Marin Soljaƒçiƒá | 2025-03-06 | Memory & Context Length, Scaling Laws | We rigorously establish a bipartite mutual information scaling law in natural language that governs long-range dependencies. This scaling law, which we show is distinct from and scales independently of the conventional two-point mutual information, is the key to understanding long-context language modeling. Using this scaling law, we formulate the Long-context Language Modeling (L$^2$M) condition, which relates a model's capacity for effective long context length modeling to the scaling of its latent state size for storing past information. Our results are validated through experiments on both transformers and state space models. This work establishes a theoretical foundation that guides the development of large language models toward longer context lengths. | [üîó Paper](http://arxiv.org/abs/2503.04725v1) |
## üîπ Security & Adversarial ML

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Iris Style Transfer: Enhancing Iris Recognition with Style Features and Privacy Preservation through Neural Style Transfer](http://arxiv.org/abs/2503.04707v1) | Mengdi Wang, Efe Bozkir, Enkelejda Kasneci | 2025-03-06 | Security & Adversarial ML | Iris texture is widely regarded as a gold standard biometric modality for authentication and identification. The demand for robust iris recognition methods, coupled with growing security and privacy concerns regarding iris attacks, has escalated recently. Inspired by neural style transfer, an advanced technique that leverages neural networks to separate content and style features, we hypothesize that iris texture's style features provide a reliable foundation for recognition and are more resilient to variations like rotation and perspective shifts than traditional approaches. Our experimental results support this hypothesis, showing a significantly higher classification accuracy compared to conventional features. Further, we propose using neural style transfer to mask identifiable iris style features, ensuring the protection of sensitive biometric information while maintaining the utility of eye images for tasks like eye segmentation and gaze estimation. This work opens new avenues for iris-oriented, secure, and privacy-aware biometric systems. | [üîó Paper](http://arxiv.org/abs/2503.04707v1) |
| [Matrix Factorization for Inferring Associations and Missing Links](http://arxiv.org/abs/2503.04680v1) | Ryan Barron, Maksim E. Eren, Duc P. Truong, Cynthia Matuszek, James Wendelberger, Mary F. Dorn, Boian Alexandrov | 2025-03-06 | Security & Adversarial ML, Graph AI | Missing link prediction is a method for network analysis, with applications in recommender systems, biology, social sciences, cybersecurity, information retrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs. Missing link prediction identifies unseen but potentially existing connections in a network by analyzing the observed patterns and relationships. In proliferation detection, this supports efforts to identify and characterize attempts by state and non-state actors to acquire nuclear weapons or associated technology - a notoriously challenging but vital mission for global security. Dimensionality reduction techniques like Non-Negative Matrix Factorization (NMF) and Logistic Matrix Factorization (LMF) are effective but require selection of the matrix rank parameter, that is, of the number of hidden features, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk), Boolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along with ensemble variants incorporating logistic factorization, for link prediction. Our methods integrate automatic model determination for rank estimation by evaluating stability and accuracy using a modified bootstrap methodology and uncertainty quantification (UQ), assessing prediction reliability under random perturbations. We incorporate Otsu threshold selection and k-means clustering for Boolean matrix factorization, comparing them to coordinate descent-based Boolean thresholding. Our experiments highlight the impact of rank k selection, evaluate model performance under varying test-set sizes, and demonstrate the benefits of UQ for reliable predictions using abstention. We validate our methods on three synthetic datasets (Boolean and uniformly distributed) and benchmark them against LMF and symmetric LMF (symLMF) on five real-world protein-protein interaction networks, showcasing an improved prediction performance. | [üîó Paper](http://arxiv.org/abs/2503.04680v1) |
## üîπ Fine-Tuning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Self-Supervised Models for Phoneme Recognition: Applications in Children's Speech for Reading Learning](http://arxiv.org/abs/2503.04710v1) | Lucas Block Medin, Thomas Pellegrini, Lucile Gelin | 2025-03-06 | Fine-Tuning, Optimization, LLM | Child speech recognition is still an underdeveloped area of research due to the lack of data (especially on non-English languages) and the specific difficulties of this task. Having explored various architectures for child speech recognition in previous work, in this article we tackle recent self-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models adapted to phoneme recognition in French child speech, and continue our experiments with the best of them, WavLM base+. We then further adapt it by unfreezing its transformer blocks during fine-tuning on child speech, which greatly improves its performance and makes it significantly outperform our base model, a Transformer+CTC. Finally, we study in detail the behaviour of these two models under the real conditions of our application, and show that WavLM base+ is more robust to various reading tasks and noise levels. Index Terms: speech recognition, child speech, self-supervised learning | [üîó Paper](http://arxiv.org/abs/2503.04710v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [An active repeating fast radio burst in a magnetized eruption environment](http://arxiv.org/abs/2503.04727v1) | Y. Li, S. B. Zhang, Y. P. Yang, C. W. Tsai, X. Yang, C. J. Law, R. Anna-Thomas, X. L. Chen, K. J. Lee, Z. F. Tang, D. Xiao, H. Xu, X. L. Yang, G. Chen, Y. Feng, D. Z. Li, R. Mckinven, J. R. Niu, K. Shin, B. J. Wang, C. F. Zhang, Y. K. Zhang, D. J. Zhou, Y. H. Zhu, Z. G. Dai, C. M. Chang, J. J. Geng, J. L. Han, L. Hu, D. Li, R. Luo, C. H. Niu, D. D. Shi, T. R. Sun, X. F. Wu, W. W. Zhu, P. Jiang, B. Zhang | 2025-03-06 | General AI | Fast radio bursts (FRBs) are millisecond-duration radio bursts with unidentified extra-galactic origin. Some FRBs exhibit mild magneto-ionic environmental variations, possibly attributed to plasma turbulence or geometric configuration variation in a binary system. Here we report an abrupt magneto-ionic environment variation of FRB 20220529, a repeating FRB from a disk galaxy at redshift 0.1839. Initially, its Faraday rotation measure (RM) was $21 \pm 96~{\rm rad~m^{-2}}$ over 17 months. In December 2023, it jumped to $1976.9~{\rm rad~m^{-2}}$, exceeding twenty times of the standard deviation of the previous RM variation, and returned to the typical values within two weeks. Such a drastic RM variation suggests a dense magnetized clump moving across the line of sight, possibly due to coronal mass ejection associated with a stellar flare. It indicates that the FRB likely has a companion star that produced the stellar flare. | [üîó Paper](http://arxiv.org/abs/2503.04727v1) |
| [Double Narrow-Line Signatures of Dark Matter Decay and New Constraints from XRISM Observations](http://arxiv.org/abs/2503.04726v1) | Wen Yin, Yutaka Fujita, Yuichiro Ezoe, Yoshitaka Ishisaki | 2025-03-06 | General AI | We investigate the indirect detection search of the two-body decay of dark matter particles into final states containing a photon, a process predicted in various promising dark matter models such as axion-like particles and sterile neutrinos. Recent and near-future photon detectors with a resolution $ R \equiv \lambda/\Delta\lambda = O(1000) $ are primarily optimized for the velocity dispersion of dark matter in the Milky Way. When performing indirect detection of dark matter in objects other than the Milky Way, one should take into account the contribution from Milky Way dark matter. As a result, the dark matter signal observed by a detector is predicted to exhibit a two-peak structure in many targets, owing to the Doppler shift, differences in radial velocities and the good energy resolution. An analysis incorporating this two-peak effect was performed using the latest XRISM observation data of the Centaurus galaxy cluster~\cite{XRISM:2025axf}. Although, due to the relatively short observation time, our derived limit is weaker than some existing limits, among dark matter searches in galaxy clusters our limit is one of the most stringent (at least in certain mass ranges). We also perform the usual single-peak analysis, for considering the various scenarios, that prefer narrow-line photon from the faraway galaxy cluster. Future data releases from XRISM as well as other observatories will further strengthen our conclusions. | [üîó Paper](http://arxiv.org/abs/2503.04726v1) |
| [Shifting Long-Context LLMs Research from Input to Output](http://arxiv.org/abs/2503.04723v2) | Yuhao Wu, Yushi Bai, Zhiqing Hu, Shangqing Tu, Ming Shan Hee, Juanzi Li, Roy Ka-Wei Lee | 2025-03-06 | General AI | Recent advancements in long-context Large Language Models (LLMs) have primarily concentrated on processing extended input contexts, resulting in significant strides in long-context comprehension. However, the equally critical aspect of generating long-form outputs has received comparatively less attention. This paper advocates for a paradigm shift in NLP research toward addressing the challenges of long-output generation. Tasks such as novel writing, long-term planning, and complex reasoning require models to understand extensive contexts and produce coherent, contextually rich, and logically consistent extended text. These demands highlight a critical gap in current LLM capabilities. We underscore the importance of this under-explored domain and call for focused efforts to develop foundational LLMs tailored for generating high-quality, long-form outputs, which hold immense potential for real-world applications. | [üîó Paper](http://arxiv.org/abs/2503.04723v2) |
| [Octagonal relations](http://arxiv.org/abs/2503.04719v1) | Zdzislaw Wojtkowiak | 2025-03-06 | General AI | We study the action of the absolute Galois group on the fundamental groups. | [üîó Paper](http://arxiv.org/abs/2503.04719v1) |
| [MIGHTEE: exploring the relationship between spectral index, redshift and radio luminosity](http://arxiv.org/abs/2503.04717v1) | Siddhant Pinjarkar, Martin J. Hardcastle, Dharam V. Lal, Daniel J. B. Smith, Jos√© Afonso, Davi Barbosa, Catherine L. Hale, Matt J. Jarvis, Sthabile Kolwa, Eric Murphy, Mattia Vaccari, Imogen H. Whittam | 2025-03-06 | General AI | It has been known for many years that there is an apparent trend for the spectral index ({\alpha}) of radio sources to steepen with redshift z, which has led to attempts to select high-redshift objects by searching for radio sources with steep spectra. In this study we use data from the MeerKAT, LOFAR, GMRT, and uGMRT telescopes, particularly using the MIGHTEE and superMIGHTEE surveys, to select compact sources over a wide range of redshifts and luminosities. We investigate the relationship between spectral index, luminosity and redshift and compare our results to those of previous studies. Although there is a correlation between {\alpha} and z in our sample for some combinations of frequency where good data are available, there is a clear offset between the {\alpha}-z relations in our sample and those derived previously from samples of more luminous objects; in other words, the {\alpha}-z relation is different for low and high luminosity sources. The relationships between {\alpha} and luminosity are also weak in our sample but in general the most luminous sources are steeper-spectrum and this trend is extended by samples from previous studies. In detail, we argue that both a {\alpha}-luminosity relation and an {\alpha}-z relation can be found in the data, but it is the former that drives the apparent {\alpha}-z relation observed in earlier work, which only appears because of the strong redshift-luminosity relation in bright, flux density-limited samples. Steep-spectrum selection should be applied with caution in searching for high-z sources in future deep surveys. | [üîó Paper](http://arxiv.org/abs/2503.04717v1) |
| [Optimal Cell Shape for Accurate Chemical Gradient Sensing in Eukaryote Chemotaxis](http://arxiv.org/abs/2503.04716v1) | Daiqiu Mou, Yuansheng Cao | 2025-03-06 | General AI | Accurate gradient sensing is crucial for efficient chemotaxis in noisy environments, but the relationship between cell shape deformations and sensing accuracy is not well understood. Using a theoretical framework based on maximum likelihood estimation, we show that the receptor dispersion, quantified by cell shape convex hull, fundamentally limits gradient sensing accuracy. Cells with a concave shape and isotropic error space achieve optimal performance in gradient detection. This concave shape, resulting from active protrusions or contractions, can significantly improve gradient sensing accuracy at the cost of increased energy expenditure. By balancing sensing accuracy and deformation cost, we predict that a concave, three-branched shape as optimal for cells in shallow gradients. To achieve efficient chemotaxis, our theory suggests that a cell should adopt a repeating "run-and-expansion" cycle. Our theoretical predictions align well with experimental observations, implying that the fast amoeboid cell motion is optimized near the physical limit for chemotaxis. This study highlights the crucial role of active cell shape deformation in facilitating accurate chemotaxis. | [üîó Paper](http://arxiv.org/abs/2503.04716v1) |
| [An Extended State Space Model of Aggregated Electric Vehicles for Flexibility Estimation and Power Control](http://arxiv.org/abs/2503.04714v1) | Yiping Liu, Xiaozhe Wang, Geza Joos | 2025-03-06 | General AI | The increasing penetration of electric vehicles (EVs) can provide substantial electricity to the grid, supporting the grids' stability. The state space model (SSM) has been proposed as an effective modeling method for power prediction and centralized control of aggregated EVs, offering low communication requirements and computational complexity. However, the SSM may overlook specific scenarios, leading to significant prediction and control inaccuracies. This paper proposes an extended state space model (eSSM) for aggregated EVs and develops associated control strategies. By accounting for the limited flexibility of fully charged and discharged EVs, the eSSM more accurately captures the state transition dynamics of EVs in various states of charge (SOC). Comprehensive simulations show that the eSSM will provide more accurate predictions of the flexibility and power trajectories of aggregated EVs, and more effectively tracks real-time power references compared to the conventional SSM method. | [üîó Paper](http://arxiv.org/abs/2503.04714v1) |
| [On the progenitor of the type Ia supernova remnant 0509-67.5](http://arxiv.org/abs/2503.04709v1) | Noam Soker | 2025-03-06 | General AI | Based on the iron and hydrogen similar elliptical morphologies of the type Ia supernova (SN Ia) remnant (SNR) 0509-67.5, I suggest that the ambient gas shaped the SN ejecta, that it is a remnant of an old planetary nebula, and that the explosion was more or less spherical. Adding that there is no observed stellar survivor in this SNR, I conclude that the SN Ia scenarios that best account for the explosion of this SN inside a planetary nebula (SNIP), are the lonely white dwarf scenarios, i.e., the core-degenerate (CD) and the double degenerate (DD) with merger to explosion delay (MED) time, i.e., the DD-MED scenario. Other scenarios encounter challenges, but I cannot completely rule them out. If true, the suggestion of SNR~0509-67.5 being a SNIP implies that the fraction of SNIPs might be higher than the previously estimated 50 percent of all normal SNe Ia. In the frame of the CD and the DD-MED scenarios, I attribute the observed double-shell structure in calcium to Rayleigh-Taylor instability during the explosion process: the caps of the Rayleigh-Taylor instability mushrooms form the outer shell. Instabilities during the explosion process might form clumps of some elements moving much faster than their mean velocity, possibly explaining fast-moving intermediate-mass elements. | [üîó Paper](http://arxiv.org/abs/2503.04709v1) |
| [One Extension to Explain Them All, One Parameter to Minimize $œá^2$, One Framework to Bring Them All, and in One Model Bind Them](http://arxiv.org/abs/2503.04705v1) | Matteo Forconi, Eleonora DI Valentino | 2025-03-06 | General AI | The increasing precision of Cosmic Microwave Background (CMB) observations has unveiled significant tensions between different datasets, notably between Planck and the Atacama Cosmology Telescope (ACT), as well as with the late-Universe measurements of the Hubble constant. In this work, we explore a variety of $\Lambda$CDM extensions to assess their ability to reconcile these discrepancies. The statistical preference for these extensions remains moderate, and imposing $n_s=1$ often worsens model performance. Our findings highlight the limitations of incremental modifications to $\Lambda$CDM and suggest that either more complex new physics or, more likely, improved systematic understanding in the CMB sector may be required to fully address the observed tensions. While CMB experiments are often considered the gold standard of precision cosmology, our results reinforce that these measurements are not immune to systematic uncertainties, which may be underestimated in current analyses. | [üîó Paper](http://arxiv.org/abs/2503.04705v1) |
| [Sharp multipolar $L^p$-Hardy-type inequalities on Riemannian manifolds](http://arxiv.org/abs/2503.04703v1) | Cristian CiulicƒÉ, Teodor RuginƒÉ | 2025-03-06 | General AI | In this paper we prove sharp multipolar Hardy-type inequalities in the Riemannian $L^p-$setting for $p\geq 2$ using the method of super-solutions and fundamental results from comparison theory on manifolds, thus generalizing previous results for $p=2$. We emphasize that when we restrict to Cartan-Hadamard manifolds, the inequalities improve in the case $2<p<N$ compared to the case $p=2$ since we obtain positive remainder terms which are controlled by curvature estimates. In the end, we treat the cases of positive and negative constant sectional curvature. | [üîó Paper](http://arxiv.org/abs/2503.04703v1) |
| [Computer-Assisted Proofs of Solitons in Bose-Einstein Condensates](http://arxiv.org/abs/2503.04701v1) | Miguel Ayala, Carlos Garc√≠a-Azpeitia, Jean-Philippe Lessard | 2025-03-06 | General AI | We rigorously prove the existence of gap solitons in the one-dimensional Gross-Pitaevskii (GP) equation with a periodic potential. These nonlinear localized solutions emerge in spectral gaps and play a crucial role in understanding Bose-Einstein condensates (BECs). To prove them, we reformulate the problem as the search for homoclinic orbits in a higher-dimensional dynamical system. We then use computer-assisted proof techniques, combined with a functional analytic framework, to rigorously validate numerically approximated homoclinic orbits. This work bridges computational evidence and formal mathematical proofs, providing a solid foundation for the study of solitons in the GP equation. | [üîó Paper](http://arxiv.org/abs/2503.04701v1) |
| [Inferring kilonova ejecta photospheric properties from early blackbody spectra](http://arxiv.org/abs/2503.04700v1) | Gilad Sadeh | 2025-03-06 | General AI | We present simple analytic corrections to the standard blackbody fitting used for early kilonova emission. We consider a spherical, relativistically expanding shell that radiates thermally at a single temperature in its own rest frame. Due to relativistic effects, including Doppler boosting, time delay, and temperature evolution -- the observed temperature is smeared across different polar angles by approximately $\sim10\%$. While the observed spectrum remains roughly consistent with a single-temperature blackbody, neglecting relativistic effects leads to significant systematic inaccuracies: the inferred photospheric velocity and temperature are overestimated by up to $\sim50\%$ for mildly relativistic velocities. By applying our analytic corrections, these deviations are reduced to within $10\%$, even in cases where the photosphere is receding and cooling is considered. Applying our corrections to observed kilonovae (AT2017gfo and the thermal component of GRB211211A) reveals that standard blackbody fitting overestimated the inferred velocities and temperatures by $10\%-40\%$. | [üîó Paper](http://arxiv.org/abs/2503.04700v1) |
| [Anyon Theory and Topological Frustration of High-Efficiency Quantum LDPC Codes](http://arxiv.org/abs/2503.04699v1) | Keyang Chen, Yuanting Liu, Yiming Zhang, Zijian Liang, Yu-An Chen, Ke Liu, Hao Song | 2025-03-06 | General AI | Quantum low-density parity-check (QLDPC) codes present a promising route to low-overhead fault-tolerant quantum computation, yet systematic strategies for their exploration remain underdeveloped. In this work, we establish a topological framework for studying the bivariate-bicycle codes, a prominent class of QLDPC codes tailored for real-world quantum hardware. Our framework enables the investigation of these codes through universal properties of topological orders. Besides providing efficient characterizations for demonstrations using Gr\"obner bases, we also introduce a novel algebraic-geometric approach based on the Bernstein--Khovanskii--Kushnirenko theorem, allowing us to analytically determine how the topological order varies with the generic choice of bivariate-bicycle codes under toric layouts. Novel phenomena are unveiled, including topological frustration, where ground-state degeneracy on a torus deviates from the total anyon number, and quasi-fractonic mobility, where anyon movement violates energy conservation. We demonstrate their inherent link to symmetry-enriched topological orders and offer an efficient method for searching for finite-size codes. Furthermore, we extend the connection between anyons and logical operators using Koszul complex theory. Our work provides a rigorous theoretical basis for exploring the fault tolerance of QLDPC codes and deepens the interplay among topological order, quantum error correction, and advanced mathematical structures. | [üîó Paper](http://arxiv.org/abs/2503.04699v1) |
| [Assessing Student Adoption of Generative Artificial Intelligence across Engineering Education from 2023 to 2024](http://arxiv.org/abs/2503.04696v1) | Jesan Ahammed Ovi, Gabe Fierro, C. Estelle Smith | 2025-03-06 | General AI | Generative Artificial Intelligence (GenAI) tools and models have the potential to re-shape educational needs, norms, practices, and policies in all sectors of engineering education. Empirical data, rather than anecdata and assumptions, on how engineering students have adopted GenAI is essential to developing a foundational understanding of students' GenAI-related behaviors and needs during academic training. This data will also help formulate effective responses to GenAI by both academic institutions and industrial employers. We collected two representative survey samples at the Colorado School of Mines, a small engineering-focused R-1 university in the USA, in May 2023 ($n_1=601$) and September 2024 ($n_2=862$) to address research questions related to (RQ1) how GenAI has been adopted by engineering students, including motivational and demographic factors contributing to GenAI use, (RQ2) students' ethical concerns about GenAI, and (RQ3) students' perceived benefits v.s. harms for themselves, science, and society. Analysis revealed a statistically significant rise in GenAI adoption rates from 2023 to 2024. Students predominantly leverage GenAI tools to deepen understanding, enhance work quality, and stay informed about emerging technologies. Although most students assess their own usage of GenAI as ethical and beneficial, they nonetheless expressed significant concerns regarding GenAI and its impacts on society. We collected student estimates of ``P(doom)'' and discovered a bimodal distribution. Thus, we show that the student body at Mines is polarized with respect to future impacts of GenAI on the engineering workforce and society, despite being increasingly willing to explore GenAI over time. We discuss implications of these findings for future research and for integrating GenAI in engineering education. | [üîó Paper](http://arxiv.org/abs/2503.04696v1) |
| [A linearly-implicit energy preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations](http://arxiv.org/abs/2503.04695v1) | Andrea Brugnoli, Denis Matignon, Joseph Morlier | 2025-03-06 | General AI | This work presents a novel formulation and numerical strategy for the simulation of geometrically nonlinear structures. First, a non-canonical Hamiltonian (Poisson) formulation is introduced by including the dynamics of the stress tensor. This framework is developed for von-K\'arm\'an nonlinearities in beams and plates, as well as finite strain elasticity with Saint-Venant material behavior. In the case of plates, both negligible and non-negligible membrane inertia are considered. For the former case the two-dimensional elasticity complex is leveraged to express the dynamics in terms of the Airy stress function. The finite element discretization employs a mixed approach, combining a conforming approximation for displacement and velocity fields with a discontinuous stress tensor representation. A staggered, linear implicit time integration scheme is proposed, establishing connections with existing explicit-implicit energy-preserving methods. The stress degrees of freedom are statically condensed, reducing the computational complexity to solving a system with a positive definite matrix. The methodology is validated through numerical experiments on the Duffing oscillator, a von-K\'arm\'an beam, and a column undergoing finite strain elasticity. Comparisons with fully implicit energy-preserving method and the explicit Newmark scheme demonstrate that the proposed approach achieves superior accuracy while maintaining energy stability. Additionally, it enables larger time steps compared to explicit schemes and exhibits computational efficiency comparable to the leapfrog method. | [üîó Paper](http://arxiv.org/abs/2503.04695v1) |
| [Rapid updating of multivariate resource models based on new information using EnKF-MDA and multi-Gaussian transformation](http://arxiv.org/abs/2503.04694v1) | Sultan Abulkhair, Peter A. Dowd, Chaoshui Xu | 2025-03-06 | General AI | Rapid resource model updating with real-time data is important for making timely decisions in resource management and mining operations. This requires optimal merging of models and observations, which can be achieved through data assimilation, and the ensemble Kalman filter (EnKF) has become a popular method for this task. However, the modelled resources in mining usually consist of multiple variables of interest with multivariate relationships of varying complexity. EnKF is not a multivariate approach, and even for univariate cases, there may be slight deviations between its outcomes and observations. This study presents a methodology for rapidly updating multivariate resource models using the EnKF with multiple data assimilations (EnKF-MDA) combined with rotation based iterative Gaussianisation (RBIG). EnKF-MDA improves the updating by assimilating the same data multiple times with an inflated measurement error, while RBIG quickly transforms the data into multi-Gaussian factors. The application of the proposed algorithm is validated by a real case study with nine cross-correlated variables. The combination of EnKF-MDA and RBIG successfully improves the accuracy of resource model updates, minimises uncertainty, and preserves the multivariate relationships. | [üîó Paper](http://arxiv.org/abs/2503.04694v1) |
| [UIPE: Enhancing LLM Unlearning by Removing Knowledge Related to Forgetting Targets](http://arxiv.org/abs/2503.04693v1) | Wenyu Wang, Mengqi Zhang, Xiaotian Ye, Zhaochun Ren, Zhumin Chen, Pengjie Ren | 2025-03-06 | General AI | Large Language Models (LLMs) inevitably acquire harmful information during training on massive datasets. LLM unlearning aims to eliminate the influence of such harmful information while maintaining the model's overall performance. Existing unlearning methods, represented by gradient ascent-based approaches, primarily focus on forgetting target data while overlooking the crucial impact of logically related knowledge on the effectiveness of unlearning. In this paper, through both theoretical and experimental analyses, we first demonstrate that a key reason for the suboptimal unlearning performance is that models can reconstruct the target content through reasoning with logically related knowledge. To address this issue, we propose Unlearning Improvement via Parameter Extrapolation (UIPE), a method that removes knowledge highly correlated with the forgetting targets. Experimental results show that UIPE significantly enhances the performance of various mainstream LLM unlearning methods on the TOFU benchmark. | [üîó Paper](http://arxiv.org/abs/2503.04693v1) |
| [From Opinion Polarization to Climate Action: A Social-Climate Model of the Opinion Spectrum](http://arxiv.org/abs/2503.04689v1) | Athira Satheesh Kumar, Kre≈°imir Josiƒá, Chris T Bauch, Madhur Anand | 2025-03-06 | General AI | We developed a coupled social-climate network model to understand the interaction between climate change opinion spread and the climate system and determine the role of this interaction in shaping collective actions and global temperature changes. In contrast to previous social-climate models that discretized opinions, we assumed opinions on climate change form a continuum, and were thereby able to capture more nuanced interactions. The model shows that resistance to behaviour change, elevated mitigation costs, and slow response to climate events can result in a global temperature anomaly in excess of 2{\deg}C. However, this outcome could be avoided by lowering mitigation costs and increasing the rate of interactions between individuals with differing opinions (social learning). Our model is the first to demonstrate the emergence of opinion polarization in a human-environment system. We predict that polarization of opinions in a population can be extinguished, and the population will adopt mitigation practices, when the response to temperature change is sensitive, even at higher mitigation costs. It also indicates that even with polarized opinion, an average pro-mitigative opinion in the population can reduce emissions. Finally, our model underscores how frequent and unexpected social or environmental changes, such as policy changes or extreme weather events, can slow climate change mitigation. This analysis helps identify the factors that support achieving international climate goals, such as leveraging peer influence and decreasing stubbornness in individuals, reducing mitigation costs, and encouraging climate-friendly lifestyles. Our model offers a valuable new framework for exploring the integration of social and natural sciences, particularly in the domain of human behavioural change. | [üîó Paper](http://arxiv.org/abs/2503.04689v1) |
| [The action of the Morava stabilizer group on the coefficients of Morava  E-theory at height 2](http://arxiv.org/abs/2503.04686v1) | Andrew Salch | 2025-03-06 | General AI | We calculate an explicit closed formula for the action of the height 2 full Morava stabilizer group on the coefficient ring of height 2 Morava E-theory. In particular, this yields an explicit, surprisingly simple closed formula for the action of the automorphism group of a height 2 formal group law on its Lubin-Tate deformation ring. The formula is of a combinatorial nature, given by sums over certain labelled ordered rooted trees. | [üîó Paper](http://arxiv.org/abs/2503.04686v1) |
| [DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module](http://arxiv.org/abs/2503.04685v2) | Krish Sharma, Niyar R Barman, Akshay Chaturvedi, Nicholas Asher | 2025-03-06 | General AI | We look at reasoning on GSM8k, a dataset of short texts presenting primary school, math problems. We find, with Mirzadeh et al. (2024), that current LLM progress on the data set may not be explained by better reasoning but by exposure to a broader pretraining data distribution. We then introduce a novel information source for helping models with less data or inferior training reason better: discourse structure. We show that discourse structure improves performance for models like Llama2 13b by up to 160%. Even for models that have most likely memorized the data set, adding discourse structural information to the model still improves predictions and dramatically improves large model performance on out of distribution examples. | [üîó Paper](http://arxiv.org/abs/2503.04685v2) |
| [Propagating Model Uncertainty through Filtering-based Probabilistic Numerical ODE Solvers](http://arxiv.org/abs/2503.04684v1) | Dingling Yao, Filip Tronarp, Nathanael Bosch | 2025-03-06 | General AI | Filtering-based probabilistic numerical solvers for ordinary differential equations (ODEs), also known as ODE filters, have been established as efficient methods for quantifying numerical uncertainty in the solution of ODEs. In practical applications, however, the underlying dynamical system often contains uncertain parameters, requiring the propagation of this model uncertainty to the ODE solution. In this paper, we demonstrate that ODE filters, despite their probabilistic nature, do not automatically solve this uncertainty propagation problem. To address this limitation, we present a novel approach that combines ODE filters with numerical quadrature to properly marginalize over uncertain parameters, while accounting for both parameter uncertainty and numerical solver uncertainty. Experiments across multiple dynamical systems demonstrate that the resulting uncertainty estimates closely match reference solutions. Notably, we show how the numerical uncertainty from the ODE solver can help prevent overconfidence in the propagated uncertainty estimates, especially when using larger step sizes. Our results illustrate that probabilistic numerical methods can effectively quantify both numerical and parametric uncertainty in dynamical systems. | [üîó Paper](http://arxiv.org/abs/2503.04684v1) |
| [Using the XMM-Newton Small Window Mode to investigate systematic uncertainties in the particle background of X-ray CCD detectors](http://arxiv.org/abs/2503.04682v1) | Gerrit Schellenberger, Ralph Kraft, Paul Nulsen, Eric D. Miller, Marshall W. Bautz, Catherine E. Grant, Dan Wilkins, Steven Allen, Silvano Molendi, David N. Burrows, Abraham D. Falcone, Valentina Fioretti, Richard F. Foster, David Hall, Michael W. J. Hubbard, Emanuele Perinati, Artem Poliszczuk, Arne Rau, Arnab Sarkar, Benjamin Schneider | 2025-03-06 | General AI | The level and uncertainty of the particle induced background in CCD detectors plays a crucial role for future X-ray instruments, such as the Wide Field Imager (WFI) onboard Athena. To mitigate the background systematic uncertainties, which will limit the Athena science goals, we aim to understand the relationship between the energetic charged particles interacting in the detector and satellite, and the instrumental science background to an unprecedented level. These particles produce easily identified "cosmic-ray tracks" along with less easily identified signals produced by secondary particles, e.g., X-rays generated by particle interactions with the instrument and indistinguishable from genuine sky X-rays. We utilize the Small Window Mode of the PN camera onboard XMM-Newton to understand the time, spatial and energy dependence of the various background components, particularly the particle induced background. While the distribution of particle events follows expected detector readout patterns, we find a particle track length distribution inconsistent with the simple, isotropic model. We also find that the detector mode-specific readout results in a shifted Cu fluorescent line. We illustrate that on long timescales the variability of the particle background correlates well with the solar cycle. This 20-year lightcurve, can be reproduced by a particle detector onboard Chandra, the HRC anti-coincidence shield. We conclude that the self-anti-coincidence method of removing X-ray-like events near detected particle tracks in the same frame can be optimized with the inclusion of additional information, such as the energy of the X-ray. The results presented here are relevant for any future pixelated X-ray imaging detector, and could allow the WFI to probe to truly faint X-ray surface brightness. | [üîó Paper](http://arxiv.org/abs/2503.04682v1) |
| [Mixed Near-field and Far-field Target Localization for Low-altitude Economy](http://arxiv.org/abs/2503.04681v1) | Cong Zhou, Changsheng You, Chao Zhou, Hongqiang Cheng, Shuo Shi | 2025-03-06 | General AI | In this paper, we study efficient mixed near-field and far-field target localization methods for low-altitude economy, by capitalizing on extremely large-scale multiple-input multiple-output (XL-MIMO) communication systems. Compared with existing works, we address three new challenges in localization, arising from 1) half-wavelength antenna spacing constraint, 2) hybrid uniform planar array (UPA) architecture, and 3) incorrect mixed-field target classification for near-field targets.To address these issues, we propose a new three-step mixed-field localization method.First, we reconstruct the signals received at UPA antennas by judiciously designing analog combining matrices over time with minimum recovery errors, thus tackling the reduced-dimensional signal-space issue in hybrid arrays.Second, based on recovered signals, we devise a modified MUSIC algorithm (catered to UPA architecture) to estimate 2D angular parameters of both far- and near-field targets. Due to half-wavelength inter-antenna spacing, there exist ambiguous angles when estimating true angles of targets.In the third step, we design an effective classification method to distinguish mixed-field targets, determine true angles of all targets, as well as estimate the ranges of near-field targets. In particular, angular ambiguity is resolved by showing an important fact that the three types of estimated angles (i.e., far-field, near-field, and ambiguous angles) exhibit significantly different patterns in the range-domain MUSIC spectrum. Furthermore, to characterize the estimation error lower-bound, we obtain a matrix closed-form Cram\'er-Rao bounds for mixed-field target localization. Finally, numerical results demonstrate the effectiveness of our proposed mixed-field localization method, which improves target-classification accuracy and achieves a lower root mean square error than various benchmark schemes. | [üîó Paper](http://arxiv.org/abs/2503.04681v1) |
| [Algebraic growth of the Cremona group](http://arxiv.org/abs/2503.04678v1) | Alberto Calabri, Serge Cantat, Alex Massarenti, Fran√ßois Maucourant, Massimiliano Mella | 2025-03-06 | General AI | We initiate the study of the ''algebraic growth'' of groups of automorphisms and birational transformations of algebraic varieties. Our main result concerns $\text{Bir}(\mathbb{P}^2)$, the Cremona group in $2$ variables. This group is the union, for all degrees $d\geq 1$, of the algebraic variety $\text{Bir}(\mathbb{P}^2)_d$ of birational transformations of the plane of degree $d$. Let $N_d$ denote the number of irreducible components of $\text{Bir}(\mathbb{P}^2)_d$. We describe the asymptotic growth of $N_d$ as $d$ goes to $+\infty$, showing that there are two constants $A$ and $B>0$ such that $$ A\sqrt{\ln(d)} \leq \ln \left(\ln \left(\sum_{e\leq d} N_e \right) \right) \leq B \sqrt{\ln(d)} $$ for all large enough degrees $d$. This growth type seems quite unusual and shows that computing the algebraic growth of $\text{Bir}(\mathbb{P}^2)$ is a challenging problem in general. | [üîó Paper](http://arxiv.org/abs/2503.04678v1) |
