# üìå AI Research Papers (November03 to November09)

## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human
  Demonstrations](http://arxiv.org/abs/2511.04671v1) | Maximus A. Pace, Prithwish Dan, Chuanruo Ning, Atiksh Bhardwaj, Audrey Du, Edward W. Duan, Wei-Chiu Ma, Kushal Kedia | 2025-11-06 | Diffusion Models | Human videos can be recorded quickly and at scale, making them an appealing source of training data for robot learning. However, humans and robots differ fundamentally in embodiment, resulting in mismatched action execution. Direct kinematic retargeting of human hand motion can therefore produce actions that are physically infeasible for robots. Despite these low-level differences, human demonstrations provide valuable motion cues about how to manipulate and interact with objects. Our key idea is to exploit the forward diffusion process: as noise is added to actions, low-level execution differences fade while high-level task guidance is preserved. We present X-Diffusion, a principled framework for training diffusion policies that maximally leverages human data without learning dynamically infeasible motions. X-Diffusion first trains a classifier to predict whether a noisy action is executed by a human or robot. Then, a human action is incorporated into policy training only after adding sufficient noise such that the classifier cannot discern its embodiment. Actions consistent with robot execution supervise fine-grained denoising at low noise levels, while mismatched human actions provide only coarse guidance at higher noise levels. Our experiments show that naive co-training under execution mismatches degrades policy performance, while X-Diffusion consistently improves it. Across five manipulation tasks, X-Diffusion achieves a 16% higher average success rate than the best baseline. The project website is available at https://portal-cornell.github.io/X-Diffusion/. | [üîó Paper](http://arxiv.org/abs/2511.04671v1) |
| [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](http://arxiv.org/abs/2511.04659v1) | Huaguan Chen, Wei Han, Haofei Sun, Ning Lin, Xingtao Song, Yunfan Yang, Jie Tian, Yang Liu, Ji-Rong Wen, Xiaoye Zhang, Xueshun Shen, Hao Sun | 2025-11-06 | Diffusion Models, Training & Evaluation | Extreme precipitation nowcasting demands high spatiotemporal fidelity and extended lead times, yet existing approaches remain limited. Numerical Weather Prediction (NWP) and its deep-learning emulations are too slow and coarse for rapidly evolving convection, while extrapolation and purely data-driven models suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce a gray-box, fully three-dimensional nowcasting framework that directly processes volumetric radar reflectivity and couples physically constrained neural operators with datadriven learning. The model learns vertically varying 3D advection fields under a conservative advection operator, parameterizes spatially varying diffusion, and introduces a Brownian-motion--inspired stochastic term to represent unresolved motions. A residual branch captures small-scale convective initiation and microphysical variability, while a diffusion-based stochastic module estimates uncertainty. The framework achieves more accurate forecasts up to three-hour lead time across precipitation regimes and ranked first in 57\% of cases in a blind evaluation by 160 meteorologists. By restoring full 3D dynamics with physical consistency, it offers a scalable and robust pathway for skillful and reliable nowcasting of extreme precipitation. | [üîó Paper](http://arxiv.org/abs/2511.04659v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference
  from weak lensing and galaxy clustering maps with deep learning. I. Analysis
  design](http://arxiv.org/abs/2511.04681v1) | A. Thomsen, J. Bucko, T. Kacprzak, V. Ajani, J. Fluri, A. Refregier, D. Anbajagane, F. J. Castander, A. Fert√©, M. Gatti, N. Jeffrey, A. Alarcon, A. Amon, K. Bechtol, M. R. Becker, G. M. Bernstein, A. Campos, A. Carnero Rosell, C. Chang, R. Chen, A. Choi, M. Crocce, C. Davis, J. DeRose, S. Dodelson, C. Doux, K. Eckert, J. Elvin-Poole, S. Everett, P. Fosalba, D. Gruen, I. Harrison, K. Herner, E. M. Huff, M. Jarvis, N. Kuropatkin, P. -F. Leget, N. MacCrann, J. McCullough, J. Myles, A. Navarro-Alsina, S. Pandey, A. Porredon, J. Prat, M. Raveri, M. Rodriguez-Monroy, R. P. Rollins, A. Roodman, E. S. Rykoff, C. S√°nchez, L. F. Secco, E. Sheldon, T. Shin, M. A. Troxel, I. Tutusaus, T. N. Varga, N. Weaverdyck, R. H. Wechsler, B. Yanny, B. Yin, Y. Zhang, J. Zuntz, S. Allam, F. Andrade-Oliveira, D. Bacon, J. Blazek, D. Brooks, R. Camilleri, J. Carretero, R. Cawthon, L. N. da Costa, M. E. da Silva Pereira, T. M. Davis, J. De Vicente, S. Desai, P. Doel, J. Garc√≠a-Bellido, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. J. James, K. Kuehn, O. Lahav, S. Lee, J. L. Marshall, J. Mena-Fern√°ndez, F. Menanteau, R. Miquel, J. Muir, R. L. C. Ogando, A. A. Plazas Malag√≥n, E. Sanchez, D. Sanchez Cid, I. Sevilla-Noarbe, M. Smith, E. Suchyta, M. E. C. Swanson, D. Thomas, C. To, D. L. Tucker | 2025-11-06 | RLHF, Model Evaluation, Responsible AI | Data-driven approaches using deep learning are emerging as powerful techniques to extract non-Gaussian information from cosmological large-scale structure. This work presents the first simulation-based inference (SBI) pipeline that combines weak lensing and galaxy clustering maps in a realistic Dark Energy Survey Year 3 (DES Y3) configuration and serves as preparation for a forthcoming analysis of the survey data. We develop a scalable forward model based on the CosmoGridV1 suite of N-body simulations to generate over one million self-consistent mock realizations of DES Y3 at the map level. Leveraging this large dataset, we train deep graph convolutional neural networks on the full survey footprint in spherical geometry to learn low-dimensional features that approximately maximize mutual information with target parameters. These learned compressions enable neural density estimation of the implicit likelihood via normalizing flows in a ten-dimensional parameter space spanning cosmological $w$CDM, intrinsic alignment, and linear galaxy bias parameters, while marginalizing over baryonic, photometric redshift, and shear bias nuisances. To ensure robustness, we extensively validate our inference pipeline using synthetic observations derived from both systematic contaminations in our forward model and independent Buzzard galaxy catalogs. Our forecasts yield significant improvements in cosmological parameter constraints, achieving $2-3\times$ higher figures of merit in the $\Omega_m - S_8$ plane relative to our implementation of baseline two-point statistics and effectively breaking parameter degeneracies through probe combination. These results demonstrate the potential of SBI analyses powered by deep learning for upcoming Stage-IV wide-field imaging surveys. | [üîó Paper](http://arxiv.org/abs/2511.04681v1) |
| [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human
  and Object Interaction](http://arxiv.org/abs/2511.04679v1) | Qingzhou Lu, Yao Feng, Baiyu Shi, Michael Piseno, Zhenan Bao, C. Karen Liu | 2025-11-06 | RLHF | Humanoid robots are expected to operate in human-centered environments where safe and natural physical interaction is essential. However, most recent reinforcement learning (RL) policies emphasize rigid tracking and suppress external forces. Existing impedance-augmented approaches are typically restricted to base or end-effector control and focus on resisting extreme forces rather than enabling compliance. We introduce GentleHumanoid, a framework that integrates impedance control into a whole-body motion tracking policy to achieve upper-body compliance. At its core is a unified spring-based formulation that models both resistive contacts (restoring forces when pressing against surfaces) and guiding contacts (pushes or pulls sampled from human motion data). This formulation ensures kinematically consistent forces across the shoulder, elbow, and wrist, while exposing the policy to diverse interaction scenarios. Safety is further supported through task-adjustable force thresholds. We evaluate our approach in both simulation and on the Unitree G1 humanoid across tasks requiring different levels of compliance, including gentle hugging, sit-to-stand assistance, and safe object manipulation. Compared to baselines, our policy consistently reduces peak contact forces while maintaining task success, resulting in smoother and more natural interactions. These results highlight a step toward humanoid robots that can safely and effectively collaborate with humans and handle objects in real-world environments. | [üîó Paper](http://arxiv.org/abs/2511.04679v1) |
| [Forgetting is Everywhere](http://arxiv.org/abs/2511.04666v1) | Ben Sanati, Thomas L. Lee, Trevor McInroe, Aidan Scannell, Nikolay Malkin, David Abel, Amos Storkey | 2025-11-06 | RLHF | A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms. | [üîó Paper](http://arxiv.org/abs/2511.04666v1) |
| [SAFe-Copilot: Unified Shared Autonomy Framework](http://arxiv.org/abs/2511.04664v1) | Phat Nguyen, Erfan Aasi, Shiva Sreeram, Guy Rosman, Andrew Silva, Sertac Karaman, Daniela Rus | 2025-11-06 | RLHF, Ongoing Learning, Training & Evaluation | Autonomous driving systems remain brittle in rare, ambiguous, and out-of-distribution scenarios, where human driver succeed through contextual reasoning. Shared autonomy has emerged as a promising approach to mitigate such failures by incorporating human input when autonomy is uncertain. However, most existing methods restrict arbitration to low-level trajectories, which represent only geometric paths and therefore fail to preserve the underlying driving intent. We propose a unified shared autonomy framework that integrates human input and autonomous planners at a higher level of abstraction. Our method leverages Vision Language Models (VLMs) to infer driver intent from multi-modal cues -- such as driver actions and environmental context -- and to synthesize coherent strategies that mediate between human and autonomous control. We first study the framework in a mock-human setting, where it achieves perfect recall alongside high accuracy and precision. A human-subject survey further shows strong alignment, with participants agreeing with arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive benchmark demonstrates a substantial reduction in collision rate and improvement in overall performance compared to pure autonomy. Arbitration at the level of semantic, language-based representations emerges as a design principle for shared autonomy, enabling systems to exercise common-sense reasoning and maintain continuity with human intent. | [üîó Paper](http://arxiv.org/abs/2511.04664v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual
  Generation](http://arxiv.org/abs/2511.04675v1) | Jinlai Liu, Jian Han, Bin Yan, Hui Wu, Fengda Zhu, Xing Wang, Yi Jiang, Bingyue Peng, Zehuan Yuan | 2025-11-06 | Multimodal AI, Diffusion Models | We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long interactive video synthesis via straightforward temporal autoregression. Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing some diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10x faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation. | [üîó Paper](http://arxiv.org/abs/2511.04675v1) |
| [Cambrian-S: Towards Spatial Supersensing in Video](http://arxiv.org/abs/2511.04670v1) | Shusheng Yang, Jihan Yang, Pinzhi Huang, Ellis Brown, Zihao Yang, Yue Yu, Shengbang Tong, Zihan Zheng, Yifan Xu, Muhan Wang, Daohan Lu, Rob Fergus, Yann LeCun, Li Fei-Fei, Saining Xie | 2025-11-06 | Multimodal AI, Scaling Laws, Memory & Context Length | We argue that progress in true multimodal intelligence calls for a shift from reactive, task-driven systems and brute-force long context towards a broader paradigm of supersensing. We frame spatial supersensing as four stages beyond linguistic-only understanding: semantic perception (naming what is seen), streaming event cognition (maintaining memory across continuous experiences), implicit 3D spatial cognition (inferring the world behind pixels), and predictive world modeling (creating internal models that filter and organize information). Current benchmarks largely test only the early stages, offering narrow coverage of spatial cognition and rarely challenging models in ways that require true world modeling. To drive progress in spatial supersensing, we present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial recall) and VSC (continual visual spatial counting). These tasks require arbitrarily long video inputs yet are resistant to brute-force context expansion. We then test data scaling limits by curating VSI-590K and training Cambrian-S, achieving +30% absolute improvement on VSI-Bench without sacrificing general capabilities. Yet performance on VSI-SUPER remains limited, indicating that scale alone is insufficient for spatial supersensing. We propose predictive sensing as a path forward, presenting a proof-of-concept in which a self-supervised next-latent-frame predictor leverages surprise (prediction error) to drive memory and event segmentation. On VSI-SUPER, this approach substantially outperforms leading proprietary baselines, showing that spatial supersensing requires models that not only see but also anticipate, select, and organize experience. | [üîó Paper](http://arxiv.org/abs/2511.04670v1) |
| [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](http://arxiv.org/abs/2511.04668v1) | Ellis Brown, Arijit Ray, Ranjay Krishna, Ross Girshick, Rob Fergus, Saining Xie | 2025-11-06 | Multimodal AI | Despite impressive high-level video comprehension, multimodal language models struggle with spatial reasoning across time and space. While current spatial training approaches rely on real-world video data, obtaining diverse footage with precise spatial annotations remains a bottleneck. To alleviate this bottleneck, we present SIMS-V -- a systematic data-generation framework that leverages the privileged information of 3D simulators to create spatially-rich video training data for multimodal language models. Using this framework, we investigate which properties of simulated data drive effective real-world transfer through systematic ablations of question types, mixes, and scales. We identify a minimal set of three question categories (metric measurement, perspective-dependent reasoning, and temporal tracking) that prove most effective for developing transferable spatial intelligence, outperforming comprehensive coverage despite using fewer question types. These insights enable highly efficient training: our 7B-parameter video LLM fine-tuned on just 25K simulated examples outperforms the larger 72B baseline and achieves competitive performance with proprietary models on rigorous real-world spatial reasoning benchmarks. Our approach demonstrates robust generalization, maintaining performance on general video understanding while showing substantial improvements on embodied and real-world spatial tasks. | [üîó Paper](http://arxiv.org/abs/2511.04668v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Quantum Search With Generalized Wildcards](http://arxiv.org/abs/2511.04669v1) | Arjan Cornelissen, Nikhil S. Mande, Subhasree Patro, Nithish Raja, Swagato Sanyal | 2025-11-06 | Optimization | In the search with wildcards problem [Ambainis, Montanaro, Quantum Inf.~Comput.'14], one's goal is to learn an unknown bit-string $x \in \{-1,1\}^n$. An algorithm may, at unit cost, test equality of any subset of the hidden string with a string of its choice. Ambainis and Montanaro showed a quantum algorithm of cost $O(\sqrt{n} \log n)$ and a near-matching lower bound of $\Omega(\sqrt{n})$. Belovs [Comput.~Comp.'15] subsequently showed a tight $O(\sqrt{n})$ upper bound.   We consider a natural generalization of this problem, parametrized by a subset $\cal{Q} \subseteq 2^{[n]}$, where an algorithm may test whether $x_S = b$ for an arbitrary $S \in \cal{Q}$ and $b \in \{-1,1\}^S$ of its choice, at unit cost. We show near-tight bounds when $\cal{Q}$ is any of the following collections: bounded-size sets, contiguous blocks, prefixes, and only the full set.   All of these results are derived using a framework that we develop. Using symmetries of the task at hand we show that the quantum query complexity of learning $x$ is characterized, up to a constant factor, by an optimization program, which is succinctly described as follows: `maximize over all odd functions $f : \{-1,1\}^n \to \mathbb{R}$ the ratio of the maximum value of $f$ to the maximum (over $T \in \cal{Q}$) standard deviation of $f$ on a subcube whose free variables are exactly $T$.'   To the best of our knowledge, ours is the first work to use the primal version of the negative-weight adversary bound (which is a maximization program typically used to show lower bounds) to show new quantum query upper bounds without explicitly resorting to SDP duality. | [üîó Paper](http://arxiv.org/abs/2511.04669v1) |
| [Multi-Method Analysis of Mathematics Placement Assessments: Classical,
  Machine Learning, and Clustering Approaches](http://arxiv.org/abs/2511.04667v1) | Julian D. Allagan, Dasia A. Singleton, Shanae N. Perry, Gabrielle C. Morgan, Essence A. Morgan | 2025-11-06 | Optimization | This study evaluates a 40-item mathematics placement examination administered to 198 students using a multi-method framework combining Classical Test Theory, machine learning, and unsupervised clustering. Classical Test Theory analysis reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$) while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement. Question 6 (Graph Interpretation) emerges as the examination's most powerful discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA F-statistic ($F = 4609.1$), and maximum Random Forest feature importance (0.206), accounting for 20.6\% of predictive power. Machine learning algorithms demonstrate exceptional performance, with Random Forest and Gradient Boosting achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering identifies a natural binary competency structure with a boundary at 42.5\%, diverging from the institutional threshold of 55\% and suggesting potential overclassification into remedial categories. The two-cluster solution exhibits exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster purity. Convergent evidence across methods supports specific refinements: replace poorly discriminating items, implement a two-stage assessment, and integrate Random Forest predictions with transparency mechanisms. These findings demonstrate that multi-method integration provides a robust empirical foundation for evidence-based mathematics placement optimization. | [üîó Paper](http://arxiv.org/abs/2511.04667v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [On the Exoplanet Yield of Gaia Astrometry](http://arxiv.org/abs/2511.04673v1) | Caleb Lammers, Joshua N. Winn | 2025-11-06 | Scaling Laws | We re-examine the expected yield of Gaia astrometric planet detections using updated models for giant-planet occurrence, the local stellar population, and Gaia's demonstrated astrometric precision. Our analysis combines a semi-analytic model that clarifies key scaling relations with more realistic Monte Carlo simulations. We predict $7{,}500 \pm 2{,}100$ planet discoveries in the 5-year dataset (DR4) and $120{,}000 \pm 22{,}000$ over the full 10-year mission (DR5), with the dominant error arising from uncertainties in giant-planet occurrence. We evaluate the sensitivity of these forecasts to the detection threshold and the desired precision for measurements of planet masses and orbital parameters. Roughly $1{,}900 \pm 540$ planets in DR4 and $38{,}000 \pm 7{,}300$ planets in DR5 should have masses and orbital periods determined to better than $20$%. Most detections will be super-Jupiters ($3$ - $13 M_{\rm J}$) on $2$ - $5$AU orbits around GKM-type stars ($0.4$ - $1.3 M_\odot$) within $500$ pc. Unresolved binary stars will lead to spurious planet detections, but we estimate that genuine planets will outnumber them by a factor of $5$ or more. An exception is planets around M-dwarfs with $a < 1$AU, for which the false-positive rate is expected to be about $50$%. To support community preparation for upcoming data releases, we provide mock catalogs of Gaia exoplanets and planet-impostor binaries. | [üîó Paper](http://arxiv.org/abs/2511.04673v1) |
| [Intermittency in Collisionless Large-Amplitude Turbulence](http://arxiv.org/abs/2511.04663v1) | Ryan Golant, Luca Comisso, Philipp Kempski, Lorenzo Sironi | 2025-11-06 | Scaling Laws | Large-amplitude turbulence -- characterized by a fluctuating magnetic field component, $\delta B$, that is stronger than the mean component, $B_0$ -- is generically intermittent, populated with intense localized structures such as sharp field-line bends and rapid field reversals. Recent MHD simulations suggest that these structures play an important role in particle transport and acceleration; however, MHD is inapplicable in most of our Universe, where the plasma is so hot or diffuse that Coulomb collisions are negligible. Therefore, in this paper, we analyze the intermittent properties of collisionless large-amplitude turbulence in electron-positron plasmas via fully kinetic 3D simulations, exploring a wide range of $\delta B / B_0$ and scale separations between the turbulence driving scale, $L$, and kinetic scales, $c/\omega_{\rm p}$. The steady-state collisionless turbulence in our simulations broadly resembles that of MHD, but the development of pressure anisotropy steepens the scaling between magnetic field strength, $B$, and scalar field-line curvature, $K_\parallel$ -- yielding $B \propto K_\parallel^{-3/4}$ -- and consequently modifies the power-law slope of the probability density function of $K_\parallel$; this slope hardens from $K_\parallel^{-2.5}$ to $K_\parallel^{-2.0}$ as $\delta B / B_0$ increases from 4 to 140. Pressure anisotropy also triggers mirror and firehose instabilities, with the volume-filling fractions of these fluctuations increasing with $\delta B / B_0$; for our largest $\delta B / B_0$, $20\%$ of the volume is mirror-unstable and $6\%$ is firehose-unstable. Both the curvature and the Larmor-scale fluctuations in collisionless large-amplitude turbulence are expected to significantly influence cosmic ray transport and acceleration in the interstellar medium of our Galaxy and the intracluster medium of galaxy clusters. | [üîó Paper](http://arxiv.org/abs/2511.04663v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation
  of Soft-Body Interactions](http://arxiv.org/abs/2511.04665v1) | Kaifeng Zhang, Shuo Sha, Hanxiao Jiang, Matthew Loper, Hyunjong Song, Guangyan Cai, Zhuo Xu, Xiaochen Hu, Changxi Zheng, Yunzhu Li | 2025-11-06 | Training & Evaluation | Robotic manipulation policies are advancing rapidly, but their direct evaluation in the real world remains costly, time-consuming, and difficult to reproduce, particularly for tasks involving deformable objects. Simulation provides a scalable and systematic alternative, yet existing simulators often fail to capture the coupled visual and physical complexity of soft-body interactions. We present a real-to-sim policy evaluation framework that constructs soft-body digital twins from real-world videos and renders robots, objects, and environments with photorealistic fidelity using 3D Gaussian Splatting. We validate our approach on representative deformable manipulation tasks, including plush toy packing, rope routing, and T-block pushing, demonstrating that simulated rollouts correlate strongly with real-world execution performance and reveal key behavioral patterns of learned policies. Our results suggest that combining physics-informed reconstruction with high-quality rendering enables reproducible, scalable, and accurate evaluation of robotic manipulation policies. Website: https://real2sim-eval.github.io/ | [üîó Paper](http://arxiv.org/abs/2511.04665v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [$\texttt{unimpeded}$: A Public Grid of Nested Sampling Chains for
  Cosmological Model Comparison and Tension Analysis](http://arxiv.org/abs/2511.04661v1) | Dily Duan Yi Ong, Will Handley | 2025-11-06 | Model Evaluation, Responsible AI | Bayesian inference is central to modern cosmology, yet comprehensive model comparison and tension quantification remain computationally prohibitive for many researchers. To address this, we release $\texttt{unimpeded}$, a publicly available Python library and data repository providing pre-computed nested sampling and MCMC chains. We apply this resource to conduct a systematic analysis across a grid of eight cosmological models, including $\Lambda$CDM and seven extensions, and 39 datasets, including individual probes and their pairwise combinations. Our model comparison reveals that whilst individual datasets show varied preferences for model extensions, the base $\Lambda$CDM model is most frequently preferred in combined analyses, with the general trend suggesting that evidence for new physics is diluted when probes are combined. Using five complementary statistics, we quantify tensions, finding the most significant to be between DES and Planck (3.57$\sigma$) and SH0ES and Planck (3.27$\sigma$) within $\Lambda$CDM. We characterise the $S_8$ tension as high-dimensional ($d_G=6.62$) and resolvable in extended models, whereas the Hubble tension is low-dimensional and persists across the model space. Caution should be exercised when combining datasets in tension. The $\texttt{unimpeded}$ data products, hosted on Zenodo, provide a powerful resource for reproducible cosmological analysis and underscore the robustness of the $\Lambda$CDM model against the current compendium of data. | [üîó Paper](http://arxiv.org/abs/2511.04661v1) |
| [Where to Experiment? Site Selection Under Distribution Shift via Optimal
  Transport and Wasserstein DRO](http://arxiv.org/abs/2511.04658v1) | Adam Bouyamourn | 2025-11-06 | Model Evaluation, Responsible AI, Optimization | How should researchers select experimental sites when the deployment population differs from observed data? I formulate the problem of experimental site selection as an optimal transport problem, developing methods to minimize downstream estimation error by choosing sites that minimize the Wasserstein distance between population and sample covariate distributions. I develop new theoretical upper bounds on PATE and CATE estimation errors, and show that these different objectives lead to different site selection strategies. I extend this approach by using Wasserstein Distributionally Robust Optimization to develop a site selection procedure robust to adversarial perturbations of covariate information: a specific model of distribution shift. I also propose a novel data-driven procedure for selecting the uncertainty radius the Wasserstein DRO problem, which allows the user to benchmark robustness levels against observed variation in their data. Simulation evidence, and a reanalysis of a randomized microcredit experiment in Morocco (Cr\'epon et al.), show that these methods outperform random and stratified sampling of sites when covariates have prognostic R-squared > .5, and alternative optimization methods i) for moderate-to-large size problem instances ii) when covariates are moderately informative about treatment effects, and iii) under induced distribution shift. | [üîó Paper](http://arxiv.org/abs/2511.04658v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Tracking and Understanding Object Transformations](http://arxiv.org/abs/2511.04678v1) | Yihong Sun, Xinyu Yang, Jennifer J. Sun, Bharath Hariharan | 2025-11-06 | Prompt Engineering | Real-world objects frequently undergo state transformations. From an apple being cut into pieces to a butterfly emerging from its cocoon, tracking through these changes is important for understanding real-world objects and dynamics. However, existing methods often lose track of the target object after transformation, due to significant changes in object appearance. To address this limitation, we introduce the task of Track Any State: tracking objects through transformations while detecting and describing state changes, accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we present TubeletGraph, a zero-shot system that recovers missing objects after transformation and maps out how object states are evolving over time. TubeletGraph first identifies potentially overlooked tracks, and determines whether they should be integrated based on semantic and proximity priors. Then, it reasons about the added tracks and generates a state graph describing each observed transformation. TubeletGraph achieves state-of-the-art tracking performance under transformations, while demonstrating deeper understanding of object transformations and promising capabilities in temporal grounding and semantic reasoning for complex object transformations. Code, additional results, and the benchmark dataset are available at https://tubelet-graph.github.io. | [üîó Paper](http://arxiv.org/abs/2511.04678v1) |
## üîπ Fine-Tuning

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical
  Consistency Checks](http://arxiv.org/abs/2511.04662v1) | Yu Feng, Nathaniel Weir, Kaj Bostrom, Sam Bayless, Darion Cassel, Sapana Chaudhary, Benjamin Kiesl-Reiter, Huzefa Rangwala | 2025-11-06 | Fine-Tuning, Prompt Engineering, LLM, Optimization | LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but they cannot reliably verify their own logic. Even when they reach correct answers, the underlying reasoning may be flawed, undermining trust in high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a neuro-symbolic method that extracts and verifies formal logical arguments from CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order logic and identifies premises that ground the argument in source context, commonsense knowledge, or prior reasoning steps. The symbolic representation enables automated solvers to verify logical validity while the NL premises allow humans and systems to identify ungrounded or fallacious reasoning steps. Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT effectively identifies flawed reasoning, and serves as a strong predictor of final answer correctness. We also leverage VeriCoT's verification signal for (1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct preference optimization (DPO) using verification-based pairwise rewards, further improving reasoning validity and accuracy. | [üîó Paper](http://arxiv.org/abs/2511.04662v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image
  Cropping](http://arxiv.org/abs/2511.04680v1) | Rafe Loya, Andrew Hamara, Benjamin Estell, Benjamin Kilpatrick, Andrew C. Freeman | 2025-11-06 | General AI | Automatic image cropping is a method for maximizing the human-perceived quality of cropped regions in photographs. Although several works have proposed techniques for producing singular crops, little work has addressed the problem of producing multiple, distinct crops with aesthetic appeal. In this paper, we motivate the problem with a discussion on modern social media applications, introduce a dataset of 277 relevant images and human labels, and evaluate the efficacy of several single-crop models with an image partitioning algorithm as a pre-processing step. The dataset is available at https://github.com/RafeLoya/carousel. | [üîó Paper](http://arxiv.org/abs/2511.04680v1) |
| [Scalable and Efficient Intra- and Inter-node Interconnection Networks
  for Post-Exascale Supercomputers and Data centers](http://arxiv.org/abs/2511.04677v1) | Joaquin Tarraga-Moreno, Daniel Barley, Francisco J. Andujar Munoz, Jesus Escudero-Sahuquillo, Holger Froning, Pedro Javier Garcia, Francisco J. Quiles, Jose Duato | 2025-11-06 | General AI | The rapid growth of data-intensive applications such as generative AI, scientific simulations, and large-scale analytics is driving modern supercomputers and data centers toward increasingly heterogeneous and tightly integrated architectures. These systems combine powerful CPUs and accelerators with emerging high-bandwidth memory and storage technologies to reduce data movement and improve computational efficiency. However, as the number of accelerators per node increases, communication bottlenecks emerge both within and between nodes, particularly when network resources are shared among heterogeneous components. | [üîó Paper](http://arxiv.org/abs/2511.04677v1) |
| [KGB-evolution: a relativistic $N$-body code for kinetic gravity braiding
  models](http://arxiv.org/abs/2511.04676v1) | Ahmad Nouri-Zonoz, Farbod Hassani, Emilio Bellini, Martin Kunz | 2025-11-06 | General AI | We present KGB-evolution, a relativistic $N$-body simulation code that extends the $k$-evolution code by incorporating an effective field theory parameterization of kinetic gravity braiding, while also including the $k$-essence model as a limiting case. As a first step, we implement the linearized dark energy stress-energy tensor and scalar field equations, providing the groundwork for a future full Horndeski theory extension. We validate KGB-evolution by comparing its power spectra against linear predictions from hi$\_$class, finding excellent agreement on large scales at low redshifts and over all scales at high redshifts. We demonstrate that nonlinear growth of matter and metric perturbations on small scales drives the linearized dark energy field into a nonlinear clustering regime, which in turn feeds back on the growth of cosmic structure. In contrast to the $k$-essence limit, a nonzero braiding considerably amplifies this backreaction, producing a significantly stronger alteration of structure formation in the kinetic gravity braiding model. | [üîó Paper](http://arxiv.org/abs/2511.04676v1) |
| [XYZ integrability the easy way](http://arxiv.org/abs/2511.04674v1) | Paul Fendley, Sascha Gehrmann, Eric Vernier, Frank Verstraete | 2025-11-06 | General AI | Sutherland showed that the XYZ quantum spin-chain Hamiltonian commutes with the eight-vertex model transfer matrix, so that Baxter's subsequent tour de force proves the integrability of both. The proof requires parametrising the Boltzmann weights using elliptic theta functions and showing they satisfy the Yang-Baxter equation. We here give a simpler derivation of the integrability of the XYZ chain by explicitly constructing an extensive sequence of conserved charges from a matrix-product operator. We show that they commute with the XYZ Hamiltonian with periodic boundary conditions or an arbitrary boundary magnetic field. A straightforward generalisation yields impurity interactions that preserve the integrability. Placing such an impurity at the edge gives an integrable generalisation of the Kondo problem with a gapped bulk. We make contact with the traditional approach by relating our matrix-product operator to products of the eight-vertex model transfer matrix. | [üîó Paper](http://arxiv.org/abs/2511.04674v1) |
| [A priori estimates and $Œ∑-$compactness for anisotropic
  Ginzburg-Landau minimizers with tangential anchoring](http://arxiv.org/abs/2511.04672v1) | Lia Bronsard, Andrew Colinet, Dominik Stantejsky, Lee van Brussel | 2025-11-06 | General AI | We consider minimizers $u_\varepsilon$ of the Ginzburg-Landau energy with quadratic divergence or curl penalization on a simply-connected two-dimensional domain $\Omega$. On the boundary, strong tangential anchoring is imposed. We prove a priori estimates for $u_\varepsilon$ in $L^\infty$ uniform in $\varepsilon$ and that the Lipschitz constant of $u_\varepsilon$ blows up like $\varepsilon^{-1}$. We then deduce compactness for a subsequence that converges to an $\mathbb{S}^1-$valued map with either one interior point defect or two boundary half-defects. We conclude our study with a proof that no boundary vortices can occur in the divergence penalized case. | [üîó Paper](http://arxiv.org/abs/2511.04672v1) |
| [Finite time blow-up for a multi-dimensional model of the Kiselev-Sarsam
  equation](http://arxiv.org/abs/2511.04660v1) | Wanwan Zhang | 2025-11-06 | General AI | In this paper, we propose and study a multi-dimensional nonlocal active scalar equation of the form \begin{eqnarray*} \partial_t\rho+g\mathcal{R}_a\rho\cdot \nabla\rho= 0,~\rho(\cdot,0)=\rho_{0}, \end{eqnarray*} where the transform $\mathcal{R}_a$ is defined by \begin{eqnarray*} \mathcal{R}_af(x)=\frac{\Gamma(\frac{n+1}{2})}{\pi^{\frac{n+1}{2}}}P.V.\int\limits_{\mathbb{R}^n}\Big(\frac{x-y}{ x-y ^{n+1}}-\frac{x-y}{( x-y ^2+a^2)^{\frac{n+1}{2}}}\Big)f(y)dy. \end{eqnarray*} This model can be viewed as a natural generalization of the well-known Kiselev-Sasarm equation, which was introduced in [14] as a one-dimensional model for the two-dimensional incompressible porous media equation. We show the local well-posedness for this multi-dimensional model as well as the gradient blow-up in finite time for a class of initial data. | [üîó Paper](http://arxiv.org/abs/2511.04660v1) |
| [Photodetection of Squeezed Light: a Whittaker-Shannon Analysis](http://arxiv.org/abs/2511.04657v1) | Jasper Kranias, Christian Drago, Colin Vendromin, J. E. Sipe | 2025-11-06 | General AI | The Whittaker-Shannon decomposition provides a temporally localized description of squeezed light, making it applicable in the CW limit and leading to a definition of squeezing strength based on the number of photon pairs at a time. We show examples of its usefulness by calculating quadrature variance in a homodyne detection scheme, coincidence detection probabilities in the continuous-wave limit, and analyzing the Hong-Ou-Mandel effect for strongly squeezed light. Quadrature uncertainty falls farther below the shot noise limit when squeezing is strong, but effects due to correlations between photon pairs are most significant with weak squeezing. Our analysis extends previous results to more general scenarios, and we leverage the Whittaker-Shannon formalism to interpret them based on the temporal properties of photon pairs. | [üîó Paper](http://arxiv.org/abs/2511.04657v1) |
