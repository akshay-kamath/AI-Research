# üìå AI Research Papers (February24 to March02)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts](http://arxiv.org/abs/2502.20395v1) | Zhongyang Li, Ziyue Li, Tianyi Zhou | 2025-02-27 | LLM, Scaling Laws, Optimization, Multimodal AI | In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method "Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters. | [üîó Paper](http://arxiv.org/abs/2502.20395v1) |
| [Evaluating the long-term viability of eye-tracking for continuous authentication in virtual reality](http://arxiv.org/abs/2502.20359v1) | Sai Ganesh Grandhi, Saeed Samet | 2025-02-27 | LLM | Traditional authentication methods, such as passwords and biometrics, verify a user's identity only at the start of a session, leaving systems vulnerable to session hijacking. Continuous authentication, however, ensures ongoing verification by monitoring user behavior. This study investigates the long-term feasibility of eye-tracking as a behavioral biometric for continuous authentication in virtual reality (VR) environments, using data from the GazebaseVR dataset. Our approach evaluates three architectures, Transformer Encoder, DenseNet, and XGBoost, on short and long-term data to determine their efficacy in user identification tasks. Initial results indicate that both Transformer Encoder and DenseNet models achieve high accuracy rates of up to 97% in short-term settings, effectively capturing unique gaze patterns. However, when tested on data collected 26 months later, model accuracy declined significantly, with rates as low as 1.78% for some tasks. To address this, we propose periodic model updates incorporating recent data, restoring accuracy to over 95%. These findings highlight the adaptability required for gaze-based continuous authentication systems and underscore the need for model retraining to manage evolving user behavior. Our study provides insights into the efficacy and limitations of eye-tracking as a biometric for VR authentication, paving the way for adaptive, secure VR user experiences. | [üîó Paper](http://arxiv.org/abs/2502.20359v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Tight Inversion: Image-Conditioned Inversion for Real Image Editing](http://arxiv.org/abs/2502.20376v1) | Edo Kadosh, Nir Goren, Or Patashnik, Daniel Garibi, Daniel Cohen-Or | 2025-02-27 | Diffusion Models | Text-to-image diffusion models offer powerful image editing capabilities. To edit real images, many methods rely on the inversion of the image into Gaussian noise. A common approach to invert an image is to gradually add noise to the image, where the noise is determined by reversing the sampling equation. This process has an inherent tradeoff between reconstruction and editability, limiting the editing of challenging images such as highly-detailed ones. Recognizing the reliance of text-to-image models inversion on a text condition, this work explores the importance of the condition choice. We show that a condition that precisely aligns with the input image significantly improves the inversion quality. Based on our findings, we introduce Tight Inversion, an inversion method that utilizes the most possible precise condition -- the input image itself. This tight condition narrows the distribution of the model's output and enhances both reconstruction and editability. We demonstrate the effectiveness of our approach when combined with existing inversion methods through extensive experiments, evaluating the reconstruction accuracy as well as the integration with various editing methods. | [üîó Paper](http://arxiv.org/abs/2502.20376v1) |
| [Constrained Generative Modeling with Manually Bridged Diffusion Models](http://arxiv.org/abs/2502.20371v1) | Saeid Naderiparizi, Xiaoxuan Liang, Berend Zwartsenberg, Frank Wood | 2025-02-27 | Diffusion Models | In this paper we describe a novel framework for diffusion-based generative modeling on constrained spaces. In particular, we introduce manual bridges, a framework that expands the kinds of constraints that can be practically used to form so-called diffusion bridges. We develop a mechanism for combining multiple such constraints so that the resulting multiply-constrained model remains a manual bridge that respects all constraints. We also develop a mechanism for training a diffusion model that respects such multiple constraints while also adapting it to match a data distribution. We develop and extend theory demonstrating the mathematical validity of our mechanisms. Additionally, we demonstrate our mechanism in constrained generative modeling tasks, highlighting a particular high-value application in modeling trajectory initializations for path planning and control in autonomous vehicles. | [üîó Paper](http://arxiv.org/abs/2502.20371v1) |
| [Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation](http://arxiv.org/abs/2502.20370v1) | Zhi Cen, Huaijin Pi, Sida Peng, Qing Shuai, Yujun Shen, Hujun Bao, Xiaowei Zhou, Ruizhen Hu | 2025-02-27 | Diffusion Models | This paper addresses the task of generating two-character online interactions. Previously, two main settings existed for two-character interaction generation: (1) generating one's motions based on the counterpart's complete motion sequence, and (2) jointly generating two-character motions based on specific conditions. We argue that these settings fail to model the process of real-life two-character interactions, where humans will react to their counterparts in real time and act as independent individuals. In contrast, we propose an online reaction policy, called Ready-to-React, to generate the next character pose based on past observed motions. Each character has its own reaction policy as its "brain", enabling them to interact like real humans in a streaming manner. Our policy is implemented by incorporating a diffusion head into an auto-regressive model, which can dynamically respond to the counterpart's motions while effectively mitigating the error accumulation throughout the generation process. We conduct comprehensive experiments using the challenging boxing task. Experimental results demonstrate that our method outperforms existing baselines and can generate extended motion sequences. Additionally, we show that our approach can be controlled by sparse signals, making it well-suited for VR and other online interactive environments. | [üîó Paper](http://arxiv.org/abs/2502.20370v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids](http://arxiv.org/abs/2502.20396v1) | Toru Lin, Kartik Sachdev, Linxi Fan, Jitendra Malik, Yuke Zhu | 2025-02-27 | RLHF, Optimization | Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collection of contact-rich manipulation tasks on a humanoid embodiment. We introduce novel techniques to overcome the identified challenges with empirical validation. Our main contributions include an automated real-to-sim tuning module that brings the simulated environment closer to the real world, a generalized reward design scheme that simplifies reward engineering for long-horizon contact-rich manipulation tasks, a divide-and-conquer distillation process that improves the sample efficiency of hard-exploration problems while maintaining sim-to-real performance, and a mixture of sparse and dense object representations to bridge the sim-to-real perception gap. We show promising results on three humanoid dexterous manipulation tasks, with ablation studies on each technique. Our work presents a successful approach to learning humanoid dexterous manipulation using sim-to-real reinforcement learning, achieving robust generalization and high performance without the need for human demonstration. | [üîó Paper](http://arxiv.org/abs/2502.20396v1) |
| [Multi-Turn Code Generation Through Single-Step Rewards](http://arxiv.org/abs/2502.20380v1) | Arnav Kumar Jain, Gonzalo Gonzalez-Pumariega, Wayne Chen, Alexander M Rush, Wenting Zhao, Sanjiban Choudhury | 2025-02-27 | RLHF, Fine-Tuning | We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $\mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode. | [üîó Paper](http://arxiv.org/abs/2502.20380v1) |
| [Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers](http://arxiv.org/abs/2502.20379v1) | Shalev Lifshitz, Sheila A. McIlraith, Yilun Du | 2025-02-27 | RLHF, Scaling Laws | By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time. | [üîó Paper](http://arxiv.org/abs/2502.20379v1) |
| [Bridging the Creativity Understanding Gap: Small-Scale Human Alignment Enables Expert-Level Humor Ranking in LLMs](http://arxiv.org/abs/2502.20356v1) | Kuan Lok Zhou, Jiayi Chen, Siddharth Suresh, Reuben Narad, Timothy T. Rogers, Lalit K Jain, Robert D Nowak, Bob Mankoff, Jifan Zhang | 2025-02-27 | RLHF | Large Language Models (LLMs) have shown significant limitations in understanding creative content, as demonstrated by Hessel et al. (2023)'s influential work on the New Yorker Cartoon Caption Contest (NYCCC). Their study exposed a substantial gap between LLMs and humans in humor comprehension, establishing that understanding and evaluating creative content is key challenge in AI development. We revisit this challenge by decomposing humor understanding into three components and systematically improve each: enhancing visual understanding through improved annotation, utilizing LLM-generated humor reasoning and explanations, and implementing targeted alignment with human preference data. Our refined approach achieves 82.4% accuracy in caption ranking, singificantly improving upon the previous 67% benchmark and matching the performance of world-renowned human experts in this domain. Notably, while attempts to mimic subgroup preferences through various persona prompts showed minimal impact, model finetuning with crowd preferences proved remarkably effective. These findings reveal that LLM limitations in creative judgment can be effectively addressed through focused alignment to specific subgroups and individuals. Lastly, we propose the position that achieving artificial general intelligence necessitates systematic collection of human preference data across creative domains. We advocate that just as human creativity is deeply influenced by individual and cultural preferences, training LLMs with diverse human preference data may be essential for developing true creative understanding. | [üîó Paper](http://arxiv.org/abs/2502.20356v1) |
| [Rotational Brownian motion and heavy quark polarization in QCD medium](http://arxiv.org/abs/2502.20352v1) | Sourav Dey, Amaresh Jaiswal | 2025-02-27 | RLHF | We consider the rotational Brownian motion of heavy quark in QCD medium and provide predictions for polarization of open heavy-flavor hadrons. We calculate expressions for vector and tensor polarization, corresponding to baryon spin polarization and meson spin alignment, respectively. We propose that the transverse momentum dependence of heavy quark polarization may serve as a distinctive signature of the intense initial magnetic field generated in off-central relativistic heavy-ion collisions. | [üîó Paper](http://arxiv.org/abs/2502.20352v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Walking the Web of Concept-Class Relationships in Incrementally Trained Interpretable Models](http://arxiv.org/abs/2502.20393v1) | Susmit Agrawal, Deepika Vemuri, Sri Siddarth Chakaravarthy P, Vineeth N. Balasubramanian | 2025-02-27 | Multimodal AI | Concept-based methods have emerged as a promising direction to develop interpretable neural networks in standard supervised settings. However, most works that study them in incremental settings assume either a static concept set across all experiences or assume that each experience relies on a distinct set of concepts. In this work, we study concept-based models in a more realistic, dynamic setting where new classes may rely on older concepts in addition to introducing new concepts themselves. We show that concepts and classes form a complex web of relationships, which is susceptible to degradation and needs to be preserved and augmented across experiences. We introduce new metrics to show that existing concept-based models cannot preserve these relationships even when trained using methods to prevent catastrophic forgetting, since they cannot handle forgetting at concept, class, and concept-class relationship levels simultaneously. To address these issues, we propose a novel method - MuCIL - that uses multimodal concepts to perform classification without increasing the number of trainable parameters across experiences. The multimodal concepts are aligned to concepts provided in natural language, making them interpretable by design. Through extensive experimentation, we show that our approach obtains state-of-the-art classification performance compared to other concept-based models, achieving over 2$\times$ the classification performance in some cases. We also study the ability of our model to perform interventions on concepts, and show that it can localize visual concepts in input images, providing post-hoc interpretations. | [üîó Paper](http://arxiv.org/abs/2502.20393v1) |
| [InsTaG: Learning Personalized 3D Talking Head from Few-Second Video](http://arxiv.org/abs/2502.20387v1) | Jiahe Li, Jiawei Zhang, Xiao Bai, Jin Zheng, Jun Zhou, Lin Gu | 2025-02-27 | Multimodal AI | Despite exhibiting impressive performance in synthesizing lifelike personalized 3D talking heads, prevailing methods based on radiance fields suffer from high demands for training data and time for each new identity. This paper introduces InsTaG, a 3D talking head synthesis framework that allows a fast learning of realistic personalized 3D talking head from few training data. Built upon a lightweight 3DGS person-specific synthesizer with universal motion priors, InsTaG achieves high-quality and fast adaptation while preserving high-level personalization and efficiency. As preparation, we first propose an Identity-Free Pre-training strategy that enables the pre-training of the person-specific model and encourages the collection of universal motion priors from long-video data corpus. To fully exploit the universal motion priors to learn an unseen new identity, we then present a Motion-Aligned Adaptation strategy to adaptively align the target head to the pre-trained field, and constrain a robust dynamic head structure under few training data. Experiments demonstrate our outstanding performance and efficiency under various data scenarios to render high-quality personalized talking heads. | [üîó Paper](http://arxiv.org/abs/2502.20387v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [LIFT-GS: Cross-Scene Render-Supervised Distillation for 3D Language Grounding](http://arxiv.org/abs/2502.20389v1) | Ang Cao, Sergio Arnaud, Oleksandr Maksymets, Jianing Yang, Ayush Jain, Sriram Yenamandra, Ada Martin, Vincent-Pierre Berges, Paul McVay, Ruslan Partsey, Aravind Rajeswaran, Franziska Meier, Justin Johnson, Jeong Joon Park, Alexander Sax | 2025-02-27 | Optimization, Multimodal AI | Our approach to training 3D vision-language understanding models is to train a feedforward model that makes predictions in 3D, but never requires 3D labels and is supervised only in 2D, using 2D losses and differentiable rendering. The approach is new for vision-language understanding. By treating the reconstruction as a ``latent variable'', we can render the outputs without placing unnecessary constraints on the network architecture (e.g. can be used with decoder-only models). For training, only need images and camera pose, and 2D labels. We show that we can even remove the need for 2D labels by using pseudo-labels from pretrained 2D models. We demonstrate this to pretrain a network, and we finetune it for 3D vision-language understanding tasks. We show this approach outperforms baselines/sota for 3D vision-language grounding, and also outperforms other 3D pretraining techniques. Project page: https://liftgs.github.io. | [üîó Paper](http://arxiv.org/abs/2502.20389v1) |
| [Shadow measurements for feedback-based quantum optimization](http://arxiv.org/abs/2502.20366v1) | Leticia Bertuzzi, Jo√£o P. Engster, Evandro C. R. da Rosa, Eduardo I. Duzzioni | 2025-02-27 | Optimization | Improving the performance of quantum algorithms is a fundamental task to achieve quantum advantage. In many cases, extracting information from quantum systems poses an important challenge for practical implementations in real-world quantum computers, given the high resource cost of performing state tomography. In this scenario, randomized measurements emerged as a promising tool. In particular, the classical shadows protocol allows one to retrieve expected values of low-weight Pauli observables by performing only local measurements. In this paper, we present an implementation of the recently introduced Feedback-based algorithm for quantum optimization (FALQON) with the Ket quantum programming platform, for solving the MaxCut optimization problem. We employ classical shadows for the feedback routine of parameter estimation and compare this approach with the direct estimation of observables. Our results show that depending on the graph geometry for the MaxCut problem, the number of measurements required to estimate expected values of observables with classical shadows can be up to 16 times lower than with direct observable estimation. Furthermore, by analyzing complete graphs, we numerically confirm a logarithmic growth in the required number of measurements relative to the number of observables, reinforcing that classical shadows can be a useful tool for estimating low-locality Pauli observables in quantum algorithms. | [üîó Paper](http://arxiv.org/abs/2502.20366v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Hamiltonian Learning at Heisenberg Limit for Hybrid Quantum Systems](http://arxiv.org/abs/2502.20373v1) | Lixing Zhang, Ze-Xun Lin, Prineha Narang, Di Luo | 2025-02-27 | Scaling Laws | Hybrid quantum systems are fundamental in quantum materials and quantum information science. In this work, we demonstrate that Hamiltonian learning in hybrid spin-boson systems can achieve the Heisenberg limit. Specifically, we establish a rigorous theoretical framework proving that, given access to an unknown hybrid Hamiltonian system, our algorithm can estimate the Hamiltonian coupling parameters up to root mean square error (RMSE) $\epsilon$ with a total evolution time scaling as $T \sim \mathcal{O}(\epsilon^{-1})$ using only $\mathcal{O}({\rm polylog}(\epsilon^{-1}))$ measurements. Furthermore, it remains robust against small state preparation and measurement (SPAM) errors. In addition, we also provide an alternative algorithm based on distributed quantum sensing, which significantly reduces the maximum evolution time per measurement.To validate our method, we apply it to the generalized Dicke model for Hamiltonian learning and the spin-boson model for spectrum learning, demonstrating its efficiency in practical quantum systems. These results provide a scalable and robust framework for precision quantum sensing and Hamiltonian characterization in hybrid quantum platforms. | [üîó Paper](http://arxiv.org/abs/2502.20373v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation](http://arxiv.org/abs/2502.20377v1) | Albert Gong, Kamilƒó Stankeviƒçi≈´tƒó, Chao Wan, Anmol Kabra, Raphael Thesmar, Johann Lee, Julius Klenke, Carla P. Gomes, Kilian Q. Weinberger | 2025-02-27 | Training & Evaluation | High-quality benchmarks are essential for evaluating reasoning and retrieval capabilities of large language models (LLMs). However, curating datasets for this purpose is not a permanent solution as they are prone to data leakage and inflated performance results. To address these challenges, we propose PhantomWiki: a pipeline to generate unique, factually consistent document corpora with diverse question-answer pairs. Unlike prior work, PhantomWiki is neither a fixed dataset, nor is it based on any existing data. Instead, a new PhantomWiki instance is generated on demand for each evaluation. We vary the question difficulty and corpus size to disentangle reasoning and retrieval capabilities respectively, and find that PhantomWiki datasets are surprisingly challenging for frontier LLMs. Thus, we contribute a scalable and data leakage-resistant framework for disentangled evaluation of reasoning, retrieval, and tool-use abilities. Our code is available at https://github.com/kilian-group/phantom-wiki. | [üîó Paper](http://arxiv.org/abs/2502.20377v1) |
| [When does a predictor know its own loss?](http://arxiv.org/abs/2502.20375v1) | Aravind Gollakota, Parikshit Gopalan, Aayush Karan, Charlotte Peale, Udi Wieder | 2025-02-27 | Training & Evaluation, Responsible AI | Given a predictor and a loss function, how well can we predict the loss that the predictor will incur on an input? This is the problem of loss prediction, a key computational task associated with uncertainty estimation for a predictor. In a classification setting, a predictor will typically predict a distribution over labels and hence have its own estimate of the loss that it will incur, given by the entropy of the predicted distribution. Should we trust this estimate? In other words, when does the predictor know what it knows and what it does not know?   In this work we study the theoretical foundations of loss prediction. Our main contribution is to establish tight connections between nontrivial loss prediction and certain forms of multicalibration, a multigroup fairness notion that asks for calibrated predictions across computationally identifiable subgroups. Formally, we show that a loss predictor that is able to improve on the self-estimate of a predictor yields a witness to a failure of multicalibration, and vice versa. This has the implication that nontrivial loss prediction is in effect no easier or harder than auditing for multicalibration. We support our theoretical results with experiments that show a robust positive correlation between the multicalibration error of a predictor and the efficacy of training a loss predictor. | [üîó Paper](http://arxiv.org/abs/2502.20375v1) |
| [The Role of Tactile Sensing for Learning Reach and Grasp](http://arxiv.org/abs/2502.20367v1) | Boya Zhang, Iris Andrussow, Andreas Zell, Georg Martius | 2025-02-27 | Training & Evaluation, RLHF | Stable and robust robotic grasping is essential for current and future robot applications. In recent works, the use of large datasets and supervised learning has enhanced speed and precision in antipodal grasping. However, these methods struggle with perception and calibration errors due to large planning horizons. To obtain more robust and reactive grasping motions, leveraging reinforcement learning combined with tactile sensing is a promising direction. Yet, there is no systematic evaluation of how the complexity of force-based tactile sensing affects the learning behavior for grasping tasks. This paper compares various tactile and environmental setups using two model-free reinforcement learning approaches for antipodal grasping. Our findings suggest that under imperfect visual perception, various tactile features improve learning outcomes, while complex tactile inputs complicate training. | [üîó Paper](http://arxiv.org/abs/2502.20367v1) |
| [OpenTAD: A Unified Framework and Comprehensive Study of Temporal Action Detection](http://arxiv.org/abs/2502.20361v1) | Shuming Liu, Chen Zhao, Fatimah Zohra, Mattia Soldan, Alejandro Pardo, Mengmeng Xu, Lama Alssum, Merey Ramazanova, Juan Le√≥n Alc√°zar, Anthony Cioppa, Silvio Giancola, Carlos Hinojosa, Bernard Ghanem | 2025-02-27 | Training & Evaluation, Model Evaluation, Multimodal AI | Temporal action detection (TAD) is a fundamental video understanding task that aims to identify human actions and localize their temporal boundaries in videos. Although this field has achieved remarkable progress in recent years, further progress and real-world applications are impeded by the absence of a standardized framework. Currently, different methods are compared under different implementation settings, evaluation protocols, etc., making it difficult to assess the real effectiveness of a specific technique. To address this issue, we propose \textbf{OpenTAD}, a unified TAD framework consolidating 16 different TAD methods and 9 standard datasets into a modular codebase. In OpenTAD, minimal effort is required to replace one module with a different design, train a feature-based TAD model in end-to-end mode, or switch between the two. OpenTAD also facilitates straightforward benchmarking across various datasets and enables fair and in-depth comparisons among different methods. With OpenTAD, we comprehensively study how innovations in different network components affect detection performance and identify the most effective design choices through extensive experiments. This study has led to a new state-of-the-art TAD method built upon existing techniques for each component. We have made our code and models available at https://github.com/sming256/OpenTAD. | [üîó Paper](http://arxiv.org/abs/2502.20361v1) |
| [Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison](http://arxiv.org/abs/2502.20353v1) | Aron Harder, Madhur Behl | 2025-02-27 | Training & Evaluation, Optimization | Scenario Description Languages (SDLs) provide structured, interpretable embeddings that represent traffic scenarios encountered by autonomous vehicles (AVs), supporting key tasks such as scenario similarity searches and edge case detection for safety analysis. This paper introduces the Trajectory-to-Action Pipeline (TAP), a scalable and automated method for extracting SDL labels from large trajectory datasets. TAP applies a rules-based cross-entropy optimization approach to learn parameters directly from data, enhancing generalization across diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD), TAP achieves 30% greater precision than Average Displacement Error (ADE) and 24% over Dynamic Time Warping (DTW) in identifying behaviorally similar trajectories. Additionally, TAP enables automated detection of unique driving behaviors, streamlining safety evaluation processes for AV testing. This work provides a foundation for scalable scenario-based AV behavior analysis, with potential extensions for integrating multi-agent contexts. | [üîó Paper](http://arxiv.org/abs/2502.20353v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [A physically motivated galaxy size definition across different state-of-the-art hydrodynamical simulations](http://arxiv.org/abs/2502.20398v1) | Elena Arjona-Galvez, Salvador Cardona-Barrero, Robert J. J. Grand, Arianna Di Cintio, Claudio Dalla Vecchia, Jose A. Benavides, Andrea V. Maccio, Noam Libeskind, Alexander Knebe | 2025-02-27 | Model Evaluation, Responsible AI | Galaxy sizes are a key parameter to distinguishing between different galaxy types and morphologies, reflecting their formation and assembly histories. Several methods define galaxy boundaries, often relying on light concentration or isophotal densities. However, these approaches were often constrained by observational limitations and did not necessarily provide a clear physical boundary for galaxy outskirts. With modern deep imaging surveys, a new physically motivated definition has emerged using the radial position of the star formation threshold as the galaxy size, approximated by the stellar mass density contour at 1 Msun pc^-2 (R_1). We test this definition using three state-of-the-art hydrodynamical simulation suites, analyzing stellar surface density profiles across a wide range of stellar masses and redshifts. We measure the galaxy sizes according to this new definition and compare them with the most traditional size metric, the stellar half-mass radius. Our analysis demonstrates that the R_1-M_star relation exhibits consistent behaviour across both low and high-stellar mass galaxies, with remarkably low scatter. This relation is independent of redshift and holds across the three different cosmological hydrodynamical simulation suites, highlighting its robustness to variations in galaxy formation models. Furthermore, we explore the connection between a galaxy's total mass within R1 and its stellar mass, finding very little scatter in this relation. This suggests that R1 could serve as a reliable observational tracer for the galaxy's dynamical mass. The size-stellar mass relation proposed provides a reliable and physically motivated method for defining the outskirts of galaxies. This method remains consistent not only at z=0 but also throughout the evolutionary history of galaxies, offering a robust and meaningful framework for galaxy evolution studies. | [üîó Paper](http://arxiv.org/abs/2502.20398v1) |
| [Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation](http://arxiv.org/abs/2502.20388v1) | Sucheng Ren, Qihang Yu, Ju He, Xiaohui Shen, Alan Yuille, Liang-Chieh Chen | 2025-02-27 | Model Evaluation, Responsible AI | Autoregressive (AR) modeling, known for its next-token prediction paradigm, underpins state-of-the-art language and visual generative models. Traditionally, a ``token'' is treated as the smallest prediction unit, often a discrete symbol in language or a quantized patch in vision. However, the optimal token definition for 2D image structures remains an open question. Moreover, AR models suffer from exposure bias, where teacher forcing during training leads to error accumulation at inference. In this paper, we propose xAR, a generalized AR framework that extends the notion of a token to an entity X, which can represent an individual patch token, a cell (a $k\times k$ grouping of neighboring patches), a subsample (a non-local grouping of distant patches), a scale (coarse-to-fine resolution), or even a whole image. Additionally, we reformulate discrete token classification as \textbf{continuous entity regression}, leveraging flow-matching methods at each AR step. This approach conditions training on noisy entities instead of ground truth tokens, leading to Noisy Context Learning, which effectively alleviates exposure bias. As a result, xAR offers two key advantages: (1) it enables flexible prediction units that capture different contextual granularity and spatial structures, and (2) it mitigates exposure bias by avoiding reliance on teacher forcing. On ImageNet-256 generation benchmark, our base model, xAR-B (172M), outperforms DiT-XL/SiT-XL (675M) while achieving 20$\times$ faster inference. Meanwhile, xAR-H sets a new state-of-the-art with an FID of 1.24, running 2.2$\times$ faster than the previous best-performing model without relying on vision foundation modules (\eg, DINOv2) or advanced guidance interval sampling. | [üîó Paper](http://arxiv.org/abs/2502.20388v1) |
| [Waves and symbols in neuromorphic hardware: from analog signal processing to digital computing on the same computational substrate](http://arxiv.org/abs/2502.20381v1) | Dmitrii Zendrikov, Alessio Franci, Giacomo Indiveri | 2025-02-27 | Model Evaluation, Responsible AI | Neural systems use the same underlying computational substrate to carry out analog filtering and signal processing operations, as well as discrete symbol manipulation and digital computation. Inspired by the computational principles of canonical cortical microcircuits, we propose a framework for using recurrent spiking neural networks to seamlessly and robustly switch between analog signal processing and categorical and discrete computation. We provide theoretical analysis and practical neural network design tools to formally determine the conditions for inducing this switch. We demonstrate the robustness of this framework experimentally with hardware soft Winner-Take-All and mixed-feedback recurrent spiking neural networks, implemented by appropriately configuring the analog neuron and synapse circuits of a mixed-signal neuromorphic processor chip. | [üîó Paper](http://arxiv.org/abs/2502.20381v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions](http://arxiv.org/abs/2502.20390v1) | Sirui Xu, Hung Yu Ling, Yu-Xiong Wang, Liang-Yan Gui | 2025-02-27 | Prompt Engineering, Optimization | Achieving realistic simulations of humans interacting with a wide range of objects has long been a fundamental goal. Extending physics-based motion imitation to complex human-object interactions (HOIs) is challenging due to intricate human-object coupling, variability in object geometries, and artifacts in motion capture data, such as inaccurate contacts and limited hand detail. We introduce InterMimic, a framework that enables a single policy to robustly learn from hours of imperfect MoCap data covering diverse full-body interactions with dynamic and varied objects. Our key insight is to employ a curriculum strategy -- perfect first, then scale up. We first train subject-specific teacher policies to mimic, retarget, and refine motion capture data. Next, we distill these teachers into a student policy, with the teachers acting as online experts providing direct supervision, as well as high-quality references. Notably, we incorporate RL fine-tuning on the student policy to surpass mere demonstration replication and achieve higher-quality solutions. Our experiments demonstrate that InterMimic produces realistic and diverse interactions across multiple HOI datasets. The learned policy generalizes in a zero-shot manner and seamlessly integrates with kinematic generators, elevating the framework from mere imitation to generative modeling of complex human-object interactions. | [üîó Paper](http://arxiv.org/abs/2502.20390v1) |
| [Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization](http://arxiv.org/abs/2502.20382v1) | Lujie Yang, H. J. Terry Suh, Tong Zhao, Bernhard Paus Graesdal, Tarik Kelestemur, Jiuguang Wang, Tao Pang, Russ Tedrake | 2025-02-27 | Prompt Engineering, Optimization, Diffusion Models | We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/. | [üîó Paper](http://arxiv.org/abs/2502.20382v1) |
## üîπ Graph AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](http://arxiv.org/abs/2502.20364v1) | Ryan C. Barron, Maksim E. Eren, Olga M. Serafimova, Cynthia Matuszek, Boian S. Alexandrov | 2025-02-27 | Graph AI, Security & Adversarial ML, Responsible AI, RAG | Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research. This technology excels at inferring relationships within vast unstructured or semi-structured datasets. The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations. It comprises constitutions, statutes, regulations, and case law. Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research. Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations. In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency. Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia. It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery. This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI. | [üîó Paper](http://arxiv.org/abs/2502.20364v1) |
| [KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language Model](http://arxiv.org/abs/2502.20350v1) | Kai Zhang, Rui Zhu, Shutian Ma, Jingwei Xiong, Yejin Kim, Fabricio Murai, Xiaozhong Liu | 2025-02-27 | Graph AI | Drug discovery is a critical task in biomedical natural language processing (NLP), yet explainable drug discovery remains underexplored. Meanwhile, large language models (LLMs) have shown remarkable abilities in natural language understanding and generation. Leveraging LLMs for explainable drug discovery has the potential to improve downstream tasks and real-world applications. In this study, we utilize open-source drug knowledge graphs, clinical trial data, and PubMed publications to construct a comprehensive dataset for the explainable drug discovery task, named \textbf{expRxRec}. Furthermore, we introduce \textbf{KEDRec-LM}, an instruction-tuned LLM which distills knowledge from rich medical knowledge corpus for drug recommendation and rationale generation. To encourage further research in this area, we will publicly release\footnote{A copy is attached with this submission} both the dataset and KEDRec-LM. | [üîó Paper](http://arxiv.org/abs/2502.20350v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Towards Responsible AI in Education: Hybrid Recommendation System for K-12 Students Case Study](http://arxiv.org/abs/2502.20354v1) | Nazarii Drushchak, Vladyslava Tyshchenko, Nataliya Polyakovska | 2025-02-27 | Responsible AI | The growth of Educational Technology (EdTech) has enabled highly personalized learning experiences through Artificial Intelligence (AI)-based recommendation systems tailored to each student needs. However, these systems can unintentionally introduce biases, potentially limiting fair access to learning resources. This study presents a recommendation system for K-12 students, combining graph-based modeling and matrix factorization to provide personalized suggestions for extracurricular activities, learning resources, and volunteering opportunities. To address fairness concerns, the system includes a framework to detect and reduce biases by analyzing feedback across protected student groups. This work highlights the need for continuous monitoring in educational recommendation systems to support equitable, transparent, and effective learning opportunities for all students. | [üîó Paper](http://arxiv.org/abs/2502.20354v1) |
## üîπ Security & Adversarial ML

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis](http://arxiv.org/abs/2502.20383v1) | Jeffrey Yang Fan Chiang, Seungjae Lee, Jia-Bin Huang, Furong Huang, Yizheng Chen | 2025-02-27 | Security & Adversarial ML, Autonomous Agents, Training & Evaluation, Model Evaluation, Responsible AI | Recent advancements in Web AI agents have demonstrated remarkable capabilities in addressing complex web navigation tasks. However, emerging research shows that these agents exhibit greater vulnerability compared to standalone Large Language Models (LLMs), despite both being built upon the same safety-aligned models. This discrepancy is particularly concerning given the greater flexibility of Web AI Agent compared to standalone LLMs, which may expose them to a wider range of adversarial user inputs. To build a scaffold that addresses these concerns, this study investigates the underlying factors that contribute to the increased vulnerability of Web AI agents. Notably, this disparity stems from the multifaceted differences between Web AI agents and standalone LLMs, as well as the complex signals - nuances that simple evaluation metrics, such as success rate, often fail to capture. To tackle these challenges, we propose a component-level analysis and a more granular, systematic evaluation framework. Through this fine-grained investigation, we identify three critical factors that amplify the vulnerability of Web AI agents; (1) embedding user goals into the system prompt, (2) multi-step action generation, and (3) observational capabilities. Our findings highlights the pressing need to enhance security and robustness in AI agent design and provide actionable insights for targeted defense strategies. | [üîó Paper](http://arxiv.org/abs/2502.20383v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Mechanics on flag manifolds](http://arxiv.org/abs/2502.20397v1) | Andrew Kuzovchikov | 2025-02-27 | General AI | We study the connection between $\mathrm{SU}(n)$ spin chains and one-dimensional sigma models on flag manifolds. Using this connection, we calculate the spectrum of the Laplace-Beltrami operator and geodesics for a particular class of metrics on $\mathbb{CP}^1$ and $\mathcal{F}_3$, which is a manifold of complete flags in $\mathbb{C}^3$. | [üîó Paper](http://arxiv.org/abs/2502.20397v1) |
| [Superconductivity in doped planar Dirac insulators: A renormalization group study](http://arxiv.org/abs/2502.20394v1) | Sk Asrap Murshed, Sanjib Kumar Das, Bitan Roy | 2025-02-27 | General AI | From a leading-order unbiased renormalization group analysis we here showcase the emergence of superconductivity (including the topological ones) from purely repulsive electron-electron interactions in two-dimensional doped Dirac insulators, featuring a Fermi surface. In the absence of chemical doping, such systems describe quantum anomalous or spin Hall and normal insulators. Otherwise a simply connected Fermi surface becomes annular deep inside the topological regime. By considering all symmetry allowed repulsive local four-fermion interactions, we show that the nature of the resulting superconducting states at low temperature follows certain Clifford algebraic selection rules, irrespective of the underlying Fermi surface topology. Within the framework of a microscopic Hubbard model, on-site repulsion among fermions with opposite orbitals (spin projections) typically favors topological $p$-wave (conventional $s$-wave) pairing. Theoretically predicted superconductivity can in principle be observed in experiments once the promising candidate materials for quantum anomalous and spin Hall insulators are doped to foster Fermi surfaces. | [üîó Paper](http://arxiv.org/abs/2502.20394v1) |
| [Scalable Signature Kernel Computations for Long Time Series via Local Neumann Series Expansions](http://arxiv.org/abs/2502.20392v1) | Matthew Tamayo-Rios, Alexander Schell, Rima Alaifari | 2025-02-27 | General AI | The signature kernel is a recent state-of-the-art tool for analyzing high-dimensional sequential data, valued for its theoretical guarantees and strong empirical performance. In this paper, we present a novel method for efficiently computing the signature kernel of long, high-dimensional time series via dynamically truncated recursive local power series expansions. Building on the characterization of the signature kernel as the solution of a Goursat PDE, our approach employs tilewise Neumann-series expansions to derive rapidly converging power series approximations of the signature kernel that are locally defined on subdomains and propagated iteratively across the entire domain of the Goursat solution by exploiting the geometry of the time series. Algorithmically, this involves solving a system of interdependent local Goursat PDEs by recursively propagating boundary conditions along a directed graph via topological ordering, with dynamic truncation adaptively terminating each local power series expansion when coefficients fall below machine precision, striking an effective balance between computational cost and accuracy. This method achieves substantial performance improvements over state-of-the-art approaches for computing the signature kernel, providing (a) adjustable and superior accuracy, even for time series with very high roughness; (b) drastically reduced memory requirements; and (c) scalability to efficiently handle very long time series (e.g., with up to half a million points or more) on a single GPU. These advantages make our method particularly well-suited for rough-path-assisted machine learning, financial modeling, and signal processing applications that involve very long and highly volatile data. | [üîó Paper](http://arxiv.org/abs/2502.20392v1) |
| [Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation](http://arxiv.org/abs/2502.20391v1) | Siddhant Haldar, Lerrel Pinto | 2025-02-27 | General AI | Building robotic agents capable of operating across diverse environments and object types remains a significant challenge, often requiring extensive data collection. This is particularly restrictive in robotics, where each data point must be physically executed in the real world. Consequently, there is a critical need for alternative data sources for robotics and frameworks that enable learning from such data. In this work, we present Point Policy, a new method for learning robot policies exclusively from offline human demonstration videos and without any teleoperation data. Point Policy leverages state-of-the-art vision models and policy architectures to translate human hand poses into robot poses while capturing object states through semantically meaningful key points. This approach yields a morphology-agnostic representation that facilitates effective policy learning. Our experiments on 8 real-world tasks demonstrate an overall 75% absolute improvement over prior works when evaluated in identical settings as training. Further, Point Policy exhibits a 74% gain across tasks for novel object instances and is robust to significant background clutter. Videos of the robot are best viewed at https://point-policy.github.io/. | [üîó Paper](http://arxiv.org/abs/2502.20391v1) |
| [ATLAS Navigator: Active Task-driven LAnguage-embedded Gaussian Splatting](http://arxiv.org/abs/2502.20386v1) | Dexter Ong, Yuezhan Tao, Varun Murali, Igor Spasojevic, Vijay Kumar, Pratik Chaudhari | 2025-02-27 | General AI | We address the challenge of task-oriented navigation in unstructured and unknown environments, where robots must incrementally build and reason on rich, metric-semantic maps in real time. Since tasks may require clarification or re-specification, it is necessary for the information in the map to be rich enough to enable generalization across a wide range of tasks. To effectively execute tasks specified in natural language, we propose a hierarchical representation built on language-embedded Gaussian splatting that enables both sparse semantic planning that lends itself to online operation and dense geometric representation for collision-free navigation. We validate the effectiveness of our method through real-world robot experiments conducted in both cluttered indoor and kilometer-scale outdoor environments, with a competitive ratio of about 60% against privileged baselines. Experiment videos and more details can be found on our project page: https://atlasnav.github.io | [üîó Paper](http://arxiv.org/abs/2502.20386v1) |
| [rSPDE: tools for statistical modeling using fractional SPDEs](http://arxiv.org/abs/2502.20385v1) | David Bolin, Alexandre B. Simas | 2025-02-27 | General AI | The R software package rSPDE contains methods for approximating Gaussian random fields based on fractional-order stochastic partial differential equations (SPDEs). A common example of such fields are Whittle-Mat\'ern fields on bounded domains in $\mathbb{R}^d$, manifolds, or metric graphs. The package also implements various other models which are briefly introduced in this article. Besides the approximation methods, the package contains methods for simulation, prediction, and statistical inference for such models, as well as interfaces to INLA, inlabru and MetricGraph. With these interfaces, fractional-order SPDEs can be used as model components in general latent Gaussian models, for which full Bayesian inference can be performed, also for fractional models on metric graphs. This includes estimation of the smoothness parameter of the fields. This article describes the computational methods used in the package and summarizes the theoretical basis for these. The main functions of the package are introduced, and their usage is illustrated through various examples. | [üîó Paper](http://arxiv.org/abs/2502.20385v1) |
| [Linear matter density perturbations in the $Œõ_{\rm s}$CDM model: Examining growth dynamics and addressing the $S_8$ tension](http://arxiv.org/abs/2502.20384v1) | √ñzg√ºr Akarsu, Arman √áam, Evangelos A. Paraskevas, Leandros Perivolaropoulos | 2025-02-27 | General AI | We investigate linear matter density perturbations in the $\Lambda_{\rm s}$CDM, in which the $\Lambda$ is replaced by late-time ($z\sim2$) mirror AdS-dS transition, resulting in distinct growth dynamics. We use two complementary approaches: (i) determining the initial density contrast and its evolution rate for a given collapse scale factor, (ii) computing the collapse scale factor for a specified initial density contrast and evolution rate. We derive analytical solutions for the growth rate $f=\Omega_{\rm m}^\gamma$ and growth index $\gamma$ in both models. Prior to the transition, the AdS-like $\Lambda$ reduces cosmic friction, causing linear matter density perturbations to grow more rapidly than in $\Lambda$CDM; this effect is most pronounced just before the transition, with a growth rate around $15\%$ higher than $\Lambda$CDM around $z\sim2$. After the transition, $\Lambda_{\rm s}$CDM behaves similarly to $\Lambda$CDM but features a larger cosmological constant, leading to higher $H(z)$ and greater cosmic friction that more effectively suppresses growth. Before the transition, $\gamma$ remains below both the $\Lambda$CDM and EdS values ($\gamma\approx6/11$); during the transition, it increases rapidly and then grows gradually, paralleling $\Lambda$CDM while remaining slightly higher in the post-transition era-though overall, it stays near $\gamma\sim0.55$. Using the Planck best-fit values, $\Omega_{\rm m0}=0.28$ for $\Lambda_{\mathrm{s}}$CDM and $\Omega_{\rm m0}=0.32$ for $\Lambda$CDM, we find $f=0.49$ and $f=0.53$, respectively. $\Lambda_{\rm s}$CDM predicts a value of $f=0.48$, recently obtained from LSS data when $\gamma$ is treated as a free parameter in $\Lambda$CDM. This suggests that $\Lambda_{\rm s}$CDM may resolve the structure growth anomaly, without deviating from $\gamma \sim 0.55$. | [üîó Paper](http://arxiv.org/abs/2502.20384v1) |
| [Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling](http://arxiv.org/abs/2502.20378v1) | Hanyang Kong, Xingyi Yang, Xinchao Wang | 2025-02-27 | General AI | Rendering dynamic scenes from monocular videos is a crucial yet challenging task. The recent deformable Gaussian Splatting has emerged as a robust solution to represent real-world dynamic scenes. However, it often leads to heavily redundant Gaussians, attempting to fit every training view at various time steps, leading to slower rendering speeds. Additionally, the attributes of Gaussians in static areas are time-invariant, making it unnecessary to model every Gaussian, which can cause jittering in static regions. In practice, the primary bottleneck in rendering speed for dynamic scenes is the number of Gaussians. In response, we introduce Efficient Dynamic Gaussian Splatting (EDGS), which represents dynamic scenes via sparse time-variant attribute modeling. Our approach formulates dynamic scenes using a sparse anchor-grid representation, with the motion flow of dense Gaussians calculated via a classical kernel representation. Furthermore, we propose an unsupervised strategy to efficiently filter out anchors corresponding to static areas. Only anchors associated with deformable objects are input into MLPs to query time-variant attributes. Experiments on two real-world datasets demonstrate that our EDGS significantly improves the rendering speed with superior rendering quality compared to previous state-of-the-art methods. | [üîó Paper](http://arxiv.org/abs/2502.20378v1) |
| [Fault-Resilience of Dissipative Processes for Quantum Computing](http://arxiv.org/abs/2502.20374v1) | James Purcell, Abhishek Rajput, Toby Cubitt | 2025-02-27 | General AI | Dissipative processes have long been proposed as a means of performing computational tasks on quantum computers that may be intrinsically more robust to noise. In this work, we prove two main results concerning the error-resilience capabilities of two types of dissipative algorithms: dissipative ground state preparation in the form of the dissipative quantum eigensolver (DQE), and dissipative quantum computation (DQC). The first result is that under circuit-level depolarizing noise, a version of the DQE algorithm applied to the geometrically local, stabilizer-encoded Hamiltonians that arise naturally when fermionic Hamiltonians are represented in qubits, can suppress the additive error in the ground space overlap of the final output state exponentially in the code distance. This enables us to get closer to fault-tolerance for this task without the associated overhead. In contrast, for computation as opposed to ground state preparation, the second result proves that DQC is no more robust to noise than the standard quantum circuit model. | [üîó Paper](http://arxiv.org/abs/2502.20374v1) |
| [Positivity of the Veneziano Amplitude in Ten Dimensions](http://arxiv.org/abs/2502.20372v1) | Gareth Mansfield | 2025-02-27 | General AI | The Veneziano amplitude describing the tree-level scattering of four open superstrings is expected to be consistent with unitarity in ten spacetime dimensions. While this follows indirectly from the no-ghost theorem, a direct proof at the level of the amplitude has only been found for $D\leq 6$. In this note, we close this gap by providing a complete proof for the partial-wave positivity of the Veneziano amplitude in $D\leq 10$, derived directly from its definition in terms of the Euler beta function. We also demonstrate that this proof can be modified to show positivity of a wider family of amplitudes relevant to the $S$-matrix bootstrap. | [üîó Paper](http://arxiv.org/abs/2502.20372v1) |
| [Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding](http://arxiv.org/abs/2502.20369v1) | Jens H√∏igaard Jensen, Kristoffer Plagborg Bak S√∏rensen, Jonas le Fevre Sejersen, Andriy Sarabakha | 2025-02-27 | General AI | Multi-agent path planning is a critical challenge in robotics, requiring agents to navigate complex environments while avoiding collisions and optimizing travel efficiency. This work addresses the limitations of existing approaches by combining Gaussian belief propagation with path integration and introducing a novel tracking factor to ensure strict adherence to global paths. The proposed method is tested with two different global path-planning approaches: rapidly exploring random trees and a structured planner, which leverages predefined lane structures to improve coordination. A simulation environment was developed to validate the proposed method across diverse scenarios, each posing unique challenges in navigation and communication. Simulation results demonstrate that the tracking factor reduces path deviation by 28% in single-agent and 16% in multi-agent scenarios, highlighting its effectiveness in improving multi-agent coordination, especially when combined with structured global planning. | [üîó Paper](http://arxiv.org/abs/2502.20369v1) |
| [Minimax rate for learning kernels in operators](http://arxiv.org/abs/2502.20368v1) | Sichong Zhang, Xiong Wang, Fei Lu | 2025-02-27 | General AI | Learning kernels in operators from data lies at the intersection of inverse problems and statistical learning, offering a powerful framework for capturing nonlocal dependency in function spaces and high-dimensional settings. In contrast to classical nonparametric regression, where the inverse problem is well-posed, kernel estimation involves a compact normal operator and an ill-posed deconvolution. To address these challenges, we introduce adaptive spectral Sobolev spaces, unifying Sobolev spaces and reproducing kernel Hilbert spaces, that automatically discard non-identifiable components and control terms with small eigenvalues. Within this framework, we establish the minimax convergence rates for the mean squared error under both polynomial and exponential spectral decay regimes. Methodologically, we develop a tamed least squares estimator achieving the minimax upper rates via controlling the left-tail probability for eigenvalues of the random normal matrix; and for the minimax lower rates, we resolve challenges from infinite-dimensional measures through their projections. | [üîó Paper](http://arxiv.org/abs/2502.20368v1) |
| [Half-Metallic Fe/MgO Superlattice: An Ideal Candidate for Magnetic Tunnel Junction Electrodes](http://arxiv.org/abs/2502.20365v1) | Nicholas A. Lanzillo, Sergey Faleev, Aakash Pushp | 2025-02-27 | General AI | Magnetic Tunnel Junction (MTJ) based Spin-Transfer Torque Magnetic Random Access Memory (STT-MRAM) is poised to replace embedded Flash for advanced applications such as automotive microcontroller units. To achieve deeper technological adoption, MTJ needs to exhibit three key features: low magnetization (Ms), high perpendicular magnetic anisotropy (PMA) and high tunnel magnetoresistance (TMR). Here, we theoretically show that when Fe/MgO multilayers are inserted into the fixed and free layers of the MTJ, these three conditions are simultaneously met. As the number of Fe/MgO multilayers in MTJ electrodes is increased, we find that the electron transport evolves from direct barrier tunneling of majority spin states to the resonant tunneling of minority spin states. Remarkably, the projected density of states (PDOS) of Fe/MgO superlattice at the MgO tunnel barrier exhibits half-metallicity near the Fermi Energy, where the minority states exist while the majority states are gapped out, resulting in astronomically high TMR. | [üîó Paper](http://arxiv.org/abs/2502.20365v1) |
| [Global Framework for Simultaneous Emulation Across the Nuclear Landscape](http://arxiv.org/abs/2502.20363v1) | Antoine Belley, Jose M. Munoz, Ronald F. Garcia Ruiz | 2025-02-27 | General AI | We introduce a hierarchical framework that combines ab initio many-body calculations with a Bayesian neural network, developing emulators capable of accurately predicting nuclear properties across the nuclear chart, including multiple isotopes simultaneously. We benchmark our developments using the oxygen isotopic chain, achieving accurate results for ground-state energies and nuclear charge radii, while providing robust uncertainty quantification. Our framework enables global sensitivity analysis of nuclear binding energies and charge radii with respect to the low-energy constants that describe the nuclear force. | [üîó Paper](http://arxiv.org/abs/2502.20363v1) |
| [Investigating the influence of the radiative torque disruption on the size evolution of dust in the heliosphere](http://arxiv.org/abs/2502.20362v1) | Chi-Hang Ng, Pin-Gao Gu, Thiem Hoang | 2025-02-27 | General AI | In this paper, we conduct a detailed study on the effect of Radiative Torque Disruption (RATD) mechanism on the fragmentation of micrometer-sized dust grains into nanoparticles within the heliosphere. We start by estimating the disruption timescales for dust grains under various centrifugal stresses. Our numerical calculations demonstrate that RATD is a highly effective mechanism for breaking down micrometer-sized grains, producing nanoparticles more efficiently than other fragmentation processes. RATD also prevents micrometer-sized grains from being expelled by radiation pressure. Our findings indicate that the location of the present water snow line depends not only on temperature but also on the size of dust grains. For smaller grains, the snow line can shift outward beyond the position defined by thermal sublimation. Furthermore, we model the size distribution of dust grains modified by the RATD mechanism using a simplified model, showing that rotational disruption significantly decreases the number density of micrometer-sized grains while substantially increasing the number density of sub-micrometer-sized grains. However, the fraction of dust grains aligned at high-$J$ attractors by radiative torques less than 80\% can considerably weaken the effect of RATD on the grain size distribution. Finally, we suggest several experiments that could potentially test the RATD mechanism and discuss the uncertainties of our model in more realistic applications to heliospheric dust. | [üîó Paper](http://arxiv.org/abs/2502.20362v1) |
| [Selfish mining under general stochastic rewards](http://arxiv.org/abs/2502.20360v1) | Maryam Bahrani, Michael Neuder, S. Matthew Weinberg | 2025-02-27 | General AI | Selfish mining, a strategy where Proof-of-Work consensus participants selectively withhold blocks, allows miners to earn disproportionately high revenue. The vast majority of the selfish mining literature focuses exclusively on block rewards. Carlsten et al. [2016] is a notable exception, which observes that similar strategic behavior may be profitable in a zero-block-reward regime if miners are compensated with transaction fees alone. As of February 2025, neither model fully captures miner incentives. The block reward remains 3.125 BTC, yet some blocks yield significantly higher revenue. For example, congestion during the launch of the Babylon protocol in August 2024 caused transaction fees to spike from 0.14 BTC to 9.52 BTC, a $68\times$ increase in fee rewards within two blocks. We present a framework for considering strategic behavior under more general miner reward functions that could be stochastic, variable in time, and/or ephemeral. This model can capture many existing reward sources (sometimes called Miner/Maximal Extractable Value or MEV) in blockchains today. We use our framework to examine the profitability of cutoff selfish mining strategies for any reward function identically distributed across forks. Our analysis requires a novel reward calculation technique to capture non-linearity in general rewards. We instantiate these results in a combined reward function that much more accurately represents miner incentives as they exist in Bitcoin today. This reward function includes block rewards and linear-in-time transaction fees, which have been studied in isolation. It also introduces a third random reward motivated by the aforementioned transaction fee spike. This instantiation enables us to (i) make qualitative observations, (ii) make quantitative claims, and (iii) confirm the theoretical analysis using Monte Carlo simulations. | [üîó Paper](http://arxiv.org/abs/2502.20360v1) |
| [Creating multi-beam interference from two-beam interference with assistant of harmonics generation](http://arxiv.org/abs/2502.20358v1) | Wuzhen Li, Zhiyuan Zhou, Li Chen, Yinhai Li, Guangcan Guo, Baosen Shi | 2025-02-27 | General AI | Linear optics-based multi-beam interference (MBI), like the Fabry-Perot interferometer, plays an important role in precision optical metrology applications such as laser stabilization in optical clocks, precision spectroscopy, and gravitational wave detection. Here, we propose and experimentally verify a nonlinear optics-based MBI principle with the assistance of cascading and recycling harmonics generation of two-beam interference. By cascading and recycling the harmonics processes, in combining with optical power amplification (OPA) to compensate for power losses arising from limited nonlinear conversion efficiency, a total 16th harmonic is achieved, and the observed interference fringes gradually evolve from a sinusoidal curve to a Lorentz-like curve. In principle, there is no limitation on the number of cascading and recycling nonlinear processes with the assistance of OPAs and sharp interference fringes, analogous to those in a high-finesse cavity, can be obtained. The nonlinear optics-based MBI mechanism revealed here will find promising applications in precision optical metrology. | [üîó Paper](http://arxiv.org/abs/2502.20358v1) |
| [Phenomenology of the Higgs sector from Reduction of Couplings in the Type-II 2HDM](http://arxiv.org/abs/2502.20357v1) | Wojciech Kotlarski, Gregory Patellis | 2025-02-27 | General AI | The idea of reduction of couplings provides a systematic procedure to search for relations among seemingly unrelated parameters of a renormalizable theory. As a consequence, such reduced theories exhibit more constrained parameter spaces. Motivated by this, in this work we perform a precise phenomenological analysis of the Higgs sector of a version of the Type-II 2HDM on which the idea of reduction of couplings has been applied. We compute Higgs boson masses and decay widths and confront them with current experimental measurements. Compared to the previous study, apart from the inclusion of actual experimental constraints on production and decay rates of Higgs bosons, we also include all model parameters in the RGE running as well as one- and two-loop threshold corrections and two-loop RGE running from the high scale. Furthermore, Higgs boson masses are now computed at the one-loop level. Top quark mass, which is an important prediction of the reduction framework, is now evaluated including previously missing sub-leading one-loop contributions, with an addition of up to four-loop pure-QCD corrections. | [üîó Paper](http://arxiv.org/abs/2502.20357v1) |
| [The entropy profiles of a definable set over finite fields](http://arxiv.org/abs/2502.20355v1) | Tobias Boege | 2025-02-27 | General AI | A definable set $X$ in the first-order language of rings defines a family of random vectors: for each finite field $\mathbb{F}_q$, let the distribution be supported and uniform on the $\mathbb{F}_q$-rational points of $X$. We employ results from the model theory of finite fields to show that their entropy profiles settle into one of finitely many stable asymptotic behaviors as $q$ grows. The attainable asymptotic entropy profiles and their dominant terms as functions of $q$ are computable. This generalizes a construction of Mat\'u\v{s} which gives an information-theoretic interpretation to algebraic matroids. | [üîó Paper](http://arxiv.org/abs/2502.20355v1) |
| [KNOWM Memristors in a Bridge Synapse delay-based Reservoir Computing system for detection of epileptic seizures](http://arxiv.org/abs/2502.20351v1) | Dawid Przyczyna, Grzegorz Hess, Konrad Szaci≈Çowski | 2025-02-27 | General AI | Nanodevices that show the potential for non-linear transformation of electrical signals and various forms of memory can be successfully used in new computational paradigms, such as neuromorphic or reservoir computing (RC). Dedicated hardware implementations based on functional neuromorphic structures significantly reduce energy consumption and/or increase computational capabilities of a given artificial neural network system. Concepts of RC, which as a flexible computational paradigm can be highly inclusive, are often used as a model to describe computations performed in materia. With mostly fixed internal structure, solid-state devices, especially memristors, are studied as computational substrates in various RC systems. In this work, we present single-node Echo State Machine (SNESM) RC system based on bridge synapse as a computational substrate (consisting of 4 memristors and a differential amplifier) used for epileptic seizure detection. KNOWM memristors were posed as ideal candidates because of their easy prototyping and reliability of operation. In this account, we present an application of commercially available KNOWM memristors in various neuromorphic applications, from simple analysis of switching and internal dynamics (elucidated form noise spectroscopy and total harmonic distortion analysis) to the classification and recognition of complex time series: epilepsy seizure recognition using a wrist-worn triaxial accelerometer. | [üîó Paper](http://arxiv.org/abs/2502.20351v1) |
| [Naturalistic Computational Cognitive Science: Towards generalizable models and theories that capture the full range of natural behavior](http://arxiv.org/abs/2502.20349v1) | Wilka Carvalho, Andrew Lampinen | 2025-02-27 | General AI | Artificial Intelligence increasingly pursues large, complex models that perform many tasks within increasingly realistic domains. How, if at all, should these developments in AI influence cognitive science?   We argue that progress in AI offers timely opportunities for cognitive science to embrace experiments with increasingly naturalistic stimuli, tasks, and behaviors; and computational models that can accommodate these changes. We first review a growing body of research spanning neuroscience, cognitive science, and AI that suggests that incorporating a broader range of naturalistic experimental paradigms (and models that accommodate them) may be necessary to resolve some aspects of natural intelligence and ensure that our theories generalize. We then suggest that integrating recent progress in AI and cognitive science will enable us to engage with more naturalistic phenomena without giving up experimental control or the pursuit of theoretically grounded understanding. We offer practical guidance on how methodological practices can contribute to cumulative progress in naturalistic computational cognitive science, and illustrate a path towards building computational models that solve the real problems of natural cognition - together with a reductive understanding of the processes and principles by which they do so. | [üîó Paper](http://arxiv.org/abs/2502.20349v1) |
