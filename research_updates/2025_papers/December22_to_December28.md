# üìå AI Research Papers (December22 to December28)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis](https://arxiv.org/abs/2512.22100v1) | Duygu Altinok | 2025-12-26 | LLM, Training & Evaluation, Optimization | Evaluating the performance of various model architectures, such as transformers, large language models (LLMs), and other NLP systems, requires comprehensive benchmarks that measure performance across multiple dimensions. Among these, the evaluation of natural language understanding (NLU) is particularly critical as it serves as a fundamental criterion for assessing model capabilities. Thus, it is essential to establish benchmarks that enable thorough evaluation and analysis of NLU abilities from diverse perspectives. While the GLUE benchmark has set a standard for evaluating English NLU, similar benchmarks have been developed for other languages, such as CLUE for Chinese, FLUE for French, and JGLUE for Japanese. However, no comparable benchmark currently exists for the Turkish language. To address this gap, we introduce TrGLUE, a comprehensive benchmark encompassing a variety of NLU tasks for Turkish. In addition, we present SentiTurca, a specialized benchmark for sentiment analysis. To support researchers, we also provide fine-tuning and evaluation code for transformer-based models, facilitating the effective use of these benchmarks. TrGLUE comprises Turkish-native corpora curated to mirror the domains and task formulations of GLUE-style evaluations, with labels obtained through a semi-automated pipeline that combines strong LLM-based annotation, cross-model agreement checks, and subsequent human validation. This design prioritizes linguistic naturalness, minimizes direct translation artifacts, and yields a scalable, reproducible workflow. With TrGLUE, our goal is to establish a robust evaluation framework for Turkish NLU, empower researchers with valuable resources, and provide insights into generating high-quality semi-automated datasets. | [üîó Paper](https://arxiv.org/abs/2512.22100v1) |
| [Unifying Learning Dynamics and Generalization in Transformers Scaling Law](https://arxiv.org/abs/2512.22088v1) | Chiwun Yang | 2025-12-26 | LLM, Optimization, Scaling Laws | The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources. Yet, while empirically validated, its theoretical underpinnings remain poorly understood. This work formalizes the learning dynamics of transformer-based language models as an ordinary differential equation (ODE) system, then approximates this process to kernel behaviors. Departing from prior toy-model analyses, we rigorously analyze stochastic gradient descent (SGD) training for multi-layer transformers on sequence-to-sequence data with arbitrary data distribution, closely mirroring real-world conditions. Our analysis characterizes the convergence of generalization error to the irreducible risk as computational resources scale with data, especially during the optimization process.   We establish a theoretical upper bound on excess risk characterized by a distinct phase transition. In the initial optimization phase, the excess risk decays exponentially relative to the computational cost ${\sf C}$. However, once a specific resource allocation threshold is crossed, the system enters a statistical phase, where the generalization error follows a power-law decay of $Œò(\mathsf{C}^{-1/6})$. Beyond this unified framework, our theory derives isolated scaling laws for model size, training time, and dataset size, elucidating how each variable independently governs the upper bounds of generalization. | [üîó Paper](https://arxiv.org/abs/2512.22088v1) |
| [Agent-based simulation of online social networks and disinformation](https://arxiv.org/abs/2512.22082v1) | Alejandro Buitrago L√≥pez, Alberto Ortega Pastor, David Montoro Aguilera, Mario Fern√°ndez T√°rraga, Jes√∫s Verd√∫ Chac√≥n, Javier Pastor-Galindo, Jos√© A. Ruip√©rez-Valiente | 2025-12-26 | LLM | Research on online social networks (OSNs) is often hindered by platform opacity, limited access to data, and ethical constraints. Simulation offer a valuable alternative, but existing frameworks frequently lack realism and explainability. This paper presents a simulation framework that models synthetic social networks with agents endowed with demographic-based personality traits and finite-state behavioral automata, enabling realistic and interpretable actions. A generative module powered by a large language model (LLM) produces context-aware social media posts consistent with each agent's profile and memory. In parallel, a red module implements DISARM-inspired workflows to orchestrate disinformation campaigns executed by malicious agents targeting simulated audiences. A Mastodon-based visualization layer supports real-time inspection and post-hoc validation of agent activity within a familiar interface. We evaluate the resulting synthetic social networks using topological metrics and LLM-based content assessments, demonstrating structural, behavioral, and linguistic realism. Overall, the framework enables the creation of customizable and controllable social network environments for studying information dynamics and the effects of disinformation. | [üîó Paper](https://arxiv.org/abs/2512.22082v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Exact inference via quasi-conjugacy in two-parameter Poisson-Dirichlet hidden Markov models](https://arxiv.org/abs/2512.22098v1) | Marco Dalla Pria, Matteo Ruggiero, Dario Span√≤ | 2025-12-26 | Diffusion Models | We introduce a nonparametric model for time-evolving, unobserved probability distributions from discrete-time data consisting of unlabelled partitions. The latent process is a two-parameter Poisson-Dirichlet diffusion, and observations arise via exchangeable sampling. Applications include social and genetic data where only aggregate clustering summaries are observed. To address the intractable likelihood, we develop a tractable inferential framework that avoids label enumeration and direct simulation of the latent state. We exploit a duality between the diffusion and a pure-death process on partitions, together with coagulation operators that encode the effect of new data. These yield closed-form, recursive updates for forward and backward inference. We compute exact posterior distributions of the latent state at arbitrary times and predictive distributions of future or interpolated partitions. This enables online and offline inference and forecasting with full uncertainty quantification, bypassing MCMC and sequential Monte Carlo. Compared to particle filtering, our method achieves higher accuracy, lower variance, and substantial computational gains. We illustrate the methodology with synthetic experiments and a social network application, recovering interpretable patterns in time-varying heterozygosity. | [üîó Paper](https://arxiv.org/abs/2512.22098v1) |
| [Plasmon-Enhanced Graphene Terahertz Photo-thermoelectric Response](https://arxiv.org/abs/2512.22063v1) | Runli Li, Shaojing Liu, Ximiao Wang, Hongjia Zhu, Yongsheng Zhu, Shangdong Li, Huanjun Chen | 2025-12-26 | Diffusion Models | Terahertz (THz) technology shows great potential in 6G communications and imaging, but faces challenges related to detector sensitivity, noise, and cryogenic operation. Here, we integrate interferometric enhancement of absorption (IEA) from a metal reflection layer with a graphene plasmon polariton atomic cavity (PPAC)-based photodetector. The hybrid configuration enhances the in-plane electric field and improves the plasmon-induced thermal gradient. Numerical simulations and photoresponse measurements were employed to systematically investigate the influence of a metal reflective layer on the photothermoelectric behavior of the device, which reveals the IEA design significantly boosts the THz absorption rate in graphene nanostructures and promotes asymmetry in the lateral diffusion of hot carriers. Compared with the bare device, the responsivity of the device is enhanced by approximately 30-folds, while maintaining a response time below 130 Œºs. We further demonstrate the potential of the device to distinguish concealed liquids, advancing high-responsivity, room-temperature, and compact terahertz imaging technology. | [üîó Paper](https://arxiv.org/abs/2512.22063v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning](https://arxiv.org/abs/2512.22120v1) | Shuoshuo Zhang, Yizhen Zhang, Jingjing Fu, Lei Song, Jiang Bian, Yujiu Yang, Rui Wang | 2025-12-26 | Multimodal AI | Large vision-language models (VLMs) often benefit from intermediate visual cues, either injected via external tools or generated as latent visual tokens during reasoning, but these mechanisms still overlook fine-grained visual evidence (e.g., polylines in charts), generalize poorly across domains, and incur high inference-time cost. In this paper, we propose Bi-directional Perceptual Shaping (BiPS), which transforms question-conditioned masked views into bidirectional where-to-look signals that shape perception during training. BiPS first applies a KL-consistency constraint between the original image and an evidence-preserving view that keeps only question-relevant regions, encouraging coarse but complete coverage of supporting pixels. It then applies a KL-separation constraint between the original and an evidence-ablated view where critical pixels are masked so the image no longer supports the original answer, discouraging text-only shortcuts (i.e., answering from text alone) and enforcing fine-grained visual reliance. Across eight benchmarks, BiPS boosts Qwen2.5-VL-7B by 8.2% on average and shows strong out-of-domain generalization to unseen datasets and image types. | [üîó Paper](https://arxiv.org/abs/2512.22120v1) |
| [ProEdit: Inversion-based Editing From Prompts Done Right](https://arxiv.org/abs/2512.22118v1) | Zhi Ouyang, Dian Zheng, Xiao-Ming Wu, Jian-Jian Jiang, Kun-Yu Lin, Jingke Meng, Wei-Shi Zheng | 2025-12-26 | Multimodal AI | Inversion-based visual editing provides an effective and training-free way to edit an image or a video based on user instructions. Existing methods typically inject source image information during the sampling process to maintain editing consistency. However, this sampling strategy overly relies on source information, which negatively affects the edits in the target image (e.g., failing to change the subject's atributes like pose, number, or color as instructed). In this work, we propose ProEdit to address this issue both in the attention and the latent aspects. In the attention aspect, we introduce KV-mix, which mixes KV features of the source and the target in the edited region, mitigating the influence of the source image on the editing region while maintaining background consistency. In the latent aspect, we propose Latents-Shift, which perturbs the edited region of the source latent, eliminating the influence of the inverted latent on the sampling. Extensive experiments on several image and video editing benchmarks demonstrate that our method achieves SOTA performance. In addition, our design is plug-and-play, which can be seamlessly integrated into existing inversion and editing methods, such as RF-Solver, FireFlow and UniEdit. | [üîó Paper](https://arxiv.org/abs/2512.22118v1) |
| [Learning Association via Track-Detection Matching for Multi-Object Tracking](https://arxiv.org/abs/2512.22105v1) | Momir Ad≈æemoviƒá | 2025-12-26 | Multimodal AI | Multi-object tracking aims to maintain object identities over time by associating detections across video frames. Two dominant paradigms exist in literature: tracking-by-detection methods, which are computationally efficient but rely on handcrafted association heuristics, and end-to-end approaches, which learn association from data at the cost of higher computational complexity. We propose Track-Detection Link Prediction (TDLP), a tracking-by-detection method that performs per-frame association via link prediction between tracks and detections, i.e., by predicting the correct continuation of each track at every frame. TDLP is architecturally designed primarily for geometric features such as bounding boxes, while optionally incorporating additional cues, including pose and appearance. Unlike heuristic-based methods, TDLP learns association directly from data without handcrafted rules, while remaining modular and computationally efficient compared to end-to-end trackers. Extensive experiments on multiple benchmarks demonstrate that TDLP consistently surpasses state-of-the-art performance across both tracking-by-detection and end-to-end methods. Finally, we provide a detailed analysis comparing link prediction with metric learning-based association and show that link prediction is more effective, particularly when handling heterogeneous features such as detection bounding boxes. Our code is available at \href{https://github.com/Robotmurlock/TDLP}{https://github.com/Robotmurlock/TDLP}. | [üîó Paper](https://arxiv.org/abs/2512.22105v1) |
| [Explainable Multimodal Regression via Information Decomposition](https://arxiv.org/abs/2512.22102v1) | Zhaozhao Ma, Shujian Yu | 2025-12-26 | Multimodal AI, AI Safety, Responsible AI, Model Evaluation | Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg. | [üîó Paper](https://arxiv.org/abs/2512.22102v1) |
| [Yume-1.5: A Text-Controlled Interactive World Generation Model](https://arxiv.org/abs/2512.22096v1) | Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang | 2025-12-26 | Multimodal AI, Optimization, Diffusion Models | Recent approaches have demonstrated the promise of using diffusion models to generate interactive and explorable worlds. However, most of these methods face critical challenges such as excessively large parameter sizes, reliance on lengthy inference steps, and rapidly growing historical context, which severely limit real-time performance and lack text-controlled generation capabilities. To address these challenges, we propose \method, a novel framework designed to generate realistic, interactive, and continuous worlds from a single image or text prompt. \method achieves this through a carefully designed framework that supports keyboard-based exploration of the generated worlds. The framework comprises three core components: (1) a long-video generation framework integrating unified context compression with linear attention; (2) a real-time streaming acceleration strategy powered by bidirectional attention distillation and an enhanced text embedding scheme; (3) a text-controlled method for generating world events. We have provided the codebase in the supplementary material. | [üîó Paper](https://arxiv.org/abs/2512.22096v1) |
| [StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars](https://arxiv.org/abs/2512.22065v1) | Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu | 2025-12-26 | Multimodal AI, Optimization, Diffusion Models | Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: https://streamavatar.github.io . | [üîó Paper](https://arxiv.org/abs/2512.22065v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Hybrid Deep Reinforcement Learning for Joint Resource Allocation in Multi-Active RIS-Aided Uplink Communications](https://arxiv.org/abs/2512.22107v1) | Mohamed Shalma, Engy Aly Maher, Ahmed El-Mahdy | 2025-12-26 | Optimization, RLHF | Active Reconfigurable Intelligent Surfaces (RIS) are a promising technology for 6G wireless networks. This paper investigates a novel hybrid deep reinforcement learning (DRL) framework for resource allocation in a multi-user uplink system assisted by multiple active RISs. The objective is to maximize the minimum user rate by jointly optimizing user transmit powers, active RIS configurations, and base station (BS) beamforming. We derive a closed-form solution for optimal beamforming and employ DRL algorithms: Soft actor-critic (SAC), deep deterministic policy gradient (DDPG), and twin delayed DDPG (TD3) to solve the high-dimensional, non-convex power and RIS optimization problem. Simulation results demonstrate that SAC achieves superior performance with high learning rate leading to faster convergence and lower computational cost compared to DDPG and TD3. Furthermore, the closed-form of optimally beamforming enhances the minimum rate effectively. | [üîó Paper](https://arxiv.org/abs/2512.22107v1) |
| [Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks](https://arxiv.org/abs/2512.22106v1) | Zubair Shah, Noaman Khan | 2025-12-26 | Optimization, Training & Evaluation, Model Evaluation | Neural network pruning is widely used to reduce model size and computational cost. Yet, most existing methods treat sparsity as an externally imposed constraint, enforced through heuristic importance scores or training-time regularization. In this work, we propose a fundamentally different perspective: pruning as an equilibrium outcome of strategic interaction among model components. We model parameter groups such as weights, neurons, or filters as players in a continuous non-cooperative game, where each player selects its level of participation in the network to balance contribution against redundancy and competition. Within this formulation, sparsity emerges naturally when continued participation becomes a dominated strategy at equilibrium. We analyze the resulting game and show that dominated players collapse to zero participation under mild conditions, providing a principled explanation for pruning behavior. Building on this insight, we derive a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit importance scores. This work focuses on establishing a principled formulation and empirical validation of pruning as an equilibrium phenomenon, rather than exhaustive architectural or large-scale benchmarking. Experiments on standard benchmarks demonstrate that the proposed approach achieves competitive sparsity-accuracy trade-offs while offering an interpretable, theory-grounded alternative to existing pruning methods. | [üîó Paper](https://arxiv.org/abs/2512.22106v1) |
| [Schwarz Information Criterion Aided Multi-Armed Bandit for Decentralized Resource Allocation in Dynamic LoRa Networks](https://arxiv.org/abs/2512.22089v1) | Ryotai Ariyoshi, Aohan Li, Mikio Hasegawa, Tomoaki Ohtsuki, Miao Pan, Zhu Han | 2025-12-26 | Optimization | This paper proposes a lightweight distributed learning method for transmission parameter selection in Long Range (LoRa) networks that can adapt to dynamic communication environments. In the proposed method, each LoRa End Device (ED) employs the Upper Confidence Bound (UCB)1-tuned algorithm to select transmission parameters including channel, transmission power, and bandwidth. The transmission parameters are selected based on the acknowledgment (ACK) feedback returned from the gateway after each transmission and the corresponding transmission energy consumption. Hence, it enables devices to simultaneously optimize transmission success rate and energy efficiency in a fully distributed manner. However, although UCB1-tuned based method is effective under stationary conditions, it suffers from slow adaptation in dynamic environments due to its strong reliance on historical observations. To address this limitation, we integrate the Schwarz Information Criterion (SIC) to our proposed method. SIC is adopted because it enables low-cost detection of changes in the communication environment, making it suitable for implementation on resource-constrained LoRa EDs. When a change is detected by SIC, the learning history of UCB1-tuned is reset, allowing rapid re-learning under the new conditions. Experimental results using real LoRa devices demonstrate that the proposed method achieves superior transmission success rate, energy efficiency, and adaptability compared with the conventional UCB1-tuned algorithm without SIC. | [üîó Paper](https://arxiv.org/abs/2512.22089v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Mass-to-Horizon Entropic Cosmology: A Unified Thermodynamic Pathway to Cosmic Acceleration](https://arxiv.org/abs/2512.22103v1) | Tomasz Denkiewicz, Hussain Gohar | 2025-12-26 | Scaling Laws | We investigate the observational tests of generalized mass-to-horizon entropic cosmology by incorporating large-scale structure growth data in addition to purely geometric probes. The theoretical framework is constructed from a generalized mass-to-horizon scaling relation, $M \propto L^n$, which implies a corresponding generalized entropic functional $S_n \propto L^{n+1}$. Within this setting, cosmic acceleration arises as an emergent phenomenon driven by an entropic force acting on the cosmological horizon. While earlier studies demonstrated that these entropic cosmologies can reproduce the background expansion history of the standard $Œõ$CDM model, here we present a comprehensive observational analysis that jointly employs Pantheon+ Type Ia supernova data with SH0ES calibration, DESI DR2 baryon acoustic oscillation measurements, cosmic microwave background (CMB) distance priors, and a suite of cosmological structure growth observations. A Bayesian model comparison indicates that the entropic models are statistically preferred over the conventional $Œõ$CDM scenario, thereby providing strong support for an entropic origin of the observed late-time cosmic acceleration in place of a fundamental cosmological constant. | [üîó Paper](https://arxiv.org/abs/2512.22103v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Random state comonads encode cellular automata evaluation](https://arxiv.org/abs/2512.22067v1) | Madalina I Sas, Julian H J Sutherland | 2025-12-26 | Training & Evaluation | Cellular automata (CA) are quintessential ALife and ubiquitous in many studies of collective behaviour and emergence, from morphogenesis to social dynamics and even brain modelling. Recently, there has been an increased interest in formalising CA, theoretically through category theory and practically in terms of a functional programming paradigm. Unfortunately, these remain either in the realm of simple implementations lacking important practical features, or too abstract and conceptually inaccessible to be useful to the ALife community at large. In this paper, we present a brief and accessible introduction to a category-theoretical model of CA computation through a practical implementation in Haskell. We instantiate arrays as comonads with state and random generators, allowing stochastic behaviour not currently supported in other known implementations. We also emphasise the importance of functional implementations for complex systems: thanks to the Curry-Howard-Lambek isomorphism, functional programs facilitate a mapping between simulation, system rules or semantics, and categorical descriptions, which may advance our understanding and development of generalised theories of emergent behaviour. Using this implementation, we show case studies of four famous CA models: first Wolfram's CA in 1D, then Conway's game of life, Greenberg-Hasings excitable cells, and the stochastic Forest Fire model in 2D, and present directions for an extension to N dimensions. Finally, we suggest that the comonadic model can encode arbitrary topologies and propose future directions for a comonadic network. | [üîó Paper](https://arxiv.org/abs/2512.22067v1) |
## üîπ Production and Deployment

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling](https://arxiv.org/abs/2512.22066v1) | Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras | 2025-12-26 | Production and Deployment | Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead. | [üîó Paper](https://arxiv.org/abs/2512.22066v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Information Critical Phases under Decoherence](https://arxiv.org/abs/2512.22121v1) | Akash Vijay, Jong Yeon Lee | 2025-12-26 | Responsible AI, Model Evaluation | Quantum critical phases are extended regions of phase space characterized by a diverging correlation length. By analogy, we define an information critical phase as an extended region of a mixed state phase diagram where the Markov length, the characteristic length scale governing the decay of the conditional mutual information (CMI), diverges.   We demonstrate that such a phase arises in decohered $\mathbb{Z}_{N}$ Toric codes by assessing both the CMI and the coherent information, the latter quantifying the robustness of the encoded logical qudits. For $N>4$, we find that the system hosts an information critical phase intervening between the decodable and non-decodable phases where the coherent information saturates to a fractional value in the thermodynamic limit, indicating that a finite fraction of logical information is still preserved. We show that the density matrix in this phase can be decomposed into a convex sum of Coulombic pure states, where gapped anyons reorganize into gapless photons. We further consider the ungauged $\mathbb{Z}_{N}$ Toric code and interpret its mixed state phase diagram in the language of strong-to-weak spontaneous symmetry breaking. We argue that in the dual model, the information critical phase arises because the spontaneously broken off-diagonal $\mathbb{Z}_{N}$ symmetry gets enhanced to a U(1) symmetry, resulting in a novel superfluid phase whose gapless modes involve coherent excitations of both the system and the environment. Finally, we propose an optimal decoding protocol for the corrupted $\mathbb{Z}_{N}$ Toric code and evaluate its effectiveness in recovering the fractional logical information preserved in the information critical phase. Our findings identify a gapless analog for mixed-state phases that still acts as a fractional topological quantum memory, thereby extending the conventional paradigm of quantum memory phases. | [üîó Paper](https://arxiv.org/abs/2512.22121v1) |
| [Classifying Urban Regions by Aggregated Pollutant Weather Correlation Strength: A Spatiotemporal Study](https://arxiv.org/abs/2512.22080v1) | Koyena Ghosh, Suchismita Banerjee, Urna Basu, Banasri Basu | 2025-12-26 | Responsible AI, Model Evaluation | Understanding pollutant meteorology interactions is essential for environmental risk assessment. This study develops an entropy-based statistical framework to analyze static and temporal dependencies between urban air pollutants and meteorological variables across multiple Indian cities. Dependence is quantified using complementary linear and nonlinear measures, including Pearson correlation, mutual information, and relative conditional entropy. A key methodological contribution is a PCA based composite indexing framework that integrates these heterogeneous metrics into a unified and interpretable correlation score. For each pollutant meteorological pair within a city, PCA is used to extract a joint variability index, while spatial variability is assessed by aggregating correlations across cities. These indices are further combined to derive a comprehensive city-level correlation score that represents overall pollutant meteorology coupling strength and enables classification of cities into distinct interaction regimes. Sensitivity analysis, performed by systematically excluding individual variable pairs, demonstrates the robustness of the framework, with no single pair exerting disproportionate influence. Temporal dependencies are examined using transfer entropy and time-delayed mutual information. Results indicate that relative humidity generally leads changes in pollutant concentrations, whereas ambient temperature tends to lag, highlighting contrasting causal influences. Mutual information peaks at zero lag and decays rapidly, indicating strong short term interactions with limited persistence. Overall, the proposed framework provides a unified and interpretable approach for assessing complex pollutant meteorology interactions across diverse locations and time. | [üîó Paper](https://arxiv.org/abs/2512.22080v1) |
| [Scaling Adversarial Training via Data Selection](https://arxiv.org/abs/2512.22069v1) | Youran Ye, Dejin Wang, Ajinkya Bhandare | 2025-12-26 | Responsible AI, Optimization, Scaling Laws, Model Evaluation | Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness. Motivated by this inefficiency, we propose \emph{Selective Adversarial Training}, which perturbs only a subset of critical samples in each minibatch. Specifically, we introduce two principled selection criteria: (1) margin-based sampling, which prioritizes samples near the decision boundary, and (2) gradient-matching sampling, which selects samples whose gradients align with the dominant batch optimization direction. Adversarial examples are generated only for the selected subset, while the remaining samples are trained cleanly using a mixed objective. Experiments on MNIST and CIFAR-10 show that the proposed methods achieve robustness comparable to, or even exceeding, full PGD adversarial training, while reducing adversarial computation by up to $50\%$, demonstrating that informed sample selection is sufficient for scalable adversarial robustness. | [üîó Paper](https://arxiv.org/abs/2512.22069v1) |
## üîπ Autonomous Agents

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting](https://arxiv.org/abs/2512.22101v1) | Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang | 2025-12-26 | Autonomous Agents | Automating end-to-end data science pipeline with AI agents still stalls on two gaps: generating insightful, diverse visual evidence and assembling it into a coherent, professional report. We present A2P-Vis, a two-part, multi-agent pipeline that turns raw datasets into a high-quality data-visualization report. The Data Analyzer orchestrates profiling, proposes diverse visualization directions, generates and executes plotting code, filters low-quality figures with a legibility checker, and elicits candidate insights that are automatically scored for depth, correctness, specificity, depth and actionability. The Presenter then orders topics, composes chart-grounded narratives from the top-ranked insights, writes justified transitions, and revises the document for clarity and consistency, yielding a coherent, publication-ready report. Together, these agents convert raw data into curated materials (charts + vetted insights) and into a readable narrative without manual glue work. We claim that by coupling a quality-assured Analyzer with a narrative Presenter, A2P-Vis operationalizes co-analysis end-to-end, improving the real-world usefulness of automated data analysis for practitioners. For the complete dataset report, please see: https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56. | [üîó Paper](https://arxiv.org/abs/2512.22101v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Charge-Informed Quantum Error Correction](https://arxiv.org/abs/2512.22119v1) | Vlad Temkin, Zack Weinstein, Ruihua Fan, Daniel Podolsky, Ehud Altman | 2025-12-26 | General AI | We investigate the statistical physics of quantum error correction in ${\rm U}(1)$ symmetry-enriched topological quantum memories. Starting from a phenomenological error model of charge-conserving noise, we study the optimal decoder assuming the local charges of each anyon can be measured. The error threshold of the optimal decoder corresponds to a continuous phase transition in a disordered two-dimensional integer loop model on the Nishimori line. Using an effective replica field theory analysis and Monte Carlo numerics, we show that the optimal decoding transition exhibits Berezinskii-Kosterlitz-Thouless universality with a modified universal jump in winding number variance. We further generalize the model beyond the Nishimori line, which defines a large class of suboptimal decoders. At low nonzero temperatures and strong disorder, we find numerical evidence of a disorder-dominated loop-glass phase which corresponds to a "confidently incorrect" decoder. The zero-temperature limit defines the minimum-cost flow decoder, which serves as the ${\rm U}(1)$ analog of minimum-weight perfect matching in $\mathbb{Z}_2$ topological codes. Both the optimal and minimum-cost flow decoders are shown to dramatically outperform the charge-agnostic optimal decoder in symmetry-enriched topological codes. | [üîó Paper](https://arxiv.org/abs/2512.22119v1) |
| [Radio Supernovae](https://arxiv.org/abs/2512.22117v1) | Esha Kundu | 2025-12-26 | General AI | Supernovae (SNe), the catastrophic end of stars' lives, are among the most energetic phenomena in the universe. Mapping the aftermath of the explosions to the properties of pre-SN stars is challenging due to the lack of knowledge about the evolution of different types of stars. The immediate surroundings of pre-SN stars carry the signature of the progenitors, and radio observations are the best way to examine the ambient media. Since radio emission originates from the interaction of supersonic SN ejecta with the relatively stationary circumstellar medium, with a few years of radio study, the mass-loss history of progenitor stars can be probed from just before the explosion of the star to thousands of years before the onset of the SN. Moreover, this can provide crucial details about the explosions, which are poorly understood to date. In this paper, we review the radio properties of different types of core-collapse explosions and thermonuclear runaways to understand their mass-loss evolution--which allows us to unravel the imprints of the progenitors on the surrounding media and thus the nature of the exploded stars. Additionally, we discuss the current state of the art in this field, including existing and the next-generation radio facilities with enhanced capabilities that provide further details about these explosions. | [üîó Paper](https://arxiv.org/abs/2512.22117v1) |
| [General Construction of Quantum Error-Correcting Codes from Multiple Classical Codes](https://arxiv.org/abs/2512.22116v1) | Yue Wu, Meng-Yuan Li, Chengshu Li, Hui Zhai | 2025-12-26 | General AI | The hypergraph product (HGP) construction of quantum error-correcting codes (QECC) offers a general and explicit method for building a QECC from two classical codes, thereby paving the way for the discovery of good quantum low-density parity-check codes. In this letter, we propose a general and explicit construction recipe for QECCs from a total of D classical codes for arbitrary D. Following this recipe guarantees the obtainment of a QECC within the stabilizer formalism and nearly exhausts all possible constructions. As examples, we demonstrate that our construction recovers the HGP construction when D = 2 and leads to four distinct types of constructions for D = 3, including a previously studied case as one of them. When the input classical codes are repetition codes, our D = 3 constructions unify various three-dimensional lattice models into a single framework, encompassing the three-dimensional toric code model, a fracton model, and two other intriguing models not previously investigated. Among these, two types of constructions exhibit a trade-off between code distance and code dimension for a fixed number of qubits by adjusting the lengths of the different classical codes, and the optimal choice can simultaneously achieve relatively large values for both code distance and code dimension. Our general construction protocol provides another perspective for enriching the structure of QECCs and enables the exploration of richer possibilities for good codes. | [üîó Paper](https://arxiv.org/abs/2512.22116v1) |
| [(De)constructing Continuous Gauge Symmetries](https://arxiv.org/abs/2512.22114v1) | Leron Borsten, Hyungrok Kim | 2025-12-26 | General AI | A $(d+1)$-dimensional field theory with a periodic spatial dimension may be approximated by a $d$-dimensional theory with a truncated Kaluza-Klein tower of $k$ fields; as $k\to\infty$, one recovers the original $(d+1)$-dimensional theory. One may similarly expect that $\operatorname U(1)$-valued Maxwell theory may be approximated by $\mathbb Z_k$-valued gauge theory and that, as $k\to\infty$, one recovers the original Maxwell theory. However, this fails: the $k\to\infty$ limit of $\mathbb Z_k$-valued gauge theory is flat Maxwell theory with no local degrees of freedom. We instead construct field theories $\mathcal T_k$ such that, with appropriate matter couplings, the $k\to\infty$ limit does recover Maxwell theory in the absence of magnetic monopoles (but with possible Wilson loops), and show that $\mathcal T_k$ can be understood as Maxwell theory with the insertion of a certain nonlocal operator that projects out principal $\operatorname U(1)$-bundles that do not arise from principal $\mathbb Z_k$-bundles sectors (in particular, projecting out sectors with monopole charges). | [üîó Paper](https://arxiv.org/abs/2512.22114v1) |
| [Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications](https://arxiv.org/abs/2512.22113v1) | Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer | 2025-12-26 | General AI | Cloud incidents pose major operational challenges in production, with unresolved production cloud incidents cost on average over $2M per hour. Prior research identifies code- and configuration-related issues as the predominant category of root causes in cloud incidents. This paper introduces PRAXIS, an orchestrator that manages and deploys an agentic workflow for diagnosing code- and configuration-caused cloud incidents. PRAXIS employs an LLM-driven structured traversal over two types of graph: (1) a service dependency graph (SDG) that captures microservice-level dependencies; and (2) a hammock-block program dependence graph (PDG) that captures code-level dependencies for each microservice. Together, these graphs encode microservice- and code-level dependencies and the LLM acts as a traversal policy over these graphs, moving between services and code dependencies to localize and explain failures. Compared to state-of-the-art ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x. PRAXIS is demonstrated on a set of 30 comprehensive real-world incidents that is being compiled into an RCA benchmark. | [üîó Paper](https://arxiv.org/abs/2512.22113v1) |
| [The Lepton-Gluon Portal Beyond Lepto-Gluons](https://arxiv.org/abs/2512.22112v1) | Linda M. Carpenter, Katherine Schwind | 2025-12-26 | General AI | We explore models where single new exotic states interact with the Standard Model through an asymmetric Standard Model portal with couplings to at least one gluon and one lepton. We consider the complete set of effective operators up to dimension 6, and examine a few additional dimension 7 operators that contain interesting field content or potential collider signals. The lepton-gluon portal allows access to exotic states with an interesting range of SU(3) and SU(2) quantum numbers. Finally, we explore potential single-production modes and their phenomenological signatures at colliders. | [üîó Paper](https://arxiv.org/abs/2512.22112v1) |
| [A simple realization of Weyl-Heisenberg covariant measurements](https://arxiv.org/abs/2512.22111v1) | Sachin Gupta, Matthew B. Weiss | 2025-12-26 | General AI | Informationally complete (IC) measurements are fundamental tools in quantum information processing, yet their physical implementation remains challenging. By the Naimark extension theorem, an IC measurement may be realized by a von Neumann measurement on an extended system after a suitable interaction. In this work, we elaborate on a simple algorithm for realizing Naimark extensions for rank-one Weyl-Heisenberg covariant informationally complete measurements in arbitrary finite dimensions. Exploiting Weyl-Heisenberg covariance, we show that the problem reduces to determining a $d \times d$ unitary from which the full $d^2 \times d^2$ unitary interaction can be constructed. The latter unitary enjoys a block-circulant structure which allows e.g., for an elegant optical implementation. We illustrate the procedure with explicit calculations for qubit, qutrit, and ququart SIC-POVMs. Finally, we show that from another point of view, this method amounts to preparing an ancilla system according to a so-called fiducial state, followed by a generalized Bell-basis measurement on the system and ancilla. These results provide a straightforward framework for implementing informationally complete measurements in the laboratory suitable for both qubit and qudit based systems. | [üîó Paper](https://arxiv.org/abs/2512.22111v1) |
| [Thermalization within a Stark manifold through Rydberg atom interactions](https://arxiv.org/abs/2512.22110v1) | Sarah E. Spielman, Sage M. Thomas, Maja Teofilovska, Annick C van Blerkom, Juniper J. Bauroth-Sherman, Nicolaus A. Chlanda, Hannah S. Conley, Philip A. Conte, Aidan D. Kirk, Thomas J. Carroll, Michael W. Noel | 2025-12-26 | General AI | One explanation of the thermalization of an isolated quantum system is the eigenstate thermalization hypothesis, which posits that all energy eigenstates are thermal. Based on this idea, we use dynamical typicality to predict the thermal state of ultracold Rb atoms exchanging energy via long-range dipole-dipole interactions. In a magneto-optical trap, we excite the atoms to the center of a manifold of nearly harmonically spaced clusters of Stark energy levels and then allow them to equilibrate. Comparing the equilibrium state to our thermal prediction across a range of densities, we find that the atoms generally fail to thermalize, though they approach the thermal state at the highest tested density. | [üîó Paper](https://arxiv.org/abs/2512.22110v1) |
| [Index-Tracking Portfolio Construction and Rebalancing under Bayesian Sparse Modelling and Uncertainty Quantification](https://arxiv.org/abs/2512.22109v1) | Dimitrios Roxanas | 2025-12-26 | General AI | We study the construction and rebalancing of sparse index-tracking portfolios from an operational research perspective, with explicit emphasis on uncertainty quantification and implementability. The decision variables are portfolio weights constrained to sum to one; the aims are to track a reference index closely while controlling the number of names and the turnover induced by rebalancing. We cast index tracking as a high-dimensional linear regression of index returns on constituent returns, and employ a sparsity-inducing Laplace prior on the weights. A single global shrinkage parameter controls the trade-off between tracking error and sparsity, and is calibrated by an empirical-Bayes stochastic approximation scheme. Conditional on this calibration, we approximate the posterior distribution of the portfolio weights using proximal Langevin-type Markov chain Monte Carlo algorithms tailored to the budget constraint. This yields posterior uncertainty on tracking error, portfolio composition and prospective rebalancing moves. Building on these posterior samples, we propose rules for rebalancing that gate trades through magnitude-based thresholds and posterior activation probabilities, thereby trading off expected tracking error against turnover and portfolio size. A case study on tracking the S&P~500 index is carried out to showcase how our tools shape the decision process from portfolio construction to rebalancing. | [üîó Paper](https://arxiv.org/abs/2512.22109v1) |
| [Keffer-like form of the symmetric Heisenberg exchange integral: Contribution to the Landau--Lifshitz--Gilbert equation and spin wave dispersion dependence](https://arxiv.org/abs/2512.22108v1) | Pavel A. Andreev | 2025-12-26 | General AI | The symmetric Heisenberg exchange interaction and antisymmetric Dzyaloshinskii-Moriya interaction are parts of the tensor potential describing effective spin-spin interaction caused by the superexchange interaction of magnetic ions via nonmagnetic ion. There is the Keffer form of the vector constant of the Dzyaloshinskii-Moriya interaction, which includes the shift of the nonmagnetic ion (ligand) from the line connecting two magnetic ions. It is suggested, in this paper, that the ligand shift can give contribution in the constant of the symmetric Heisenberg interaction in antiferromagnetic or ferrimagnetic materials. Hence, the constant of the Heisenberg interaction is composed minimum of two terms. One does not depend on the ligand shift an gives standard contribution in the energy density like term with no derivatives of the spin densities or term containing two spatial derivatives of the spin densities. It is demonstrated that additional term gives a term in the energy density containing one spatial derivative of the spin density. Corresponding contribution in the Landau--Lifshitz--Gilbert equation is found. Possibility of the noncollinear equilibrium order of spin under influence of new spin torque is discussed. Modification of the spin wave (normal modes) dispersion dependencies in the antiferromagnetic materials is found for the collinear order and for the cycloidal order of spins. Effective spin current is derived and applied for the spin-current model of the polarization origin in multiferroics. | [üîó Paper](https://arxiv.org/abs/2512.22108v1) |
| [Non-abelian soft radiation data for a celestial theory](https://arxiv.org/abs/2512.22104v1) | Lorenzo Magnea, Enrico Zunino | 2025-12-26 | General AI | Celestial holography posits that the long-distance behavior of gauge and gravity theories is dictated by two-dimensional conformal field theories defined on the celestial sphere. For non-abelian gauge theories, this proposal is verified, to all perturbative orders, by dipole color correlations in the infrared factor of non-abelian scattering amplitudes, which are given by a correlator of matrix-valued vertex operators in a free-boson theory on the sphere. Decades of high-order gauge-theory calculations have provided a number of further results that can be used to test and constrain a possible celestial theory: they include explicit expressions for soft emission currents up to three particles, and up to three loops for single soft emission. In this paper, we analyze this trove of data, appropriately translated in the celestial language, and we use them to extract information on the celestial theory. In particular, we show that all logarithms arising in the loop expansion of the single soft current can be reabsorbed in the scale choices for the $d$-dimensional coupling, casting some doubt on the need for a logarithmic celestial theory. We then note that the celestial OPEs suggested by the structure of multiple emission currents in collinear limits are never ambiguous, but involve coefficients depending on gluon energy fractions, which break holomorphic factorization, as well as associativity when double limits are taken. Strongly-ordered soft limits recover associativity, but suffer from ambiguities already discussed in earlier literature. | [üîó Paper](https://arxiv.org/abs/2512.22104v1) |
| [Effect of Population Imbalance on Vortex Mass in Superfluid Fermi Gases](https://arxiv.org/abs/2512.22099v1) | Lucas Levrouw, Hiromitsu Takeuchi, Jacques Tempere | 2025-12-26 | General AI | One of the fundamental parameters associated with quantized vortices in superfluids is the vortex mass, which is the inertia of a vortex. As of yet, this mass has not been observed in a superfluid. However, ultracold Fermi gases provide a promising platform in which recently much experimental progress was made, offering tunability of the interaction as well as control on the single-vortex level. Not only can the scattering length be freely tuned, allowing exploration of the BEC-BCS crossover, but also an imbalance between different pseudospin states can be introduced. We study the effect of introducing this imbalance on the vortex mass, using a method based on an effective field theory for superfluid Fermi gases. We find that it is crucial to consider the imbalance in conjunction with nonzero temperatures; at some temperatures, the vortex mass is significantly enhanced while at others, the vortex mass is diminished. This pronounced temperature dependence highlights the need for careful tuning of experimental conditions and identifies favorable parameter regimes in which the vortex mass is likely to be observed. | [üîó Paper](https://arxiv.org/abs/2512.22099v1) |
| [Decay of Mass of the Solution to the Cauchy Problem of the p-Laplacian with Absorption on Infinite Graphs](https://arxiv.org/abs/2512.22095v1) | Alan A. Tedeev | 2025-12-26 | General AI | We consider the Cauchy problem for the nonstationary discrete p-Laplacian with inhomogeneous density \r{ho}(x) on an infinite graph which supports the Sobolev inequality. For nonnegative solutions when p > 2, we prove the precise rate of stabilization in time, provided \r{ho}(x) is a non-power function. When p > 2 and \r{ho}(x) goes to zero fast enough, we prove the universal bound. Our technique relies on suitable energy inequalities and a new embedding result. | [üîó Paper](https://arxiv.org/abs/2512.22095v1) |
| [Gauge Coupling Unification in Gauge-Higgs GUT: Theory and Phenomenology](https://arxiv.org/abs/2512.22094v1) | Andrei Angelescu, Andreas Bally, Florian Goertz, Sascha Weber | 2025-12-26 | General AI | We present a concise survey of the running of gauge couplings in realistic models of gauge-Higgs grand unification in a slice of AdS$_5$ space and investigate their potential unification. Besides unifying the gauge groups of the Standard Model, these models can address various unresolved puzzles, such as the lightness of the Higgs boson and the strong hierarchies within fermion masses and mixings, as well as provide a common origin of the gauge symmetries and the sector that spontaneously breaks them. At the same time, they furnish interesting LHC signatures in the form of TeV-scale resonances of the $X,Y$-like bosons, providing a trace of the grand-unified group, accessible at low energies. Using the method of Planck-brane correlators allows us to evolve the couplings consistently from the electroweak scale up to the Planck scale, avoiding shortcomings of other frequently-used approaches and including the effects of bulk scalars, fermions, and gauge-bosons within a common framework. We thereby revisit, contrast, and supplement results in the literature, the latter for example by including brane masses and the gauge-Higgs vacuum expectation value. Moreover, in a phenomenology section, we apply our results to the concrete case of Georgi-Glashow-like unification with a SU(6) $\supset$ SU(5) symmetry in the 5D bulk, presenting a quantitative survey of the quality of unification. We find that grand unification is possible in such models in the presence of moderately large brane kinetic terms. | [üîó Paper](https://arxiv.org/abs/2512.22094v1) |
| [A Minimal Network of Brain Dynamics: Hierarchy of Approximations to Quasi-critical Neural Network Dynamics](https://arxiv.org/abs/2512.22093v1) | Jeremy B. Goetz, Naruepon Weerawongphrom, Rashid V. Williams-Garc√≠a, John M. Beggs, Gerardo Ortiz | 2025-12-26 | General AI | We present an interacting branching model of neural network dynamics, incorporating key biological features such as inhibition with several types of inhibitory interactions. We establish a hierarchy of analytical mean-field approximations to the model, which characterizes nonequilibrium phase transitions between disorder and ordered phases, and perform a stability analysis. Generically, inhibitory neurons increase the stability of the model dynamics. The model is consistent with the quasi-criticality hypothesis in that it displays regions of maximal dynamical susceptibility and maximal mutual information predicated on the strength of the external stimuli. Directed percolation emerges as the universality class of the critical transition of the model, consistent with some previous experimental data and models. In the unstable phase, chaotic dynamics emerge, which may be linked to the occurrence of epileptic seizures. | [üîó Paper](https://arxiv.org/abs/2512.22093v1) |
| [Flat space Fermionic Wave-function coeffients](https://arxiv.org/abs/2512.22092v1) | Bo-Ting Chen, Wei-Ming Chen, Yu-tin Huang, Zi-Xun Huang, Yohan Liu | 2025-12-26 | General AI | In this work we analyze the analytic structure of tree-level flat-space wavefunction coefficients (WFCs), with particular attention to fermionic operators, and derive cutting rules for internal-fermion lines. Building on these results, we set up an iterative procedure that, starting from the flat-space S-matrix, reconstructs the 3- and 4-point WFCs with the correct partial- and total-energy poles and satisfying the requisite cutting rules. Consequently, the "four-particle test" for flat-space WFCs imposes no additional constraints beyond the consistency of the flat-space S-matrix. | [üîó Paper](https://arxiv.org/abs/2512.22092v1) |
| [Factoriality and birational rigidity of two families of singular quartic three-folds](https://arxiv.org/abs/2512.22091v1) | Aleksandr V. Pukhlikov | 2025-12-26 | General AI | In this paper we study two families of three-dimensional quartics in the complex projective space ${\mathbb P}^4$: hypersurfaces with a unique quadratic singularity of rank 3, which is resolved by two blowups, and hypersurfaces with two quadratic singularities of rank 3 and 4, respectively. Both families have codimension 3 in the natural parameter space. For a Zariski general quartic in each of these families we prove factoriality and birational rigidity and describe its group of birational self-maps. | [üîó Paper](https://arxiv.org/abs/2512.22091v1) |
| [Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge](https://arxiv.org/abs/2512.22090v1) | Quentin Michaud, Sara Ramezanian, Dhouha Ayed, Olivier Levillain, Joaquin Garcia-Alfaro | 2025-12-26 | General AI | Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem. | [üîó Paper](https://arxiv.org/abs/2512.22090v1) |
| [Context as a Tool: Context Management for Long-Horizon SWE-Agents](https://arxiv.org/abs/2512.22087v1) | Shukai Liu, Jian Yang, Bo Jiang, Yizhi Li, Jinyang Guo, Xianglong Liu, Bryan Dai | 2025-12-26 | General AI | Agents based on large language models have recently shown strong potential on real-world software engineering (SWE) tasks that require long-horizon interaction with repository-scale codebases. However, most existing agents rely on append-only context maintenance or passively triggered compression heuristics, which often lead to context explosion, semantic drift, and degraded reasoning in long-running interactions. We propose CAT, a new context management paradigm that elevates context maintenance to a callable tool integrated into the decision-making process of agents. CAT formalizes a structured context workspace consisting of stable task semantics, condensed long-term memory, and high-fidelity short-term interactions, and enables agents to proactively compress historical trajectories into actionable summaries at appropriate milestones. To support context management for SWE-agents, we propose a trajectory-level supervision framework, CAT-GENERATOR, based on an offline data construction pipeline that injects context-management actions into complete interaction trajectories. Using this framework, we train a context-aware model, SWE-Compressor. Experiments on SWE-Bench-Verified demonstrate that SWE-Compressor reaches a 57.6% solved rate and significantly outperforms ReAct-based agents and static compression baselines, while maintaining stable and scalable long-horizon reasoning under a bounded context budget. | [üîó Paper](https://arxiv.org/abs/2512.22087v1) |
| [Unlocking klockmannite: formation of colloidal quasi-2D CuSe nanocrystals and photo-physical properties arising from crystal anisotropy](https://arxiv.org/abs/2512.22086v1) | Urvi Parekh, Nadiia Didukh, Samira Dabelstein, Ronja Piehler, Eugen Klein, Jivesh Kaushal, Tobias Korn, Stefan Lochbrunner, Christian Klinke, Stefan Scheel, Rostyslav Lesyuk | 2025-12-26 | General AI | Copper selenide is an exceptional quasi-layered monolithic material that exhibits both semiconducting and metallic properties in adjacent visible and near-infrared (NIR) spectral ranges. Here we introduce a thiol-free colloidal synthesis for generating quasi-2D klockmannite copper selenide nanocrystals via hot injection method, achieving shape control by tuning the injection temperature and precursor concentrations without any additional ligands. This approach produces large klockmannite nanosheets with lateral sizes from 200 nm to several micrometres, as well as uniform triangular nanoplatelets with sizes of 12-25 nm that are monocrystalline and display strong NIR plasmonic absorption. The spectral features of the anisotropic klockmannite phase in the NIR have been analysed using complex-scaled discrete dipole approximation (CSDDA) calculations, which reveal pronounced optical anisotropy and the emergence of hyperbolic regime. The combined effect of propagating and evanescent fields is regarded as the underlying reason of such modes in the hyperbolic domain. Finally, the ultrafast photophysical behaviour of the material in klockmannite phase is examined, including hot-hole cooling, trapping, and coherent phonons generation. Our findings emphasize the important role of the intrinsic crystal anisotropy in governing the physical properties of nanoscale klockmannite. | [üîó Paper](https://arxiv.org/abs/2512.22086v1) |
| [A Frobenius-Optimal Projection for Enforcing Linear Conservation in Learned Dynamical Models](https://arxiv.org/abs/2512.22084v1) | John M. Mango, Ronald Katende | 2025-12-26 | General AI | We consider the problem of restoring linear conservation laws in data-driven linear dynamical models. Given a learned operator $\widehat{A}$ and a full-rank constraint matrix $C$ encoding one or more invariants, we show that the matrix closest to $\widehat{A}$ in the Frobenius norm and satisfying $C^\top A = 0$ is the orthogonal projection $A^\star = \widehat{A} - C(C^\top C)^{-1}C^\top \widehat{A}$. This correction is uniquely defined, low rank and fully determined by the violation $C^\top \widehat{A}$. In the single-invariant case it reduces to a rank-one update. We prove that $A^\star$ enforces exact conservation while minimally perturbing the dynamics, and we verify these properties numerically on a Markov-type example. The projection provides an elementary and general mechanism for embedding exact invariants into any learned linear model. | [üîó Paper](https://arxiv.org/abs/2512.22084v1) |
| [Towards precise baryogenesis in the 2HDM$+a$](https://arxiv.org/abs/2512.22081v1) | T. Gent, S. Huber, K. Mimasu, J. M. No | 2025-12-26 | General AI | We perform a detailed investigation of the viable baryogenesis parameter space of a non-minimal Higgs sector consisting of two Higgs doublets and a singlet pseudoscalar (2HDM$+a$). In such a model, an early Universe period of transient CP violation may occur, driven by a nonvanishing vacuum expectation value of the CP-odd scalar $a$. This naturally avoids the stringent electric dipole moment experimental constraints on beyond-the-Standard-Model sources of CP violation. We provide a state-of-art computation of the baryon asymmetry, providing several important improvements over existing baryogenesis computations for this model. We show that the required thermal history and successful baryogenesis lead to a predictive scenario, testable in the near future by a combination of LHC searches and low-energy flavour measurements. Our improved predictions for the baryon asymmetry find that it is rather suppressed compared to earlier predictions, requiring larger mixing between the singlet and 2HDM pseudoscalars and hence leading to a more easily testable model at colliders. | [üîó Paper](https://arxiv.org/abs/2512.22081v1) |
| [Heterogeneous fragmentation of empty sites promotes cooperation in phenotypically diverse populations with tag-mediated interactions](https://arxiv.org/abs/2512.22077v1) | Hui Zhang, Tarik Hadzibeganovic, Xiao-Pu Han | 2025-12-26 | General AI | Habitat loss and fragmentation have often been viewed as major threats to species interaction and global biodiversity conservation. However, habitat degradation can also give rise to positive ecological and behavioral responses, challenging the notion that its consequences are entirely detrimental. While controlling for the degree of total habitat loss, we studied the influence of habitat fragmentation and phenotypic diversity on the evolution of tag-based cooperation in structured populations with multiple strategies. We developed a spatially explicit agent-based model with empty sites in which phenotypically diverse artificial decision makers engaged into pairwise Snowdrift-game interactions and imitated strategies of their opponent co-players. We systematically varied the number of phenotypic features in the population, the clustering degree of empty sites unsuitable for habitation, as well as the cost-to-benefit ratio $r$, and we measured the resulting equilibrium densities of conditional and unconditional strategies. Our Monte Carlo simulations revealed a complex interplay between the three investigated factors, such that higher phenotypic diversity in combination with lower $r$ and low to intermediate clustering degrees of empty sites markedly suppressed ethnocentric cooperation but simultaneously boosted unconditional, pure altruism. This dominance of unconditional cooperation was remarkably robust to variation in the initial conditions, suggesting that heterogeneous fragmentation of empty sites in moderately degraded habitats can function as a potent cooperation-promoting mechanism even in the presence of initially more favorable strategies. Our study showcases anti-fragility of cooperators in spatially fragmented but phenotypically diverse populations, as they were also able to benefit from harsh environmental conditions emerging in sparsely connected habitat remnants. | [üîó Paper](https://arxiv.org/abs/2512.22077v1) |
| [ReSMT: An SMT-Based Tool for Reverse Engineering](https://arxiv.org/abs/2512.22076v1) | Nir Somech, Guy Katz | 2025-12-26 | General AI | Software obfuscation techniques make code more difficult   to understand, without changing its functionality. Such techniques   are often used by authors of malicious software to avoid   detection. Reverse Engineering   of obfuscated code, i.e., the process of overcoming obfuscation and   answering questions about the functionality of the code, is   notoriously difficult; and while various tools and methods exist for   this purpose, the process remains complex and slow, especially when   dealing with layered or customized obfuscation techniques.   Here, we present a novel, automated tool for addressing some of the   challenges in reverse engineering of obfuscated code. Our tool,   called ReSMT, converts the obfuscated assembly code into a complex   system of logical assertions that represent the code functionality,   and then applies SMT solving and simulation tools to inspect the   obfuscated code's execution. The approach is mostly automatic,   alleviating the need for highly specialized deobfuscation skills.   In an elaborate case study that we conducted, ReSMT successfully   tackled complex obfuscated code, and was able to solve reverse-engineering   queries about it. We believe that these results showcase the potential   and usefulness of our proposed approach. | [üîó Paper](https://arxiv.org/abs/2512.22076v1) |
| [Primordial black holes and smooth coarse-graining in excursion set theory](https://arxiv.org/abs/2512.22075v1) | Daiki Saito, Koki Tokeshi | 2025-12-26 | General AI | The excursion-set formalism enables us to infer the mass distribution of collapsed objects, such as primordial black holes (PBHs), by the language of stochastic processes. Within the framework, this article investigates how a smooth coarse-graining procedure affects the resulting PBH mass function. As a demonstrative example, we employ a Gaussian window function, for which the stochastic noise becomes fully correlated across scales. It is found that these correlated noises result in a mass function of PBHs, whose maximum and its neighbourhood are predominantly determined by the probability that the density contrast exceeds a given threshold at each mass scale. Our results clarify the role of noise correlations induced by smooth coarse-graining and highlight their importance in predicting the abundance of PBHs. | [üîó Paper](https://arxiv.org/abs/2512.22075v1) |
| [Semiperfect rings with a Nakayama permutation: A survey of Double annihilator property and Size condition](https://arxiv.org/abs/2512.22074v1) | Dominik Krasula | 2025-12-26 | General AI | For a semiperfect ring with essential socles, the Double annihilator property encodes that the top and socle have anti-isomorphic lattices of submodules, whereas the Size condition encodes that they are isomorphic as modules. Interest in both concepts, particularly for finite rings, was revived by coding theory, where they characterise QF rings and Frobenius rings, respectively. However, their shared origins date back to the work of T. Nakayama.   We study these concepts through the lens of the Nakayama permutation, an invariant initially used to define (quasi-)Frobenius rings. We propose semiperfect rings as the setting for this study, treating them as the natural generalisation of finite rings, because they possess the characteristic decomposition of unity preserved by projection onto a semisimple top. This allows us to extend the utility of the Nakayama permutation beyond the classical Artinian setting.   By analysing the Nakayama permutation in this broader context, we show that many classical properties of (quasi-)Frobenius rings are not exclusive to the finite case, but are special cases of the general behaviour of semiperfect rings with essential socles.   We illustrate these results using B. J. M√ºller's representation of semiperfect rings as rings of formal matrices. The clear description of socles and tops in this setting provides a straightforward method for constructing counterexamples, such as quasi-Frobenius rings that are not Frobenius. | [üîó Paper](https://arxiv.org/abs/2512.22074v1) |
| [Ferroelectricity in magnon Bose-Einstein condensate: non-reciprocal superfluidity, exceptional points and Majorana bosons](https://arxiv.org/abs/2512.22073v1) | Kazuki Yamamoto, Takuto Kawakami, Mikito Koshino | 2025-12-26 | General AI | We investigate a ferroelectric instability of a magnon Bose-Einstein condensate, mediated by its interaction with an electric field through a geometric Aharonov-Casher (AC) phase. A distinct feature of the system is the positive feedback loop in which an electric field induces magnon orbital motion via the AC phase, generating electric polarization that in turn enhances the original field. Based on bosonic Bogoliubov-de Gennes (BdG) mean-field theory, we show that this feedback drives a spontaneous ferroelectric transition in the magnon superfluid, accompanied by a persistent magnon supercurrent. In the resulting ferroelectric phase, the quasiparticle excitation spectrum becomes nonreciprocal, reflecting spontaneous breaking of spatial inversion symmetry. At the critical point of the transition, the bosonic BdG Hamiltonian exhibits coalescence of both eigenvalues and eigenvectors, forming an exceptional point. The corresponding eigenvector is an equally weighted superposition of bosonic quasiparticle and quasihole states and is invariant under particle-hole transformation, allowing it to be interpreted as a bosonic analog of a Majorana fermion. | [üîó Paper](https://arxiv.org/abs/2512.22073v1) |
| [Rotationally invariant dynamical lattice regulators for Euclidean quantum field theories](https://arxiv.org/abs/2512.22072v1) | Tsogtgerel Gantumur | 2025-12-26 | General AI | We introduce a dynamical-lattice regulator (DLR) for Euclidean quantum field theories on a fixed hypercubic graph $Œõ\simeq \mathbb{Z}^d$, in which the embedding $x:Œõ\to \mathbb{R}^d$ is promoted to a dynamical field and integrated over subject to shape-regularity constraints. The total action is local on $Œõ$, gauge invariant, and depends on $x$ only through Euclidean invariants built from edge vectors (local metrics, volumes, etc.), hence the partition function is exactly covariant under the global Euclidean group SE(d) at any lattice spacing. The intended symmetry-restoring mechanism is not rigid global zero modes but short-range *local twisting* of the embedding that mixes local orientations; accordingly, our universality discussion is conditioned on a short-range geometry hypothesis (SR): after quotienting the global SE(d) modes, connected correlators of local geometric observables have correlation length O(1) in lattice units.   We prove Osterwalder-Schrader reflection positivity for the coupled system with embedding $x$ and generic gauge/matter fields $(U,Œ¶)$ in finite volume by treating $x$ as an additional multiplet of scalar fields on $Œõ$. Assuming (SR), integrating out $x$ at fixed cutoff yields a local Symanzik effective action in which geometry fluctuations generate only SO(d)-invariant irrelevant operators and finite renormalizations; in particular, in $d=4$ we recover the standard one-loop $Œ≤$-function in a scalar $œÜ^4$ test theory. Finally, we describe a practical local Monte Carlo update and report $d=2$ proof-of-concept simulations showing a well-behaved geometry sector and a substantial reduction of axis-vs-diagonal cutoff artifacts relative to a fixed lattice at matched bare parameters. | [üîó Paper](https://arxiv.org/abs/2512.22072v1) |
| [Existence of spectral submanifolds in time delay systems](https://arxiv.org/abs/2512.22062v1) | Gergely Buza, George Haller | 2025-12-26 | General AI | Spectral submanifolds (SSMs) are invariant manifolds of a dynamical system, defined by the property of being tangent to a spectral subspace of the linearized dynamics at a steady state. We show existence, along with certain desirable properties such as smoothness, attractivity and conditional uniqueness, of SSMs associated to a large class of spectral subspaces in time delay systems. Building on these results, we generalize the criteria for existence of inertial manifolds -- defined as globally exponentially attracting Lipschitz invariant manifolds of finite dimension -- and show that they need not have dimension equal to that of the physical configuration, in contrast to previous accounts. We then demonstrate the applicability of these results on a few simple examples. | [üîó Paper](https://arxiv.org/abs/2512.22062v1) |
