# 📌 AI Research Papers (March17 to March23)

## 🔹 LLM

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [XAttention: Block Sparse Attention with Antidiagonal Scoring](http://arxiv.org/abs/2503.16428v1) | Ruyi Xu, Guangxuan Xiao, Haofeng Huang, Junxian Guo, Song Han | 2025-03-20 | LLM, Optimization, Multimodal AI | Long-Context Transformer Models (LCTMs) are vital for real-world applications but suffer high computational costs due to attention's quadratic complexity. Block-sparse attention mitigates this by focusing computation on critical regions, yet existing methods struggle with balancing accuracy and efficiency due to costly block importance measurements. In this paper, we introduce XAttention, a plug-and-play framework that dramatically accelerates long-context inference in Transformers models using sparse attention. XAttention's key innovation is the insight that the sum of antidiagonal values (i.e., from the lower-left to upper-right) in the attention matrix provides a powerful proxy for block importance. This allows for precise identification and pruning of non-essential blocks, resulting in high sparsity and dramatically accelerated inference. Across comprehensive evaluations on demanding long-context benchmarks-including RULER and LongBench for language, VideoMME for video understanding, and VBench for video generation. XAttention achieves accuracy comparable to full attention while delivering substantial computational gains. We demonstrate up to 13.5x acceleration in attention computation. These results underscore XAttention's ability to unlock the practical potential of block sparse attention, paving the way for scalable and efficient deployment of LCTMs in real-world applications. Code is available at https://github.com/mit-han-lab/x-attention. | [🔗 Paper](http://arxiv.org/abs/2503.16428v1) |
| [GAEA: A Geolocation Aware Conversational Model](http://arxiv.org/abs/2503.16423v1) | Ron Campos, Ashmal Vayani, Parth Parag Kulkarni, Rohit Gupta, Aritra Dutta, Mubarak Shah | 2025-03-20 | LLM, Multimodal AI, Training & Evaluation | Image geolocalization, in which, traditionally, an AI model predicts the precise GPS coordinates of an image is a challenging task with many downstream applications. However, the user cannot utilize the model to further their knowledge other than the GPS coordinate; the model lacks an understanding of the location and the conversational ability to communicate with the user. In recent days, with tremendous progress of large multimodal models (LMMs) proprietary and open-source researchers have attempted to geolocalize images via LMMs. However, the issues remain unaddressed; beyond general tasks, for more specialized downstream tasks, one of which is geolocalization, LMMs struggle. In this work, we propose to solve this problem by introducing a conversational model GAEA that can provide information regarding the location of an image, as required by a user. No large-scale dataset enabling the training of such a model exists. Thus we propose a comprehensive dataset GAEA with 800K images and around 1.6M question answer pairs constructed by leveraging OpenStreetMap (OSM) attributes and geographical context clues. For quantitative evaluation, we propose a diverse benchmark comprising 4K image-text pairs to evaluate conversational capabilities equipped with diverse question types. We consider 11 state-of-the-art open-source and proprietary LMMs and demonstrate that GAEA significantly outperforms the best open-source model, LLaVA-OneVision by 25.69% and the best proprietary model, GPT-4o by 8.28%. Our dataset, model and codes are available | [🔗 Paper](http://arxiv.org/abs/2503.16423v1) |
| [The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination](http://arxiv.org/abs/2503.16402v1) | Yifan Sun, Han Wang, Dongbai Li, Gang Wang, Huan Zhang | 2025-03-20 | LLM, Model Evaluation, Training & Evaluation | Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples in the training set-has raised increasing concerns in Large Language Model (LLM) evaluation, leading to falsely inflated performance estimates and undermining evaluation reliability. To address this, researchers have proposed various mitigation strategies to update existing benchmarks, including modifying original questions or generating new ones based on them. However, a rigorous examination of the effectiveness of these mitigation strategies remains lacking. In this paper, we design a systematic and controlled pipeline along with two novel metrics-fidelity and contamination resistance-to provide a fine-grained and comprehensive assessment of existing BDC mitigation strategies. Previous assessment methods, such as accuracy drop and accuracy matching, focus solely on aggregate accuracy, often leading to incomplete or misleading conclusions. Our metrics address this limitation by emphasizing question-level evaluation result matching. Extensive experiments with 10 LLMs, 5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios reveal that no existing strategy significantly improves resistance over the vanilla case (i.e., no benchmark update) across all benchmarks, and none effectively balances fidelity and contamination resistance. These findings underscore the urgent need for designing more effective BDC mitigation strategies. Our code repository is available at https://github.com/ASTRAL-Group/BDC_mitigation_assessment. | [🔗 Paper](http://arxiv.org/abs/2503.16402v1) |
## 🔹 Diffusion Models

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Do Visual Imaginations Improve Vision-and-Language Navigation Agents?](http://arxiv.org/abs/2503.16394v1) | Akhil Perincherry, Jacob Krantz, Stefan Lee | 2025-03-20 | Diffusion Models | Vision-and-Language Navigation (VLN) agents are tasked with navigating an unseen environment using natural language instructions. In this work, we study if visual representations of sub-goals implied by the instructions can serve as navigational cues and lead to increased navigation performance. To synthesize these visual representations or imaginations, we leverage a text-to-image diffusion model on landmark references contained in segmented instructions. These imaginations are provided to VLN agents as an added modality to act as landmark cues and an auxiliary loss is added to explicitly encourage relating these with their corresponding referring expressions. Our findings reveal an increase in success rate (SR) of around 1 point and up to 0.5 points in success scaled by inverse path length (SPL) across agents. These results suggest that the proposed approach reinforces visual understanding compared to relying on language instructions alone. Code and data for our work can be found at https://www.akhilperincherry.com/VLN-Imagine-website/. | [🔗 Paper](http://arxiv.org/abs/2503.16394v1) |
## 🔹 Multimodal AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance](http://arxiv.org/abs/2503.16421v1) | Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Qi Dai, Zuxuan Wu | 2025-03-20 | Multimodal AI, Training & Evaluation | Recent advances in video generation have led to remarkable improvements in visual quality and temporal coherence. Upon this, trajectory-controllable video generation has emerged to enable precise object motion control through explicitly defined spatial paths. However, existing methods struggle with complex object movements and multi-object motion control, resulting in imprecise trajectory adherence, poor object consistency, and compromised visual quality. Furthermore, these methods only support trajectory control in a single format, limiting their applicability in diverse scenarios. Additionally, there is no publicly available dataset or benchmark specifically tailored for trajectory-controllable video generation, hindering robust training and systematic evaluation. To address these challenges, we introduce MagicMotion, a novel image-to-video generation framework that enables trajectory control through three levels of conditions from dense to sparse: masks, bounding boxes, and sparse boxes. Given an input image and trajectories, MagicMotion seamlessly animates objects along defined trajectories while maintaining object consistency and visual quality. Furthermore, we present MagicData, a large-scale trajectory-controlled video dataset, along with an automated pipeline for annotation and filtering. We also introduce MagicBench, a comprehensive benchmark that assesses both video quality and trajectory control accuracy across different numbers of objects. Extensive experiments demonstrate that MagicMotion outperforms previous methods across various metrics. Our project page are publicly available at https://quanhaol.github.io/magicmotion-site. | [🔗 Paper](http://arxiv.org/abs/2503.16421v1) |
## 🔹 Optimization

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation](http://arxiv.org/abs/2503.16430v1) | Yuqing Wang, Zhijie Lin, Yao Teng, Yuanzhi Zhu, Shuhuai Ren, Jiashi Feng, Xihui Liu | 2025-03-20 | Optimization | Autoregressive visual generation models typically rely on tokenizers to compress images into tokens that can be predicted sequentially. A fundamental dilemma exists in token representation: discrete tokens enable straightforward modeling with standard cross-entropy loss, but suffer from information loss and tokenizer training instability; continuous tokens better preserve visual details, but require complex distribution modeling, complicating the generation pipeline. In this paper, we propose TokenBridge, which bridges this gap by maintaining the strong representation capacity of continuous tokens while preserving the modeling simplicity of discrete tokens. To achieve this, we decouple discretization from the tokenizer training process through post-training quantization that directly obtains discrete tokens from continuous representations. Specifically, we introduce a dimension-wise quantization strategy that independently discretizes each feature dimension, paired with a lightweight autoregressive prediction mechanism that efficiently model the resulting large token space. Extensive experiments show that our approach achieves reconstruction and generation quality on par with continuous methods while using standard categorical prediction. This work demonstrates that bridging discrete and continuous paradigms can effectively harness the strengths of both approaches, providing a promising direction for high-quality visual generation with simple autoregressive modeling. Project page: https://yuqingwang1029.github.io/TokenBridge. | [🔗 Paper](http://arxiv.org/abs/2503.16430v1) |
| [Bézier Splatting for Fast and Differentiable Vector Graphics](http://arxiv.org/abs/2503.16424v1) | Xi Liu, Chaoyi Zhou, Nanxuan Zhao, Siyu Huang | 2025-03-20 | Optimization | Differentiable vector graphics (VGs) are widely used in image vectorization and vector synthesis, while existing representations are costly to optimize and struggle to achieve high-quality rendering results for high-resolution images. This work introduces a new differentiable VG representation, dubbed B\'ezier splatting, that enables fast yet high-fidelity VG rasterization. B\'ezier splatting samples 2D Gaussians along B\'ezier curves, which naturally provide positional gradients at object boundaries. Thanks to the efficient splatting-based differentiable rasterizer, B\'ezier splatting achieves over 20x and 150x faster per forward and backward rasterization step for open curves compared to DiffVG. Additionally, we introduce an adaptive pruning and densification strategy that dynamically adjusts the spatial distribution of curves to escape local minima, further improving VG quality. Experimental results show that B\'ezier splatting significantly outperforms existing methods with better visual fidelity and 10x faster optimization speed. | [🔗 Paper](http://arxiv.org/abs/2503.16424v1) |
| [1000+ FPS 4D Gaussian Splatting for Dynamic Scene Rendering](http://arxiv.org/abs/2503.16422v1) | Yuheng Yuan, Qiuhong Shen, Xingyi Yang, Xinchao Wang | 2025-03-20 | Optimization | 4D Gaussian Splatting (4DGS) has recently gained considerable attention as a method for reconstructing dynamic scenes. Despite achieving superior quality, 4DGS typically requires substantial storage and suffers from slow rendering speed. In this work, we delve into these issues and identify two key sources of temporal redundancy. (Q1) \textbf{Short-Lifespan Gaussians}: 4DGS uses a large portion of Gaussians with short temporal span to represent scene dynamics, leading to an excessive number of Gaussians. (Q2) \textbf{Inactive Gaussians}: When rendering, only a small subset of Gaussians contributes to each frame. Despite this, all Gaussians are processed during rasterization, resulting in redundant computation overhead. To address these redundancies, we present \textbf{4DGS-1K}, which runs at over 1000 FPS on modern GPUs. For Q1, we introduce the Spatial-Temporal Variation Score, a new pruning criterion that effectively removes short-lifespan Gaussians while encouraging 4DGS to capture scene dynamics using Gaussians with longer temporal spans. For Q2, we store a mask for active Gaussians across consecutive frames, significantly reducing redundant computations in rendering. Compared to vanilla 4DGS, our method achieves a $41\times$ reduction in storage and $9\times$ faster rasterization speed on complex dynamic scenes, while maintaining comparable visual quality. Please see our project page at https://4DGS-1K.github.io. | [🔗 Paper](http://arxiv.org/abs/2503.16422v1) |
| [SynCity: Training-Free Generation of 3D Worlds](http://arxiv.org/abs/2503.16420v1) | Paul Engstler, Aleksandar Shtedritski, Iro Laina, Christian Rupprecht, Andrea Vedaldi | 2025-03-20 | Optimization | We address the challenge of generating 3D worlds from textual descriptions. We propose SynCity, a training- and optimization-free approach, which leverages the geometric precision of pre-trained 3D generative models and the artistic versatility of 2D image generators to create large, high-quality 3D spaces. While most 3D generative models are object-centric and cannot generate large-scale worlds, we show how 3D and 2D generators can be combined to generate ever-expanding scenes. Through a tile-based approach, we allow fine-grained control over the layout and the appearance of scenes. The world is generated tile-by-tile, and each new tile is generated within its world-context and then fused with the scene. SynCity generates compelling and immersive scenes that are rich in detail and diversity. | [🔗 Paper](http://arxiv.org/abs/2503.16420v1) |
| [DreamTexture: Shape from Virtual Texture with Analysis by Augmentation](http://arxiv.org/abs/2503.16412v1) | Ananta R. Bhattarai, Xingzhe He, Alla Sheffer, Helge Rhodin | 2025-03-20 | Optimization, Diffusion Models | DreamFusion established a new paradigm for unsupervised 3D reconstruction from virtual views by combining advances in generative models and differentiable rendering. However, the underlying multi-view rendering, along with supervision from large-scale generative models, is computationally expensive and under-constrained. We propose DreamTexture, a novel Shape-from-Virtual-Texture approach that leverages monocular depth cues to reconstruct 3D objects. Our method textures an input image by aligning a virtual texture with the real depth cues in the input, exploiting the inherent understanding of monocular geometry encoded in modern diffusion models. We then reconstruct depth from the virtual texture deformation with a new conformal map optimization, which alleviates memory-intensive volumetric representations. Our experiments reveal that generative models possess an understanding of monocular shape cues, which can be extracted by augmenting and aligning texture cues -- a novel monocular reconstruction paradigm that we call Analysis by Augmentation. | [🔗 Paper](http://arxiv.org/abs/2503.16412v1) |
| [M3: 3D-Spatial MultiModal Memory](http://arxiv.org/abs/2503.16413v1) | Xueyan Zou, Yuchen Song, Ri-Zhao Qiu, Xuanbin Peng, Jianglong Ye, Sifei Liu, Xiaolong Wang | 2025-03-20 | Optimization, Multimodal AI | We present 3D Spatial MultiModal Memory (M3), a multimodal memory system designed to retain information about medium-sized static scenes through video sources for visual perception. By integrating 3D Gaussian Splatting techniques with foundation models, M3 builds a multimodal memory capable of rendering feature representations across granularities, encompassing a wide range of knowledge. In our exploration, we identify two key challenges in previous works on feature splatting: (1) computational constraints in storing high-dimensional features for each Gaussian primitive, and (2) misalignment or information loss between distilled features and foundation model features. To address these challenges, we propose M3 with key components of principal scene components and Gaussian memory attention, enabling efficient training and inference. To validate M3, we conduct comprehensive quantitative evaluations of feature similarity and downstream tasks, as well as qualitative visualizations to highlight the pixel trace of Gaussian memory attention. Our approach encompasses a diverse range of foundation models, including vision-language models (VLMs), perception models, and large multimodal and language models (LMMs/LLMs). Furthermore, to demonstrate real-world applicability, we deploy M3's feature field in indoor scenes on a quadruped robot. Notably, we claim that M3 is the first work to address the core compression challenges in 3D feature distillation. | [🔗 Paper](http://arxiv.org/abs/2503.16413v1) |
| [Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them](http://arxiv.org/abs/2503.16401v1) | Guanyu Chen, Peiyang Wang, Tianren Zhang, Feng Chen | 2025-03-20 | Optimization | Large language models (LLMs) and Vision language models (VLMs) have been able to perform various forms of reasoning tasks in a wide range of scenarios, but are they truly engaging in task abstraction and rule-based reasoning beyond mere memorization and pattern matching? To answer this question, we propose a novel experimental approach, Misleading Fine-Tuning (MisFT), to examine whether LLMs/VLMs perform abstract reasoning by altering their original understanding of fundamental rules. In particular, by constructing a dataset with math expressions that contradict correct operation principles, we fine-tune the model to learn those contradictory rules and assess its generalization ability on different test domains. Through a series of experiments, we find that current LLMs/VLMs are capable of effectively applying contradictory rules to solve practical math word problems and math expressions represented by images, implying the presence of an internal mechanism that abstracts before reasoning. | [🔗 Paper](http://arxiv.org/abs/2503.16401v1) |
| [Scale-wise Distillation of Diffusion Models](http://arxiv.org/abs/2503.16397v1) | Nikita Starodubcev, Denis Kuznedelev, Artem Babenko, Dmitry Baranchuk | 2025-03-20 | Optimization, Diffusion Models | We present SwD, a scale-wise distillation framework for diffusion models (DMs), which effectively employs next-scale prediction ideas for diffusion-based few-step generators. In more detail, SwD is inspired by the recent insights relating diffusion processes to the implicit spectral autoregression. We suppose that DMs can initiate generation at lower data resolutions and gradually upscale the samples at each denoising step without loss in performance while significantly reducing computational costs. SwD naturally integrates this idea into existing diffusion distillation methods based on distribution matching. Also, we enrich the family of distribution matching approaches by introducing a novel patch loss enforcing finer-grained similarity to the target distribution. When applied to state-of-the-art text-to-image diffusion models, SwD approaches the inference times of two full resolution steps and significantly outperforms the counterparts under the same computation budget, as evidenced by automated metrics and human preference studies. | [🔗 Paper](http://arxiv.org/abs/2503.16397v1) |
| [SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation](http://arxiv.org/abs/2503.16396v2) | Chun-Han Yao, Yiming Xie, Vikram Voleti, Huaizu Jiang, Varun Jampani | 2025-03-20 | Optimization, Multimodal AI, Diffusion Models | We present Stable Video 4D 2.0 (SV4D 2.0), a multi-view video diffusion model for dynamic 3D asset generation. Compared to its predecessor SV4D, SV4D 2.0 is more robust to occlusions and large motion, generalizes better to real-world videos, and produces higher-quality outputs in terms of detail sharpness and spatio-temporal consistency. We achieve this by introducing key improvements in multiple aspects: 1) network architecture: eliminating the dependency of reference multi-views and designing blending mechanism for 3D and frame attention, 2) data: enhancing quality and quantity of training data, 3) training strategy: adopting progressive 3D-4D training for better generalization, and 4) 4D optimization: handling 3D inconsistency and large motion via 2-stage refinement and progressive frame sampling. Extensive experiments demonstrate significant performance gain by SV4D 2.0 both visually and quantitatively, achieving better detail (-14\% LPIPS) and 4D consistency (-44\% FV4D) in novel-view video synthesis and 4D optimization (-12\% LPIPS and -24\% FV4D) compared to SV4D. | [🔗 Paper](http://arxiv.org/abs/2503.16396v2) |
## 🔹 Scaling Laws

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Acceptance dependence of factorial cumulants, long-range correlations and the antiproton puzzle](http://arxiv.org/abs/2503.16405v1) | Adam Bzdak, Volker Koch, Volodymyr Vovchenko | 2025-03-20 | Scaling Laws | We analyze joint factorial cumulants of protons and antiprotons in relativistic heavy-ion collisions and point out that they obey the scaling $\hat{C}_{nm}^{p,\bar{p}} \propto \langle N_p\rangle^n \langle N_{\bar{p}} \rangle^m$ as a function of acceptance when only long-range correlations are present in the system, such as global baryon conservation and volume fluctuations. This hypothesis can be directly tested experimentally without the need for corrections for volume fluctuations. We show that if correlations among protons and antiprotons are driven by global baryon conservation and volume fluctuations only, the equality $\hat{C}_{2}^{p} / \langle N_p \rangle^2 = \hat{C}_{2}^{\bar{p}} / \langle N_{\bar{p}} \rangle^2$ holds for large systems created in central collisions. We point out that the experimental data of the STAR Collaboration from phase I of RHIC beam energy scan are approximately consistent with the scaling $\hat{C}_{nm}^{p,\bar{p}} \propto \langle N_p \rangle^n \langle N_{\bar{p}} \rangle^m$, but the normalized antiproton correlations are stronger than that of protons, $-\hat{C}_{2}^{\bar{p}} / \langle N_{\bar{p}} \rangle^2 > -\hat{C}_{2}^{p} / \langle N_p \rangle^2$, indicating that global baryon conservation and volume fluctuations alone cannot explain the data. We also discuss high-order factorial cumulants which can be measured with sufficient precision within phase II of RHIC-BES. | [🔗 Paper](http://arxiv.org/abs/2503.16405v1) |
| [ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos](http://arxiv.org/abs/2503.16400v1) | Haolin Yang, Feilong Tang, Ming Hu, Yulong Li, Junjie Guo, Yexin Liu, Zelin Peng, Junjun He, Zongyuan Ge, Imran Razzak | 2025-03-20 | Scaling Laws, Multimodal AI, Diffusion Models, RLHF | Video diffusion models (VDMs) facilitate the generation of high-quality videos, with current research predominantly concentrated on scaling efforts during training through improvements in data quality, computational resources, and model complexity. However, inference-time scaling has received less attention, with most approaches restricting models to a single generation attempt. Recent studies have uncovered the existence of "golden noises" that can enhance video quality during generation. Building on this, we find that guiding the scaling inference-time search of VDMs to identify better noise candidates not only evaluates the quality of the frames generated in the current step but also preserves the high-level object features by referencing the anchor frame from previous multi-chunks, thereby delivering long-term value. Our analysis reveals that diffusion models inherently possess flexible adjustments of computation by varying denoising steps, and even a one-step denoising approach, when guided by a reward signal, yields significant long-term benefits. Based on the observation, we proposeScalingNoise, a plug-and-play inference-time search strategy that identifies golden initial noises for the diffusion sampling process to improve global content consistency and visual diversity. Specifically, we perform one-step denoising to convert initial noises into a clip and subsequently evaluate its long-term value, leveraging a reward model anchored by previously generated content. Moreover, to preserve diversity, we sample candidates from a tilted noise distribution that up-weights promising noises. In this way, ScalingNoise significantly reduces noise-induced errors, ensuring more coherent and spatiotemporally consistent video generation. Extensive experiments on benchmark datasets demonstrate that the proposed ScalingNoise effectively improves long video generation. | [🔗 Paper](http://arxiv.org/abs/2503.16400v1) |
## 🔹 Training & Evaluation

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [On the Holographic Dual of a Symmetry Operator at Finite Temperature](http://arxiv.org/abs/2503.16427v1) | Jonathan J. Heckman, Max Hübner, Chitraang Murdia | 2025-03-20 | Training & Evaluation | Topological symmetry operators of holographic large $N$ CFT$_D$'s are dual to dynamical branes in the gravity dual AdS$_{D+1}$. We use this correspondence to establish a dictionary between thermal expectation values of symmetry operators in the Euclidean CFT$_D$ and the evaluation of gravitational saddles in the presence of a dynamical brane. Expectation values of $0$-form symmetry operators in the CFT$_D$ are then related to branes wrapped on volume minimizing cycles in the bulk, i.e., the Euclidean continuation of a black hole horizon. We illustrate with some representative examples, including gravity in AdS$_3$, duality / triality defects in 4D $\mathcal{N} = 4$ Super Yang-Mills theory, and the dual of R-symmetry operators probing 5D BPS black holes. | [🔗 Paper](http://arxiv.org/abs/2503.16427v1) |
| [The global convergence time of stochastic gradient descent in non-convex landscapes: Sharp estimates via large deviations](http://arxiv.org/abs/2503.16398v1) | Waïss Azizian, Franck Iutzeler, Jérôme Malick, Panayotis Mertikopoulos | 2025-03-20 | Training & Evaluation | In this paper, we examine the time it takes for stochastic gradient descent (SGD) to reach the global minimum of a general, non-convex loss function. We approach this question through the lens of randomly perturbed dynamical systems and large deviations theory, and we provide a tight characterization of the global convergence time of SGD via matching upper and lower bounds. These bounds are dominated by the most "costly" set of obstacles that the algorithm may need to overcome to reach a global minimizer from a given initialization, coupling in this way the global geometry of the underlying loss landscape with the statistics of the noise entering the process. Finally, motivated by applications to the training of deep neural networks, we also provide a series of refinements and extensions of our analysis for loss functions with shallow local minima. | [🔗 Paper](http://arxiv.org/abs/2503.16398v1) |
## 🔹 Model Evaluation

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Tokenize Image as a Set](http://arxiv.org/abs/2503.16425v1) | Zigang Geng, Mengde Xu, Han Hu, Shuyang Gu | 2025-03-20 | Model Evaluation, Diffusion Models, Responsible AI | This paper proposes a fundamentally new paradigm for image generation through set-based tokenization and distribution modeling. Unlike conventional methods that serialize images into fixed-position latent codes with a uniform compression ratio, we introduce an unordered token set representation to dynamically allocate coding capacity based on regional semantic complexity. This TokenSet enhances global context aggregation and improves robustness against local perturbations. To address the critical challenge of modeling discrete sets, we devise a dual transformation mechanism that bijectively converts sets into fixed-length integer sequences with summation constraints. Further, we propose Fixed-Sum Discrete Diffusion--the first framework to simultaneously handle discrete values, fixed sequence length, and summation invariance--enabling effective set distribution modeling. Experiments demonstrate our method's superiority in semantic-aware representation and generation quality. Our innovations, spanning novel representation and modeling strategies, advance visual generation beyond traditional sequential token paradigms. Our code and models are publicly available at https://github.com/Gengzigang/TokenSet. | [🔗 Paper](http://arxiv.org/abs/2503.16425v1) |
| [VerbDiff: Text-Only Diffusion Models with Enhanced Interaction Awareness](http://arxiv.org/abs/2503.16406v1) | SeungJu Cha, Kwanyoung Lee, Ye-Chan Kim, Hyunwoo Oh, Dong-Jin Kim | 2025-03-20 | Model Evaluation, Diffusion Models, Responsible AI | Recent large-scale text-to-image diffusion models generate photorealistic images but often struggle to accurately depict interactions between humans and objects due to their limited ability to differentiate various interaction words. In this work, we propose VerbDiff to address the challenge of capturing nuanced interactions within text-to-image diffusion models. VerbDiff is a novel text-to-image generation model that weakens the bias between interaction words and objects, enhancing the understanding of interactions. Specifically, we disentangle various interaction words from frequency-based anchor words and leverage localized interaction regions from generated images to help the model better capture semantics in distinctive words without extra conditions. Our approach enables the model to accurately understand the intended interaction between humans and objects, producing high-quality images with accurate interactions aligned with specified verbs. Extensive experiments on the HICO-DET dataset demonstrate the effectiveness of our method compared to previous approaches. | [🔗 Paper](http://arxiv.org/abs/2503.16406v1) |
| [Quantum Characterization, Verification, and Validation](http://arxiv.org/abs/2503.16383v1) | Robin Blume-Kohout, Timothy Proctor, Kevin Young | 2025-03-20 | Model Evaluation, Training & Evaluation | Quantum characterization, verification, and validation (QCVV) is a set of techniques to probe, describe, and assess the behavior of quantum bits (qubits), quantum information-processing registers, and quantum computers. QCVV protocols probe and describe the effects of unwanted decoherence so that it can be eliminated or mitigated. They can be usefully divided into characterization techniques that estimate predictive models for a device's behavior from data, and benchmarking techniques that assess overall performance of a device. In this introductory article, we briefly summarize the history of QCVV, introduce the mathematical models and metrics upon which it relies, and then summarize the foundational fields of tomography, randomized benchmarking, and holistic benchmarks. We conclude with brief descriptions of (and references to) advanced topics including gate set tomography, phase estimation, Pauli noise learning, characterization of mid-circuit measurements and non-Markovianity, classical shadows, verification and certification, and logical qubit assessment. | [🔗 Paper](http://arxiv.org/abs/2503.16383v1) |
## 🔹 Production and Deployment

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [DynamicVis: An Efficient and General Visual Foundation Model for Remote Sensing Image Understanding](http://arxiv.org/abs/2503.16426v1) | Keyan Chen, Chenyang Liu, Bowen Chen, Wenyuan Li, Zhengxia Zou, Zhenwei Shi | 2025-03-20 | Production and Deployment | The advancement of remote sensing technology has improved the spatial resolution of satellite imagery, facilitating more detailed visual representations for diverse interpretations. However, existing methods exhibit limited generalization capabilities across varied applications. While some contemporary foundation models demonstrate potential, they are hindered by insufficient cross-task adaptability and primarily process low-resolution imagery of restricted sizes, thus failing to fully exploit high-resolution data or leverage comprehensive large-scene semantics. Crucially, remote sensing imagery differs fundamentally from natural images, as key foreground targets (eg., maritime objects, artificial structures) often occupy minimal spatial proportions (~1%) and exhibit sparse distributions. Efficiently modeling cross-task generalizable knowledge from lengthy 2D tokens (~100,000) poses a significant challenge yet remains critical for remote sensing image understanding. Motivated by the selective attention mechanisms inherent to the human visual system, we propose DynamicVis, a dynamic visual perception foundation model for remote sensing imagery. The framework integrates a novel dynamic region perception backbone based on the selective state space model, which strategically balances localized detail extraction with global contextual integration, enabling computationally efficient encoding of large-scale data while maintaining architectural scalability. To enhance cross-task knowledge transferring, we introduce a multi-instance learning paradigm utilizing meta-embedding representations, trained on million-scale region-level annotations. Evaluations across nine downstream tasks demonstrate the model's versatility. DynamicVis achieves multi-level feature modeling with exceptional efficiency, processing (2048x2048) pixels with 97 ms latency (6% of ViT's) and 833 MB GPU memory (3% of ViT's). | [🔗 Paper](http://arxiv.org/abs/2503.16426v1) |
| [SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World](http://arxiv.org/abs/2503.16399v1) | Chen Chen, Zhirui Wang, Taowei Sheng, Yi Jiang, Yundu Li, Peirui Cheng, Luning Zhang, Kaiqiang Chen, Yanfeng Hu, Xue Yang, Xian Sun | 2025-03-20 | Production and Deployment, RLHF | Existing vision-based 3D occupancy prediction methods are inherently limited in accuracy due to their exclusive reliance on street-view imagery, neglecting the potential benefits of incorporating satellite views. We propose SA-Occ, the first Satellite-Assisted 3D occupancy prediction model, which leverages GPS & IMU to integrate historical yet readily available satellite imagery into real-time applications, effectively mitigating limitations of ego-vehicle perceptions, involving occlusions and degraded performance in distant regions. To address the core challenges of cross-view perception, we propose: 1) Dynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions caused by the temporal asynchrony between satellite and street views; 2) 3D-Proj Guidance, a module that enhances 3D feature extraction from inherently 2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the sampling density between street and satellite views. Evaluated on Occ3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among single-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring only 6.93 ms of additional latency per frame. Our code and newly curated dataset are available at https://github.com/chenchen235/SA-Occ. | [🔗 Paper](http://arxiv.org/abs/2503.16399v1) |
## 🔹 Prompt Engineering

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models](http://arxiv.org/abs/2503.16419v1) | Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Shaochen, Zhong, Hanjie Chen, Xia Hu | 2025-03-20 | Prompt Engineering, Training & Evaluation, LLM, Optimization, Model Evaluation, RLHF | Large Language Models (LLMs) have demonstrated remarkable capabilities in complex tasks. Recent advancements in Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have further improved performance in System-2 reasoning domains like mathematics and programming by harnessing supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance the Chain-of-Thought (CoT) reasoning. However, while longer CoT reasoning sequences improve performance, they also introduce significant computational overhead due to verbose and redundant outputs, known as the "overthinking phenomenon". In this paper, we provide the first structured survey to systematically investigate and explore the current progress toward achieving efficient reasoning in LLMs. Overall, relying on the inherent mechanism of LLMs, we categorize existing works into several key directions: (1) model-based efficient reasoning, which considers optimizing full-length reasoning models into more concise reasoning models or directly training efficient reasoning models; (2) reasoning output-based efficient reasoning, which aims to dynamically reduce reasoning steps and length during inference; (3) input prompts-based efficient reasoning, which seeks to enhance reasoning efficiency based on input prompt properties such as difficulty or length control. Additionally, we introduce the use of efficient data for training reasoning models, explore the reasoning capabilities of small language models, and discuss evaluation methods and benchmarking. | [🔗 Paper](http://arxiv.org/abs/2503.16419v1) |
| [Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation](http://arxiv.org/abs/2503.16385v1) | Yijia Luo, Yulin Song, Xingyao Zhang, Jiaheng Liu, Weixun Wang, GengRu Chen, Wenbo Su, Bo Zheng | 2025-03-20 | Prompt Engineering, Optimization | Recent advancements in large language models (LLMs) have demonstrated remarkable reasoning capabilities through long chain-of-thought (CoT) reasoning. The R1 distillation scheme has emerged as a promising approach for training cost-effective models with enhanced reasoning abilities. However, the underlying mechanisms driving its effectiveness remain unclear. This study examines the universality of distillation data and identifies key components that enable the efficient transfer of long-chain reasoning capabilities in LLM distillation. Our findings reveal that the effectiveness of long CoT reasoning distillation from teacher models like Qwen-QwQ degrades significantly on nonhomologous models, challenging the assumed universality of current distillation methods. To gain deeper insights into the structure and patterns of long CoT reasoning, we propose DLCoT (Deconstructing Long Chain-of-Thought), a distillation data enhancement framework. DLCoT consists of three key steps: (1) data segmentation to decompose complex long CoT structures, (2) simplification by eliminating unsolvable and redundant solutions, and (3) optimization of intermediate error states. Our approach significantly improves model performance and token efficiency, facilitating the development of high-performance LLMs. | [🔗 Paper](http://arxiv.org/abs/2503.16385v1) |
## 🔹 Responsible AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Survey on Evaluation of LLM-based Agents](http://arxiv.org/abs/2503.16416v1) | Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun Zhao, Roy Bar-Haim, Arman Cohan, Michal Shmueli-Scheuer | 2025-03-20 | Responsible AI, Model Evaluation, Training & Evaluation | The emergence of LLM-based agents represents a paradigm shift in AI, enabling autonomous systems to plan, reason, use tools, and maintain memory while interacting with dynamic environments. This paper provides the first comprehensive survey of evaluation methodologies for these increasingly capable agents. We systematically analyze evaluation benchmarks and frameworks across four critical dimensions: (1) fundamental agent capabilities, including planning, tool use, self-reflection, and memory; (2) application-specific benchmarks for web, software engineering, scientific, and conversational agents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating agents. Our analysis reveals emerging trends, including a shift toward more realistic, challenging evaluations with continuously updated benchmarks. We also identify critical gaps that future research must address-particularly in assessing cost-efficiency, safety, and robustness, and in developing fine-grained, and scalable evaluation methods. This survey maps the rapidly evolving landscape of agent evaluation, reveals the emerging trends in the field, identifies current limitations, and proposes directions for future research. | [🔗 Paper](http://arxiv.org/abs/2503.16416v1) |
| [Computing Lindahl Equilibrium for Public Goods with and without Funding Caps](http://arxiv.org/abs/2503.16414v1) | Christian Kroer, Dominik Peters | 2025-03-20 | Responsible AI | Lindahl equilibrium is a solution concept for allocating a fixed budget across several divisible public goods. It always lies in the core, meaning that the equilibrium allocation satisfies desirable stability and proportional fairness properties. We consider a model where agents have separable linear utility functions over the public goods, and the output assigns to each good an amount of spending, summing to at most the available budget.   In the uncapped setting, each of the public goods can absorb any amount of funding. In this case, it is known that Lindahl equilibrium is equivalent to maximizing Nash social welfare, and this allocation can be computed by a public-goods variant of the proportional response dynamics. We introduce a new convex programming formulation for computing this solution and show that it is related to Nash welfare maximization through duality and reformulation. We then show that the proportional response dynamics is equivalent to running mirror descent on our new formulation, thereby providing a new and immediate proof of the convergence guarantee for the dynamics. Our new formulation has similarities to Shmyrev's convex program for Fisher market equilibrium.   In the capped setting, each public good has an upper bound on the amount of funding it can receive. In this setting, existence of Lindahl equilibrium was only known via fixed-point arguments. The existence of an efficient algorithm computing one has been a long-standing open question. We prove that our new convex program continues to work when the cap constraints are added, and its optimal solutions are Lindahl equilibria. Thus, we establish that Lindahl equilibrium can be efficiently computed in the capped setting. Our result also implies that approximately core-stable allocations can be efficiently computed for the class of separable piecewise-linear concave (SPLC) utilities. | [🔗 Paper](http://arxiv.org/abs/2503.16414v1) |
## 🔹 Fine-Tuning

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Sonata: Self-Supervised Learning of Reliable Point Representations](http://arxiv.org/abs/2503.16429v1) | Xiaoyang Wu, Daniel DeTone, Duncan Frost, Tianwei Shen, Chris Xie, Nan Yang, Jakob Engel, Richard Newcombe, Hengshuang Zhao, Julian Straub | 2025-03-20 | Fine-Tuning, Prompt Engineering, Optimization | In this paper, we question whether we have a reliable self-supervised point cloud model that can be used for diverse 3D tasks via simple linear probing, even with limited data and minimal computation. We find that existing 3D self-supervised learning approaches fall short when evaluated on representation quality through linear probing. We hypothesize that this is due to what we term the "geometric shortcut", which causes representations to collapse to low-level spatial features. This challenge is unique to 3D and arises from the sparse nature of point cloud data. We address it through two key strategies: obscuring spatial information and enhancing the reliance on input features, ultimately composing a Sonata of 140k point clouds through self-distillation. Sonata is simple and intuitive, yet its learned representations are strong and reliable: zero-shot visualizations demonstrate semantic grouping, alongside strong spatial reasoning through nearest-neighbor relationships. Sonata demonstrates exceptional parameter and data efficiency, tripling linear probing accuracy (from 21.8% to 72.5%) on ScanNet and nearly doubling performance with only 1% of the data compared to previous approaches. Full fine-tuning further advances SOTA across both 3D indoor and outdoor perception tasks. | [🔗 Paper](http://arxiv.org/abs/2503.16429v1) |
| [InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity](http://arxiv.org/abs/2503.16418v1) | Liming Jiang, Qing Yan, Yumin Jia, Zichuan Liu, Hao Kang, Xin Lu | 2025-03-20 | Fine-Tuning, LLM, Optimization, Diffusion Models, RLHF | Achieving flexible and high-fidelity identity-preserved image generation remains formidable, particularly with advanced Diffusion Transformers (DiTs) like FLUX. We introduce InfiniteYou (InfU), one of the earliest robust frameworks leveraging DiTs for this task. InfU addresses significant issues of existing methods, such as insufficient identity similarity, poor text-image alignment, and low generation quality and aesthetics. Central to InfU is InfuseNet, a component that injects identity features into the DiT base model via residual connections, enhancing identity similarity while maintaining generation capabilities. A multi-stage training strategy, including pretraining and supervised fine-tuning (SFT) with synthetic single-person-multiple-sample (SPMS) data, further improves text-image alignment, ameliorates image quality, and alleviates face copy-pasting. Extensive experiments demonstrate that InfU achieves state-of-the-art performance, surpassing existing baselines. In addition, the plug-and-play design of InfU ensures compatibility with various existing methods, offering a valuable contribution to the broader community. | [🔗 Paper](http://arxiv.org/abs/2503.16418v1) |
## 🔹 General AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [A Complete Active Space Self-Consistent Field (CASSCF) approach for
  molecules in QED environments](http://arxiv.org/abs/2503.16417v1) | Riccardo Alessandro, Henrik Koch, Enrico Ronca | 2025-03-20 | General AI | Multireference systems are usually challenging to investigate using ab initio methods as they require an accurate description of static electron correlation. The urgency of developing similar approaches is even more pressing when molecules strongly interact with light in quantum-electrodynamics (QED) environments. In fact, in this context, multireference effects might be induced or reduced by the presence of the field. In this work, we extend the Complete Active Space Self-Consistent Field (CASSCF) approach to polaritonic systems. The method is tested on benchmark multireference problems and applied to investigate field-induced effects on the electronic structure of well-known multiconfigurational processes. We analyze the strengths and limitations of the method with particular attention to the appearance of possible origin dependencies. | [🔗 Paper](http://arxiv.org/abs/2503.16417v1) |
| [Apparent $w<-1$ and a Lower $S_8$ from Dark Axion and Dark Baryons
  Interactions](http://arxiv.org/abs/2503.16415v1) | Justin Khoury, Meng-Xiang Lin, Mark Trodden | 2025-03-20 | General AI | We show that a simple coupling between dark energy and dark matter can simultaneously address two distinct hints at new physics coming from cosmological observations. The first is the recent evidence from the DESI project and supernovae observations that the dark energy equation of state~$w$ is evolving over cosmic time from an earlier value that is~$<-1$ to a present-day value~$>-1$. The second observation is the so-called~$S_8$ tension, describing the suppression of the growth of matter overdensities compared to that expected in the~$\Lambda$CDM model. We propose a stable, technically natural particle physics implementation of this idea, in which dark matter consists of dark baryons in a strongly-coupled hidden sector, and the dark energy field is the associated dark axion. The time-variation of the dark matter mass results in an effective dark energy equation of state that exhibits a phantom crossing behavior consistent with recent results. It also results in a slight delay in matter-radiation equality, which suppresses the overall growth of density perturbations. | [🔗 Paper](http://arxiv.org/abs/2503.16415v1) |
| [Parallel Domain-Decomposition Algorithms for Complexity Certification of
  Branch-and-Bound Algorithms for Mixed-Integer Linear and Quadratic
  Programming](http://arxiv.org/abs/2503.16411v1) | Shamisa Shoja, Daniel Arnström, Daniel Axehill | 2025-03-20 | General AI | When implementing model predictive control (MPC) for hybrid systems with a linear or a quadratic performance measure, a mixed-integer linear program (MILP) or a mixed-integer quadratic program (MIQP) needs to be solved, respectively, at each sampling instant. Recent work has introduced the possibility to certify the computational complexity of branch-and-bound (B&B) algorithms when solving MILP and MIQP problems formulated as multi-parametric MILPs (mp-MILPs) and mp-MIQPs. Such a framework allows for computing the worst-case computational complexity of standard B&B-based MILP and MIQP solvers, quantified by metrics such as the total number of LP/QP iterations and B&B nodes. These results are highly relevant for real-time hybrid MPC applications. In this paper, we extend this framework by developing parallel, domain-decomposition versions of the previously proposed algorithm, allowing it to scale to larger problem sizes and enable the use of high-performance computing (HPC) resources. Furthermore, to reduce peak memory consumption, we introduce two modifications to the existing (serial) complexity certification framework, integrating them into the proposed parallel algorithms. Numerical experiments show that the parallel algorithms significantly reduce computation time while maintaining the correctness of the original framework. | [🔗 Paper](http://arxiv.org/abs/2503.16411v1) |
| [Simultaneous transport and tunneling spectroscopy of moiré graphene:
  Distinct observation of the superconducting gap and signatures of nodal
  superconductivity](http://arxiv.org/abs/2503.16410v1) | Jeong Min Park, Shuwen Sun, Kenji Watanabe, Takashi Taniguchi, Pablo Jarillo-Herrero | 2025-03-20 | General AI | Understanding the nature of superconductivity in magic-angle graphene remains challenging. A key difficulty lies in discerning the different energy scales in this strongly interacting system, particularly the superconducting gap. Here, we report the first simultaneous tunneling spectroscopy and transport measurements of magic-angle graphene, providing a novel approach to probe the superconducting state. This approach allows us to identify two coexisting V-shaped tunneling gaps with different energy scales: a distinct low-energy superconducting gap that vanishes at the superconducting critical temperature and magnetic field, and a higher-energy pseudogap. The superconducting tunneling spectra display a linear gap-filling behavior with temperature and magnetic field and exhibit the Volovik effect, consistent with a nodal order parameter. Our work reveals the unconventional nature of the superconducting gap in magic-angle graphene and establishes an experimental framework for multidimensional investigation of tunable quantum materials. | [🔗 Paper](http://arxiv.org/abs/2503.16410v1) |
| [A foundational derivation of quantum weak values and time-dependent
  density functional theory](http://arxiv.org/abs/2503.16409v1) | Russell B. Thompson, Zarin Tasneem, Yves Caudano | 2025-03-20 | General AI | The equations of time-dependent density functional theory are derived, via the expression for the quantum weak value, from ring polymer quantum theory using a symmetry between time and imaginary time. The imaginary time path integral formalism of Feynman, in which inverse temperature is seen to be a Wick rotation of time, allows one to write the equilibrium partition function of a quantum system in a form isomorphic with the path integral expression for the dynamics. Therefore the self-consistent field theory equations which are solutions to the equilibrium partition function are Wick rotated back into a set of dynamic equations, which are shown to give the formula for the quantum weak value. As a special case, this in turn reduces to the equations of time-dependent density functional theory. This first-principles derivation does not use the theorems of density functional theory, which are instead applied to guarantee equivalence with standard quantum mechanics. An expression for finite-temperature dynamics is also derived using the limits of the equilibrium equations and the ground state dynamics. This finite temperature expression shows that a ring polymer model for quantum particles holds for time-dependent systems as well as static situations. Issues arising in time-dependent density functional theory, such as causality, initial state dependence, and $v$-representability, are discussed in the context of the ring polymer derivation. Connections with a variety of quantum phenomena is reviewed, and a possible link with de Broglie-Bohm theory is mentioned. | [🔗 Paper](http://arxiv.org/abs/2503.16409v1) |
| [RoboFactory: Exploring Embodied Agent Collaboration with Compositional
  Constraints](http://arxiv.org/abs/2503.16408v1) | Yiran Qin, Li Kang, Xiufeng Song, Zhenfei Yin, Xiaohong Liu, Xihui Liu, Ruimao Zhang, Lei Bai | 2025-03-20 | General AI | Designing effective embodied multi-agent systems is critical for solving complex real-world tasks across domains. Due to the complexity of multi-agent embodied systems, existing methods fail to automatically generate safe and efficient training data for such systems. To this end, we propose the concept of compositional constraints for embodied multi-agent systems, addressing the challenges arising from collaboration among embodied agents. We design various interfaces tailored to different types of constraints, enabling seamless interaction with the physical world. Leveraging compositional constraints and specifically designed interfaces, we develop an automated data collection framework for embodied multi-agent systems and introduce the first benchmark for embodied multi-agent manipulation, RoboFactory. Based on RoboFactory benchmark, we adapt and evaluate the method of imitation learning and analyzed its performance in different difficulty agent tasks. Furthermore, we explore the architectures and training strategies for multi-agent imitation learning, aiming to build safe and efficient embodied multi-agent systems. | [🔗 Paper](http://arxiv.org/abs/2503.16408v1) |
| [Deep Feynman-Kac Methods for High-dimensional Semilinear Parabolic
  Equations: Revisit](http://arxiv.org/abs/2503.16407v1) | Xiaotao Zheng, Xingye Yue, Jiyang Shi | 2025-03-20 | General AI | Deep Feynman-Kac method was first introduced to solve parabolic partial differential equations(PDE) by Beck et al. (SISC, V.43, 2021), named Deep Splitting method since they trained the Neural Networks step by step in the time direction. In this paper, we propose a new training approach with two different features. Firstly, neural networks are trained at all time steps globally, instead of step by step. Secondly, the training data are generated in a new way, in which the method is consistent with a direct Monte Carlo scheme when dealing with a linear parabolic PDE. Numerical examples show that our method has significant improvement both in efficiency and accuracy. | [🔗 Paper](http://arxiv.org/abs/2503.16407v1) |
| [Series-parallel graphs and hypercube degeneracy](http://arxiv.org/abs/2503.16404v1) | Daniel G. Zhu | 2025-03-20 | General AI | Several recent works have identified patterns that must exist in dense subsets of either the vertices or the edges of a large hypercube. We introduce a framework, based on the concept of series-parallel graphs, that unifies and generalizes these results. | [🔗 Paper](http://arxiv.org/abs/2503.16404v1) |
| [Skew shapes, Ehrhart positivity and beyond](http://arxiv.org/abs/2503.16403v1) | Luis Ferroni, Alejandro H. Morales, Greta Panova | 2025-03-20 | General AI | A classical result by Kreweras (1965) allows one to compute the number of plane partitions of a given skew shape and bounded parts as certain determinants. We prove that these determinants expand as polynomials with nonnegative coefficients. This result can be reformulated in terms of order polynomials of cell posets of skew shapes, and explains important positivity phenomena about the Ehrhart polynomials of shard polytopes, matroids, and order polytopes. Among other applications, we generalize a positivity statement from Schubert calculus by Fomin and Kirillov (1997) from straight shapes to skew shapes. We show that all shard polytopes are Ehrhart positive and, stronger, that all fence posets, including the zig-zag poset, have order polynomials with nonnegative coefficients. We present a more general method for proving positivity which reduces to showing positivity of the linear terms of the order polynomials and we state conjectures on other positive classes of posets. | [🔗 Paper](http://arxiv.org/abs/2503.16403v1) |
| [Truthful Elicitation of Imprecise Forecasts](http://arxiv.org/abs/2503.16395v1) | Anurag Singh, Siu Lun Chau, Krikamol Muandet | 2025-03-20 | General AI | The quality of probabilistic forecasts is crucial for decision-making under uncertainty. While proper scoring rules incentivize truthful reporting of precise forecasts, they fall short when forecasters face epistemic uncertainty about their beliefs, limiting their use in safety-critical domains where decision-makers (DMs) prioritize proper uncertainty management. To address this, we propose a framework for scoring imprecise forecasts -- forecasts given as a set of beliefs. Despite existing impossibility results for deterministic scoring rules, we enable truthful elicitation by drawing connection to social choice theory and introducing a two-way communication framework where DMs first share their aggregation rules (e.g., averaging or min-max) used in downstream decisions for resolving forecast ambiguity. This, in turn, helps forecasters resolve indecision during elicitation. We further show that truthful elicitation of imprecise forecasts is achievable using proper scoring rules randomized over the aggregation procedure. Our approach allows DM to elicit and integrate the forecaster's epistemic uncertainty into their decision-making process, thus improving credibility. | [🔗 Paper](http://arxiv.org/abs/2503.16395v1) |
| [Multiplicity $=$ Volume formula and Newton non-degenerate ideals in
  regular local rings](http://arxiv.org/abs/2503.16393v1) | Tài Huy Hà, Thai Thanh Nguyen, Vinh Anh Pham | 2025-03-20 | General AI | We develop the notions of Newton non-degenerate (NND) ideals and Newton polyhedra for regular local rings. These concepts were first defined in the context of complex analysis. We show that the characterization of NND ideals via their integral closures known in the analytical setting extends to regular local rings. We use the limiting body $\mathcal{C}(\mathcal{I})$ associated to a graded family $\mathcal{I}$ of ideals to provide a new understanding of the celebrated "Multiplicity $=$ Volume" formula. Particularly, we prove that, for a Noetherian graded family $\mathcal{I}$ of $\mathfrak{m}$-primary ideals in a regular local ring $(R,\mathfrak{m})$ of dimension $d$, the equality $$e(\mathcal{I}) = d!\text{co-vol}_d(\mathcal{C}(\mathcal{I}))$$ holds if and only if $\mathcal{I}$ contains certain subfamily of NND ideals. | [🔗 Paper](http://arxiv.org/abs/2503.16393v1) |
| [Graph of Effort: Quantifying Risk of AI Usage for Vulnerability
  Assessment](http://arxiv.org/abs/2503.16392v1) | Anket Mehra, Andreas Aßmuth, Malte Prieß | 2025-03-20 | General AI | With AI-based software becoming widely available, the risk of exploiting its capabilities, such as high automation and complex pattern recognition, could significantly increase. An AI used offensively to attack non-AI assets is referred to as offensive AI.   Current research explores how offensive AI can be utilized and how its usage can be classified. Additionally, methods for threat modeling are being developed for AI-based assets within organizations. However, there are gaps that need to be addressed. Firstly, there is a need to quantify the factors contributing to the AI threat. Secondly, there is a requirement to create threat models that analyze the risk of being attacked by AI for vulnerability assessment across all assets of an organization. This is particularly crucial and challenging in cloud environments, where sophisticated infrastructure and access control landscapes are prevalent. The ability to quantify and further analyze the threat posed by offensive AI enables analysts to rank vulnerabilities and prioritize the implementation of proactive countermeasures.   To address these gaps, this paper introduces the Graph of Effort, an intuitive, flexible, and effective threat modeling method for analyzing the effort required to use offensive AI for vulnerability exploitation by an adversary. While the threat model is functional and provides valuable support, its design choices need further empirical validation in future work. | [🔗 Paper](http://arxiv.org/abs/2503.16392v1) |
| [Intrinsic superconducting diode effect and nonreciprocal
  superconductivity in rhombohedral graphene multilayers](http://arxiv.org/abs/2503.16391v1) | Yinqi Chen, Constantin Schrade | 2025-03-20 | General AI | Rhombohedral tetralayer graphene has recently emerged as an exciting platform for a possible chiral superconducting state. Here, we theoretically demonstrate and study the emergence of nonreciprocal superconductivity and an intrinsic superconducting diode effect in this system. Our results are based on a fully self-consistent framework for determining the superconducting order parameter from a Kohn-Luttinger mechanism to superconductivity and show that large diode efficiencies, $\sim$ 60%, are achievable and highly tunable by an external displacement field. Moreover, we also find that the diodicity shows a characteristic angular dependence with multiple enhanced lobes, which depend on the Fermi surface structure of the underlying normal state. Hence, our results suggest that the intrinsic superconducting diode effect could provide insights into the type of Fermi surface topology from which superconductivity arises. | [🔗 Paper](http://arxiv.org/abs/2503.16391v1) |
| [Phonons in Electron Crystals with Berry Curvature](http://arxiv.org/abs/2503.16390v1) | Junkai Dong, Ophelia Evelyn Sommer, Tomohiro Soejima, Daniel E. Parker, Ashvin Vishwanath | 2025-03-20 | General AI | Recent advances in 2D materials featuring nonzero Berry curvature have inspired extensions of the Wigner crystallization paradigm. This paper derives a low-energy effective theory for such quantum crystals, including the anomalous Hall crystal (AHC) with nonzero Chern number. First we show that the low frequency dispersion of phonons in AHC, despite the presence of Berry curvature, resembles that of the zero field (rather than finite magnetic field) Wigner crystal due to the commutation of translation generators. We explain how key parameters of the phonon theory such as elastic constants and effective mass can be extracted from microscopic models, and apply them to two families of models: the recently introduced $\lambda$-jellium model and a model of rhombohedral multilayer graphene (RMG). In the $\lambda$-jellium model, we explore the energy landscape as crystal geometry shifts, revealing that AHC can become "soft" under certain conditions. This causes transitions in lattice geometry, although the quantized Hall response remains unchanged. Surprisingly, the Berry curvature seems to enhance the effective mass, leading to a reduction in phonon speed. For the AHC in RMG, we obtain estimates of phonon speed and shear stiffness. We also identify a previously overlooked "kineo-elastic" term in the phonon effective action that is present in the symmetry setting of RMG, and leads to dramatic differences in phonon speeds in opposite directions. We numerically confirm these predictions of the effective actions by time-dependent Hartree-Fock calculations. Our work points to the wealth of new phenomena that can arise when electron crystallization occurs in the presence of band geometry and topology. | [🔗 Paper](http://arxiv.org/abs/2503.16390v1) |
| [Attentional Triple-Encoder Network in Spatiospectral Domains for Medical
  Image Segmentation](http://arxiv.org/abs/2503.16389v1) | Kristin Qi, Xinhan Di | 2025-03-20 | General AI | Retinal Optical Coherence Tomography (OCT) segmentation is essential for diagnosing pathology. Traditional methods focus on either spatial or spectral domains, overlooking their combined dependencies. We propose a triple-encoder network that integrates CNNs for spatial features, Fast Fourier Convolution (FFC) for spectral features, and attention mechanisms to capture global relationships across both domains. Attention fusion modules integrate convolution and cross-attention to further enhance features. Our method achieves an average Dice score improvement from 0.855 to 0.864, outperforming prior work. | [🔗 Paper](http://arxiv.org/abs/2503.16389v1) |
| [A Mixed-FEM approximation with uniform conservation of the exponential
  stability for a class of anisotropic port-Hamiltonian system and its
  application to LQ control](http://arxiv.org/abs/2503.16388v1) | Luis A. Mora, Kirsten Morris | 2025-03-20 | General AI | In this manuscript, we present a mixed finite element discretization for a class of boundary-damped anisotropic port-Hamiltonian systems. Using a multiplier method, we demonstrate that the resulting approximation model uniformly preserves the exponential stability of the uncontrolled system, establishing a lower bound for the exponential decay rate that is independent of the mesh size. This property is illustrated through the spatial discretization of a piezoelectric beam. Furthermore, we show how the uniform preservation of exponential stability by the proposed model aids in the convergence of controllers derived from an infinite-time linear quadratic control design, in comparison to models obtained from the standard finite-element method. | [🔗 Paper](http://arxiv.org/abs/2503.16388v1) |
| [Open String Axiverse](http://arxiv.org/abs/2503.16387v1) | Rudin Petrossian-Byrne, Giovanni Villadoro | 2025-03-20 | General AI | Localized charged fields are a general feature of many realistic string compactifications. In four dimensions they can lead to a multitude of perturbatively-exact global symmetries. If spontaneously broken, they generate a new axiverse compatible with post-inflationary evolutions. | [🔗 Paper](http://arxiv.org/abs/2503.16387v1) |
| [On Decomposability of Virtual Artin Groups](http://arxiv.org/abs/2503.16386v1) | Federica Gavazzi | 2025-03-20 | General AI | A group is called decomposable if it can be expressed as a direct product of two proper subgroups, and indecomposable otherwise. This paper explores the decomposability of virtual Artin groups, which were introduced by Bellingeri, Paris, and Thiel as a generalization of classical Artin groups within the framework of virtual braid theory. We establish that for any connected Coxeter graph {\Gamma}, the associated virtual Artin group VA[{\Gamma}] is indecomposable. Specifically, virtual braid groups are indecomposable. As a consequence of the indecomposability result, we deduce that studying the automorphism group of a virtual Artin group reduces to analyzing the automorphism groups of its irreducible components. | [🔗 Paper](http://arxiv.org/abs/2503.16386v1) |
| [Spontaneous vortex-antivortex lattice and Majorana fermions in
  rhombohedral graphene](http://arxiv.org/abs/2503.16384v1) | Filippo Gaggioli, Daniele Guerci, Liang Fu | 2025-03-20 | General AI | The discovery of superconducting states in multilayer rhombohedral graphene with spin and valley polarization has raised an interesting question: how does superconductivity cope with time-reversal symmetry breaking? %In the normal state, spin and valley polarization break time-reversal symmetry, while trigonal warping enforces $C_{3z}$. Below the critical temperature, the superconducting phase displays signatures of chiral behavior and is stabilized by out-of-plane fields as large as $\sim 0.5\,\text{T}$. In this work, using Ginzburg-Landau theory and microscopic calculation, we predict the existence of a new superconducting state at low electron density, which exhibits a spontaneously formed lattice of vortices and antivortices hosting Majorana zero-modes in their cores. We further identify this vortex-antivortex lattice (VAL) state in the experimental phase diagram and describe its experimental manifestations. | [🔗 Paper](http://arxiv.org/abs/2503.16384v1) |
| [Sparse Nonparametric Contextual Bandits](http://arxiv.org/abs/2503.16382v1) | Hamish Flynn, Julia Olkhovskaya, Paul Rognon-Vael | 2025-03-20 | General AI | This paper studies the problem of simultaneously learning relevant features and minimising regret in contextual bandit problems. We introduce and analyse a new class of contextual bandit problems, called sparse nonparametric contextual bandits, in which the expected reward function lies in the linear span of a small unknown set of features that belongs to a known infinite set of candidate features. We consider two notions of sparsity, for which the set of candidate features is either countable or uncountable. Our contribution is two-fold. First, we provide lower bounds on the minimax regret, which show that polynomial dependence on the number of actions is generally unavoidable in this setting. Second, we show that a variant of the Feel-Good Thompson Sampling algorithm enjoys regret bounds that match our lower bounds up to logarithmic factors of the horizon, and have logarithmic dependence on the effective number of candidate features. When we apply our results to kernelised and neural contextual bandits, we find that sparsity always enables better regret bounds, as long as the horizon is large enough relative to the sparsity and the number of actions. | [🔗 Paper](http://arxiv.org/abs/2503.16382v1) |
| [Non-Markovian Relaxation Spectroscopy of Fluxonium Qubits](http://arxiv.org/abs/2503.16381v1) | Ze-Tong Zhuang, Dario Rosenstock, Bao-Jie Liu, Aaron Somoroff, Vladimir E. Manucharyan, Chen Wang | 2025-03-20 | General AI | Recent studies have shown that parasitic two-level systems (TLS) in superconducting qubits, which are a leading source of decoherence, can have relaxation times longer than the qubits themselves. However, the standard techniques used to characterize qubit relaxation is only valid for measuring $T_1$ under Markovian assumptions and could mask such non-Markovian behavior of the environment in practice. Here, we introduce two-timescale relaxometry, a technique to probe the qubit and environment relaxation simultaneously and efficiently. We apply it to high-coherence fluxonium qubits over a frequency range of 0.1-0.4 GHz, which reveals a discrete spectrum of TLS with millisecond lifetimes. Our analysis of the spectrum is consistent with a random distribution of TLS in the aluminum oxide tunnel barrier of the Josephson junction chain of the fluxonium with an average density and electric dipole similar to previous TLS studies at much higher frequencies. Our study suggests that investigating and mitigating TLS in the junction chain is crucial to the development of various types of noise-protected qubits in circuit QED. | [🔗 Paper](http://arxiv.org/abs/2503.16381v1) |
