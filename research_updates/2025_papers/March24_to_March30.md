# üìå AI Research Papers (March24 to March30)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Video-R1: Reinforcing Video Reasoning in MLLMs](http://arxiv.org/abs/2503.21776v1) | Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Benyou Wang, Xiangyu Yue | 2025-03-27 | LLM, Multimodal AI, RLHF, Prompt Engineering | Inspired by DeepSeek-R1's success in eliciting reasoning abilities through rule-based reinforcement learning (RL), we introduce Video-R1 as the first attempt to systematically explore the R1 paradigm for eliciting video reasoning within multimodal large language models (MLLMs). However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data. To address these issues, we first propose the T-GRPO algorithm, which encourages models to utilize temporal information in videos for reasoning. Additionally, instead of relying solely on video data, we incorporate high-quality image-reasoning data into the training process. We have constructed two datasets: Video-R1-COT-165k for SFT cold start and Video-R1-260k for RL training, both comprising image and video data. Experimental results demonstrate that Video-R1 achieves significant improvements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as well as on general video benchmarks including MVBench and TempCompass, etc. Notably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning benchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All codes, models, data are released. | [üîó Paper](http://arxiv.org/abs/2503.21776v1) |
| [MemInsight: Autonomous Memory Augmentation for LLM Agents](http://arxiv.org/abs/2503.21760v1) | Rana Salama, Jason Cai, Michelle Yuan, Anna Currey, Monica Sunkara, Yi Zhang, Yassine Benajiba | 2025-03-27 | LLM | Large language model (LLM) agents have evolved to intelligently process information, make decisions, and interact with users or tools. A key capability is the integration of long-term memory capabilities, enabling these agents to draw upon historical interactions and knowledge. However, the growing memory size and need for semantic structuring pose significant challenges. In this work, we propose an autonomous memory augmentation approach, MemInsight, to enhance semantic data representation and retrieval mechanisms. By leveraging autonomous augmentation to historical interactions, LLM agents are shown to deliver more accurate and contextualized responses. We empirically validate the efficacy of our proposed approach in three task scenarios; conversational recommendation, question answering and event summarization. On the LLM-REDIAL dataset, MemInsight boosts persuasiveness of recommendations by up to 14%. Moreover, it outperforms a RAG baseline by 34% in recall for LoCoMo retrieval. Our empirical results show the potential of MemInsight to enhance the contextual performance of LLM agents across multiple tasks. | [üîó Paper](http://arxiv.org/abs/2503.21760v1) |
| [Reconstructing Humans with a Biomechanically Accurate Skeleton](http://arxiv.org/abs/2503.21751v1) | Yan Xia, Xiaowei Zhou, Etienne Vouga, Qixing Huang, Georgios Pavlakos | 2025-03-27 | LLM | In this paper, we introduce a method for reconstructing 3D humans from a single image using a biomechanically accurate skeleton model. To achieve this, we train a transformer that takes an image as input and estimates the parameters of the model. Due to the lack of training data for this task, we build a pipeline to produce pseudo ground truth model parameters for single images and implement a training procedure that iteratively refines these pseudo labels. Compared to state-of-the-art methods for 3D human mesh recovery, our model achieves competitive performance on standard benchmarks, while it significantly outperforms them in settings with extreme 3D poses and viewpoints. Additionally, we show that previous reconstruction methods frequently violate joint angle limits, leading to unnatural rotations. In contrast, our approach leverages the biomechanically plausible degrees of freedom making more realistic joint rotation estimates. We validate our approach across multiple human pose estimation benchmarks. We make the code, models and data available at: https://isshikihugh.github.io/HSMR/ | [üîó Paper](http://arxiv.org/abs/2503.21751v1) |
| [Local Primordial non-Gaussian Bias from Time Evolution](http://arxiv.org/abs/2503.21736v1) | James M. Sullivan, Uros Seljak | 2025-03-27 | LLM, Model Evaluation, Responsible AI | Primordial non-Gaussianity (PNG) is a signature of fundamental physics in the early universe that is probed by cosmological observations. It is well known that the local type of PNG generates a strong signal in the two-point function of large-scale structure tracers, such as galaxies. This signal, often termed ``scale-dependent bias'' is a generic feature of modulation of gravitational structure formation by a large-scale mode. It is less well-appreciated that the coefficient controlling this signal, $b_{\phi}$, is closely connected to the time evolution of the tracer number density. This correspondence between time evolution and local PNG can be simply explained for a universal tracer whose mass function only depends on peak height, and more generally for non-universal tracers in the separate universe picture, which we validate in simulations. We also describe how to recover the bias of tracers subject to a survey selection function, and perform a simple demonstration on simulated galaxies. Since the local PNG amplitude in $n-$point statistics ($f_{\rm NL}$) is largely degenerate with the coefficient $b_{\phi}$, this proof of concept study demonstrates that galaxy survey data can allow for more optimal and robust extraction of local PNG information from upcoming surveys. | [üîó Paper](http://arxiv.org/abs/2503.21736v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [A Unified Image-Dense Annotation Generation Model for Underwater Scenes](http://arxiv.org/abs/2503.21771v1) | Hongkai Lin, Dingkang Liang, Zhenghao Qi, Xiang Bai | 2025-03-27 | Diffusion Models | Underwater dense prediction, especially depth estimation and semantic segmentation, is crucial for gaining a comprehensive understanding of underwater scenes. Nevertheless, high-quality and large-scale underwater datasets with dense annotations remain scarce because of the complex environment and the exorbitant data collection costs. This paper proposes a unified Text-to-Image and DEnse annotation generation method (TIDE) for underwater scenes. It relies solely on text as input to simultaneously generate realistic underwater images and multiple highly consistent dense annotations. Specifically, we unify the generation of text-to-image and text-to-dense annotations within a single model. The Implicit Layout Sharing mechanism (ILS) and cross-modal interaction method called Time Adaptive Normalization (TAN) are introduced to jointly optimize the consistency between image and dense annotations. We synthesize a large-scale underwater dataset using TIDE to validate the effectiveness of our method in underwater dense prediction tasks. The results demonstrate that our method effectively improves the performance of existing underwater dense prediction models and mitigates the scarcity of underwater data with dense annotations. We hope our method can offer new perspectives on alleviating data scarcity issues in other fields. The code is available at https: //github.com/HongkLin/TIDE. | [üîó Paper](http://arxiv.org/abs/2503.21771v1) |
| [Lumina-Image 2.0: A Unified and Efficient Image Generative Framework](http://arxiv.org/abs/2503.21758v1) | Qi Qin, Le Zhuo, Yi Xin, Ruoyi Du, Zhen Li, Bin Fu, Yiting Lu, Jiakang Yuan, Xinyue Li, Dongyang Liu, Xiangyang Zhu, Manyuan Zhang, Will Beddow, Erwann Millon, Victor Perez, Wenhai Wang, Conghui He, Bo Zhang, Xiaohong Liu, Hongsheng Li, Yu Qiao, Chang Xu, Peng Gao | 2025-03-27 | Diffusion Models | We introduce Lumina-Image 2.0, an advanced text-to-image generation framework that achieves significant progress compared to previous work, Lumina-Next. Lumina-Image 2.0 is built upon two key principles: (1) Unification - it adopts a unified architecture (Unified Next-DiT) that treats text and image tokens as a joint sequence, enabling natural cross-modal interactions and allowing seamless task expansion. Besides, since high-quality captioners can provide semantically well-aligned text-image training pairs, we introduce a unified captioning system, Unified Captioner (UniCap), specifically designed for T2I generation tasks. UniCap excels at generating comprehensive and accurate captions, accelerating convergence and enhancing prompt adherence. (2) Efficiency - to improve the efficiency of our proposed model, we develop multi-stage progressive training strategies and introduce inference acceleration techniques without compromising image quality. Extensive evaluations on academic benchmarks and public text-to-image arenas show that Lumina-Image 2.0 delivers strong performances even with only 2.6B parameters, highlighting its scalability and design efficiency. We have released our training details, code, and models at https://github.com/Alpha-VLLM/Lumina-Image-2.0. | [üîó Paper](http://arxiv.org/abs/2503.21758v1) |
| [A Unified Framework for Diffusion Bridge Problems: Flow Matching and
  Schr√∂dinger Matching into One](http://arxiv.org/abs/2503.21756v1) | Minyoung Kim | 2025-03-27 | Diffusion Models | The bridge problem is to find an SDE (or sometimes an ODE) that bridges two given distributions. The application areas of the bridge problem are enormous, among which the recent generative modeling (e.g., conditional or unconditional image generation) is the most popular. Also the famous Schr\"{o}dinger bridge problem, a widely known problem for a century, is a special instance of the bridge problem. Two most popular algorithms to tackle the bridge problems in the deep learning era are: (conditional) flow matching and iterative fitting algorithms, where the former confined to ODE solutions, and the latter specifically for the Schr\"{o}dinger bridge problem. The main contribution of this article is in two folds: i) We provide concise reviews of these algorithms with technical details to some extent; ii) We propose a novel unified perspective and framework that subsumes these seemingly unrelated algorithms (and their variants) into one. In particular, we show that our unified framework can instantiate the Flow Matching (FM) algorithm, the (mini-batch) optimal transport FM algorithm, the (mini-batch) Schr\"{o}dinger bridge FM algorithm, and the deep Schr\"{o}dinger bridge matching (DSBM) algorithm as its special cases. We believe that this unified framework will be useful for viewing the bridge problems in a more general and flexible perspective, and in turn can help researchers and practitioners to develop new bridge algorithms in their fields. | [üîó Paper](http://arxiv.org/abs/2503.21756v1) |
| [CTRL-O: Language-Controllable Object-Centric Visual Representation
  Learning](http://arxiv.org/abs/2503.21747v1) | Aniket Didolkar, Andrii Zadaianchuk, Rabiul Awal, Maximilian Seitzer, Efstratios Gavves, Aishwarya Agrawal | 2025-03-27 | Diffusion Models | Object-centric representation learning aims to decompose visual scenes into fixed-size vectors called "slots" or "object files", where each slot captures a distinct object. Current state-of-the-art object-centric models have shown remarkable success in object discovery in diverse domains, including complex real-world scenes. However, these models suffer from a key limitation: they lack controllability. Specifically, current object-centric models learn representations based on their preconceived understanding of objects, without allowing user input to guide which objects are represented. Introducing controllability into object-centric models could unlock a range of useful capabilities, such as the ability to extract instance-specific representations from a scene. In this work, we propose a novel approach for user-directed control over slot representations by conditioning slots on language descriptions. The proposed ConTRoLlable Object-centric representation learning approach, which we term CTRL-O, achieves targeted object-language binding in complex real-world scenes without requiring mask supervision. Next, we apply these controllable slot representations on two downstream vision language tasks: text-to-image generation and visual question answering. The proposed approach enables instance-specific text-to-image generation and also achieves strong performance on visual question answering. | [üîó Paper](http://arxiv.org/abs/2503.21747v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Stable-SCore: A Stable Registration-based Framework for 3D Shape
  Correspondence](http://arxiv.org/abs/2503.21766v1) | Haolin Liu, Xiaohang Zhan, Zizheng Yan, Zhongjin Luo, Yuxin Wen, Xiaoguang Han | 2025-03-27 | RLHF | Establishing character shape correspondence is a critical and fundamental task in computer vision and graphics, with diverse applications including re-topology, attribute transfer, and shape interpolation. Current dominant functional map methods, while effective in controlled scenarios, struggle in real situations with more complex challenges such as non-isometric shape discrepancies. In response, we revisit registration-for-correspondence methods and tap their potential for more stable shape correspondence estimation. To overcome their common issues including unstable deformations and the necessity for careful pre-alignment or high-quality initial 3D correspondences, we introduce Stable-SCore: A Stable Registration-based Framework for 3D Shape Correspondence. We first re-purpose a foundation model for 2D character correspondence that ensures reliable and stable 2D mappings. Crucially, we propose a novel Semantic Flow Guided Registration approach that leverages 2D correspondence to guide mesh deformations. Our framework significantly surpasses existing methods in challenging scenarios, and brings possibilities for a wide array of real applications, as demonstrated in our results. | [üîó Paper](http://arxiv.org/abs/2503.21766v1) |
| [LeX-Art: Rethinking Text Generation via Scalable High-Quality Data
  Synthesis](http://arxiv.org/abs/2503.21749v1) | Shitian Zhao, Qilong Wu, Xinyue Li, Bo Zhang, Ming Li, Qi Qin, Dongyang Liu, Kaipeng Zhang, Hongsheng Li, Yu Qiao, Peng Gao, Bin Fu, Zhen Li | 2025-03-27 | RLHF, Diffusion Models, Training & Evaluation | We introduce LeX-Art, a comprehensive suite for high-quality text-image synthesis that systematically bridges the gap between prompt expressiveness and text rendering fidelity. Our approach follows a data-centric paradigm, constructing a high-quality data synthesis pipeline based on Deepseek-R1 to curate LeX-10K, a dataset of 10K high-resolution, aesthetically refined 1024$\times$1024 images. Beyond dataset construction, we develop LeX-Enhancer, a robust prompt enrichment model, and train two text-to-image models, LeX-FLUX and LeX-Lumina, achieving state-of-the-art text rendering performance. To systematically evaluate visual text generation, we introduce LeX-Bench, a benchmark that assesses fidelity, aesthetics, and alignment, complemented by Pairwise Normalized Edit Distance (PNED), a novel metric for robust text accuracy evaluation. Experiments demonstrate significant improvements, with LeX-Lumina achieving a 79.81% PNED gain on CreateBench, and LeX-FLUX outperforming baselines in color (+3.18%), positional (+4.45%), and font accuracy (+3.81%). Our codes, models, datasets, and demo are publicly available. | [üîó Paper](http://arxiv.org/abs/2503.21749v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [VideoMage: Multi-Subject and Motion Customization of Text-to-Video
  Diffusion Models](http://arxiv.org/abs/2503.21781v1) | Chi-Pin Huang, Yen-Siang Wu, Hung-Kai Chung, Kai-Po Chang, Fu-En Yang, Yu-Chiang Frank Wang | 2025-03-27 | Multimodal AI, Diffusion Models | Customized text-to-video generation aims to produce high-quality videos that incorporate user-specified subject identities or motion patterns. However, existing methods mainly focus on personalizing a single concept, either subject identity or motion pattern, limiting their effectiveness for multiple subjects with the desired motion patterns. To tackle this challenge, we propose a unified framework VideoMage for video customization over both multiple subjects and their interactive motions. VideoMage employs subject and motion LoRAs to capture personalized content from user-provided images and videos, along with an appearance-agnostic motion learning approach to disentangle motion patterns from visual appearance. Furthermore, we develop a spatial-temporal composition scheme to guide interactions among subjects within the desired motion patterns. Extensive experiments demonstrate that VideoMage outperforms existing methods, generating coherent, user-controlled videos with consistent subject identities and interactions. | [üîó Paper](http://arxiv.org/abs/2503.21781v1) |
| [Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model](http://arxiv.org/abs/2503.21782v1) | Abdelrahman Shaker, Muhammad Maaz, Chenhui Gou, Hamid Rezatofighi, Salman Khan, Fahad Shahbaz Khan | 2025-03-27 | Multimodal AI | Video understanding models often struggle with high computational requirements, extensive parameter counts, and slow inference speed, making them inefficient for practical use. To tackle these challenges, we propose Mobile-VideoGPT, an efficient multimodal framework designed to operate with fewer than a billion parameters. Unlike traditional video large multimodal models (LMMs), Mobile-VideoGPT consists of lightweight dual visual encoders, efficient projectors, and a small language model (SLM), enabling real-time throughput. To further improve efficiency, we present an Attention-Based Frame Scoring mechanism to select the key-frames, along with an efficient token projector that prunes redundant visual tokens and preserves essential contextual cues. We evaluate our model across well-established six video understanding benchmarks (e.g., MVBench, EgoSchema, NextQA, and PercepTest). Our results show that Mobile-VideoGPT-0.5B can generate up to 46 tokens per second while outperforming existing state-of-the-art 0.5B-parameter models by 6 points on average with 40% fewer parameters and more than 2x higher throughput. Our code and models are publicly available at: https://github.com/Amshaker/Mobile-VideoGPT. | [üîó Paper](http://arxiv.org/abs/2503.21782v1) |
| [StyleMotif: Multi-Modal Motion Stylization using Style-Content Cross
  Fusion](http://arxiv.org/abs/2503.21775v1) | Ziyu Guo, Young Yoon Lee, Joseph Liu, Yizhak Ben-Shabat, Victor Zordan, Mubbasir Kapadia | 2025-03-27 | Multimodal AI, Diffusion Models | We present StyleMotif, a novel Stylized Motion Latent Diffusion model, generating motion conditioned on both content and style from multiple modalities. Unlike existing approaches that either focus on generating diverse motion content or transferring style from sequences, StyleMotif seamlessly synthesizes motion across a wide range of content while incorporating stylistic cues from multi-modal inputs, including motion, text, image, video, and audio. To achieve this, we introduce a style-content cross fusion mechanism and align a style encoder with a pre-trained multi-modal model, ensuring that the generated motion accurately captures the reference style while preserving realism. Extensive experiments demonstrate that our framework surpasses existing methods in stylized motion generation and exhibits emergent capabilities for multi-modal motion stylization, enabling more nuanced motion synthesis. Source code and pre-trained models will be released upon acceptance. Project Page: https://stylemotif.github.io | [üîó Paper](http://arxiv.org/abs/2503.21775v1) |
| [Exploring the Evolution of Physics Cognition in Video Generation: A
  Survey](http://arxiv.org/abs/2503.21765v1) | Minghui Lin, Xiang Wang, Yishan Wang, Shu Wang, Fengqi Dai, Pengxiang Ding, Cunxiang Wang, Zhengrong Zuo, Nong Sang, Siteng Huang, Donglin Wang | 2025-03-27 | Multimodal AI, Diffusion Models | Recent advancements in video generation have witnessed significant progress, especially with the rapid advancement of diffusion models. Despite this, their deficiencies in physical cognition have gradually received widespread attention - generated content often violates the fundamental laws of physics, falling into the dilemma of ''visual realism but physical absurdity". Researchers began to increasingly recognize the importance of physical fidelity in video generation and attempted to integrate heuristic physical cognition such as motion representations and physical knowledge into generative systems to simulate real-world dynamic scenarios. Considering the lack of a systematic overview in this field, this survey aims to provide a comprehensive summary of architecture designs and their applications to fill this gap. Specifically, we discuss and organize the evolutionary process of physical cognition in video generation from a cognitive science perspective, while proposing a three-tier taxonomy: 1) basic schema perception for generation, 2) passive cognition of physical knowledge for generation, and 3) active cognition for world simulation, encompassing state-of-the-art methods, classical paradigms, and benchmarks. Subsequently, we emphasize the inherent key challenges in this domain and delineate potential pathways for future research, contributing to advancing the frontiers of discussion in both academia and industry. Through structured review and interdisciplinary analysis, this survey aims to provide directional guidance for developing interpretable, controllable, and physically consistent video generation paradigms, thereby propelling generative models from the stage of ''visual mimicry'' towards a new phase of ''human-like physical comprehension''. | [üîó Paper](http://arxiv.org/abs/2503.21765v1) |
| [VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic
  Faithfulness](http://arxiv.org/abs/2503.21755v1) | Dian Zheng, Ziqi Huang, Hongbo Liu, Kai Zou, Yinan He, Fan Zhang, Yuanhan Zhang, Jingwen He, Wei-Shi Zheng, Yu Qiao, Ziwei Liu | 2025-03-27 | Multimodal AI, RLHF, Training & Evaluation | Video generation has advanced significantly, evolving from producing unrealistic outputs to generating videos that appear visually convincing and temporally coherent. To evaluate these video generative models, benchmarks such as VBench have been developed to assess their faithfulness, measuring factors like per-frame aesthetics, temporal consistency, and basic prompt adherence. However, these aspects mainly represent superficial faithfulness, which focus on whether the video appears visually convincing rather than whether it adheres to real-world principles. While recent models perform increasingly well on these metrics, they still struggle to generate videos that are not just visually plausible but fundamentally realistic. To achieve real "world models" through video generation, the next frontier lies in intrinsic faithfulness to ensure that generated videos adhere to physical laws, commonsense reasoning, anatomical correctness, and compositional integrity. Achieving this level of realism is essential for applications such as AI-assisted filmmaking and simulated world modeling. To bridge this gap, we introduce VBench-2.0, a next-generation benchmark designed to automatically evaluate video generative models for their intrinsic faithfulness. VBench-2.0 assesses five key dimensions: Human Fidelity, Controllability, Creativity, Physics, and Commonsense, each further broken down into fine-grained capabilities. Tailored for individual dimensions, our evaluation framework integrates generalists such as state-of-the-art VLMs and LLMs, and specialists, including anomaly detection methods proposed for video generation. We conduct extensive annotations to ensure alignment with human judgment. By pushing beyond superficial faithfulness toward intrinsic faithfulness, VBench-2.0 aims to set a new standard for the next generation of video generative models in pursuit of intrinsic faithfulness. | [üîó Paper](http://arxiv.org/abs/2503.21755v1) |
| [3DGen-Bench: Comprehensive Benchmark Suite for 3D Generative Models](http://arxiv.org/abs/2503.21745v1) | Yuhan Zhang, Mengchen Zhang, Tong Wu, Tengfei Wang, Gordon Wetzstein, Dahua Lin, Ziwei Liu | 2025-03-27 | Multimodal AI, Diffusion Models, Training & Evaluation | 3D generation is experiencing rapid advancements, while the development of 3D evaluation has not kept pace. How to keep automatic evaluation equitably aligned with human perception has become a well-recognized challenge. Recent advances in the field of language and image generation have explored human preferences and showcased respectable fitting ability. However, the 3D domain still lacks such a comprehensive preference dataset over generative models. To mitigate this absence, we develop 3DGen-Arena, an integrated platform in a battle manner. Then, we carefully design diverse text and image prompts and leverage the arena platform to gather human preferences from both public users and expert annotators, resulting in a large-scale multi-dimension human preference dataset 3DGen-Bench. Using this dataset, we further train a CLIP-based scoring model, 3DGen-Score, and a MLLM-based automatic evaluator, 3DGen-Eval. These two models innovatively unify the quality evaluation of text-to-3D and image-to-3D generation, and jointly form our automated evaluation system with their respective strengths. Extensive experiments demonstrate the efficacy of our scoring model in predicting human preferences, exhibiting a superior correlation with human ranks compared to existing metrics. We believe that our 3DGen-Bench dataset and automated evaluation system will foster a more equitable evaluation in the field of 3D generation, further promoting the development of 3D generative models and their downstream applications. | [üîó Paper](http://arxiv.org/abs/2503.21745v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Semantic Library Adaptation: LoRA Retrieval and Fusion for
  Open-Vocabulary Semantic Segmentation](http://arxiv.org/abs/2503.21780v1) | Reza Qorbani, Gianluca Villani, Theodoros Panagiotakopoulos, Marc Botet Colomer, Linus H√§renstam-Nielsen, Mattia Segu, Pier Luigi Dovesi, Jussi Karlgren, Daniel Cremers, Federico Tombari, Matteo Poggi | 2025-03-27 | Optimization, Multimodal AI | Open-vocabulary semantic segmentation models associate vision and text to label pixels from an undefined set of classes using textual queries, providing versatile performance on novel datasets. However, large shifts between training and test domains degrade their performance, requiring fine-tuning for effective real-world applications. We introduce Semantic Library Adaptation (SemLA), a novel framework for training-free, test-time domain adaptation. SemLA leverages a library of LoRA-based adapters indexed with CLIP embeddings, dynamically merging the most relevant adapters based on proximity to the target domain in the embedding space. This approach constructs an ad-hoc model tailored to each specific input without additional training. Our method scales efficiently, enhances explainability by tracking adapter contributions, and inherently protects data privacy, making it ideal for sensitive applications. Comprehensive experiments on a 20-domain benchmark built over 10 standard datasets demonstrate SemLA's superior adaptability and performance across diverse settings, establishing a new standard in domain adaptation for open-vocabulary semantic segmentation. | [üîó Paper](http://arxiv.org/abs/2503.21780v1) |
| [X$^{2}$-Gaussian: 4D Radiative Gaussian Splatting for Continuous-time
  Tomographic Reconstruction](http://arxiv.org/abs/2503.21779v1) | Weihao Yu, Yuanhao Cai, Ruyi Zha, Zhiwen Fan, Chenxin Li, Yixuan Yuan | 2025-03-27 | Optimization | Four-dimensional computed tomography (4D CT) reconstruction is crucial for capturing dynamic anatomical changes but faces inherent limitations from conventional phase-binning workflows. Current methods discretize temporal resolution into fixed phases with respiratory gating devices, introducing motion misalignment and restricting clinical practicality. In this paper, We propose X$^2$-Gaussian, a novel framework that enables continuous-time 4D-CT reconstruction by integrating dynamic radiative Gaussian splatting with self-supervised respiratory motion learning. Our approach models anatomical dynamics through a spatiotemporal encoder-decoder architecture that predicts time-varying Gaussian deformations, eliminating phase discretization. To remove dependency on external gating devices, we introduce a physiology-driven periodic consistency loss that learns patient-specific breathing cycles directly from projections via differentiable optimization. Extensive experiments demonstrate state-of-the-art performance, achieving a 9.93 dB PSNR gain over traditional methods and 2.25 dB improvement against prior Gaussian splatting techniques. By unifying continuous motion modeling with hardware-free period learning, X$^2$-Gaussian advances high-fidelity 4D CT reconstruction for dynamic clinical imaging. Project website at: https://x2-gaussian.github.io/. | [üîó Paper](http://arxiv.org/abs/2503.21779v1) |
| [Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single
  Video](http://arxiv.org/abs/2503.21761v1) | David Yifan Yao, Albert J. Zhai, Shenlong Wang | 2025-03-27 | Optimization, Multimodal AI | This paper presents a unified approach to understanding dynamic scenes from casual videos. Large pretrained vision foundation models, such as vision-language, video depth prediction, motion tracking, and segmentation models, offer promising capabilities. However, training a single model for comprehensive 4D understanding remains challenging. We introduce Uni4D, a multi-stage optimization framework that harnesses multiple pretrained models to advance dynamic 3D modeling, including static/dynamic reconstruction, camera pose estimation, and dense 3D motion tracking. Our results show state-of-the-art performance in dynamic 4D modeling with superior visual quality. Notably, Uni4D requires no retraining or fine-tuning, highlighting the effectiveness of repurposing visual foundation models for 4D understanding. | [üîó Paper](http://arxiv.org/abs/2503.21761v1) |
| [Fwd2Bot: LVLM Visual Token Compression with Double Forward Bottleneck](http://arxiv.org/abs/2503.21757v1) | Adrian Bulat, Yassine Ouali, Georgios Tzimiropoulos | 2025-03-27 | Optimization | In this work, we aim to compress the vision tokens of a Large Vision Language Model (LVLM) into a representation that is simultaneously suitable for (a) generative and (b) discriminative tasks, (c) is nearly lossless, and (d) is storage-efficient. We propose a novel compression approach, called Fwd2Bot, that uses the LVLM itself to compress the visual information in a task-agnostic manner. At the core of Fwd2bot there exists a "double-forward pass" training strategy, whereby, during the first forward pass, the LLM (of the LVLM) creates a bottleneck by condensing the visual information into a small number of summary tokens. Then, using the same LLM, the second forward pass processes the language instruction(s) alongside the summary tokens, used as a direct replacement for the image ones. The training signal is provided by two losses: an autoregressive one applied after the second pass that provides a direct optimization objective for compression, and a contrastive loss, applied after the first pass, that further boosts the representation strength, especially for discriminative tasks. The training is further enhanced by stage-specific adapters. We accompany the proposed method by an in-depth ablation study. Overall, Fwd2Bot results in highly-informative compressed representations suitable for both generative and discriminative tasks. For generative tasks, we offer a 2x higher compression rate without compromising the generative capabilities, setting a new state-of-the-art result. For discriminative tasks, we set a new state-of-the-art on image retrieval and compositionality. | [üîó Paper](http://arxiv.org/abs/2503.21757v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Quantum enhanced parameter estimation with monitored quantum
  nonequilibrium systems using inefficient photo detection](http://arxiv.org/abs/2503.21753v1) | Albert Cabot, Federico Carollo, Igor Lesanovsky | 2025-03-27 | Scaling Laws | Many-body quantum systems hosting emergent collective behavior bear the promise to enable quantum enhanced parameter estimation. Formally this means that the variance of the parameter to be estimated decreases faster than $N^{-1}$, where $N$ is the number of particles forming the quantum system. In practice such scaling is challenging to achieve as the underlying many-body correlations are fragile. Moreover, devising the optimal measurements that indeed tap the quantum enhancement is often rather involved. Here we show that the inefficient detection of the photo emission from a dissipative quantum many-body system is sufficient to reach quantum enhanced parameter estimation even when some loss channels remain completely unmonitored. We illustrate our approach by considering the so-called boundary time-crystal, which is a nonequilibrium many-body system that has been realized recently experimentally in cold atomic gases. By analyzing the structure of the temporal correlations of its emission field, we are able to construct a family of near optimal parameter estimation measurements with a simple interferometric setup. | [üîó Paper](http://arxiv.org/abs/2503.21753v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Test-Time Visual In-Context Tuning](http://arxiv.org/abs/2503.21777v1) | Jiahao Xie, Alessio Tonioni, Nathalie Rauschmayr, Federico Tombari, Bernt Schiele | 2025-03-27 | Training & Evaluation | Visual in-context learning (VICL), as a new paradigm in computer vision, allows the model to rapidly adapt to various tasks with only a handful of prompts and examples. While effective, the existing VICL paradigm exhibits poor generalizability under distribution shifts. In this work, we propose test-time Visual In-Context Tuning (VICT), a method that can adapt VICL models on the fly with a single test sample. Specifically, we flip the role between the task prompts and the test sample and use a cycle consistency loss to reconstruct the original task prompt output. Our key insight is that a model should be aware of a new test distribution if it can successfully recover the original task prompts. Extensive experiments on six representative vision tasks ranging from high-level visual understanding to low-level image processing, with 15 common corruptions, demonstrate that our VICT can improve the generalizability of VICL to unseen new domains. In addition, we show the potential of applying VICT for unseen tasks at test time. Code: https://github.com/Jiahao000/VICT. | [üîó Paper](http://arxiv.org/abs/2503.21777v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Optimal Stepsize for Diffusion Sampling](http://arxiv.org/abs/2503.21774v1) | Jianning Pei, Han Hu, Shuyang Gu | 2025-03-27 | Model Evaluation, Optimization, Diffusion Models, Responsible AI | Diffusion models achieve remarkable generation quality but suffer from computational intensive sampling due to suboptimal step discretization. While existing works focus on optimizing denoising directions, we address the principled design of stepsize schedules. This paper proposes Optimal Stepsize Distillation, a dynamic programming framework that extracts theoretically optimal schedules by distilling knowledge from reference trajectories. By reformulating stepsize optimization as recursive error minimization, our method guarantees global discretization bounds through optimal substructure exploitation. Crucially, the distilled schedules demonstrate strong robustness across architectures, ODE solvers, and noise schedules. Experiments show 10x accelerated text-to-image generation while preserving 99.4% performance on GenEval. Our code is available at https://github.com/bebebe666/OptimalSteps. | [üîó Paper](http://arxiv.org/abs/2503.21774v1) |
| [Adiabatic quantum state preparation in integrable models](http://arxiv.org/abs/2503.21741v1) | Maximilian Lutz, Lorenzo Piroli, Georgios Styliaris, J. Ignacio Cirac | 2025-03-27 | Model Evaluation, Training & Evaluation | We propose applying the adiabatic algorithm to prepare high-energy eigenstates of integrable models on a quantum computer. We first review the standard adiabatic algorithm to prepare ground states in each magnetization sector of the prototypical XXZ Heisenberg chain. Based on the thermodynamic Bethe ansatz, we show that the algorithm circuit depth is polynomial in the number of qubits $N$, outperforming previous methods explicitly relying on integrability. Next, we propose a protocol to prepare arbitrary eigenstates of integrable models that satisfy certain conditions. For a given target eigenstate, we construct a suitable parent Hamiltonian written in terms of a complete set of local conserved quantities. We propose using such Hamiltonian as an input for an adiabatic algorithm. After benchmarking this construction in the case of the non-interacting XY spin chain, where we can rigorously prove its efficiency, we apply it to prepare arbitrary eigenstates of the Richardson-Gaudin models. In this case, we provide numerical evidence that the circuit depth of our algorithm is polynomial in $N$ for all eigenstates, despite the models being interacting. | [üîó Paper](http://arxiv.org/abs/2503.21741v1) |
## üîπ Production and Deployment

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [LOCORE: Image Re-ranking with Long-Context Sequence Modeling](http://arxiv.org/abs/2503.21772v1) | Zilin Xiao, Pavel Suma, Ayush Sachdeva, Hao-Jen Wang, Giorgos Kordopatis-Zilos, Giorgos Tolias, Vicente Ordonez | 2025-03-27 | Production and Deployment | We introduce LOCORE, Long-Context Re-ranker, a model that takes as input local descriptors corresponding to an image query and a list of gallery images and outputs similarity scores between the query and each gallery image. This model is used for image retrieval, where typically a first ranking is performed with an efficient similarity measure, and then a shortlist of top-ranked images is re-ranked based on a more fine-grained similarity measure. Compared to existing methods that perform pair-wise similarity estimation with local descriptors or list-wise re-ranking with global descriptors, LOCORE is the first method to perform list-wise re-ranking with local descriptors. To achieve this, we leverage efficient long-context sequence models to effectively capture the dependencies between query and gallery images at the local-descriptor level. During testing, we process long shortlists with a sliding window strategy that is tailored to overcome the context size limitations of sequence models. Our approach achieves superior performance compared with other re-rankers on established image retrieval benchmarks of landmarks (ROxf and RPar), products (SOP), fashion items (In-Shop), and bird species (CUB-200) while having comparable latency to the pair-wise local descriptor re-rankers. | [üîó Paper](http://arxiv.org/abs/2503.21772v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release
  Analytics](http://arxiv.org/abs/2503.21735v1) | Arsham Gholamzadeh Khoee, Shuai Wang, Yinan Yu, Robert Feldt, Dhasarathy Parthasarathy | 2025-03-27 | Responsible AI, Model Evaluation, Prompt Engineering, Training & Evaluation | Ensuring the reliability and effectiveness of software release decisions is critical, particularly in safety-critical domains like automotive systems. Precise analysis of release validation data, often presented in tabular form, plays a pivotal role in this process. However, traditional methods that rely on manual analysis of extensive test datasets and validation metrics are prone to delays and high costs. Large Language Models (LLMs) offer a promising alternative but face challenges in analytical reasoning, contextual understanding, handling out-of-scope queries, and processing structured test data consistently; limitations that hinder their direct application in safety-critical scenarios. This paper introduces GateLens, an LLM-based tool for analyzing tabular data in the automotive domain. GateLens translates natural language queries into Relational Algebra (RA) expressions and then generates optimized Python code. It outperforms the baseline system on benchmarking datasets, achieving higher F1 scores and handling complex and ambiguous queries with greater robustness. Ablation studies confirm the critical role of the RA module, with performance dropping sharply when omitted. Industrial evaluations reveal that GateLens reduces analysis time by over 80% while maintaining high accuracy and reliability. As demonstrated by presented results, GateLens achieved high performance without relying on few-shot examples, showcasing strong generalization across various query types from diverse company roles. Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation. Results show that by automating test result analysis, GateLens enables faster, more informed, and dependable release decisions, and can thus advance software scalability and reliability in automotive systems. | [üîó Paper](http://arxiv.org/abs/2503.21735v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [HS-SLAM: Hybrid Representation with Structural Supervision for Improved
  Dense SLAM](http://arxiv.org/abs/2503.21778v1) | Ziren Gong, Fabio Tosi, Youmin Zhang, Stefano Mattoccia, Matteo Poggi | 2025-03-27 | General AI | NeRF-based SLAM has recently achieved promising results in tracking and reconstruction. However, existing methods face challenges in providing sufficient scene representation, capturing structural information, and maintaining global consistency in scenes emerging significant movement or being forgotten. To this end, we present HS-SLAM to tackle these problems. To enhance scene representation capacity, we propose a hybrid encoding network that combines the complementary strengths of hash-grid, tri-planes, and one-blob, improving the completeness and smoothness of reconstruction. Additionally, we introduce structural supervision by sampling patches of non-local pixels rather than individual rays to better capture the scene structure. To ensure global consistency, we implement an active global bundle adjustment (BA) to eliminate camera drifts and mitigate accumulative errors. Experimental results demonstrate that HS-SLAM outperforms the baselines in tracking and reconstruction accuracy while maintaining the efficiency required for robotics. | [üîó Paper](http://arxiv.org/abs/2503.21778v1) |
| [Simulating quantum circuits with restricted quantum computers](http://arxiv.org/abs/2503.21773v1) | Christophe Piveteau | 2025-03-27 | General AI | It is one of the most fundamental objectives in quantum information science to understand the boundary between the computational power of classical and quantum computers. One possible avenue to explore this boundary is to identify classes of quantum circuits that can be efficiently simulated on a classical computer. Instead of simulating a general quantum circuit with a classical device, new schemes have recently emerged to simulate them on a quantum device that is restricted in some manner. As such, these techniques allow us to study how the restrictions impact the computational power of the device. One such technique is called quasiprobability simulation (QPS) and it estimates the result of a quantum circuit with a Monte Carlo procedure that randomly replaces circuit elements with ones that can be executed on the restricted quantum device.   The main focus of this thesis is dedicated to the QPS-based simulation of nonlocal quantum computation using local quantum operations. On the practical side, this enables the simulation of large quantum circuits using multiple smaller quantum devices - a procedure that is sometimes called circuit knitting. We uncover a rich mathematical formalism with many connections to the resource theory of entanglement. We characterize the optimal simulation overhead for a broad range of practically relevant nonlocal states and channels and we explicitly provide achieving protocols. Moreover, we also investigate the utility of classical communication between the local parties. Our results address both the single-shot and asymptotic regime.   We frame QPS in a quantum resource theoretic framework, which highlights similarities that arise in the different instantiations of the technique. Furthermore, we study the importance of classical side information in the QPS procedure and how it impacts the overhead and expressibility of QPS. | [üîó Paper](http://arxiv.org/abs/2503.21773v1) |
| [Visual Jenga: Discovering Object Dependencies via Counterfactual
  Inpainting](http://arxiv.org/abs/2503.21770v1) | Anand Bhattad, Konpat Preechakul, Alexei A. Efros | 2025-03-27 | General AI | This paper proposes a novel scene understanding task called Visual Jenga. Drawing inspiration from the game Jenga, the proposed task involves progressively removing objects from a single image until only the background remains. Just as Jenga players must understand structural dependencies to maintain tower stability, our task reveals the intrinsic relationships between scene elements by systematically exploring which objects can be removed while preserving scene coherence in both physical and geometric sense. As a starting point for tackling the Visual Jenga task, we propose a simple, data-driven, training-free approach that is surprisingly effective on a range of real-world images. The principle behind our approach is to utilize the asymmetry in the pairwise relationships between objects within a scene and employ a large inpainting model to generate a set of counterfactuals to quantify the asymmetry. | [üîó Paper](http://arxiv.org/abs/2503.21770v1) |
| [Kondo-lattice phenomenology of twisted bilayer WSe$_2$ from compact
  molecular orbitals of topological bands](http://arxiv.org/abs/2503.21769v1) | Fang Xie, Chenyuan Li, Jennifer Cano, Qimiao Si | 2025-03-27 | General AI | The discovery of superconductivity and correlated electronic phases in twisted bilayer WSe$_2$ (Xia et al., Nature 2024; Guo et al., Nature 2025) has generated considerable excitement. Accompanying the superconductivity and a correlated insulator phase is the Kondo-lattice-like phenomenology in transport properties. Here we consider how such phenomenology can develop when the combination of the active bands are topological. We advance a unique construction of compact molecular orbitals through a partial Wannierization that is symmetry preserving. The resulting Anderson lattice model provides the basis for a microscopic understanding of the experimental observation, including the involved energy scales. Our approach may apply to a broad range of settings where topology and correlations interplay. | [üîó Paper](http://arxiv.org/abs/2503.21769v1) |
| [Results on branching random walks and rumor processes via germ order](http://arxiv.org/abs/2503.21768v1) | Daniela Bertacchi, Fabio Zucca | 2025-03-27 | General AI | Germ order is a non-standard stochastic order defined through the comparison of the generating functions of the processes. This order was first introduced for branching random walks with a constant breeding law and independent dispersal of offspring, which are characterized by a one-dimensional generating function. In this work, we investigate the properties of the extension of this concept to processes characterized by a multidimensional generating function, such as general branching random walks and rumor processes. In particular, we use germ ordering to characterize the behavior of certain branching random walks and rumor processes with inhomogeneous breeding/transmitting laws. | [üîó Paper](http://arxiv.org/abs/2503.21768v1) |
| [Semantic Consistent Language Gaussian Splatting for Point-Level
  Open-vocabulary Querying](http://arxiv.org/abs/2503.21767v1) | Hairong Yin, Huangying Zhan, Yi Xu, Raymond A. Yeh | 2025-03-27 | General AI | Open-vocabulary querying in 3D Gaussian Splatting aims to identify semantically relevant regions within a 3D Gaussian representation based on a given text query. Prior work, such as LangSplat, addressed this task by retrieving these regions in the form of segmentation masks on 2D renderings. More recently, OpenGaussian introduced point-level querying, which directly selects a subset of 3D Gaussians. In this work, we propose a point-level querying method that builds upon LangSplat's framework. Our approach improves the framework in two key ways: (a) we leverage masklets from the Segment Anything Model 2 (SAM2) to establish semantic consistent ground-truth for distilling the language Gaussians; (b) we introduces a novel two-step querying approach that first retrieves the distilled ground-truth and subsequently uses the ground-truth to query the individual Gaussians. Experimental evaluations on three benchmark datasets demonstrate that the proposed method achieves better performance compared to state-of-the-art approaches. For instance, our method achieves an mIoU improvement of +20.42 on the 3D-OVS dataset. | [üîó Paper](http://arxiv.org/abs/2503.21767v1) |
| [Phases with non-invertible symmetries in 1+1D $\unicode{x2013}$ symmetry
  protected topological orders as duality automorphisms](http://arxiv.org/abs/2503.21764v2) | √ñmer M. Aksoy, Xiao-Gang Wen | 2025-03-27 | General AI | We explore 1+1 dimensional (1+1D) gapped phases in systems with non-invertible symmetries, focusing on symmetry-protected topological (SPT) phases (defined as gapped phases with non-degenerate ground states), as well as SPT orders (defined as the differences between gapped/gapless phases with identical bulk excitations spectrum). For group-like symmetries, distinct SPT phases share identical bulk excitations and always differ by SPT orders. However, for certain non-invertible symmetries, we discover novel SPT phases that have different bulk excitations and thus do not differ by SPT orders. Additionally, we also study the spontaneous symmetry-breaking (SSB) phases of non-invertible symmetries. Unlike group-like symmetries, non-invertible symmetries lack the concept of subgroups, which complicates the definition of SSB phases as well as their identification. This challenge can be addressed by employing the symmetry-topological-order (symTO) framework for the symmetry. The Lagrangian condensable algebras and automorphisms of the symTO facilitate the classification of gapped phases in systems with such symmetries, enabling the analysis of both SPT and SSB phases (including those that differ by SPT orders). Finally, we apply this methodology to investigate gapless phases in symmetric systems and to study gapless phases differing by SPT orders. | [üîó Paper](http://arxiv.org/abs/2503.21764v2) |
| [Identification and estimation of treatment effects in a linear factor
  model with fixed number of time periods](http://arxiv.org/abs/2503.21763v1) | Koki Fusejima, Takuya Ishihara | 2025-03-27 | General AI | This paper provides a new approach for identifying and estimating the Average Treatment Effect on the Treated under a linear factor model that allows for multiple time-varying unobservables. Unlike the majority of the literature on treatment effects in linear factor models, our approach does not require the number of pre-treatment periods to go to infinity to obtain a valid estimator. Our identification approach employs a certain nonlinear transformations of the time invariant observed covariates that are sufficiently correlated with the unobserved variables. This relevance condition can be checked with the available data on pre-treatment periods by validating the correlation of the transformed covariates and the pre-treatment outcomes. Based on our identification approach, we provide an asymptotically unbiased estimator of the effect of participating in the treatment when there is only one treated unit and the number of control units is large. | [üîó Paper](http://arxiv.org/abs/2503.21763v1) |
| [On the open TS/ST correspondence](http://arxiv.org/abs/2503.21762v1) | Matijn Fran√ßois, Alba Grassi | 2025-03-27 | General AI | The topological string/spectral theory correspondence establishes a precise, non-perturbative duality between topological strings on local Calabi-Yau threefolds and the spectral theory of quantized mirror curves. While this duality has been rigorously formulated for the closed topological string sector, the open string sector remains less understood. Building on the results of [1-3], we make further progress in this direction by constructing entire, off-shell eigenfunctions for the quantized mirror curve from open topological string partition functions. We focus on local $\mathbb{F}_0$, whose mirror curve corresponds to the Baxter equation of the two-particle, relativistic Toda lattice. We then study the standard and dual four-dimensional limits, where the quantum mirror curve for local $\mathbb{F}_0$ degenerates into the modified Mathieu and McCoy-Tracy-Wu operators, respectively. In these limits, our framework provides a way to construct entire, off-shell eigenfunctions for the difference equations associated with these operators. Furthermore, we find a simple relation between the on-shell eigenfunctions of the modified Mathieu and McCoy-Tracy-Wu operators, leading to a functional relation between the operators themselves. | [üîó Paper](http://arxiv.org/abs/2503.21762v1) |
| [Large Scale Structure and the Cosmic Web](http://arxiv.org/abs/2503.21759v1) | Rita Tojeiro, Katarina Kraljic | 2025-03-27 | General AI | The formation and evolution of galaxies cannot be separated from large scale structure growth. Dark matter halos (and, therefore, galaxies) form and grow within the cosmic web - the classification of large-scale structure as distinct environments, namely voids, walls, filaments and nodes. Thanks to the rapid development of extragalactic spectroscopic redshift surveys and cosmological simulations over the last two decades, we are now able to measure the impact of the cosmic web on galaxies and halos in observations and in simulations. In this chapter we summarise the state of play in our understanding of the link between dark matter halos, galaxies, and the cosmic web. | [üîó Paper](http://arxiv.org/abs/2503.21759v1) |
| [Differential and symbolic powers of ideals](http://arxiv.org/abs/2503.21754v1) | Alessandro De Stefani, Elo√≠sa Grifo, Jack Jeffries | 2025-03-27 | General AI | We characterize symbolic powers of prime ideals in polynomial rings over any field in terms of $\mathbb{Z}$-linear differential operators, and of prime ideals in polynomial rings over complete discrete valuation rings with a $p$-derivation $\delta$ in terms of $\mathbb{Z}$-linear differential operators and of $\delta$. This extends previous work of the same authors, as it allows the removal of separability hypotheses that were otherwise necessary. The absence of separability and the fact that modules of $\mathbb{Z}$-linear differential operators are typically not finitely generated require the introduction of new techniques. As a byproduct, we extend a characterization of symbolic powers due to Cid-Ruiz which also holds in the nonsmooth case. Finally, we produce an example of an unramified discrete valuation ring that has no $p$-derivations. | [üîó Paper](http://arxiv.org/abs/2503.21754v1) |
| [Hypergraphic zonotopes and acyclohedra](http://arxiv.org/abs/2503.21752v1) | Cosmin Pohoata, Daniel G. Zhu | 2025-03-27 | General AI | We introduce a higher-uniformity analogue of graphic zonotopes and permutohedra. Specifically, given a $(d+1)$-uniform hypergraph $H$, we define its hypergraphic zonotope $\mathcal{Z}_H$, and when $H$ is the complete $(d+1)$-uniform hypergraph $K^{(d+1)}_n$, we call its hypergraphic zonotope the acyclohedron $\mathcal{A}_{n,d}$.   We express the volume of $\mathcal{Z}_H$ as a homologically weighted count of the spanning $d$-dimensional hypertrees of $H$, which is closely related to Kalai's generalization of Cayley's theorem in the case when $H=K^{(d+1)}_n$ (but which, curiously, is not the same). We also relate the vertices of hypergraphic zonotopes to a notion of acyclic orientations previously studied by Linial and Morganstern for complete hypergraphs. | [üîó Paper](http://arxiv.org/abs/2503.21752v1) |
| [Optical control of orbital magnetism in magic angle twisted bilayer
  graphene](http://arxiv.org/abs/2503.21750v1) | Eylon Persky, Minhao He, Jiaqi Cai, Takashi Taniguchi, Kenji Watanabe, Xiaodong Xu, Aharon Kapitulnik | 2025-03-27 | General AI | Flat bands in graphene-based moir\'e structures host a wide range of emerging strongly correlated and topological phenomena. Optically probing and controlling them can reveal important information such as symmetry and dynamics, but have so far been challenging due to the small energy gap compared to optical wavelengths. Here, we report near infrared optical control of orbital magnetism and associated anomalous Hall effects (AHE) in a magic angle twisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the properties of the AHE, such as hysteresis and amplitude, can be controlled by light near integer moir\'e fillings, where spontaneous ferromagnetism exists. By modulating the light helicity, we observe periodic modulation of the transverse resistance in a wide range of fillings, indicating light induced orbital magnetization through a large inverse Faraday effect. At the transition between metallic and AHE regimes, we also reveal large and random switching of the Hall resistivity, which are attributed to optical control of percolating cluster of magnetic domains. Our results open the door to optical manipulation of correlation and topology in MATBG and related structures. | [üîó Paper](http://arxiv.org/abs/2503.21750v1) |
| [Extracting energy via bosonic Gaussian operations](http://arxiv.org/abs/2503.21748v1) | Frank Ernesto Quintela Rodriguez, Francesco Anna Mele, Salvatore Francesco Emanuele Oliviero, Vittorio Giovannetti, Ludovico Lami, Vasco Cavina | 2025-03-27 | General AI | Quantum thermodynamics is often formulated as a theory with constrained access to operations and resources. In this manuscript, we find a closed formula for the Gaussian ergotropy, i.e. the maximum energy that can be extracted from bosonic systems governed by quadratic Hamiltonians by means of Gaussian unitaries only. This formula resembles the well-known eigenvalue-based expression for the standard ergotropy, but is instead formulated using symplectic eigenvalues. We further prove that the Gaussian ergotropy is additive, indicating that the multiple-copy scenario does not benefit from Gaussian entangling operations. Extending our analysis to the relationship between ergotropic and entropic functions, we establish bounds linking entropic measures of Gaussianity to extractable work. Finally, we generalise our framework to open systems by studying the optimal state preparation that minimises the energy output in a Gaussian channel. | [üîó Paper](http://arxiv.org/abs/2503.21748v1) |
| [Effects of dissipation on phase diagram and bosonic excitations in the
  quark-meson model](http://arxiv.org/abs/2503.21746v1) | Johannes V. Roth, Yunxin Ye, S√∂ren Schlichting, Lorenz von Smekal | 2025-03-27 | General AI | In this work we study the quark-meson model within a real-time formulation of the functional renormalization group (FRG) on the Schwinger-Keldysh contour. First, we discuss in detail the symmetry of thermal equilibrium for the fermionic sector of the Keldysh action. We take into account dissipation for the bosonic degrees of freedom in the spirit of the Caldeira-Leggett model by coupling the system to an $O(4)$ invariant external heat bath. We study the effect of dissipation on static equilibrium properties, most prominently on the FRG flow of the effective potential and thus on the resulting phase diagram. We find that, unlike in classical systems, through the contributions from non-zero Matsubara modes the dissipative dynamics can in general have an effect on static observables. We investigate these effects within two phenomenological models for the temperature dependence of the pion damping to verify that they are quantitatively small. To estimate their largest possible influence, we consider limits where the damping constants approach infinity. | [üîó Paper](http://arxiv.org/abs/2503.21746v1) |
| [Expectation for the MeV Gamma-Ray Emission from Pair-Instability
  Supernovae](http://arxiv.org/abs/2503.21744v1) | Ryo Sawada | 2025-03-27 | General AI | Pair-instability supernovae (PISNe) are predicted thermonuclear explosions of massive stars with helium core masses exceeding $\sim 65M_\odot$ and synthesize substantial amounts of radioactive $\mathrm{^{56}Ni}$ ($M(\mathrm{^{56}Ni})\sim60M_\odot$ in extreme cases). To investigate their observational signatures, we developed a 1D Monte Carlo radiation transport code and performed simulations of gamma-ray and hard X-ray emissions from the decay chain $\mathrm{^{56}Ni}\to\mathrm{^{56}Co}\to\mathrm{^{56}Fe}$. We find that key gamma-ray lines (847 and 1238 keV) from $\mathrm{^{56}Co}$ decay in the $130M_\odot$ helium core model can be detected up to 300-400 Mpc by next-generation MeV gamma-ray telescopes. In contrast, the signals from the $100M_\odot$ model remain below the detection limits. Our results provide the template for gamma-ray follow-up observations of PISNe. Considering theoretical predictions and observational constraints, we estimate PISN event rates within 300 Mpc to be approximately 0.1 events per year, highlighting their rarity but also emphasizing their feasibility as targets for future gamma-ray observations over the decade. | [üîó Paper](http://arxiv.org/abs/2503.21744v1) |
| [Three-Dimensional Stacking as a Line Intensity Mapping Statistic](http://arxiv.org/abs/2503.21743v1) | D. A. Dunne, K. A. Cleary, P. C. Breysse, D. T. Chung, H. T. Ihle, J. G. S. Lunde, H. Padmanabhan, N. -O. Stutzer, J. R. Bond, J. O. Gundersen, J. Kim, A. C. S. Readhead | 2025-03-27 | General AI | Line-intensity mapping (LIM) is a growing technique that measures the integrated spectral-line emission from unresolved galaxies over a three-dimensional region of the Universe. Although LIM experiments ultimately aim to provide powerful cosmological constraints via auto-correlation, many LIM experiments are also designed to take advantage of overlapping galaxy surveys, enabling joint analyses of the two datasets. We introduce a flexible simulation pipeline that can generate mock galaxy surveys and mock LIM data simultaneously for the same population of simulated galaxies. Using this pipeline, we explore a simple joint analysis technique: three-dimensional co-addition (stacking) of LIM data on the positions of galaxies from a traditional galaxy catalogue. We test how the output of this technique reacts to changes in experimental design of both the LIM experiment and the galaxy survey, its sensitivity to various astrophysical parameters, and its susceptibility to common systematic errors. We find that an ideal catalogue for a stacking analysis targets as many high-mass dark matter halos as possible. We also find that the signal in a LIM stacking analysis originates almost entirely from the large-scale clustering of halos around the catalogue objects, rather than the catalogue objects themselves. While stacking is a sensitive and conceptually simple way to achieve a LIM detection, thus providing a valuable way to validate a LIM auto-correlation detection, it will likely require a full cross-correlation to achieve further characterization of the galaxy tracers involved, as the cosmological and astrophysical parameters we explore here have degenerate effects on the stack. | [üîó Paper](http://arxiv.org/abs/2503.21743v1) |
| [Les Houches lectures on non-perturbative Seiberg-Witten geometry](http://arxiv.org/abs/2503.21742v1) | Lo√Øc Bramley, Lotte Hollands, Subrabalan Murugesan | 2025-03-27 | General AI | In these lectures we detail the interplay between the low-energy dynamics of quantum field theories with four supercharges and the exact WKB analysis. This exposition may be the first comprehensive account of this connection, containing various novel arguments and illustrative examples.   The lectures start with the introduction of massive two-dimensional $\mathcal{N}=(2,2)$ theories and their spectra of BPS solitons. We place these theories in a two-dimensional cigar background with supersymmetric boundary conditions labelled by a phase $\zeta = e^{i \vartheta}$, while turning on the two-dimensional $\Omega$-background with parameter~$\epsilon$. We show that the resulting partition function $\mathcal{Z}_{\mathrm{2d}}^\vartheta(\epsilon)$ can be characterized as the Borel-summed solution, in the direction $\vartheta$, to an associated Schr\"odinger equation. The partition function $\mathcal{Z}_{\mathrm{2d}}^\vartheta(\epsilon)$ is locally constant in the phase $\vartheta$ and jumps across phases $\vartheta_\textrm{BPS}$ associated with the BPS solitons. Since these jumps are non-perturbative in the parameter~$\epsilon$, we refer to $Z^\vartheta_\mathrm{2d}(\epsilon)$ as the non-perturbative partition function for the original two-dimensional $\mathcal{N}=(2,2)$ theory. We completely determine this partition function $\mathcal{Z}^\vartheta_\mathrm{2d}(\epsilon)$ in two classes of examples, Landau-Ginzburg models and gauged linear sigma models, and show that $\mathcal{Z}^\vartheta_\mathrm{2d}(\epsilon)$ encodes the well-known vortex partition function at a special phase $\vartheta_\textrm{FN}$ associated with the presence of self-solitons. This analysis generalizes to four-dimensional $\mathcal{N}=2$ theories in the $\frac{1}{2} \Omega$-background. | [üîó Paper](http://arxiv.org/abs/2503.21742v1) |
| [Transitioning to Memory Burden: Detectable Small Primordial Black Holes
  as Dark Matter](http://arxiv.org/abs/2503.21740v1) | Gia Dvali, Michael Zantedeschi, Sebastian Zell | 2025-03-27 | General AI | Mounting theoretical evidence suggests that black holes are subjected to the memory burden effect, implying that after certain time the information stored in them suppresses the decay rate. This effect opens up a new window for small primordial black holes (PBHs) below $10^{15}\,{\rm g}$ as dark matter. We show that the smooth transition from semi-classical evaporation to the memory-burdened phase strongly impacts observational bounds on the abundance of small PBHs. The most stringent constraints come from present-day fluxes of astrophysical particles. Remarkably, currently-transitioning small PBHs are detectable through high-energetic neutrino events. | [üîó Paper](http://arxiv.org/abs/2503.21740v1) |
| [Emergent Non-Markovian Gain in Open Quantum Systems](http://arxiv.org/abs/2503.21739v1) | H. Z. Shen, Cheng Shang, Yan-Hui Zhou, X. X. Yi | 2025-03-27 | General AI | Non-Markovian dynamics go beyond the Markovian approximation by capturing memory effects and information backflow in open quantum systems, which are crucial for describing realistic physical processes. In this work, we study the exact non-Markovian dynamics of a driven cavity coupled to an anisotropic three-dimensional photonic-crystal environment via counterrotating-wave interactions. We derive an exact analytical expression for the cavity amplitude satisfying the integro-differential equation, which includes the contributions of the bound states outside the continuum and the dissipative parts with the continuum spectrum. Based on the characteristic function method, we derive the exact non-Markovian master equation for the cavity, which contributes to the gain of the cavity. We give the physical origin of non-Markovian gain in the presence of bound states in the system consisting of cavity and environment, which has no Markovian counterparts due to the nonexponential gain in the non-Markovian structured environment. We find that three different types of bound states can be formed in the system, containing one bound state with no inversion of photon number, two bound states with the periodic equal-amplitude oscillation, and the gain with two complex roots without the bound states formation. We derive a current equation including the source from the driving field, the transient current induced by the change in the number of photons, and the two-photon current caused by the counterrotating-wave term. The results are compared with those given by the rotating-wave interactions and extended to a more general quantum network involving an arbitrary number of coupled cavities. Our findings may pave the way for a deeper understanding of non-Markovian dynamics with gain in quantum networks involving counterrotating-wave effects. | [üîó Paper](http://arxiv.org/abs/2503.21739v1) |
| [Galaxy Morphologies at Cosmic Noon with JWST : A Foundation for
  Exploring Gas Transport with Bars and Spiral Arms](http://arxiv.org/abs/2503.21738v1) | Juan M. Espejo Salcedo, Stavros Pastras, Josef V√°cha, Claudia Pulsoni, Reinhard Genzel, N. M. F√∂rster Schreiber, Jean-Baptiste Jolly, Capucine Barfety, Jianhang Chen, Giulia Tozzi, Daizhong Liu, Lilian Lee, Stijn Wuyts, Linda Tacconi, Ric Davies, Hannah √úbler, Dieter Lutz, Emily Wisnioski, Jinyi Shangguan, Minju Lee, H. Sedona Price, Frank Eisenhauer, Alvio Renzini, Amit Nestor Shachar, Rodrigo Herrera-Camus | 2025-03-27 | General AI | How radial flows shape galaxy structure and evolution remains an open question. Internal drivers of such flows, such as bars and spiral arms, known to mediate gas flows in the local Universe, are now observable at high redshift thanks to JWST's unobscured view. We investigate the morphology of massive star-forming galaxies at 0.8 < z < 1.3 and 2.0 < z < 2.5, epochs marking the peak and decline of cosmic star formation, both well-covered by kinematic surveys. Using JWST/NIRCam imaging, we visually classify 1,451 galaxies, identify non-axisymmetric features, count the number of spiral arms, analyze non-parametric morphological indicators and study the dynamical support of the sample covered by kinematics (10% of the sample) as measured via v/{\sigma}. Disk galaxies dominate the sample (82%), with 48% exhibiting spiral structure and 11% hosting bars. Both fractions decline with redshift, consistent with previous studies. The proportion of two- and three-armed spirals remains largely unchanged across redshift, with roughly two-thirds showing two arms and one-third showing three arms in both bins. Notably, we find a higher incidence of three-armed spirals than reported in the local Universe, suggesting a mild evolution in spiral arm multiplicity. Non-parametric morphological metrics strongly correlate with stellar mass but show no significant redshift evolution. Finally, kinematic analysis reveals a strong correlation between disk morphology and rotational support, with most disks exhibiting v/{\sigma} > 3 and median values of v/{\sigma} > 7 for spirals and v/{\sigma} > 5 for barred galaxies. This study establishes a population-wide framework for linking galaxy morphology and dynamics at cosmic noon, providing a key reference for future studies on the role of detailed structural features in galaxy evolution. | [üîó Paper](http://arxiv.org/abs/2503.21738v1) |
| [High-intensity Voronoi percolation on manifolds](http://arxiv.org/abs/2503.21737v1) | Tillmann B√ºhler, Barbara Dembin, Ritvik Ramanan Radhakrishnan, Franco Severo | 2025-03-27 | General AI | We study Voronoi percolation on a large class of $d$-dimensional Riemannian manifolds, which includes hyperbolic space $\mathbb{H}^d$ for $d\geq 2$. We prove that as the intensity $\lambda$ of the underlying Poisson point process tends to infinity, both critical parameters $p_c(M,\lambda)$ and $p_u(M,\lambda)$ converge to the Euclidean critical parameter $p_c(\mathbb{R}^d)$. This extends a recent result of Hansen & M\"uller in the special case $M=\mathbb{H}^2$ to a general class of manifolds of arbitrary dimension. A crucial step in our proof, which may be of independent interest, is to show that if $M$ is simply connected and one-ended, then embedded graphs induced by a general class of tessellations on $M$ have connected minimal cutsets. In particular, this result applies to $\varepsilon$-nets, allowing us to implement a "fine-graining" argument. We also develop an annealed way of exploring the Voronoi cells that we use to characterize the uniqueness phase. | [üîó Paper](http://arxiv.org/abs/2503.21737v1) |
| [Structure and Melting of Fe, MgO, SiO2, and MgSiO3 in Planets: Database,
  Inversion, and Phase Diagram](http://arxiv.org/abs/2503.21734v1) | Junjie Dong, Gabriel-Darius Mardaru, Paul D. Asimow, Lars P. Stixrude, Rebecca A. Fischer | 2025-03-27 | General AI | We present globally inverted pressure-temperature (P-T) phase diagrams up to 5,000 GPa for four fundamental planetary materials, Fe, MgO, SiO2, and MgSiO3, derived from logistic regression and supervised learning, together with an experimental phase equilibria database. These new P-T phase diagrams provide a solution to long-standing disputes about their melting curves. Their implications extend to the melting and freezing of rocky materials in the interior of giant planets and super-Earth exoplanets, contributing to the refinement of their internal structure models. | [üîó Paper](http://arxiv.org/abs/2503.21734v1) |
| [Fully dynamic biconnectivity in $\tilde{\mathcal{O}}(\log^2 n)$ time](http://arxiv.org/abs/2503.21733v1) | Jacob Holm, Wojciech Nadara, Eva Rotenberg, Marek Soko≈Çowski | 2025-03-27 | General AI | We present a deterministic fully-dynamic data structure for maintaining information about the cut-vertices in a graph; i.e. the vertices whose removal would disconnect the graph. Our data structure supports insertion and deletion of edges, as well as queries to whether a pair of connected vertices are either biconnected, or can be separated by a cutvertex, and in the latter case we support access to separating cutvertices. All update operations are supported in amortized $O(\log^2 n \log^2 \log n)$ time, and queries take worst-case $O(\log n \log^2 \log n)$ time. Note that these time bounds match the current best for deterministic dynamic connectivity up to $\log \log n$ factors.   We obtain our improved running time by a series of reductions from the original problem into well-defined data structure problems. While we do apply the well-known techniques for improving running time of two-edge connectivity [STOC'00, SODA'18], these techniques alone do not lead to an update time of $\tilde{O}(\log^3 n)$, let alone the $\tilde{O}(\log^2 n)$ we give as a final result.   Our contributions include a formally defined transient expose operation, which can be thought of as a cheaper read-only expose operation on a top tree. For each vertex in the graph, we maintain a data structure over its neighbors, and in this data structure we apply biasing (twice) to save two $\tilde{O}(\log n)$ factors. One of these biasing techniques is a new biased disjoint sets data structure, which may be of independent interest. Moreover, in this neighborhood data structure, we facilitate that the vertex can select two VIP neighbors that get special treatment, corresponding to its potentially two neighbors on an exposed path, improving a $\log n$-time operation down to constant time. It is this combination of VIP neighbors with the transient expose that saves an $\tilde{O}(\log n)$-factor from another bottleneck. | [üîó Paper](http://arxiv.org/abs/2503.21733v1) |
