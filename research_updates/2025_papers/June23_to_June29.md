# üìå AI Research Papers (June23 to June29)

## üîπ LLM

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Whole-Body Conditioned Egocentric Video Prediction](http://arxiv.org/abs/2506.21552v1) | Yutong Bai, Danny Tran, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik | 2025-06-26 | LLM, Multimodal AI, Training & Evaluation, Diffusion Models | We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human. | [üîó Paper](http://arxiv.org/abs/2506.21552v1) |
| [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and
  Model Selection at Scale](http://arxiv.org/abs/2506.21550v1) | Xiaona Zhou, Constantin Brif, Ismini Lourentzou | 2025-06-26 | LLM, Training & Evaluation, Security & Adversarial ML, Model Evaluation | Multivariate time series anomaly detection (MTS-AD) is critical in domains like healthcare, cybersecurity, and industrial monitoring, yet remains challenging due to complex inter-variable dependencies, temporal dynamics, and sparse anomaly labels. We introduce mTSBench, the largest benchmark to date for MTS-AD and unsupervised model selection, spanning 344 labeled time series across 19 datasets and 12 diverse application domains. mTSBench evaluates 24 anomaly detection methods, including large language model (LLM)-based detectors for multivariate time series, and systematically benchmarks unsupervised model selection techniques under standardized conditions. Consistent with prior findings, our results confirm that no single detector excels across datasets, underscoring the importance of model selection. However, even state-of-the-art selection methods remain far from optimal, revealing critical gaps. mTSBench provides a unified evaluation suite to enable rigorous, reproducible comparisons and catalyze future advances in adaptive anomaly detection and robust model selection. | [üîó Paper](http://arxiv.org/abs/2506.21550v1) |
| [PsyLite Technical Report](http://arxiv.org/abs/2506.21536v1) | Fangjun Ding, Renyu Zhang, Xinyu Feng, Chengye Xie, Zheng Zhang, Yanting Zhang | 2025-06-26 | LLM, Optimization, Training & Evaluation | With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\%) and dialogue safety (\safe{} score improvement of 2.4\%). Additionally, the model uses quantization technology (GGUF q4\_k\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments. | [üîó Paper](http://arxiv.org/abs/2506.21536v1) |
## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised
  Multi-View Diffusion](http://arxiv.org/abs/2506.21544v1) | Yansong Qu, Shaohui Dai, Xinyang Li, Yuze Wang, You Shen, Liujuan Cao, Rongrong Ji | 2025-06-26 | Diffusion Models | Reconstructing 3D objects from a single image is a long-standing challenge, especially under real-world occlusions. While recent diffusion-based view synthesis models can generate consistent novel views from a single RGB image, they generally assume fully visible inputs and fail when parts of the object are occluded. This leads to inconsistent views and degraded 3D reconstruction quality. To overcome this limitation, we propose an end-to-end framework for occlusion-aware multi-view generation. Our method directly synthesizes six structurally consistent novel views from a single partially occluded image, enabling downstream 3D reconstruction without requiring prior inpainting or manual annotations. We construct a self-supervised training pipeline using the Pix2Gestalt dataset, leveraging occluded-unoccluded image pairs and pseudo-ground-truth views to teach the model structure-aware completion and view consistency. Without modifying the original architecture, we fully fine-tune the view synthesis model to jointly learn completion and multi-view generation. Additionally, we introduce the first benchmark for occlusion-aware reconstruction, encompassing diverse occlusion levels, object categories, and mask patterns. This benchmark provides a standardized protocol for evaluating future methods under partial occlusions. Our code is available at https://github.com/Quyans/DeOcc123. | [üîó Paper](http://arxiv.org/abs/2506.21544v1) |
## üîπ RLHF

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [MADrive: Memory-Augmented Driving Scene Modeling](http://arxiv.org/abs/2506.21520v1) | Polina Karpikova, Daniil Selikhanovych, Kirill Struminsky, Ruslan Musaev, Maria Golitsyna, Dmitry Baranchuk | 2025-06-26 | RLHF, Multimodal AI | Recent advances in scene reconstruction have pushed toward highly realistic modeling of autonomous driving (AD) environments using 3D Gaussian splatting. However, the resulting reconstructions remain closely tied to the original observations and struggle to support photorealistic synthesis of significantly altered or novel driving scenarios. This work introduces MADrive, a memory-augmented reconstruction framework designed to extend the capabilities of existing scene reconstruction methods by replacing observed vehicles with visually similar 3D assets retrieved from a large-scale external memory bank. Specifically, we release MAD-Cars, a curated dataset of ${\sim}70$K 360{\deg} car videos captured in the wild and present a retrieval module that finds the most similar car instances in the memory bank, reconstructs the corresponding 3D assets from video, and integrates them into the target scene through orientation alignment and relighting. The resulting replacements provide complete multi-view representations of vehicles in the scene, enabling photorealistic synthesis of substantially altered configurations, as demonstrated in our experiments. Project page: https://yandex-research.github.io/madrive/ | [üîó Paper](http://arxiv.org/abs/2506.21520v1) |
| [Mitigating Hallucination of Large Vision-Language Models via Dynamic
  Logits Calibration](http://arxiv.org/abs/2506.21509v1) | Jiahe Chen, Jiaying He, Qian Shao, Qiyuan Chen, Jiahe Ying, Hongxia Xu, Jintai Chen, Jianwei Zheng, Jian Wu | 2025-06-26 | RLHF, Responsible AI, Multimodal AI, Model Evaluation | Large Vision-Language Models (LVLMs) have demonstrated significant advancements in multimodal understanding, yet they are frequently hampered by hallucination-the generation of text that contradicts visual input. Existing training-free decoding strategies exhibit critical limitations, including the use of static constraints that do not adapt to semantic drift during generation, inefficiency stemming from the need for multiple forward passes, and degradation of detail due to overly rigid intervention rules. To overcome these challenges, this paper introduces Dynamic Logits Calibration (DLC), a novel training-free decoding framework designed to dynamically align text generation with visual evidence at inference time. At the decoding phase, DLC step-wise employs CLIP to assess the semantic alignment between the input image and the generated text sequence. Then, the Relative Visual Advantage (RVA) of candidate tokens is evaluated against a dynamically updated contextual baseline, adaptively adjusting output logits to favor tokens that are visually grounded. Furthermore, an adaptive weighting mechanism, informed by a real-time context alignment score, carefully balances the visual guidance while ensuring the overall quality of the textual output. Extensive experiments conducted across diverse benchmarks and various LVLM architectures (such as LLaVA, InstructBLIP, and MiniGPT-4) demonstrate that DLC significantly reduces hallucinations, outperforming current methods while maintaining high inference efficiency by avoiding multiple forward passes. Overall, we present an effective and efficient decoding-time solution to mitigate hallucinations, thereby enhancing the reliability of LVLMs for more practices. Code will be released on Github. | [üîó Paper](http://arxiv.org/abs/2506.21509v1) |
| [Robust Alignment via Partial Gromov-Wasserstein Distances](http://arxiv.org/abs/2506.21507v1) | Xiaoyun Gong, Sloan Nietert, Ziv Goldfeld | 2025-06-26 | RLHF | The Gromov-Wasserstein (GW) problem provides a powerful framework for aligning heterogeneous datasets by matching their internal structures in a way that minimizes distortion. However, GW alignment is sensitive to data contamination by outliers, which can greatly distort the resulting matching scheme. To address this issue, we study robust GW alignment, where upon observing contaminated versions of the clean data distributions, our goal is to accurately estimate the GW alignment cost between the original (uncontaminated) measures. We propose an estimator based on the partial GW distance, which trims out a fraction of the mass from each distribution before optimally aligning the rest. The estimator is shown to be minimax optimal in the population setting and is near-optimal in the finite-sample regime, where the optimality gap originates only from the suboptimality of the plug-in estimator in the empirical estimation setting (i.e., without contamination). Towards the analysis, we derive new structural results pertaining to the approximate pseudo-metric structure of the partial GW distance. Overall, our results endow the partial GW distance with an operational meaning by posing it as a robust surrogate of the classical distance when the observed data may be contaminated. | [üîó Paper](http://arxiv.org/abs/2506.21507v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly
  Detection Benchmark](http://arxiv.org/abs/2506.21549v1) | Alex Costanzino, Pierluigi Zama Ramirez, Luigi Lella, Matteo Ragaglia, Alessandro Oliva, Giuseppe Lisanti, Luigi Di Stefano | 2025-06-26 | Multimodal AI | We propose SiM3D, the first benchmark considering the integration of multiview and multimodal information for comprehensive 3D anomaly detection and segmentation (ADS), where the task is to produce a voxel-based Anomaly Volume. Moreover, SiM3D focuses on a scenario of high interest in manufacturing: single-instance anomaly detection, where only one object, either real or synthetic, is available for training. In this respect, SiM3D stands out as the first ADS benchmark that addresses the challenge of generalising from synthetic training data to real test data. SiM3D includes a novel multimodal multiview dataset acquired using top-tier industrial sensors and robots. The dataset features multiview high-resolution images (12 Mpx) and point clouds (7M points) for 333 instances of eight types of objects, alongside a CAD model for each type. We also provide manually annotated 3D segmentation GTs for anomalous test samples. To establish reference baselines for the proposed multiview 3D ADS task, we adapt prominent singleview methods and assess their performance using novel metrics that operate on Anomaly Volumes. | [üîó Paper](http://arxiv.org/abs/2506.21549v1) |
| [SAM4D: Segment Anything in Camera and LiDAR Streams](http://arxiv.org/abs/2506.21547v1) | Jianyun Xu, Song Wang, Ziqian Ni, Chunyong Hu, Sheng Yang, Jianke Zhu, Qiang Li | 2025-06-26 | Multimodal AI | We present SAM4D, a multi-modal and temporal foundation model designed for promptable segmentation across camera and LiDAR streams. Unified Multi-modal Positional Encoding (UMPE) is introduced to align camera and LiDAR features in a shared 3D space, enabling seamless cross-modal prompting and interaction. Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA), which leverages ego-motion compensation to enhance temporal consistency and long-horizon feature retrieval, ensuring robust segmentation across dynamically changing autonomous driving scenes. To avoid annotation bottlenecks, we develop a multi-modal automated data engine that synergizes VFM-driven video masklets, spatiotemporal 4D reconstruction, and cross-modal masklet fusion. This framework generates camera-LiDAR aligned pseudo-labels at a speed orders of magnitude faster than human annotation while preserving VFM-derived semantic fidelity in point cloud representations. We conduct extensive experiments on the constructed Waymo-4DSeg, which demonstrate the powerful cross-modal segmentation ability and great potential in data annotation of proposed SAM4D. | [üîó Paper](http://arxiv.org/abs/2506.21547v1) |
| [WorldVLA: Towards Autoregressive Action World Model](http://arxiv.org/abs/2506.21539v1) | Jun Cen, Chaohui Yu, Hangjie Yuan, Yuming Jiang, Siteng Huang, Jiayan Guo, Xin Li, Yibing Song, Hao Luo, Fan Wang, Deli Zhao, Hao Chen | 2025-06-26 | Multimodal AI | We present WorldVLA, an autoregressive action world model that unifies action and image understanding and generation. Our WorldVLA intergrates Vision-Language-Action (VLA) model and world model in one single framework. The world model predicts future images by leveraging both action and image understanding, with the purpose of learning the underlying physics of the environment to improve action generation. Meanwhile, the action model generates the subsequent actions based on image observations, aiding in visual understanding and in turn helps visual generation of the world model. We demonstrate that WorldVLA outperforms standalone action and world models, highlighting the mutual enhancement between the world model and the action model. In addition, we find that the performance of the action model deteriorates when generating sequences of actions in an autoregressive manner. This phenomenon can be attributed to the model's limited generalization capability for action prediction, leading to the propagation of errors from earlier actions to subsequent ones. To address this issue, we propose an attention mask strategy that selectively masks prior actions during the generation of the current action, which shows significant performance improvement in the action chunk generation task. | [üîó Paper](http://arxiv.org/abs/2506.21539v1) |
| [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and
  Identity-Specific Adaptation](http://arxiv.org/abs/2506.21513v1) | Wentao Hu, Shunkai Li, Ziqiao Peng, Haoxian Zhang, Fan Shi, Xiaoqiang Liu, Pengfei Wan, Di Zhang, Hui Tian | 2025-06-26 | Multimodal AI, Ongoing Learning | Creating high-quality, generalizable speech-driven 3D talking heads remains a persistent challenge. Previous methods achieve satisfactory results for fixed viewpoints and small-scale audio variations, but they struggle with large head rotations and out-of-distribution (OOD) audio. Moreover, they are constrained by the need for time-consuming, identity-specific training. We believe the core issue lies in the lack of sufficient 3D priors, which limits the extrapolation capabilities of synthesized talking heads. To address this, we propose GGTalker, which synthesizes talking heads through a combination of generalizable priors and identity-specific adaptation. We introduce a two-stage Prior-Adaptation training strategy to learn Gaussian head priors and adapt to individual characteristics. We train Audio-Expression and Expression-Visual priors to capture the universal patterns of lip movements and the general distribution of head textures. During the Customized Adaptation, individual speaking styles and texture details are precisely modeled. Additionally, we introduce a color MLP to generate fine-grained, motion-aligned textures and a Body Inpainter to blend rendered results with the background, producing indistinguishable, photorealistic video frames. Comprehensive experiments show that GGTalker achieves state-of-the-art performance in rendering quality, 3D consistency, lip-sync accuracy, and training efficiency. | [üîó Paper](http://arxiv.org/abs/2506.21513v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Continuous symmetry breaking in 1D spin chains and 1+1D field theory](http://arxiv.org/abs/2506.21540v1) | Adam Nahum | 2025-06-26 | Optimization | We argue that ground states of 1D spin chains can spontaneously break U(1) ``easy-plane'' spin rotation symmetry, via true long-range order of $(S^x, S^y)$, at the phase transition between two quasi-long-range-ordered phases. The critical point can be reached by tuning a single parameter in a Hamiltonian with the same symmetry as the XXZ model, without further fine-tuning. Equivalently, it can arise in systems of bosons with particle-hole symmetry, as a long-range-ordered transition point between two quasi-long-range-ordered superfluids. Our approach is to start with the continuum field theory of the isotropic Heisenberg ferromagnet and consider generic perturbations that respect easy-plane symmetry. We argue for a renormalization-group flow to a critical point where long-range order in $(S^x, S^y)$ is enabled by coexisting critical fluctuations of $S^z$. (We also discuss multicritical points where further parameters are tuned to zero.) These results show that it is much easier to break continuous symmetries in 1D than standard lore would suggest. The failure of standard intuition for 1D chains (based on the quantum--classical correspondence) can be attributed to Berry phases, which prevent the 1+1D system from mapping to a classical 2D spin model. The present theory also gives an example of an ordered state whose Goldstone mode is interacting even in the infra-red, rather than becoming a free field. | [üîó Paper](http://arxiv.org/abs/2506.21540v1) |
| [Exploring the Design Space of 3D MLLMs for CT Report Generation](http://arxiv.org/abs/2506.21535v1) | Mohammed Baharoon, Jun Ma, Congyu Fang, Augustin Toma, Bo Wang | 2025-06-26 | Optimization, Multimodal AI | Multimodal Large Language Models (MLLMs) have emerged as a promising way to automate Radiology Report Generation (RRG). In this work, we systematically investigate the design space of 3D MLLMs, including visual input representation, projectors, Large Language Models (LLMs), and fine-tuning techniques for 3D CT report generation. We also introduce two knowledge-based report augmentation methods that improve performance on the GREEN score by up to 10\%, achieving the 2nd place on the MICCAI 2024 AMOS-MM challenge. Our results on the 1,687 cases from the AMOS-MM dataset show that RRG is largely independent of the size of LLM under the same training protocol. We also show that larger volume size does not always improve performance if the original ViT was pre-trained on a smaller volume size. Lastly, we show that using a segmentation mask along with the CT volume improves performance. The code is publicly available at https://github.com/bowang-lab/AMOS-MM-Solution | [üîó Paper](http://arxiv.org/abs/2506.21535v1) |
| [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](http://arxiv.org/abs/2506.21514v1) | Mohammed Rakib, Arunkumar Bagavathi | 2025-06-26 | Optimization, Multimodal AI, Training & Evaluation | Multimodal learning aims to leverage information from diverse data modalities to achieve more comprehensive performance. However, conventional multimodal models often suffer from modality imbalance, where one or a few modalities dominate model optimization, leading to suboptimal feature representation and underutilization of weak modalities. To address this challenge, we introduce Gradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework that optimizes the multimodal model with a custom-built loss function that fuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a dynamic sequential modality prioritization (SMP) technique in the learning process to ensure each modality leads the learning process, avoiding the pitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D on multiple real-world datasets and show that G$^{2}$D amplifies the significance of weak modalities while training and outperforms state-of-the-art methods in classification and regression tasks. Our code is available at https://github.com/rAIson-Lab/G2D. | [üîó Paper](http://arxiv.org/abs/2506.21514v1) |
| [Assessing an evolutionary search engine for small language models,
  prompts, and evaluation metrics](http://arxiv.org/abs/2506.21512v1) | Cl√°udio L√∫cio do Val Lopes, Lucca Machado | 2025-06-26 | Optimization, Training & Evaluation | The concurrent optimization of language models and instructional prompts presents a significant challenge for deploying efficient and effective AI systems, particularly when balancing performance against computational costs like token usage. This paper introduces and assesses a bi-objective evolutionary search engine designed to navigate this complex space, focusing specifically on Small Language Models (SLMs). We employ the NSGA-II algorithm and prompt grammar to simultaneously optimize for task accuracy and token efficiency across some reasoning tasks. Our results successfully identify diverse, high-performing model-prompt combinations, quantitatively revealing the critical trade-off between the two objectives. This research highlights task-specific affinities between particular SLMs and prompt structures (e.g., instructions, context, chain of thought). The generated practical Pareto fronts offer decision-makers a portfolio of optimized solutions adaptable to their specific constraints. This automated approach moves beyond traditional manual tuning, providing a foundational framework for discovering effective human-AI interaction patterns. | [üîó Paper](http://arxiv.org/abs/2506.21512v1) |
| [skLEP: A Slovak General Language Understanding Benchmark](http://arxiv.org/abs/2506.21508v1) | Marek ≈†uppa, Andrej Ridzik, Daniel Hl√°dek, Tom√°≈° Jav≈Ørek, Vikt√≥ria Ondrejov√°, Krist√≠na S√°sikov√°, Martin Tamajka, Mari√°n ≈†imko | 2025-06-26 | Optimization, Training & Evaluation | In this work, we introduce skLEP, the first comprehensive benchmark specifically designed for evaluating Slovak natural language understanding (NLU) models. We have compiled skLEP to encompass nine diverse tasks that span token-level, sentence-pair, and document-level challenges, thereby offering a thorough assessment of model capabilities. To create this benchmark, we curated new, original datasets tailored for Slovak and meticulously translated established English NLU resources. Within this paper, we also present the first systematic and extensive evaluation of a wide array of Slovak-specific, multilingual, and English pre-trained language models using the skLEP tasks. Finally, we also release the complete benchmark data, an open-source toolkit facilitating both fine-tuning and evaluation of models, and a public leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering reproducibility and drive future research in Slovak NLU. | [üîó Paper](http://arxiv.org/abs/2506.21508v1) |
## üîπ Scaling Laws

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [On the visibility window for Brownian interlacements, Poisson cylinders
  and Boolean models](http://arxiv.org/abs/2506.21516v1) | Yingxin Mu, Artem Sapozhnikov | 2025-06-26 | Scaling Laws | We study visibility inside the vacant set of three models in $\mathbb R^d$ with slow decay of spatial correlations: Brownian interlacements, Poisson cylinders and Poisson-Boolean models. Let $Q_x$ be the radius of the largest ball centered at $x$ every point of which is visible from $0$ through the vacant set of one of these models. We prove that conditioned on $x$ being visible from $0$, $Q_x/\delta_{\ x\ }$ converges weakly, as $x\to\infty$, to the exponential distribution with an explicit intensity, which depends on the parameters of the respective model. The scaling function $\delta_r$ is the visibility window introduced in arXiv:2304.10298, a length scale of correlations in the visible set at distance $r$ from $0$. | [üîó Paper](http://arxiv.org/abs/2506.21516v1) |
| [Gaussian Invariant Markov Chain Monte Carlo](http://arxiv.org/abs/2506.21511v1) | Michalis K. Titsias, Angelos Alexopoulos, Siran Liu, Petros Dellaportas | 2025-06-26 | Scaling Laws | We develop sampling methods, which consist of Gaussian invariant versions of random walk Metropolis (RWM), Metropolis adjusted Langevin algorithm (MALA) and second order Hessian or Manifold MALA. Unlike standard RWM and MALA we show that Gaussian invariant sampling can lead to ergodic estimators with improved statistical efficiency. This is due to a remarkable property of Gaussian invariance that allows us to obtain exact analytical solutions to the Poisson equation for Gaussian targets. These solutions can be used to construct efficient and easy to use control variates for variance reduction of estimators under any intractable target. We demonstrate the new samplers and estimators in several examples, including high dimensional targets in latent Gaussian models where we compare against several advanced methods and obtain state-of-the-art results. We also provide theoretical results regarding geometric ergodicity, and an optimal scaling analysis that shows the dependence of the optimal acceptance rate on the Gaussianity of the target. | [üîó Paper](http://arxiv.org/abs/2506.21511v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Benchmarking and Parallelization of Electrostatic Particle-In-Cell for
  low-temperature Plasma Simulation by particle-thread Binding](http://arxiv.org/abs/2506.21524v1) | Libn Varghese, Bhaskar Chaudhury, Miral Shah, Mainak Bandyopadhyay | 2025-06-26 | Training & Evaluation, Model Evaluation | The Particle-In-Cell (PIC) method for plasma simulation tracks particle phase space information using particle and grid data structures. High computational costs in 2D and 3D device-scale PIC simulations necessitate parallelization, with the Charge Deposition (CD) subroutine often becoming a bottleneck due to frequent particle-grid interactions. Conventional methods mitigate dependencies by generating private grids for each core, but this approach faces scalability issues. We propose a novel approach based on a particle-thread binding strategy that requires only four private grids per node in distributed memory systems or four private grids in shared memory systems, enhancing CD scalability and performance while maintaining conventional data structures and requiring minimal changes to existing PIC codes. This method ensures complete accessibility of grid data structure for concurrent threads and avoids simultaneous access to particles within the same cell using additional functions and flags. Performance evaluations using a PIC benchmark for low-temperature partially magnetized E x B discharge simulation on a shared memory as well as a distributed memory system (1000 cores) demonstrate the method's scalability, and additionally, we show the method has little hardware dependency. | [üîó Paper](http://arxiv.org/abs/2506.21524v1) |
| [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](http://arxiv.org/abs/2506.21506v1) | Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jim√©nez Guti√©rrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su | 2025-06-26 | Training & Evaluation, Model Evaluation | Agentic search such as Deep Research systems, where large language models autonomously browse the web, synthesize information, and return comprehensive citation-backed answers, represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1,000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of nine frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, showing a great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems. | [üîó Paper](http://arxiv.org/abs/2506.21506v1) |
## üîπ Prompt Engineering

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [WAFT: Warping-Alone Field Transforms for Optical Flow](http://arxiv.org/abs/2506.21526v1) | Yihan Wang, Jia Deng | 2025-06-26 | Prompt Engineering | We introduce Warping-Alone Field Transforms (WAFT), a simple and effective method for optical flow. WAFT is similar to RAFT but replaces cost volume with high-resolution warping, achieving better accuracy with lower memory cost. This design challenges the conventional wisdom that constructing cost volumes is necessary for strong performance. WAFT is a simple and flexible meta-architecture with minimal inductive biases and reliance on custom designs. Compared with existing methods, WAFT ranks 1st on Spring and KITTI benchmarks, achieves the best zero-shot generalization on KITTI, while being up to 4.1x faster than methods with similar performance. Code and model weights are available at https://github.com/princeton-vl/WAFT. | [üîó Paper](http://arxiv.org/abs/2506.21526v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [HalluSegBench: Counterfactual Visual Reasoning for Segmentation
  Hallucination Evaluation](http://arxiv.org/abs/2506.21546v1) | Xinzhuo Li, Adheesh Juvekar, Xingyou Liu, Muntasir Wahed, Kiet A. Nguyen, Ismini Lourentzou | 2025-06-26 | Responsible AI, Multimodal AI, Training & Evaluation, Model Evaluation | Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity. | [üîó Paper](http://arxiv.org/abs/2506.21546v1) |
| [Data Efficacy for Language Model Training](http://arxiv.org/abs/2506.21545v1) | Yalun Dai, Yangyu Huang, Xin Zhang, Wenshan Wu, Chong Li, Wenhui Lu, Shijie Cao, Li Dong, Scarlett Li | 2025-06-26 | Responsible AI, Model Evaluation | Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training. | [üîó Paper](http://arxiv.org/abs/2506.21545v1) |
| [Revealing electron-lattice decoupling by Peltier thermometry and
  nanoscale thermal imaging in graphene](http://arxiv.org/abs/2506.21523v1) | Saurabh Kumar Srivastav, Tobias V√∂lkl, Gary Quaresima, Yuri Myasoedov, Martin E. Huber, Kenji Watanabe, Takashi Taniguchi, L. S. Levitov, D. A. Pesin, Eli Zeldov | 2025-06-26 | Responsible AI, Model Evaluation | Electrical currents in low-dimensional quantum materials can drive electrons far from equilibrium, creating stark imbalance between electron and lattice temperatures. Yet, no existing methods enable simultaneous nanoscale mapping of both temperatures at cryogenic conditions. Here, we introduce a scanning probe technique that images the local lattice temperature and extracts electron temperature at gate-defined p-n junctions in graphene. By applying an alternating electrical current and analyzing first- and second-harmonic responses, we disentangle Joule heating from the Peltier effect-the latter encoding the local electron temperature. This enables the first spatially resolved cryogenic imaging of both phenomena in graphene. Even under modest current bias, the electron temperature increases by nearly three orders of magnitude more than the lattice temperature, revealing strong electron-phonon decoupling and indicating a previously unrecognized electron cooling pathway. Our minimally invasive method is broadly applicable to van der Waals heterostructures and opens new avenues for probing energy dissipation and non-equilibrium transport in correlated and hydrodynamic electron systems. | [üîó Paper](http://arxiv.org/abs/2506.21523v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Where to find Grokking in LLM Pretraining? Monitor
  Memorization-to-Generalization without Test](http://arxiv.org/abs/2506.21551v1) | Ziyue Li, Chenrui Fan, Tianyi Zhou | 2025-06-26 | General AI | Grokking, i.e., test performance keeps improving long after training loss converged, has been recently witnessed in neural network training, making the mechanism of generalization and other emerging capabilities such as reasoning mysterious. While prior studies usually train small models on a few toy or highly-specific tasks for thousands of epochs, we conduct the first study of grokking on checkpoints during one-pass pretraining of a 7B large language model (LLM), i.e., OLMoE. We compute the training loss and evaluate generalization on diverse benchmark tasks, including math reasoning, code generation, and commonsense/domain-specific knowledge retrieval tasks.   Our study, for the first time, verifies that grokking still happens in the pretraining of large-scale foundation models, though different data may enter grokking stages asynchronously. We further demystify grokking's "emergence of generalization" by investigating LLM internal dynamics. Specifically, we find that training samples' pathways (i.e., expert choices across layers) evolve from random, instance-specific to more structured and shareable between samples during grokking. Also, the complexity of a sample's pathway reduces despite the converged loss. These indicate a memorization-to-generalization conversion, providing a mechanistic explanation of delayed generalization. In the study, we develop two novel metrics to quantify pathway distance and the complexity of a single pathway. We show their ability to predict the generalization improvement on diverse downstream tasks. They are efficient, simple to compute and solely dependent on training data. Hence, they have practical value for pretraining, enabling us to monitor the generalization performance without finetuning and test. Theoretically, we show that more structured pathways reduce model complexity and improve the generalization bound. | [üîó Paper](http://arxiv.org/abs/2506.21551v1) |
| [Natal kick by early-asymmetrical pairs of jets to the neutron star of
  supernova remnant S147](http://arxiv.org/abs/2506.21548v1) | Dmitry Shishkin, Ealeal Bear, Noam Soker | 2025-06-26 | General AI | We analyze the bipolar morphology of the jet-shaped core-collapse supernova (CCSN) remnant (CCSNR) S147 and its neutron star (NS) kick velocity, and suggest that two pairs of unequal, opposite jets contributed to the NS kick velocity. This kick by early asymmetrical pairs (kick-BEAP) of jets mechanism operates within the framework of the jittering jets explosion mechanism (JJEM). We examine the prominent pair of large ears and, based on their flat structure rather than the more common conical structure of ears, conclude that two pairs of jets close in angle inflated the two opposite ears. We connect two opposite X-ray bright zones by an additional axis to create the full point-symmetric morphology of CCSNR S147. We propose that the two unequal jets that formed the X-ray bright zones imparted the first kick-BEAP, while the two pairs of jets that formed the ears imparted the second kick-BEAP. The two kick velocities are of about equal magnitude of ~450 km/s, which implies very energetic jets. Such jets can excite gravitational waves that present detectors can detect from the Galaxy and the Magellanic Clouds. We use the morphology we identify to estimate the CCSNR age at 23,000 yr. Our results strengthen the JJEM. | [üîó Paper](http://arxiv.org/abs/2506.21548v1) |
| [Detecting weighted hidden cliques](http://arxiv.org/abs/2506.21543v1) | Urmisha Chatterjee, Karissa Huang, Ritabrata Karmakar, B. R. Vinay Kumar, G√°bor Lugosi, Nandan Malhotra, Anirban Mandal, Maruf Alam Tarafdar | 2025-06-26 | General AI | We study a generalization of the classical hidden clique problem to graphs with real-valued edge weights. Formally, we define a hypothesis testing problem. Under the null hypothesis, edges of a complete graph on $n$ vertices are associated with independent and identically distributed edge weights from a distribution $P$. Under the alternate hypothesis, $k$ vertices are chosen at random and the edge weights between them are drawn from a distribution $Q$, while the remaining are sampled from $P$. The goal is to decide, upon observing the edge weights, which of the two hypotheses they were generated from. We investigate the problem under two different scenarios: (1) when $P$ and $Q$ are completely known, and (2) when there is only partial information of $P$ and $Q$. In the first scenario, we obtain statistical limits on $k$ when the two hypotheses are distinguishable, and when they are not. Additionally, in each of the scenarios, we provide bounds on the minimal risk of the hypothesis testing problem when $Q$ is not absolutely continuous with respect to $P$. We also provide computationally efficient spectral tests that can distinguish the two hypotheses as long as $k=\Omega(\sqrt{n})$ in both the scenarios. | [üîó Paper](http://arxiv.org/abs/2506.21543v1) |
| [Quintessence and phantoms in light of DESI 2025](http://arxiv.org/abs/2506.21542v1) | Ioannis D. Gialamas, Gert H√ºtsi, Martti Raidal, Juan Urrutia, Martin Vasar, Hardi Veerm√§e | 2025-06-26 | General AI | We analyse DESI BAO, CMB, and supernova data to explore the physical origin of the DESI indication for dynamical dark energy. Beyond the standard CPL parametrization, we explore truncated alternatives and quintessence models. We conclude that there is compelling evidence for dark energy to be decaying in the late universe, but the evidence for a phantom behaviour is less significant. Models without phantom behaviour are compatible with the data at the $2\sigma$ CL. Furthermore, we examine a concrete quintessence scenario with a Higgs-like potential, allowing for a direct comparison with parametrized approaches and testing its consistency with current observations. This framework enables a broader investigation of late-time cosmic evolution and reveals a $93.8\%$ preference for a future transition into an anti-de Sitter space, which may ultimately lead to a cosmological collapse of our Universe. | [üîó Paper](http://arxiv.org/abs/2506.21542v1) |
| [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud
  Representation Learning](http://arxiv.org/abs/2506.21541v1) | Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang | 2025-06-26 | General AI | Recently, Mamba-based methods have demonstrated impressive performance in point cloud representation learning by leveraging State Space Model (SSM) with the efficient context modeling ability and linear complexity. However, these methods still face two key issues that limit the potential of SSM: Destroying the adjacency of 3D points during SSM processing and failing to retain long-sequence memory as the input length increases in downstream tasks. To address these issues, we propose StruMamba3D, a novel paradigm for self-supervised point cloud representation learning. It enjoys several merits. First, we design spatial states and use them as proxies to preserve spatial dependencies among points. Second, we enhance the SSM with a state-wise update strategy and incorporate a lightweight convolution to facilitate interactions between spatial states for efficient structure modeling. Third, our method reduces the sensitivity of pre-trained Mamba-based models to varying input lengths by introducing a sequence length-adaptive strategy. Experimental results across four downstream tasks showcase the superior performance of our method. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40 and 92.75% accuracy on the most challenging split of ScanObjectNN without voting strategy. | [üîó Paper](http://arxiv.org/abs/2506.21541v1) |
| [Maximal Matching Matters: Preventing Representation Collapse for Robust
  Cross-Modal Retrieval](http://arxiv.org/abs/2506.21538v1) | Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas | 2025-06-26 | General AI | Cross-modal image-text retrieval is challenging because of the diverse possible associations between content from different modalities. Traditional methods learn a single-vector embedding to represent semantics of each sample, but struggle to capture nuanced and diverse relationships that can exist across modalities. Set-based approaches, which represent each sample with multiple embeddings, offer a promising alternative, as they can capture richer and more diverse relationships. In this paper, we show that, despite their promise, these set-based representations continue to face issues including sparse supervision and set collapse, which limits their effectiveness. To address these challenges, we propose Maximal Pair Assignment Similarity to optimize one-to-one matching between embedding sets which preserve semantic diversity within the set. We also introduce two loss functions to further enhance the representations: Global Discriminative Loss to enhance distinction among embeddings, and Intra-Set Divergence Loss to prevent collapse within each set. Our method achieves state-of-the-art performance on MS-COCO and Flickr30k without relying on external data. | [üîó Paper](http://arxiv.org/abs/2506.21538v1) |
| [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog
  Rydberg Atom Quantum Computers](http://arxiv.org/abs/2506.21537v1) | Nicholas S. DiBrita, Jason Han, Tirthak Patel | 2025-06-26 | General AI | Research in quantum machine learning has recently proliferated due to the potential of quantum computing to accelerate machine learning. An area of machine learning that has not yet been explored is neural ordinary differential equation (neural ODE) based residual neural networks (ResNets), which aim to improve the effectiveness of neural networks using the principles of ordinary differential equations. In this work, we present our insights about why analog Rydberg atom quantum computers are especially well-suited for ResNets. We also introduce ResQ, a novel framework to optimize the dynamics of Rydberg atom quantum computers to solve classification problems in machine learning using analog quantum neural ODEs. | [üîó Paper](http://arxiv.org/abs/2506.21537v1) |
| [Rashba spin-orbit coupling and artificially engineered topological
  superconductors](http://arxiv.org/abs/2506.21534v1) | Sankar Das Sarma, Katharina Laubscher, Haining Pan, Jay D. Sau, Tudor D. Stanescu | 2025-06-26 | General AI | One of the most important physical effects in condensed matter physics is the Rashba spin-orbit coupling (RSOC), introduced in seminal works by Emmanuel Rashba. In this article, we discuss, describe, and review (providing critical perspectives on) the crucial role of RSOC in the currently active research area of topological quantum computation. Most, if not all, of the current experimental topological quantum computing platforms use the idea of Majorana zero modes as the qubit ingredient because of their non-Abelian anyonic property of having an intrinsic quantum degeneracy, which enables nonlocal encoding protected by a topological energy gap. It turns out that RSOC is a crucial ingredient in producing a low-dimensional topological superconductor in the laboratory, and such topological superconductors naturally have isolated localized midgap Majorana zero modes. In addition, increasing the RSOC strength enhances the topological gap, thus enhancing the topological immunity of the qubits to decoherence. Thus, Rashba's classic work on SOC may lead not only to the realization of localized non-Abelian anyons, but also fault tolerant quantum computation. | [üîó Paper](http://arxiv.org/abs/2506.21534v1) |
| [On the Invariance of Expansive Measures for Flows](http://arxiv.org/abs/2506.21533v1) | Eduardo Pedrosa, Elias Rego, Alexandre Trilles | 2025-06-26 | General AI | We study expansive measures for continuous flows without fixed points on compact metric spaces, as introduced in [6]. We provide a new characterization of expansive measures through dynamical balls that, in contrast to the dynamical balls considered in [6], are actually Borel sets. This makes the theory more amenable to measure-theoretic analysis. We then establish a version of the Brin-Katok local entropy formula for flows using these generalized dynamical balls. As an application, we prove that every ergodic invariant measure with positive entropy is positively expansive, thus extending the results of [1] to the setting of regular flows. This implies that flows with positive topological entropy admit expansive invariant measures. Furthermore, we show that the stable classes of such measures have zero measure. Lastly, we prove that the set of expansive measures forms a $G_{\delta\sigma}$ subset in the weak*-topology and that every expansive measure (invariant or not) can be approximated by expansive measures supported on invariant sets. | [üîó Paper](http://arxiv.org/abs/2506.21533v1) |
| ["What's Up, Doc?": Analyzing How Users Seek Health Information in
  Large-Scale Conversational AI Datasets](http://arxiv.org/abs/2506.21532v1) | Akshay Paruchuri, Maryam Aziz, Rohit Vartak, Ayman Ali, Best Uchehara, Xin Liu, Ishan Chatterjee, Monica Agrawal | 2025-06-26 | General AI | People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. Code and artifacts to retrieve our analyses and combine them into a curated dataset can be found here: https://github.com/yahskapar/HealthChat | [üîó Paper](http://arxiv.org/abs/2506.21532v1) |
| [The Kaleidoscope Survey: Strong Gravitational Lensing in Galaxy Clusters
  with Radial Arcs](http://arxiv.org/abs/2506.21531v2) | Catherine Cerny, Mathilde Jauzac, David Lagattuta, Anna Niemiec, Guillaume Mahler, Alastair Edge, Richard Massey, Joseph Allingham | 2025-06-26 | General AI | We measure the dark matter density profiles of six galaxy clusters: A383, MS 2137-23, MACS J0326.8-0043, MACS J1427.6-2521, MACS J0417.5-1154, and MACS J0949.8+1708. Each cluster contains at least one radial arc, a unique physical feature that allows for more precise measurements of the inner mass profile (R < 50 kpc) from strong lensing. We present the first strong lensing analysis for MACS J0326 and MACS J1427. We use a combination of HST imaging and VLT/MUSE observations from the ESO Kaleidoscope Clusters Survey, a large `filler' program, to identify and measure redshifts for multiply-imaged systems and obtain the 2-D stellar velocity dispersion for each centrally-located brightest cluster galaxy (BCG). The BCG kinematics are used to subtract the baryonic mass component from the inner mass profile. We find total mass density profiles consistent with previous works using a combination of strong lensing and BCG kinematics. The overall shape of these profiles appears core-like, with an average dark matter slope measurement of $\gamma$~0.66. These results demonstrate the ongoing need for the construction of observational models for galaxy clusters, and show how galaxy-scale kinematics can be used to disentangle baryonic and dark matter concentrations in cluster cores. | [üîó Paper](http://arxiv.org/abs/2506.21531v2) |
| [Detectability and Parameter Estimation for Einstein Telescope
  Configurations with GWJulia](http://arxiv.org/abs/2506.21530v1) | Andrea Begnoni, Stefano Anselmi, Mauro Pieroni, Alessandro Renzi, Angelo Ricciardone | 2025-06-26 | General AI | Future gravitational-wave (GW) detectors are expected to detect tens of thousands of compact binary coalescences (CBC) per year, depending also on the final detectors layout. For this reason, it is essential to have a fast, reliable tool for forecasting how different detector layouts will affect parameter estimation for these events. The Fisher Information Matrix (FIM) is a common tool for tackling this problem. In this paper, we present a new open source code GWJulia to perform FIM analysis of CBC parameters, i.e., stellar black-hole binaries (BBH), neutron star binaries (BNS), and neutron star-black hole binaries (NSBH). The code is purely written in Julia, making it fast while maintaining a high level of accuracy. We consider a set of case studies to compare different Einstein Telescope (ET) designs. We compare a 10km triangular configuration with two 15km L-shaped detectors with different orientations and temperatures. We discuss also the accuracy of combinations of parameters, which is very informative for cosmology or population studies. Finally, we focus on the detection of golden events and explore how the FIM can guide posterior sampling of GW signals using a novel Hamiltonian Monte Carlo (HMC) sampler. The code is publicly available at https://github.com/andrea-begnoni/GW.jl | [üîó Paper](http://arxiv.org/abs/2506.21530v1) |
| [Landau levels of a Dirac electron in graphene from non-uniform magnetic
  fields](http://arxiv.org/abs/2506.21529v1) | Aritra Ghosh | 2025-06-26 | General AI | The occurrence of Landau levels in quantum mechanics is well known when a charged particle is subjected to a uniform magnetic field. Considering the recent interest in the electronic properties of graphene which admits a dispersion relation which is linear in the momentum near the Dirac points, we revisit the problem of Landau levels in the spirit of the Dirac Hamiltonian and ask if there are certain non-uniform magnetic fields which also lead to a spectrum consisting of the Landau levels. The answer, as we show, is in the affirmative. In particular, by considering isospectral deformations of the uniform magnetic field, we present explicit expressions for non-uniform magnetic fields that are strictly isospectral to their uniform counterpart, thus supporting the Landau levels. | [üîó Paper](http://arxiv.org/abs/2506.21529v1) |
| [Koszul complexes and derived intersections](http://arxiv.org/abs/2506.21528v1) | Tristan Bozec, Julien Grivaux | 2025-06-26 | General AI | The aim of this article is to provide a complementary understanding to some results of the second author using the machinery of Koszul complexes, and to explain how this approach can provide a new description of projective derived intersections. | [üîó Paper](http://arxiv.org/abs/2506.21528v1) |
| [Asymptotic Inference for Exchangeable Gibbs Partition](http://arxiv.org/abs/2506.21527v1) | Takuya Koriyama | 2025-06-26 | General AI | We study the asymptotic properties of parameter estimation and predictive inference under the exchangeable Gibbs partition, characterized by a discount parameter $\alpha\in(0,1)$ and a triangular array $v_{n,k}$ satisfying a backward recursion. Assuming that $v_{n,k}$ admits a mixture representation over the Ewens--Pitman family $(\alpha, \theta)$, with $\theta$ integrated by an unknown mixing distribution, we show that the (quasi) maximum likelihood estimator $\hat\alpha_n$ (QMLE) for $\alpha$ is asymptotically mixed normal. This generalizes earlier results for the Ewens--Pitman model to a more general class. We further study the predictive task of estimating the probability simplex $\mathsf{p}_n$, which governs the allocation of the $(n+1)$-th item, conditional on the current partition of $[n]$. Based on the asymptotics of the QMLE $\hat{\alpha}_n$, we construct an estimator $\hat{\mathsf{p}}_n$ and derive the limit distributions of the $f$-divergence $\mathsf{D}_f(\hat{\mathsf{p}}_n  \mathsf{p}_n)$ for general convex functions $f$, including explicit results for the TV distance and KL divergence. These results lead to asymptotically valid confidence intervals for both parameter estimation and prediction. | [üîó Paper](http://arxiv.org/abs/2506.21527v1) |
| [The spectrum of global representations for families of bounded rank and
  VI-modules](http://arxiv.org/abs/2506.21525v1) | Miguel Barrero, Tobias Barthel, Luca Pol, Neil Strickland, Jordan Williamson | 2025-06-26 | General AI | A global representation is a compatible collection of representations of the outer automorphism groups of the finite groups belonging to a family $\mathscr{U}$. These arise in classical representation theory, in the study of representation stability, as well as in global homotopy theory. In this paper we begin a systematic study of the derived category $\mathsf{D}(\mathscr{U};k)$ of global representations over fields $k$ of characteristic zero, from the point-of-view of tensor-triangular geometry. We calculate its Balmer spectrum for various infinite families of finite groups including elementary abelian $p$-groups, cyclic groups, and finite abelian $p$-groups of bounded rank. We then deduce that the Balmer spectrum associated to the family of finite abelian $p$-groups has infinite Krull dimension and infinite Cantor--Bendixson rank, illustrating the complex phenomena we encounter. As a concrete application, we provide a complete tt-theoretic classification of finitely generated derived VI-modules. Our proofs rely on subtle information about the growth behaviour of global representations studied in a companion paper, as well as novel methods from non-rigid tt-geometry. | [üîó Paper](http://arxiv.org/abs/2506.21525v1) |
| [Counting biquadratic number fields with quaternionic and dihedral
  extensions](http://arxiv.org/abs/2506.21522v1) | Louis M. Gaudet, Siman Wong | 2025-06-26 | General AI | We establish asymptotic formulae for the number of biquadratic number fields of bounded discriminant that can be embedded into a quaternionic or a dihedral extension. To prove these results, we express the solvability of these inverse Galois problems in terms of Hilbert symbols, and then apply a method of Heath-Brown to bound sums of linked quadratic characters. | [üîó Paper](http://arxiv.org/abs/2506.21522v1) |
| [Potemkin Understanding in Large Language Models](http://arxiv.org/abs/2506.21521v1) | Marina Mancoridis, Bec Weeks, Keyon Vafa, Sendhil Mullainathan | 2025-06-26 | General AI | Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations. | [üîó Paper](http://arxiv.org/abs/2506.21521v1) |
| [Hunting for UVdim stars in Galactic Open clusters. Clues from
  ultraviolet photometry](http://arxiv.org/abs/2506.21519v1) | G. Cordoni, A. P. Milone, L. Casagrande, L. Venuti, E. P. Lagioia, F. Muratore, A. F. Marino, G. S. Da Costa, F. Dell'Agli, F. D'Antona | 2025-06-26 | General AI | Split main-sequences (MSs) and extended main-sequence turn-offs (eMSTOs) have been observed in nearly all Magellanic Clouds clusters younger than 2 Gyr. More recently, Hubble Space Telescope (HST) ultraviolet photometry uncovered a puzzling new population of UV-absorbed stars, dubbed UVdim, in five Magellanic Clouds clusters aged between 40 and 200 Myr, as well as in one 1.5 Gyr-old cluster. These UVdim stars predominantly lie on the blue MS, which is composed of slow rotators, and their distinct UV properties are believed to stem from dusty circumstellar disks. Although eMSTOs are common in both Magellanic Clouds and Galactic open clusters (OCs) of comparable ages, UVdim stars have not yet been investigated in Galactic OCs. In this work, we fill that gap by combining Swift/UVOT, SkyMapper, and Gaia photometry to extend the search for UVdim stars to 35 Galactic OCs younger than 2 Gyr. By constructing colour-colour diagrams analogous to those employed with HST WFC3/UVIS, we find no evidence of UVdim-like stars in most Galactic open clusters and identify possible UVdim candidates in only five systems. The rarity of UVdim stars in young OCs suggests a potential difference between Magellanic Cloud clusters and their Milky Way counterparts, although the underlying reason remains unclear. | [üîó Paper](http://arxiv.org/abs/2506.21519v1) |
| [New plasmon-like mode in PdTe$_{2}$: Raman scattering and memory
  function study](http://arxiv.org/abs/2506.21518v1) | Bharathiganesh Devanarayanan, Sahil Rathi, Jalaja Pandya, Sonika, C. S. Yadav, Navinder Singh, Satyendra Nath Gupta | 2025-06-26 | General AI | PdTe$_2$ is a type II Dirac semimetal that has garnered significant attention due to its intriguing electronic and topological properties. Here, we report temperature dependent Raman scattering study of PdTe$_2$ in the temperature range from 10 K to 300 K. Our study reveals emergence of a new unreported peak below 100 K, centered around 250 cm$^{-1}$. We argue that the new mode is not a phonon mode because the Raman spectra calculated using Density Functional Theory shows only two intense peaks at 85 $ cm^{-1}$ and 128 $cm^{-1}$. To ascertain the origin of this new peak, we constructed a microscopic model of electrons coupling to a single plasmon mode at 250 $cm^{-1}$ and using the memory function formalism, we obtained that the Raman relaxation rate is linear in frequency. We also performed phenomenological analysis of the Raman response from the experimental data and computed frequency dependent Raman relaxation rate, which is also found to exhibit a linear dependence on frequency. With the congruence of our theoretical and phenomenological results we could ascertain that the new mode observed at low temperatures is indeed a plasmon-like mode. Further, phonon frequencies and line widths of the two phonon modes exhibit anomalous behavior above 100 K. | [üîó Paper](http://arxiv.org/abs/2506.21518v1) |
| [The Relation between Solar Spicules and Magnetohydrodynamic Shocks](http://arxiv.org/abs/2506.21517v1) | Sankalp Srivastava, Piyali Chatterjee, Sahel Dey, Robertus Erd√©lyi | 2025-06-26 | General AI | Spicules are thin, elongated jet-like features seen in observations of the solar atmosphere, at the interface between the solar photosphere and the corona. These features exhibit highly complex dynamics and are a necessary connecting link between the cooler, denser solar chromosphere and the extremely hot, tenuous corona. In this work, we explore the spatial and temporal relation between solar spicules and magneto-hydrodynamic (MHD) shocks using data from a 2D radiative MHD (rMHD) simulation of the solar atmosphere driven by solar convection. Here, we demonstrate, through direct identification, that slow MHD shocks, which propagate along magnetic field lines, are regions of strong positive vertical acceleration of the plasma that forms the tip of the spicule material during its rise phase. We quantify the effect of pressure and Lorentz forces on the acceleration of the plasma inside the shocks during the rise of spicules. The causality between spicule and shock propagation in the atmosphere of the model is also investigated. It is further shown that the strength of these shocks may play a vital role in determining the height of the spicules, supporting the idea that shocks act as drivers of some spicules. In addition, we also find the presence of structures similar to propagating coronal disturbances (PCDs) in the simulation, linked with the spicules. Here, PCDs appear to be associated with the shock waves driving the spicules that subsequently propagate into the corona and have similar speeds to those reported in observations. | [üîó Paper](http://arxiv.org/abs/2506.21517v1) |
| [A priori estimates of stable solutions of the general Hardy-Henon
  equation in the ball](http://arxiv.org/abs/2506.21515v1) | J. Silverio Martinez-Baena, Salvador Villegas | 2025-06-26 | General AI | This paper is devoted to the study of semi-stable radial solutions $u\in H^1(B_1)$ of $-\Delta u=\vert x\vert^\alpha f(u) \mbox{ in } B_1\setminus\lbrace0\rbrace$, where $f\in C^1(\mathbb{R})$ is a general nonlinearity, $\alpha>-2$ and $B_1$ is the unit ball of $\mathbb{R}^N$, $N>1$. We establish the boudness of such solutions for dimensions $2\leq N<10+4\alpha$ and sharp pointwise estimates in the case $N\geq10+4\alpha$. In addition, we provide, for this range of dimensions, a large family of semi-stable radially decreasing unbounded $H^1(B_1)$ solutions. | [üîó Paper](http://arxiv.org/abs/2506.21515v1) |
| [Joint Scheduling of DER under Demand Charges: Structure and
  Approximation](http://arxiv.org/abs/2506.21510v1) | Ruixiao Yang, Gulai Shen, Ahmed S. Alahmed, Chuchu Fan | 2025-06-26 | General AI | We study the joint scheduling of behind-the-meter distributed energy resources (DERs), including flexible loads, renewable generation, and battery energy storage systems, under net energy metering frameworks with demand charges. The problem is formulated as a stochastic dynamic program aimed at maximizing expected operational surplus while accounting for renewable generation uncertainty. We analytically characterize the structure of the optimal control policy and show that it admits a threshold-based form. However, due to the strong temporal coupling of the storage and demand charge constraints, the number of conditional branches in the policy scales combinatorially with the scheduling horizon, as it requires a look-ahead over future states. To overcome the high computational complexity in the general formulation, an efficient approximation algorithm is proposed, which searches for the peak demand under a mildly relaxed problem. We show that the algorithm scales linearly with the scheduling horizon. Extensive simulations using two open-source datasets validate the proposed algorithm and compare its performance against different DER control strategies, including a reinforcement learning-based one. Under varying storage and tariff parameters, the results show that the proposed algorithm outperforms various benchmarks in achieving a relatively small solution gap compared to the theoretical upper bound. | [üîó Paper](http://arxiv.org/abs/2506.21510v1) |
| [On a minimal free resolution of the residue field over a local ring of
  codepth 3 of class T](http://arxiv.org/abs/2506.21505v1) | Van C. Nguyen, Oana Veliche | 2025-06-26 | General AI | Let $R$ be any local ring with residue field $k$, and $A$ the homology of the Koszul complex on a minimal set of generators of the maximal ideal of $R$. In this paper, we show that a minimal free resolution of $k$ over $R$ can be obtained from a graded minimal free resolution of $k$ over $A$. More precisely, this is done by the iterated mapping cone construction, introduced by the authors in a previous work, using specific choices of ingredients. As applications, using this general perspective, we exhibit a minimal free resolution of $k$ over a complete intersection ring of any codepth, and explicitly construct a minimal free resolution of $k$ over a local ring of codepth 3 of class $T$ in terms of Koszul blocks. | [üîó Paper](http://arxiv.org/abs/2506.21505v1) |
| [Correlated reaction coordinate motion produces non-additive rate
  enhancement for electron and energy transfer in multi-acceptor structures](http://arxiv.org/abs/2506.21504v1) | Hanggai Nuomin, Feng-Feng Song, Peng Zhang, David N. Beratan | 2025-06-26 | General AI | Molecular structures with multiple donor, bridge, or acceptor units can display quantum interference effects that influence electron and energy transfer (ET and EnT) rates. Recent experiments found a 4- to 5-fold increase in ET rates for donor-acceptor structures with two acceptors compared to one. This result is surprising: simple classical or quantum analysis suggests a factor of two rate enhancement. We analyze the coupling interactions in multiple acceptor systems and find that rate enhancements beyond additive effects arise from acceptor-acceptor interactions that: 1) shift the reaction free energy, 2) change the donor-acceptor couplings, and 3) alter the reaction-coordinate motion. Consideration of these effects explains the observed rates in multi-acceptor systems and suggests strategies to tailor energy and electron transfer kinetics. | [üîó Paper](http://arxiv.org/abs/2506.21504v1) |
| [Excitation of Giant Surface Waves During Laser Wake Field Acceleration](http://arxiv.org/abs/2506.21503v1) | Travis Garrett, Christopher Pieronek, E. Rockafellow, Oliver Sale, Sahir Virani, J. E. Shrock, B. Miao, A. Sloss, Jennifer Elle, H. M. Milchberg | 2025-06-26 | General AI | We have detected the presence of very high intensity surface waves that are excited during plasma waveguided laser wakefield acceleration. Wakefield acceleration can be enchanced by the introduction of an ``all optical" plasma waveguide that confines and guides a laser pulse at the optimal intensity over long distances, producing quasimonoenergetic multi-GeV electron bunches. However strong pulses of radio frequency radiation (RF) are also produced, and particle in cell simulations show why: a continuous stream of multi-MeV electrons are also ejected radially from the plasma due to nonlinear wave breaking, and these excite and copropagate coherently with a giant cylindrical Sommerfeld surface wave. Laboratory measurements, simulations, and analytic approximations all converge on a 20 J laser pulse exciting a 1 Joule, 400 GW broadband THz surface wave, with a peak electric field strength of 35 GV/m. | [üîó Paper](http://arxiv.org/abs/2506.21503v1) |
