# 📌 AI Research Papers (March31 to April06)

## 🔹 LLM

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [On Vanishing Variance in Transformer Length Generalization](http://arxiv.org/abs/2504.02827v1) | Ruining Li, Gabrijel Boduljak, Jensen, Zhou | 2025-04-03 | LLM | It is a widely known issue that Transformers, when trained on shorter sequences, fail to generalize robustly to longer ones at test time. This raises the question of whether Transformer models are real reasoning engines, despite their impressive abilities in mathematical problem solving and code synthesis. In this paper, we offer a vanishing variance perspective on this issue. To the best of our knowledge, we are the first to demonstrate that even for today's frontier models, a longer sequence length results in a decrease in variance in the output of the multi-head attention modules. On the argmax retrieval and dictionary lookup tasks, our experiments show that applying layer normalization after the attention outputs leads to significantly better length generalization. Our analyses attribute this improvement to a reduction-though not a complete elimination-of the distribution shift caused by vanishing variance. | [🔗 Paper](http://arxiv.org/abs/2504.02827v1) |
| [Efficient Autoregressive Shape Generation via Octree-Based Adaptive
  Tokenization](http://arxiv.org/abs/2504.02817v1) | Kangle Deng, Hsueh-Ti Derek Liu, Yiheng Zhu, Xiaoxia Sun, Chong Shang, Kiran Bhat, Deva Ramanan, Jun-Yan Zhu, Maneesh Agrawala, Tinghui Zhou | 2025-04-03 | LLM | Many 3D generative models rely on variational autoencoders (VAEs) to learn compact shape representations. However, existing methods encode all shapes into a fixed-size token, disregarding the inherent variations in scale and complexity across 3D data. This leads to inefficient latent representations that can compromise downstream generation. We address this challenge by introducing Octree-based Adaptive Tokenization, a novel framework that adjusts the dimension of latent representations according to shape complexity. Our approach constructs an adaptive octree structure guided by a quadric-error-based subdivision criterion and allocates a shape latent vector to each octree cell using a query-based transformer. Building upon this tokenization, we develop an octree-based autoregressive generative model that effectively leverages these variable-sized representations in shape generation. Extensive experiments demonstrate that our approach reduces token counts by 50% compared to fixed-size methods while maintaining comparable visual quality. When using a similar token length, our method produces significantly higher-quality shapes. When incorporated with our downstream generative model, our method creates more detailed and diverse 3D content than existing approaches. | [🔗 Paper](http://arxiv.org/abs/2504.02817v1) |
| [Spline-based Transformers](http://arxiv.org/abs/2504.02797v1) | Prashanth Chandran, Agon Serifi, Markus Gross, Moritz Bächer | 2025-04-03 | LLM | We introduce Spline-based Transformers, a novel class of Transformer models that eliminate the need for positional encoding. Inspired by workflows using splines in computer animation, our Spline-based Transformers embed an input sequence of elements as a smooth trajectory in latent space. Overcoming drawbacks of positional encoding such as sequence length extrapolation, Spline-based Transformers also provide a novel way for users to interact with transformer latent spaces by directly manipulating the latent control points to create new latent trajectories and sequences. We demonstrate the superior performance of our approach in comparison to conventional positional encoding on a variety of datasets, ranging from synthetic 2D to large-scale real-world datasets of images, 3D shapes, and animations. | [🔗 Paper](http://arxiv.org/abs/2504.02797v1) |
## 🔹 Diffusion Models

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Unified World Models: Coupling Video and Action Diffusion for
  Pretraining on Large Robotic Datasets](http://arxiv.org/abs/2504.02792v1) | Chuning Zhu, Raymond Yu, Siyuan Feng, Benjamin Burchfiel, Paarth Shah, Abhishek Gupta | 2025-04-03 | Diffusion Models, Scaling Laws, LLM, Multimodal AI | Imitation learning has emerged as a promising approach towards building generalist robots. However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations. Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available. This data provides a rich source of information about real-world dynamics and agent-environment interactions. Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods. In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning. Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality. We show that by simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator. Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies. Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling. Videos and code are available at https://weirdlabuw.github.io/uwm/. | [🔗 Paper](http://arxiv.org/abs/2504.02792v1) |
## 🔹 Multimodal AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage
  Security Inspection](http://arxiv.org/abs/2504.02823v1) | Divya Velayudhan, Abdelfatah Ahmed, Mohamad Alansari, Neha Gour, Abderaouf Behouch, Taimur Hassan, Syed Talal Wasim, Nabil Maalej, Muzammal Naseer, Juergen Gall, Mohammed Bennamoun, Ernesto Damiani, Naoufel Werghi | 2025-04-03 | Multimodal AI, Security & Adversarial ML | Advancements in Computer-Aided Screening (CAS) systems are essential for improving the detection of security threats in X-ray baggage scans. However, current datasets are limited in representing real-world, sophisticated threats and concealment tactics, and existing approaches are constrained by a closed-set paradigm with predefined labels. To address these challenges, we introduce STCray, the first multimodal X-ray baggage security dataset, comprising 46,642 image-caption paired scans across 21 threat categories, generated using an X-ray scanner for airport security. STCray is meticulously developed with our specialized protocol that ensures domain-aware, coherent captions, that lead to the multi-modal instruction following data in X-ray baggage security. This allows us to train a domain-aware visual AI assistant named STING-BEE that supports a range of vision-language tasks, including scene comprehension, referring threat localization, visual grounding, and visual question answering (VQA), establishing novel baselines for multi-modal learning in X-ray baggage security. Further, STING-BEE shows state-of-the-art generalization in cross-domain settings. Code, data, and models are available at https://divs1159.github.io/STING-BEE/. | [🔗 Paper](http://arxiv.org/abs/2504.02823v1) |
| [MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies
  and Emotions](http://arxiv.org/abs/2504.02794v1) | Behdokht Kiafar, Pavan Uttej Ravva, Asif Ahmmed Joy, Salam Daher, Roghayeh Leila Barmaki | 2025-04-03 | Multimodal AI | The need to improve geriatric care quality presents a challenge that requires insights from stakeholders. While simulated trainings can boost competencies, extracting meaningful insights from these practices to enhance simulation effectiveness remains a challenge. In this study, we introduce Multimodal Epistemic Network Analysis (MENA), a novel framework for analyzing caregiver attitudes and emotions in an Augmented Reality setting and exploring how the awareness of a virtual geriatric patient (VGP) impacts these aspects. MENA enhances the capabilities of Epistemic Network Analysis by detecting positive emotions, enabling visualization and analysis of complex relationships between caregiving competencies and emotions in dynamic caregiving practices. The framework provides visual representations that demonstrate how participants provided more supportive care and engaged more effectively in person-centered caregiving with aware VGP. This method could be applicable in any setting that depends on dynamic interpersonal interactions, as it visualizes connections between key elements using network graphs and enables the direct comparison of multiple networks, thereby broadening its implications across various fields. | [🔗 Paper](http://arxiv.org/abs/2504.02794v1) |
## 🔹 Training & Evaluation

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual
  Editing](http://arxiv.org/abs/2504.02826v1) | Xiangyu Zhao, Peiyuan Zhang, Kexian Tang, Hao Li, Zicheng Zhang, Guangtao Zhai, Junchi Yan, Hua Yang, Xue Yang, Haodong Duan | 2025-04-03 | Training & Evaluation, Multimodal AI, LLM, Model Evaluation | Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To address this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and an LMM-as-a-judge approach. Our experiments reveal that while GPT-4o-Native significantly outperforms other open-source and proprietary models, even this state-of-the-art system struggles with logical reasoning tasks, highlighting an area that remains underexplored. As an initial effort, RISEBench aims to provide foundational insights into reasoning-aware visual editing and to catalyze future research. Though still in its early stages, we are committed to continuously expanding and refining the benchmark to support more comprehensive, reliable, and scalable evaluations of next-generation multimodal systems. Our code and data will be released at https://github.com/PhoenixZ810/RISEBench. | [🔗 Paper](http://arxiv.org/abs/2504.02826v1) |
| [BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose
  Estimation](http://arxiv.org/abs/2504.02812v1) | Van Nguyen Nguyen, Stephen Tyree, Andrew Guo, Mederic Fourmy, Anas Gouda, Taeyeop Lee, Sungphill Moon, Hyeontae Son, Lukas Ranftl, Jonathan Tremblay, Eric Brachmann, Bertram Drost, Vincent Lepetit, Carsten Rother, Stan Birchfield, Jiri Matas, Yann Labbe, Martin Sundermeyer, Tomas Hodan | 2025-04-03 | Training & Evaluation | We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks, each defined by a task, object onboarding setup, and dataset group. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 25X faster and 13% more accurate than GenFlow. Methods have a similar ranking on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still noticealy (-53%) behind the accuracy for seen objects (GDet2023). The online evaluation system stays open and is available at http://bop.felk.cvut.cz/ | [🔗 Paper](http://arxiv.org/abs/2504.02812v1) |
| [Generative Evaluation of Complex Reasoning in Large Language Models](http://arxiv.org/abs/2504.02810v1) | Haowei Lin, Xiangyu Wang, Ruilin Yan, Baizhou Huang, Haotian Ye, Jianhua Zhu, Zihao Wang, James Zou, Jianzhu Ma, Yitao Liang | 2025-04-03 | Training & Evaluation, Model Evaluation | With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments. To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs. KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty. Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization. We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students. Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges. Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities. | [🔗 Paper](http://arxiv.org/abs/2504.02810v1) |
| [A Survey of Large Language Models in Mental Health Disorder Detection on
  Social Media](http://arxiv.org/abs/2504.02800v2) | Zhuohan Ge, Nicole Hu, Darian Li, Yubo Wang, Shihao Qi, Yuming Xu, Han Shi, Jason Zhang | 2025-04-03 | Training & Evaluation | The detection and intervention of mental health issues represent a critical global research focus, and social media data has been recognized as an important resource for mental health research. However, how to utilize Large Language Models (LLMs) for mental health problem detection on social media poses significant challenges. Hence, this paper aims to explore the potential of LLM applications in social media data analysis, focusing not only on the most common psychological disorders such as depression and anxiety but also incorporating psychotic disorders and externalizing disorders, summarizing the application methods of LLM from different dimensions, such as text data analysis and detection of mental disorders, and revealing the major challenges and shortcomings of current research. In addition, the paper provides an overview of popular datasets, and evaluation metrics. The survey in this paper provides a comprehensive frame of reference for researchers in the field of mental health, while demonstrating the great potential of LLMs in mental health detection to facilitate the further application of LLMs in future mental health interventions. | [🔗 Paper](http://arxiv.org/abs/2504.02800v2) |
| [Systematic Evaluation of Large Vision-Language Models for Surgical
  Artificial Intelligence](http://arxiv.org/abs/2504.02799v1) | Anita Rau, Mark Endo, Josiah Aklilu, Jaewoo Heo, Khaled Saab, Alberto Paderno, Jeffrey Jopling, F. Christopher Holsinger, Serena Yeung-Levy | 2025-04-03 | Training & Evaluation, Multimodal AI | Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications. | [🔗 Paper](http://arxiv.org/abs/2504.02799v1) |
| [A Framework for Robust Cognitive Evaluation of LLMs](http://arxiv.org/abs/2504.02789v1) | Karin de Langis, Jong Inn Park, Bin Hu, Khanh Chi Le, Andreas Schramm, Michael C. Mensink, Andrew Elfenbein, Dongyeop Kang | 2025-04-03 | Training & Evaluation, Responsible AI, Model Evaluation | Emergent cognitive abilities in large language models (LLMs) have been widely observed, but their nature and underlying mechanisms remain poorly understood. A growing body of research draws on cognitive science to investigate LLM cognition, but standard methodologies and experimen-tal pipelines have not yet been established. To address this gap we develop CognitivEval, a framework for systematically evaluating the artificial cognitive capabilities of LLMs, with a particular emphasis on robustness in response collection. The key features of CognitivEval include: (i) automatic prompt permutations, and (ii) testing that gathers both generations and model probability estimates. Our experiments demonstrate that these features lead to more robust experimental outcomes. Using CognitivEval, we replicate five classic experiments in cognitive science, illustrating the framework's generalizability across various experimental tasks and obtaining a cognitive profile of several state of the art LLMs. CognitivEval will be released publicly to foster broader collaboration within the cognitive science community. | [🔗 Paper](http://arxiv.org/abs/2504.02789v1) |
| [GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image
  Generation](http://arxiv.org/abs/2504.02782v1) | Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan | 2025-04-03 | Training & Evaluation, Diffusion Models, LLM | The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval. | [🔗 Paper](http://arxiv.org/abs/2504.02782v1) |
| [Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy
  for Estimating Energy Consumption of Base Stations](http://arxiv.org/abs/2504.02781v1) | Selim Ickin, Shruti Bothe, Aman Raparia, Nitin Khanna, Erik Sanders | 2025-04-03 | Training & Evaluation, Optimization | Optimization of radio hardware and AI-based network management software yield significant energy savings in radio access networks. The execution of underlying Machine Learning (ML) models, which enable energy savings through recommended actions, may require additional compute and energy, highlighting the opportunity to explore and adopt accurate and energy-efficient ML technologies. This work evaluates the novel use of sparsely structured Neural Circuit Policies (NCPs) in a use case to estimate the energy consumption of base stations. Sparsity in ML models yields reduced memory, computation and energy demand, hence facilitating a low-cost and scalable solution. We also evaluate the generalization capability of NCPs in comparison to traditional and widely used ML models such as Long Short Term Memory (LSTM), via quantifying their sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a clear reduction in computational overhead and energy consumption. Moreover, results indicated that the NCPs are robust to varying HPs such as number of epochs and neurons in each layer, making them a suitable option to ease model management and to reduce energy consumption in Machine Learning Operations (MLOps) in telecommunications. | [🔗 Paper](http://arxiv.org/abs/2504.02781v1) |
## 🔹 Prompt Engineering

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Concept Lancet: Image Editing with Compositional Representation
  Transplant](http://arxiv.org/abs/2504.02828v1) | Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Hancheng Min, Chris Callison-Burch, René Vidal | 2025-04-03 | Prompt Engineering, Diffusion Models | Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation. | [🔗 Paper](http://arxiv.org/abs/2504.02828v1) |
| [F-ViTA: Foundation Model Guided Visible to Thermal Translation](http://arxiv.org/abs/2504.02801v1) | Jay N. Paranjape, Celso de Melo, Vishal M. Patel | 2025-04-03 | Prompt Engineering, Diffusion Models, Ongoing Learning | Thermal imaging is crucial for scene understanding, particularly in low-light and nighttime conditions. However, collecting large thermal datasets is costly and labor-intensive due to the specialized equipment required for infrared image capture. To address this challenge, researchers have explored visible-to-thermal image translation. Most existing methods rely on Generative Adversarial Networks (GANs) or Diffusion Models (DMs), treating the task as a style transfer problem. As a result, these approaches attempt to learn both the modality distribution shift and underlying physical principles from limited training data. In this paper, we propose F-ViTA, a novel approach that leverages the general world knowledge embedded in foundation models to guide the diffusion process for improved translation. Specifically, we condition an InstructPix2Pix Diffusion Model with zero-shot masks and labels from foundation models such as SAM and Grounded DINO. This allows the model to learn meaningful correlations between scene objects and their thermal signatures in infrared imagery. Extensive experiments on five public datasets demonstrate that F-ViTA outperforms state-of-the-art (SOTA) methods. Furthermore, our model generalizes well to out-of-distribution (OOD) scenarios and can generate Long-Wave Infrared (LWIR), Mid-Wave Infrared (MWIR), and Near-Infrared (NIR) translations from the same visible image. Code: https://github.com/JayParanjape/F-ViTA/tree/master. | [🔗 Paper](http://arxiv.org/abs/2504.02801v1) |
## 🔹 AI Safety

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Do Two AI Scientists Agree?](http://arxiv.org/abs/2504.02822v1) | Xinghong Fu, Ziming Liu, Max Tegmark | 2025-04-03 | AI Safety | When two AI models are trained on the same scientific task, do they learn the same theory or two different theories? Throughout history of science, we have witnessed the rise and fall of theories driven by experimental validation or falsification: many theories may co-exist when experimental data is lacking, but the space of survived theories become more constrained with more experimental data becoming available. We show the same story is true for AI scientists. With increasingly more systems provided in training data, AI scientists tend to converge in the theories they learned, although sometimes they form distinct groups corresponding to different theories. To mechanistically interpret what theories AI scientists learn and quantify their agreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI Scientists, trained on standard problems in physics, aggregating training results across many seeds simulating the different configurations of AI scientists. Our findings suggests for AI scientists switch from learning a Hamiltonian theory in simple setups to a Lagrangian formulation when more complex systems are introduced. We also observe strong seed dependence of the training dynamics and final learned weights, controlling the rise and fall of relevant theories. We finally demonstrate that not only can our neural networks aid interpretability, it can also be applied to higher dimensional problems. | [🔗 Paper](http://arxiv.org/abs/2504.02822v1) |
| [Sparse Autoencoders Learn Monosemantic Features in Vision-Language
  Models](http://arxiv.org/abs/2504.02821v1) | Mateusz Pach, Shyamgopal Karthik, Quentin Bouniot, Serge Belongie, Zeynep Akata | 2025-04-03 | AI Safety, Multimodal AI | Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs. | [🔗 Paper](http://arxiv.org/abs/2504.02821v1) |
## 🔹 General AI

| 📄 Title | 🖊 Authors | 📅 Date | 🏷 Tags | 📜 Summary | 🔗 Link |
|---------|---------|---------|---------|---------|---------|
| [Bubbles in a box: Eliminating edge nucleation in cold-atom simulators of
  vacuum decay](http://arxiv.org/abs/2504.02829v1) | Alexander C. Jenkins, Hiranya V. Peiris, Andrew Pontzen | 2025-04-03 | General AI | The decay of metastable 'false vacuum' states via bubble nucleation plays a crucial role in many cosmological scenarios. Cold-atom analog experiments will soon provide the first empirical probes of this process, with potentially far-reaching implications for early-Universe cosmology and high-energy physics. However, an inevitable difference between these analog systems and the early Universe is that the former have a boundary. We show, using a combination of Euclidean calculations and real-time lattice simulations, that these boundaries generically cause rapid bubble nucleation on the edge of the experiment, obscuring the bulk nucleation that is relevant for cosmology. We demonstrate that implementing a high-density 'trench' region at the boundary completely eliminates this problem, and recovers the desired cosmological behavior. Our findings are relevant for ongoing efforts to probe vacuum decay in the laboratory, providing a practical solution to a key experimental obstacle. | [🔗 Paper](http://arxiv.org/abs/2504.02829v1) |
| [From moving groups to star formation in the Solar Neighborhood](http://arxiv.org/abs/2504.02825v1) | Cameren Swiggum, João Alves, Elena D'Onghia | 2025-04-03 | General AI | Moving groups in the solar neighborhood are ensembles of co-moving stars, likely originating due to forces from spiral arms, the Galactic bar, or external perturbations. Their co-movement with young clusters indicates recent star formation within these moving groups, but a lack of precise three-dimensional position and velocity measurements has obscured this connection. Using backward orbit integrations of 509 clusters within 1 kpc - based on Gaia DR3 and supplemented with APOGEE-2 and GALAH DR3 radial velocities - we trace their evolution over the past 100 Myr. We find that most clusters separate into three spatial groups that each trace one of the Pleiades, Coma Berenices, and Sirius moving groups. The same trend is not seen for the Hyades moving group. The young clusters of the Alpha Persei, Messier 6, and Collinder 135 families of clusters, previously found to have formed in three massive star-forming complexes, co-move with either the Pleiades (Alpha Persei and Messier 6) or Coma Berenices (Collinder 135). Our results provide a sharper view of how large-scale Galactic dynamics have shaped recent, nearby star formation. | [🔗 Paper](http://arxiv.org/abs/2504.02825v1) |
| [Observation of non-Hermitian dislocation bound states and dislocation
  skin effects](http://arxiv.org/abs/2504.02824v1) | Jia-Xin Zhong, Bitan Roy, Yun Jing | 2025-04-03 | General AI | The confluence of Non-Hermitian (NH) topology and crystal defects has culminated significant interest, yet its experimental exploration has been limited due to the challenges involved in design and measurements. Here, we showcase experimental observation of NH dislocation bound states (NHDS) and the dislocation-induced NH skin effect in two-dimensional acoustic NH Chern lattices. By embedding edge dislocations in such acoustic lattices and implementing precision-controlled hopping and onsite gain/loss via active meta-atoms, we reveal robust defect-bound states localized at dislocation cores within the line gap of the complex energy spectrum. These NHDS survive against moderate NH perturbations but gradually delocalize and merge with the bulk (skin) states as the system arrives at the shore of fostering exceptional points in the Brillouin zone under periodic (open) boundary conditions. Furthermore, our experiments demonstrate that the dislocation core can feature weak NH skin effects when its direction is perpendicular to the Burgers vector in periodic systems. Our findings pave an experimental pathway for probing NH topology via lattice defects and open new avenues for defect-engineered topological devices. | [🔗 Paper](http://arxiv.org/abs/2504.02824v1) |
| [Excitation of the Glashow resonance without neutrino beams](http://arxiv.org/abs/2504.02820v1) | I. Alikhanov | 2025-04-03 | General AI | The $s$-channel process $\bar\nu_ee^-\rightarrow W^-$(on-shell) is now referred to as the Glashow resonance and being searched for at kilometer-scale neutrino ice/water detectors like IceCube, Baikal-GVD or KM3NeT. After over a decade of observations, IceCube has recorded only a few relevant neutrino events such that further exploration yet remains necessary for unambiguous confirmation of the existence of this resonant interaction. Meanwhile, its experimental discovery would provide an additional important test of the Standard Model. One might therefore ask: are there reactions with the Glashow resonance that would not necessitate having initial (anti)neutrino beams? This article suggests a surprisingly positive answer to the question $-$ namely, that the process may proceed in electron-positron collisions at accelerator energies, occurring as $e^+e^-\rightarrow W^-\rho(770)^+$. Although the resonance appears somewhat disguised, the underlying physics is transparent, quite resembling the well known radiative return: emission of $\rho^+$ from the initial state converts the incident $e^+$ into $\bar\nu_e$. Likewise, the CP conjugate channel, $\nu_e e^+\rightarrow W^+$, takes the form $e^+e^-\rightarrow W^+\rho(770)^-$. Similar reactions with muons are also possible. Within this viewpoint, future high-luminosity lepton colliders seem to be promising for excitation of the Glashow resonance in laboratory conditions. | [🔗 Paper](http://arxiv.org/abs/2504.02820v1) |
| [GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution
  Kernel Using Gaussian Mixture Rings](http://arxiv.org/abs/2504.02819v1) | Yuexi Du, Jiazhen Zhang, Nicha C. Dvornek, John A. Onofrey | 2025-04-03 | General AI | Symmetry, where certain features remain invariant under geometric transformations, can often serve as a powerful prior in designing convolutional neural networks (CNNs). While conventional CNNs inherently support translational equivariance, extending this property to rotation and reflection has proven challenging, often forcing a compromise between equivariance, efficiency, and information loss. In this work, we introduce Gaussian Mixture Ring Convolution (GMR-Conv), an efficient convolution kernel that smooths radial symmetry using a mixture of Gaussian-weighted rings. This design mitigates discretization errors of circular kernels, thereby preserving robust rotation and reflection equivariance without incurring computational overhead. We further optimize both the space and speed efficiency of GMR-Conv via a novel parameterization and computation strategy, allowing larger kernels at an acceptable cost. Extensive experiments on eight classification and one segmentation datasets demonstrate that GMR-Conv not only matches conventional CNNs' performance but can also surpass it in applications with orientation-less data. GMR-Conv is also proven to be more robust and efficient than the state-of-the-art equivariant learning methods. Our work provides inspiring empirical evidence that carefully applied radial symmetry can alleviate the challenges of information loss, marking a promising advance in equivariant network architectures. The code is available at https://github.com/XYPB/GMR-Conv. | [🔗 Paper](http://arxiv.org/abs/2504.02819v1) |
| [Universal Log-Optimality for General Classes of e-processes and
  Sequential Hypothesis Tests](http://arxiv.org/abs/2504.02818v1) | Ian Waudby-Smith, Ricardo Sandoval, Michael I. Jordan | 2025-04-03 | General AI | We consider the problem of sequential hypothesis testing by betting. For a general class of composite testing problems -- which include bounded mean testing, equal mean testing for bounded random tuples, and some key ingredients of two-sample and independence testing as special cases -- we show that any $e$-process satisfying a certain sublinear regret bound is adaptively, asymptotically, and almost surely log-optimal for a composite alternative. This is a strong notion of optimality that has not previously been established for the aforementioned problems and we provide explicit test supermartingales and $e$-processes satisfying this notion in the more general case. Furthermore, we derive matching lower and upper bounds on the expected rejection time for the resulting sequential tests in all of these cases. The proofs of these results make weak, algorithm-agnostic moment assumptions and rely on a general-purpose proof technique involving the aforementioned regret and a family of numeraire portfolios. Finally, we discuss how all of these theorems hold in a distribution-uniform sense, a notion of log-optimality that is stronger still and seems to be new to the literature. | [🔗 Paper](http://arxiv.org/abs/2504.02818v1) |
| [On cycle covers of infinite bipartite graphs](http://arxiv.org/abs/2504.02816v1) | Leandro Aurichi, Paulo Magalhães Júnior, Lyubomyr Zdomskyy | 2025-04-03 | General AI | Given a graph $G$ and a subset $X$ of vertices of $G$ with size at least two, we denote by $N^2_G(X)$ the set of vertices of $G$ that have at least two neighbors in $X$. We say that a bipartite graph $G$ with sides $A$ and $B$ satisfies the double Hall property if for every subset $X$ of vertices of $A$ with size at least 2, $\vert N^2_G(X)\vert \geq \vert X\vert$. Salia conjectured that if $G$ is a bipartite graph that satisfies the double Hall property, then there exists a cycle in $G$ that covers all vertices of $A$. In this work, we study this conjecture restricted to infinite graphs. For this, we use the definition of ends and infinite cycles. It is simple to see that Salia's conjecture is false for infinite graphs in general. Consequently, all our results are partial. Under certain hypothesis it is possible to obtain a collection of pairwise disjoint 2-regular subgraphs that covers $A$. We show that if side $B$ is locally finite and side $A$ is countable, then the conjecture is true. Furthermore, assuming the conjecture holds for finite graphs, we show that it holds for infinite graphs with a restriction on the degree of the vertices of $B$. This result is inspired by the result obtained by Bar\'at, Grzesik, Jung, Nagy and P\'alv\"olgyi for finite graphs. Finally, we also show that if Salia's conjecture holds for some cases of infinite graphs, then the conjecture about finite graphs presented by Lavrov and Vandenbussche is true. | [🔗 Paper](http://arxiv.org/abs/2504.02816v1) |
| [Logarithmic entanglement lightcone from eigenstate correlations in the
  many-body localised phase](http://arxiv.org/abs/2504.02815v1) | Ratul Thakur, Bikram Pain, Sthitadhi Roy | 2025-04-03 | General AI | We investigate the operator entanglement of the time-evolution operator through the framework of eigenstate correlations. Focusing on strongly disordered quantum many-body systems in the many-body localised (MBL) regime, we analyse the operator entanglement across various spatiotemporal cuts, revealing the logarithmic lightcone of entanglement spreading. We demonstrate that this logarithmic lightcone arises directly from a hierarchy of energyscales and lengthscales encoded in eigenstate correlations. By characterising the statistics of these hierarchical scales, we develop a microscopic theory for the spatiotemporal structure of entanglement spreading in MBL systems -- without invoking phenomenological constructs such as $\ell$-bits. This approach reveals the fundamental connection between eigenstate correlations and the emergent entanglement structure in MBL systems. | [🔗 Paper](http://arxiv.org/abs/2504.02815v1) |
| [Convergence of the Markovian iteration for coupled FBSDEs via a
  differentiation approach](http://arxiv.org/abs/2504.02814v1) | Zhipeng Huang, Cornelis W. Oosterlee | 2025-04-03 | General AI | In this paper, we investigate the Markovian iteration method for solving coupled forward-backward stochastic differential equations (FBSDEs) featuring a fully coupled forward drift, meaning the drift term explicitly depends on both the forward and backward processes. An FBSDE system typically involves three stochastic processes: the forward process $X$, the backward process $Y$ representing the solution, and the $Z$ process corresponding to the scaled derivative of $Y$. Prior research by Bender and Zhang (2008) has established convergence results for iterative schemes dealing with $Y$-coupled FBSDEs. However, extending these results to equations with $Z$ coupling poses significant challenges, especially in uniformly controlling the Lipschitz constant of the decoupling fields across iterations and time steps within a fixed-point framework.   To overcome this issue, we propose a novel differentiation-based method for handling the $Z$ process. This approach enables improved management of the Lipschitz continuity of decoupling fields, facilitating the well-posedness of the discretized FBSDE system with fully coupled drift. We rigorously prove the convergence of our Markovian iteration method in this more complex setting. Finally, numerical experiments confirm our theoretical insights, showcasing the effectiveness and accuracy of the proposed methodology. | [🔗 Paper](http://arxiv.org/abs/2504.02814v1) |
| [Regularity and bounded $t$-structures for algebraic stacks](http://arxiv.org/abs/2504.02813v1) | Timothy De Deyn, Pat Lank, Kabeer Manali Rahul, Fei Peng | 2025-04-03 | General AI | Our work shows (the expected) cohomological characterization for regularity of (Noetherian) algebraic stacks; such a stack is regular if and only if all complexes with bounded and coherent cohomology are perfect. This naturally enables us to extend various statements known for schemes to algebraic stacks. In particular, the conjectures by Antieau--Gepner--Heller and Bondal--Van den Bergh, both resolved for schemes by Neeman, are proven for suitable algebraic stacks. | [🔗 Paper](http://arxiv.org/abs/2504.02813v1) |
| [An Assessment of the CO$_2$ Emission Reduction Potential of Residential
  Load Management in Developing and Developed Countries](http://arxiv.org/abs/2504.02811v1) | Alona Zharova, Felix Creutzig | 2025-04-03 | General AI | Intermittent renewable energies are increasingly dominating electricity grids and are forecasted to be the main force driving out fossil fuels from the grid in most major economies until 2040. However, grids based on intermittent renewables are challenged by diurnal and seasonal mismatch between supply of sun and wind and demand for electricity, including for heat pumps and electric two and four wheelers. Load management and demand response measures promise to adjust for this mismatch, utilizing information- and price-based approaches to steer demand towards times with high supply of intermittent renewables. Here, we systematically review the literature estimating CO$_2$ savings from residential load management in developing and developed nations. We find that load management holds high potential, locally differentiated with energy mix (including the respective share of renewables and fossils), climate zone, and the regulatory environment and price mechanism. Most identified studies suggest a mitigation potential between 1 and 20%. Load management becomes more relevant with higher shares of intermittent renewables, and when electricity prices are high. Importantly, load management aligns consumers' financial incentives with climate change mitigation, thus rendering accompanying strategies politically feasible. We summarize key regulatory steps to facilitate load management in economies and to realize relevant consumer surplus and mitigation potential. | [🔗 Paper](http://arxiv.org/abs/2504.02811v1) |
| [Fractional attractors in light of the latest ACT observations](http://arxiv.org/abs/2504.02809v1) | Christian Dioguardi, Antonio J. Iovino, Antonio Racioppi | 2025-04-03 | General AI | In light of the latest results from ACT observations we review a class of potentials labeled as fractional attractors, that can originate from Palatini gravity. We show in a model independent way that this class of potentials predicts both a spectral index $n_s$ and a tensor-to-scalar ratio $r$ which fit the $1\sigma$ region of the combination ACT+Planck data for a wide choice of the parameters. We also provide a numerical fit for the parameter space of this models in the case of a simple quadratic and quartic fractional potential. | [🔗 Paper](http://arxiv.org/abs/2504.02809v1) |
| [Quantum theory does not need complex numbers](http://arxiv.org/abs/2504.02808v1) | Timothee Hoffreumon, Mischa P. Woods | 2025-04-03 | General AI | The longstanding debate over whether quantum theory fundamentally requires complex numbers--or if their use is merely a convenient choice--has persisted for decades. Until recently, this question was considered open. However, in [M.-O. Renou et al, Nature 600, 625-629, 2021], a decisive argument was presented asserting that quantum theory needs complex numbers. In this work, we demonstrate that a formulation of quantum theory based solely on real numbers is indeed possible while retaining key features such as theory-representation locality (i.e. local physical operations are represented by local changes to the states) and the positive semi-definiteness of its states and effects. We observe that the standard system combination rule--the tensor product--was derived after the development of single-system complex quantum theory. By starting from a single-system quantum theory using only real numbers, we derive a combination rule that produces a real quantum theory with properties analogous to those of conventional complex quantum theory. We also prove that the conventional tensor product rule can also lead to a real and representation-local theory, albeit with a modified characterization of the state space. We thus conclude that complex numbers are a mere convenience in quantum theory. | [🔗 Paper](http://arxiv.org/abs/2504.02808v1) |
| [MegaMath: Pushing the Limits of Open Math Corpora](http://arxiv.org/abs/2504.02807v1) | Fan Zhou, Zengzhi Wang, Nikhil Ranjan, Zhoujun Cheng, Liping Tang, Guowei He, Zhengzhong Liu, Eric P. Xing | 2025-04-03 | General AI | Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet. (2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity. (3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data. By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets. | [🔗 Paper](http://arxiv.org/abs/2504.02807v1) |
| [Vertex-Based Localization of Turán's Theorem](http://arxiv.org/abs/2504.02806v1) | Rajat Adak | 2025-04-03 | General AI | For a simple graph $G$, let $n$ and $m$ denote the number of vertices and edges in $G$, respectively. Tur\'{a}n's theorem states that in a simple $K_{r+1}$ free graph, $m \leq \frac{n^2(r-1)}{2r}$. In this paper, we generalize this result as follows: For each $v \in V(G)$, let $c(v)$ be the order of the largest clique that contains $v$. We show that \[ m \leq \frac{n}{2}\sum_{v\in V(G)}\frac{c(v)-1}{c(v)}\] Furthermore, we characterize the class of extremal graphs that attain equality in this bound. | [🔗 Paper](http://arxiv.org/abs/2504.02806v1) |
| [The M31-M33 Interaction: Impact on M31's Center of Mass Motion and
  Satellite Orbits](http://arxiv.org/abs/2504.02805v1) | Ekta Patel, Nicolas Garavito-Camargo, Ivanna Escala | 2025-04-03 | General AI | Inspired by recent studies of the Milky Way--LMC interaction and its implications for the Milky Way's global dynamical history, we investigate how the massive satellite galaxy M33 influences Andromeda's (M31) center of mass (COM) position and velocity as it passes through M31's halo. Using recent 6-dimensional phase space measurements for both galaxies, we use backward integration to revisit M33's orbital history in a massive M31 potential ($3\times10^{12}\,M_{\odot}$) for the first time. As previously concluded, we find that a first infall orbit is still the most statistically significant ($\gtrsim$ 90%) orbital solution for M33, except for a high mass M31 combined with M31 proper motions from HST (as opposed to Gaia), where there is a greater likelihood (~65%) of a previous encounter. However, the minimum distance between M33 and M31 during this passage is typically $\geq$ 100 kpc, two to three times larger than the distance required to explain M33's warped stellar and gaseous disks. We quantify the magnitude and direction of M31's evolving COM position ($R_{COM}$) and velocity ($V_{COM}$) owing to M33, finding $R_{COM}\approx$100-150 kpc at maximum and $V_{COM}\approx$20-40 km s$^{-1}$. Furthermore, we explore the implications of this phenomenon for the M31 satellite system, specifically whether M33's gravitational influence is linked to the lopsided distribution of M31 satellites and whether M33 significantly perturbs the orbits of other M31 satellites. While M33 alone may not explain the lopsided nature of M31's satellite system, its dynamical impact is non-negligible and must be accounted for in future dynamical studies of the M31 system. | [🔗 Paper](http://arxiv.org/abs/2504.02805v1) |
| [Convergence of Ricci flow and long-time existence of Harmonic map heat
  flow](http://arxiv.org/abs/2504.02804v1) | Kyeongsu Choi, Yi Lai | 2025-04-03 | General AI | For an ancient Ricci flow asymptotic to a compact integrable shrinker, or a Ricci flow developing a finite-time singularity modelled on the shrinker, we establish the long-time existence of a harmonic map heat flow between the Ricci flow and the shrinker for all times. This provides a global parabolic gauge for the Ricci flow and implies the uniqueness of the tangent flow without modulo any diffeomorphisms.   We present two main applications: First, we construct and classify all ancient Ricci flows asymptotic to any compact integrable shrinker, showing that they converge exponentially. Second, we obtain the optimal convergence rate at singularities modelled on the shrinker, characterized by the first negative eigenvalue of the stability operator for the entropy. In particular, we show that any Ricci flow developing a round $\mathbb S^n$ singularity converges at least at the rate $(-t)^{\frac{n+1}{n-1}}$. | [🔗 Paper](http://arxiv.org/abs/2504.02804v1) |
| [Beyond Discretization: A Continuous-Time Framework for Event Generation
  in Neuromorphic Pixels](http://arxiv.org/abs/2504.02803v1) | Aaron J. Hendrickson, David P. Haefner | 2025-04-03 | General AI | A novel continuous-time framework is proposed for modeling neuromorphic image sensors in the form of an initial canonical representation with analytical tractability. Exact simulation algorithms are developed in parallel with closed-form expressions that characterize the model's dynamics. This framework enables the generation of synthetic event streams in genuine continuous-time, which combined with the analytical results, reveal the underlying mechanisms driving the oscillatory behavior of event data presented in the literature. | [🔗 Paper](http://arxiv.org/abs/2504.02803v1) |
| [Complex Heavy Quarkonium Potential in an Anisotropic Collisional
  Quark-Gluon Plasma](http://arxiv.org/abs/2504.02802v1) | Manas Debnath, Lata Thakur, Najmul Haque | 2025-04-03 | General AI | We compute the complex heavy-quark potential in an anisotropic quark-gluon plasma (QGP) using kinetic theory with a Bhatnagar-Gross-Krook (BGK) collision kernel to incorporate collisions via gluon collective modes. By modifying the medium's dielectric permittivity with momentum anisotropy and finite collisional rates, we derive both the real and imaginary components of the potential. While collisions have minimal impact on the real part and binding energy, they significantly amplify the imaginary part, modulating the effects of anisotropy. This enhancement increases quarkonium dissociation rates in a nonequilibrium QGP, offering deeper insights into suppression mechanisms. | [🔗 Paper](http://arxiv.org/abs/2504.02802v1) |
| [North+Lone Star Supernova Host Survey I: Local Host-Galaxy H$α$
  Surface Brightness and the Hubble Residuals of Type Ia Supernovae](http://arxiv.org/abs/2504.02798v1) | Ann M. Isaacs, Patrick Kelly, J. Craig Wheeler | 2025-04-03 | General AI | We present optical integral-field unit (IFU) spectroscopy acquired with the George and Cynthia Mitchell Spectrograph on the Harlan J. Smith telescope at McDonald Observatory of 94 galaxies (0.01 < z < 0.058) that have hosted Type Ia supernovae (SNe Ia). We selected host galaxies with star-forming morphology, consistent with the criteria used by Riess et al. (2022). We measured the H${\alpha}$ surface brightness of each host galaxy within 1 kpc of the location of the supernova. Using distances from the Pantheon+ sample, we find a step in Hubble residuals compared to local H${\alpha}$ surface brightness of -0.097 $\pm$ 0.051 mag at 1.9${\sigma}$ significance in a sample of 73 host galaxies, where SNe in environments with smaller H${\alpha}$ surface brightness are, on average, less luminous after correction for light-curve shape and color. Almost all of the SNe in our sample were discovered by targeted surveys. Using an independent sample primarily from the untargeted Nearby Supernova Factory survey, Rigault et al. (2020) found a step of 0.045 $\pm$ 0.029 mag where SNe in passive environments are instead brighter, which is in 2.4${\sigma}$ tension with our measurement. Rigault et al. (2013) designated SNe Ia comparatively small HRs (< -0.1) and faint local H${\alpha}$ surface brightness (SB) (<log10(H${\alpha}$ SB/(erg$^{-1}$s$^{-1}$kpc$^2$))=38.32 as the M$_2$ population. SNe that would be classified as M$_2$ are less highly represented in our sample (7% versus 21%). When we include an additional twelve early-type galaxies, the number of M$_2$ SNe is almost doubled, although the tension with the HR step measured by Rigault et al. (2020) persists at 1.7${\sigma}$. | [🔗 Paper](http://arxiv.org/abs/2504.02798v1) |
| [Suppression of decoherence dynamics by a dissipative bath at strong
  coupling](http://arxiv.org/abs/2504.02796v1) | Jitian Chen, Jakub Garwoła, Dvira Segal | 2025-04-03 | General AI | Control of decoherence in open quantum systems has become a topic of great interest due to the emergence of quantum technologies that depend on quantum coherent effects. In this work, we investigate the decoherence dynamics of systems coupled to multiple baths through noncommuting systems' operators, and beyond the weak system-bath coupling limit. By building on cooperative effects between baths, we propose a novel strategy to mitigate rapid decoherence. Concretely, we study the dynamics of a qubit coupled to multiple environments with arbitrary interaction strengths, and along different coordinates. Based on insights gained on the decoherence dynamics from the analytical Effective Hamiltonian method, we carry out numerical simulations using the Reaction Coordinate quantum master equation method. In contrast to standard expectations, we show that when the system strongly interacts with a decohering bath, increasing its coupling to a second, dissipative bath slows down the decoherence dynamics. Our work offers insights into the preservation of quantum coherences in open quantum systems based on frustration effects, by utilizing cooperative effects between different heat baths. | [🔗 Paper](http://arxiv.org/abs/2504.02796v1) |
| [Greedy Regular Convolutions](http://arxiv.org/abs/2504.02795v1) | Jan Snellman | 2025-04-03 | General AI | We introduce a class of convolutions on arithmetical functions that are regular in the sense of of Narkiewicz, homogeneous in the sense of Burnett et al, and bounded, in the sense that there exists a common finite bound for the rank of primitive numbers. Among these "greedy convolutions" the unitary convolution and the "ternary convolution" are particularly interesting: they are the only regular, homogeneous convolutions where each primitive number have the same finite rank. While the greedy convolution of length 3, also described in detail, has primitive numbers of rank 3 and rank 1, it is still special in that the set of primitives can be generated by a simple recursive procedure that we name selective sifting. | [🔗 Paper](http://arxiv.org/abs/2504.02795v1) |
| [A Framework for Situating Innovations, Opportunities, and Challenges in
  Advancing Vertical Systems with Large AI Models](http://arxiv.org/abs/2504.02793v1) | Gaurav Verma, Jiawei Zhou, Mohit Chandra, Srijan Kumar, Munmun De Choudhury | 2025-04-03 | General AI | Large artificial intelligence (AI) models have garnered significant attention for their remarkable, often "superhuman", performance on standardized benchmarks. However, when these models are deployed in high-stakes verticals such as healthcare, education, and law, they often reveal notable limitations. For instance, they exhibit brittleness to minor variations in input data, present contextually uninformed decisions in critical settings, and undermine user trust by confidently producing or reproducing inaccuracies. These challenges in applying large models necessitate cross-disciplinary innovations to align the models' capabilities with the needs of real-world applications. We introduce a framework that addresses this gap through a layer-wise abstraction of innovations aimed at meeting users' requirements with large models. Through multiple case studies, we illustrate how researchers and practitioners across various fields can operationalize this framework. Beyond modularizing the pipeline of transforming large models into useful "vertical systems", we also highlight the dynamism that exists within different layers of the framework. Finally, we discuss how our framework can guide researchers and practitioners to (i) optimally situate their innovations (e.g., when vertical-specific insights can empower broadly impactful vertical-agnostic innovations), (ii) uncover overlooked opportunities (e.g., spotting recurring problems across verticals to develop practically useful foundation models instead of chasing benchmarks), and (iii) facilitate cross-disciplinary communication of critical challenges (e.g., enabling a shared vocabulary for AI developers, domain experts, and human-computer interaction scholars). | [🔗 Paper](http://arxiv.org/abs/2504.02793v1) |
| [Variability study of classical supergiant X-ray binary 4U 1907+09 using
  NuSTAR](http://arxiv.org/abs/2504.02791v1) | Raj Kumara, Sayantan Bhattacharya, Sudip Bhattacharyya, Subir Bhattacharyyaa | 2025-04-03 | General AI | We investigate the X-ray variability of the supergiant X-ray binary 4U 1907+09 using the new NuSTAR observation of 2024. The source had a relatively stable flux level during previous NuSTAR observations, but the flux varied significantly during the current one. The light curve exhibits dips (off-state) and flares (on-state). The phase-coherent timing analysis during the on-state yields a pulse period of $443.99(4)~\mathrm{s}$, showing the pulsar's continued spin-down. The pulse profiles show an asymmetric double-peaked structure with a phase separation of 0.47 between the two peaks. A cyclotron resonance scattering feature (CRSF) is also detected at $\sim 17.6~\mathrm{keV}$, along with its harmonic at $\sim 38~\mathrm{keV}$, persisting across all flux states. Flux-resolved spectroscopy reveals that the CRSF remains constant despite a 25-fold change in flux. The spectral parameters like photon index and e-fold energy are out of phase with the pulse shape, whereas cutoff energy is in phase with the pulse shape. The source's luminosity during the on-state is $2.85 \times 10^{35}~\mathrm{erg~s^{-1}}$, consistent with a "pencil" beam radiation pattern expected at this flux level from a collisionless gas-mediated shock. These results offer further insights into the accretion dynamics and magnetic field geometry of this system. | [🔗 Paper](http://arxiv.org/abs/2504.02791v1) |
| [Dynamic Treewidth in Logarithmic Time](http://arxiv.org/abs/2504.02790v1) | Tuukka Korhonen | 2025-04-03 | General AI | We present a dynamic data structure that maintains a tree decomposition of width at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is updated by edge insertions and deletions. The amortized update time of our data structure is $2^{O(k)} \log n$, where $n$ is the number of vertices. The data structure also supports maintaining any ``dynamic programming scheme'' on the tree decomposition, providing, for example, a dynamic version of Courcelle's theorem with $O_{k}(\log n)$ amortized update time; the $O_{k}(\cdot)$ notation hides factors that depend on $k$. This improves upon a result of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\l}owski [FOCS 2023], who gave a similar data structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$. Furthermore, our data structure is arguably simpler.   Our main novel idea is to maintain a tree decomposition that is ``downwards well-linked'', which allows us to implement local rotations and analysis similar to those for splay trees. | [🔗 Paper](http://arxiv.org/abs/2504.02790v1) |
| [Pivoting technique for the circle homeomorphism group](http://arxiv.org/abs/2504.02788v1) | Inhyeok Choi | 2025-04-03 | General AI | We adapt Gou{\"e}zel's pivoting technique to the circle homeomorphism group. As an application, we give different proofs of Gilabert Vio's probabilistic Tits alternative and Malicet's exponential synchronization. | [🔗 Paper](http://arxiv.org/abs/2504.02788v1) |
| [A 3D view of dwarf galaxies with Gaia and VLT/FLAMES II. The Sextans
  dwarf spheroidal](http://arxiv.org/abs/2504.02787v1) | Eline Tolstoy, Giuseppina Battaglia, José María Arroyo-Polonio, Anthony G. A. Brown, Thom van Essen, Davide Massari, Ása Skúladóttir, Michael J. Irwin, Salvatore Taibi, John Pritchard | 2025-04-03 | General AI | The Sextans dwarf spheroidal galaxy has been challenging to study in a comprehensive way as it is highly extended on the sky, with an uncertain but large tidal radius of between 80-160 arcminutes (or 3-4kpc), and an extremely low central surface brightness of SigmaV = 26.2 mag/arcsec2. Here we present a new homogeneous survey of 41 VLT/FLAMES multi-fibre spectroscopic pointings that contain 2108 individual spectra, and combined with Gaia DR3 photometry and astrometry we present v-los measurements for 333 individual Red Giant Branch stars that are consistent with membership in the Sextans dwarf spheroidal galaxy. In addition, we provide the metallicity, [Fe/H], determined from the two strongest CaII triplet lines, for 312 of these stars. We look again at the global characteristics of Sextans, deriving a mean line-of-sight velocity of <v-los> = +227.1km/s and a mean metallicity of <[Fe/H]> = -2.37. The metallicity distribution is clearly double peaked, with the highest peak at [Fe/H]= -2.81 and another broader peak at [Fe/H]= -2.09. Thus it appears that Sextans hosts two populations and the superposition leads to a radial variation in the mean metallicity, with the more metal rich population being centrally concentrated. In addition there is an intriguing group of 9 probable members in the outer region of Sextans at higher [Fe/H] than the mean in this region. If this group could be confirmed as members they would eliminate the metallicity gradient. We also look again at the Colour-Magnitude Diagram of the resolved stellar population in Sextans. We also look again at the relation between Sextans and the intriguingly nearby globular cluster, Pal3. The global properties of Sextans have not changed significantly compared to previous studies, but they are now more precise, and the sample of known members in the outer regions is now more complete. | [🔗 Paper](http://arxiv.org/abs/2504.02787v1) |
| [Quantum maximally symmetric space-times](http://arxiv.org/abs/2504.02786v1) | Pedro Meert, Andrea Giusti, Roberto Casadio | 2025-04-03 | General AI | We show that 4-dimensional maximally symmetric spacetimes can be obtained from a coherent state quantisation of gravity, always resulting in geometries that approach the Minkowski vacuum exponentially away from the radius of curvature. A possible connection with the central charge in the AdS/CFT correspondence is also noted. | [🔗 Paper](http://arxiv.org/abs/2504.02786v1) |
| [Beating full state tomography for unentangled spectrum estimation](http://arxiv.org/abs/2504.02785v1) | Angelos Pelecanos, Xinyu Tan, Ewin Tang, John Wright | 2025-04-03 | General AI | How many copies of a mixed state $\rho \in \mathbb{C}^{d \times d}$ are needed to learn its spectrum? To date, the best known algorithms for spectrum estimation require as many copies as full state tomography, suggesting the possibility that learning a state's spectrum might be as difficult as learning the entire state. We show that this is not the case in the setting of unentangled measurements, by giving a spectrum estimation algorithm that uses $n = O(d^3\cdot (\log\log(d) / \log(d))^4 )$ copies of $\rho$, which is asymptotically fewer than the $n = \Omega(d^3)$ copies necessary for full state tomography. Our algorithm is inspired by the technique of local moment matching from classical statistics, and shows how it can be applied in the quantum setting.   As an important subroutine in our spectrum estimation algorithm, we give an estimator of the $k$-th moment $\operatorname{tr}(\rho^k)$ which performs unentangled measurements and uses $O(d^{3-2/k})$ copies of $\rho$ in order to achieve a constant multiplicative error. This directly translates to an additive-error estimator of quantum Renyi entropy of order $k$ with the same number of copies.   Finally, we present numerical evidence that the sample complexity of spectrum estimation can only improve over full state tomography by a sub-polynomial factor. Specifically, for spectrum learning with fully entangled measurements, we run simulations which suggest a lower bound of $\Omega(d^{2 - \gamma})$ copies for any constant $\gamma > 0$. From this, we conclude the current best lower bound of $\Omega(d)$ is likely not tight. | [🔗 Paper](http://arxiv.org/abs/2504.02785v1) |
| [The level of distribution of the sum-of-digits function in arithmetic
  progressions](http://arxiv.org/abs/2504.02784v1) | Nathan Toumi | 2025-04-03 | General AI | For $q \geq 2$, $n \in \mathbb{N}$, let $s_{q}(n)$ denote the sum of the digits of $n$ written in base $q$. Spiegelhofer (2020) proved that the Thue--Morse sequence has level of distribution $1$, improving on a former result of Fouvry and Mauduit (1996). In this paper we generalize this result to sequences of type $\left\{\exp\left(2\pi i\ell s_q(n)/b\right)\right\}_{n \in \mathbb{N}}$ and provide an explicit exponent in the upper bound. | [🔗 Paper](http://arxiv.org/abs/2504.02784v1) |
| [Non-linear elasticity effects and stratification in brushes of branched
  polyelectrolytes](http://arxiv.org/abs/2504.02783v1) | Inna O. Lebedeva, Oleg V. Shavykin, Igor M. Neelov, Ekaterina B. Zhulina, Frans A. M. Leermakers, Oleg V. Borisov | 2025-04-03 | General AI | Brushes formed by arm-tethered starlike polyelectrolytes may exhibit internal segregation into weakly and strongly extended populations (stratified two-layer structure) when strong ionic intermolecular repulsions induce stretching of the tethers up to the limit of their extensibility. We propose an approximate Poisson-Boltzmann theory for analysis of the structure of the stratified brush and compare it with results of numerical self-consistent field modelling. Both analytical and numerical models point to formation of a narrow cloud of counterions (internal double electrical layer) localized inside stratified brush at the boundary between the layers. | [🔗 Paper](http://arxiv.org/abs/2504.02783v1) |
| [From Consumption to Collaboration: Measuring Interaction Patterns to
  Augment Human Cognition in Open-Ended Tasks](http://arxiv.org/abs/2504.02780v1) | Joshua Holstein, Moritz Diener, Philipp Spitzer | 2025-04-03 | General AI | The rise of Generative AI, and Large Language Models (LLMs) in particular, is fundamentally changing cognitive processes in knowledge work, raising critical questions about their impact on human reasoning and problem-solving capabilities. As these AI systems become increasingly integrated into workflows, they offer unprecedented opportunities for augmenting human thinking while simultaneously risking cognitive erosion through passive consumption of generated answers. This tension is particularly pronounced in open-ended tasks, where effective solutions require deep contextualization and integration of domain knowledge. Unlike structured tasks with established metrics, measuring the quality of human-LLM interaction in such open-ended tasks poses significant challenges due to the absence of ground truth and the iterative nature of solution development. To address this, we present a framework that analyzes interaction patterns along two dimensions: cognitive activity mode (exploration vs. exploitation) and cognitive engagement mode (constructive vs. detrimental). This framework provides systematic measurements to evaluate when LLMs are effective tools for thought rather than substitutes for human cognition, advancing theoretical understanding and practical guidance for developing AI systems that protect and augment human cognitive capabilities. | [🔗 Paper](http://arxiv.org/abs/2504.02780v1) |
