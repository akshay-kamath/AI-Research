# üìå AI Research Papers (December15 to December21)

## üîπ Diffusion Models

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Both Semantics and Reconstruction Matter: Making Representation Encoders Ready for Text-to-Image Generation and Editing](https://arxiv.org/abs/2512.17909v1) | Shilong Zhang, He Zhang, Zhifei Zhang, Chongjian Ge, Shuchen Xue, Shaoteng Liu, Mengwei Ren, Soo Ye Kim, Yuqian Zhou, Qing Liu, Daniil Pakhomov, Kai Zhang, Zhe Lin, Ping Luo | 2025-12-19 | Diffusion Models, Training & Evaluation, Model Evaluation | Modern Latent Diffusion Models (LDMs) typically operate in low-level Variational Autoencoder (VAE) latent spaces that are primarily optimized for pixel-level reconstruction. To unify vision generation and understanding, a burgeoning trend is to adopt high-dimensional features from representation encoders as generative latents. However, we empirically identify two fundamental obstacles in this paradigm: (1) the discriminative feature space lacks compact regularization, making diffusion models prone to off-manifold latents that lead to inaccurate object structures; and (2) the encoder's inherently weak pixel-level reconstruction hinders the generator from learning accurate fine-grained geometry and texture. In this paper, we propose a systematic framework to adapt understanding-oriented encoder features for generative tasks. We introduce a semantic-pixel reconstruction objective to regularize the latent space, enabling the compression of both semantic information and fine-grained details into a highly compact representation (96 channels with 16x16 spatial downsampling). This design ensures that the latent space remains semantically rich and achieves state-of-the-art image reconstruction, while remaining compact enough for accurate generation. Leveraging this representation, we design a unified Text-to-Image (T2I) and image editing model. Benchmarking against various feature spaces, we demonstrate that our approach achieves state-of-the-art reconstruction, faster convergence, and substantial performance gains in both T2I and editing tasks, validating that representation encoders can be effectively adapted into robust generative components. | [üîó Paper](https://arxiv.org/abs/2512.17909v1) |
| [Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting](https://arxiv.org/abs/2512.17908v1) | Ananta R. Bhattarai, Helge Rhodin | 2025-12-19 | Diffusion Models, Optimization | Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning. | [üîó Paper](https://arxiv.org/abs/2512.17908v1) |
| [Dexterous World Models](https://arxiv.org/abs/2512.17907v1) | Byungjun Kim, Taeksoo Kim, Junyoung Lee, Hanbyul Joo | 2025-12-19 | Diffusion Models, Multimodal AI | Recent progress in 3D reconstruction has made it easy to create realistic digital twins from everyday environments. However, current digital twins remain largely static and are limited to navigation and view synthesis without embodied interactivity. To bridge this gap, we introduce Dexterous World Model (DWM), a scene-action-conditioned video diffusion framework that models how dexterous human actions induce dynamic changes in static 3D scenes.   Given a static 3D scene rendering and an egocentric hand motion sequence, DWM generates temporally coherent videos depicting plausible human-scene interactions. Our approach conditions video generation on (1) static scene renderings following a specified camera trajectory to ensure spatial consistency, and (2) egocentric hand mesh renderings that encode both geometry and motion cues to model action-conditioned dynamics directly. To train DWM, we construct a hybrid interaction video dataset. Synthetic egocentric interactions provide fully aligned supervision for joint locomotion and manipulation learning, while fixed-camera real-world videos contribute diverse and realistic object dynamics.   Experiments demonstrate that DWM enables realistic and physically plausible interactions, such as grasping, opening, and moving objects, while maintaining camera and scene consistency. This framework represents a first step toward video diffusion-based interactive digital twins and enables embodied simulation from egocentric actions. | [üîó Paper](https://arxiv.org/abs/2512.17907v1) |
| [Diffusion Forcing for Multi-Agent Interaction Sequence Modeling](https://arxiv.org/abs/2512.17900v1) | Vongani H. Maluleke, Kie Horiuchi, Lea Wilken, Evonne Ng, Jitendra Malik, Angjoo Kanazawa | 2025-12-19 | Diffusion Models, Multimodal AI, LLM | Understanding and generating multi-person interactions is a fundamental challenge with broad implications for robotics and social computing. While humans naturally coordinate in groups, modeling such interactions remains difficult due to long temporal horizons, strong inter-agent dependencies, and variable group sizes. Existing motion generation methods are largely task-specific and do not generalize to flexible multi-agent generation. We introduce MAGNet (Multi-Agent Diffusion Forcing Transformer), a unified autoregressive diffusion framework for multi-agent motion generation that supports a wide range of interaction tasks through flexible conditioning and sampling. MAGNet performs dyadic prediction, partner inpainting, and full multi-agent motion generation within a single model, and can autoregressively generate ultra-long sequences spanning hundreds of v. Building on Diffusion Forcing, we introduce key modifications that explicitly model inter-agent coupling during autoregressive denoising, enabling coherent coordination across agents. As a result, MAGNet captures both tightly synchronized activities (e.g, dancing, boxing) and loosely structured social interactions. Our approach performs on par with specialized methods on dyadic benchmarks while naturally extending to polyadic scenarios involving three or more interacting people, enabled by a scalable architecture that is agnostic to the number of agents. We refer readers to the supplemental video, where the temporal dynamics and spatial coordination of generated interactions are best appreciated. Project page: https://von31.github.io/MAGNet/ | [üîó Paper](https://arxiv.org/abs/2512.17900v1) |
| [RadarGen: Automotive Radar Point Cloud Generation from Cameras](https://arxiv.org/abs/2512.17897v1) | Tomer Borreda, Fangqiang Ding, Sanja Fidler, Shengyu Huang, Or Litany | 2025-12-19 | Diffusion Models, Multimodal AI | We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities. | [üîó Paper](https://arxiv.org/abs/2512.17897v1) |
| [Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow](https://arxiv.org/abs/2512.17878v1) | Herlock Rahimi | 2025-12-19 | Diffusion Models, Multimodal AI | Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.   A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments. | [üîó Paper](https://arxiv.org/abs/2512.17878v1) |
| [InSPECT: Invariant Spectral Features Preservation of Diffusion Models](https://arxiv.org/abs/2512.17873v1) | Baohua Yan, Qingyuan Liu, Jennifer Kava, Xuan Di | 2025-12-19 | Diffusion Models | Modern diffusion models (DMs) have achieved state-of-the-art image generation. However, the fundamental design choice of diffusing data all the way to white noise and then reconstructing it leads to an extremely difficult and computationally intractable prediction task. To overcome this limitation, we propose InSPECT (Invariant Spectral Feature-Preserving Diffusion Model), a novel diffusion model that keeps invariant spectral features during both the forward and backward processes. At the end of the forward process, the Fourier coefficients smoothly converge to a specified random noise, enabling features preservation while maintaining diversity and randomness. By preserving invariant features, InSPECT demonstrates enhanced visual diversity, faster convergence rate, and a smoother diffusion process. Experiments on CIFAR-10, Celeb-A, and LSUN demonstrate that InSPECT achieves on average a 39.23% reduction in FID and 45.80% improvement in IS against DDPM for 10K iterations under specified parameter settings, which demonstrates the significant advantages of preserving invariant features: achieving superior generation quality and diversity, while enhancing computational efficiency and enabling faster convergence rate. To the best of our knowledge, this is the first attempt to analyze and preserve invariant spectral features in diffusion models. | [üîó Paper](https://arxiv.org/abs/2512.17873v1) |
| [InfinityEBSD : Metrics-Guided Infinite-Size EBSD Map Generation With Diffusion Models](https://arxiv.org/abs/2512.17859v1) | Sterley Labady, Youssef Mesri, Daniel Pino Munoz, Baptiste Flipon, Marc Bernacki | 2025-12-19 | Diffusion Models | Materials performance is deeply linked to their microstructures, which govern key properties such as strength, durability, and fatigue resistance. EBSD is a major technique for characterizing these microstructures, but acquiring large and statistically representative EBSD maps remains slow, costly, and often limited to small regions. In this work, we introduce InfinityEBSD, a diffusion-based method for generating monophase realistic EBSD maps of arbitrary size, conditioned on physically meaningful microstructural metrics. This approach supports two primary use cases: extending small experimental EBSD maps to arbitrary sizes, and generating entirely new maps directly from statistical descriptors, without any input map. Conditioning is achieved through eight microstructural descriptors, including grain size, grain perimeter, grain inertia ratio, coordination number and disorientation angle distribution, allowing the model to generate maps that are both visually realistic and physically interpretable. A patch-wise geometric extension strategy ensures spatial continuity across grains, enabling the model to produce large-scale EBSD maps while maintaining coherent grain boundaries and orientation transitions. The generated maps can also be exported as valid Channel Text Files (CTF) for immediate post-processing and analysis in software such as MTEX or simulation environments like DIGIMU. We quantitatively validate our results by comparing distributions of the guiding metrics before and after generation, showing that the model respects the statistical targets while introducing morphological diversity. InfinityEBSD demonstrates that diffusion models, guided by physical metrics, can bridge the gap between synthetic and realistic materials representation, paving the way for future developments such as 3D realistic microstructure generation from 2D data. | [üîó Paper](https://arxiv.org/abs/2512.17859v1) |
## üîπ Multimodal AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Map2Video: Street View Imagery Driven AI Video Generation](https://arxiv.org/abs/2512.17883v1) | Hye-Young Jo, Mose Sakashita, Aditi Mishra, Ryo Suzuki, Koichiro Niinuma, Aakar Gupta | 2025-12-19 | Multimodal AI | AI video generation has lowered barriers to video creation, but current tools still struggle with inconsistency. Filmmakers often find that clips fail to match characters and backgrounds, making it difficult to build coherent sequences. A formative study with filmmakers highlighted challenges in shot composition, character motion, and camera control. We present Map2Video, a street view imagery-driven AI video generation tool grounded in real-world geographies. The system integrates Unity and ComfyUI with the VACE video generation model, as well as OpenStreetMap and Mapillary for street view imagery. Drawing on familiar filmmaking practices such as location scouting and rehearsal, Map2Video enables users to choose map locations, position actors and cameras in street view imagery, sketch movement paths, refine camera motion, and generate spatially consistent videos. We evaluated Map2Video with 12 filmmakers. Compared to an image-to-video baseline, it achieved higher spatial accuracy, required less cognitive effort, and offered stronger controllability for both scene replication and open-ended creative exploration. | [üîó Paper](https://arxiv.org/abs/2512.17883v1) |
## üîπ Optimization

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Exploring the Effect of Basis Rotation on NQS Performance](https://arxiv.org/abs/2512.17893v1) | Sven Benjamin Ko≈æiƒá, Vinko Zlatiƒá, Fabio Franchini, Salvatore Marco Giampaolo | 2025-12-19 | Optimization | Neural Quantum States (NQS) use neural networks to represent wavefunctions of quantum many-body systems, but their performance depends on the choice of basis, yet the underlying mechanism remains poorly understood. We use a fully solvable one-dimensional Ising model to show that local basis rotations leave the loss landscape unchanged while relocating the exact wavefunction in parameter space, effectively increasing its geometric distance from typical initializations. By sweeping a rotation angle, we compute quantum Fisher information and Fubini-Study distances to quantify how the rotated wavefunction moves within the loss landscape. Shallow architectures (with focus on Restricted Boltzmann Machines (RBMs)) trained with quantum natural gradient are more likely to fall into saddle-point regions depending on the rotation angle: they achieve low energy error but fail to reproduce correct coefficient distributions. In the ferromagnetic case, near-degenerate eigenstates create high-curvature barriers that trap optimization at intermediate fidelities. We introduce a framework based on an analytically solvable rotated Ising model to investigate how relocating the target wavefunction within a fixed loss landscape exposes information-geometric barriers,such as saddle points and high-curvature regions,that hinder shallow NQS optimization, underscoring the need for landscape-aware model design in variational training. | [üîó Paper](https://arxiv.org/abs/2512.17893v1) |
| [Optimal Control Problems with Nonlocal Conservation Laws: Existence of Optimizers and Singular Limits in Approximations of Local Conservation Laws](https://arxiv.org/abs/2512.17870v1) | Alexander Keimer, Lukas Pflug, Jakob Rodestock | 2025-12-19 | Optimization | This contribution considers optimal control problems subject to nonlocal conservation laws -- those in which the velocity depends nonlocally (i.e., via a convolution) on the solution -- and the so-called singular limit. First, the existence of minimizers is demonstrated for a broad class of optimal control problems, involving optimization over the initial datum, velocity, and nonlocal kernel for classical tracking-type $L^2$ cost functionals. Then, it is proven that the obtained minimizers converge to minimizers of the corresponding local optimal control problem when the kernel function of the convolution is of exponential type and approaches a Dirac distribution. Finally, some numerical results are presented. | [üîó Paper](https://arxiv.org/abs/2512.17870v1) |
## üîπ Training & Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [When Reasoning Meets Its Laws](https://arxiv.org/abs/2512.17901v1) | Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang | 2025-12-19 | Training & Evaluation | Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/ | [üîó Paper](https://arxiv.org/abs/2512.17901v1) |
| [Keypoint Counting Classifiers: Turning Vision Transformers into Self-Explainable Models Without Training](https://arxiv.org/abs/2512.17891v1) | Kristoffer Wickstr√∏m, Teresa Dorszewski, Siyan Chen, Michael Kampffmeyer, Elisabeth Wetzer, Robert Jenssen | 2025-12-19 | Training & Evaluation | Current approaches for designing self-explainable models (SEMs) require complicated training procedures and specific architectures which makes them impractical. With the advance of general purpose foundation models based on Vision Transformers (ViTs), this impracticability becomes even more problematic. Therefore, new methods are necessary to provide transparency and reliability to ViT-based foundation models. In this work, we present a new method for turning any well-trained ViT-based model into a SEM without retraining, which we call Keypoint Counting Classifiers (KCCs). Recent works have shown that ViTs can automatically identify matching keypoints between images with high precision, and we build on these results to create an easily interpretable decision process that is inherently visualizable in the input. We perform an extensive evaluation which show that KCCs improve the human-machine communication compared to recent baselines. We believe that KCCs constitute an important step towards making ViT-based foundation models more transparent and reliable. | [üîó Paper](https://arxiv.org/abs/2512.17891v1) |
| [The role of charm and unflavored mesons in prompt atmospheric lepton fluxes](https://arxiv.org/abs/2512.17886v1) | Laksha Pradip Das, Diksha Garg, Maria Vittoria Garzelli, Mary Hall Reno, G√ºnter Sigl | 2025-12-19 | Training & Evaluation, Scaling Laws | The all-sky very-high-energy ($10^4-10^6$ GeV) atmospheric muon flux measured by IceCube shows a spectral hardening at the highest energies, indicating the presence of a prompt component. IceCube has also measured the atmospheric muon neutrino flux at high energy. However, since this flux is dominated by astrophysical neutrinos, only an upper bound can be placed on the prompt atmospheric $ŒΩ_Œº+\barŒΩ_Œº$ contribution. In this work, we provide a new evaluation of the prompt atmospheric muon flux including an intrinsic charm component in the cosmic ray-air interactions. The latter enhances the forward production of $\bar{D}^0$, $D^-$, and $Œõ_c$, which subsequently decay into final states containing muons and muon neutrinos. We show how the increase in the prompt muon flux due to intrinsic charm is accompanied by a corresponding enhancement in the prompt muon neutrino flux. We implement different intrinsic charm production models in MCEq to calculate the resulting lepton fluxes. We discuss the challenges of achieving predictions that are simultaneously consistent with both IceCube's high-energy atmospheric muon flux measurements and IceCube upper bound on the prompt muon neutrino flux, and we quantify the resulting discrepancies. As possible solutions, we explore scaling of the unflavored meson contributions to the prompt atmospheric muon flux to assess how such adjustments can reconcile these differences. The tensions emphasized in our work call for a refinement of the hadronic interaction models, especially the production of unflavored mesons, and for new experimental data sensitive to unflavored meson and heavy flavor production with reliable estimates of the associated uncertainties. We suggest that the energy and zenith angle dependence of muon and neutrino flux ratios from future neutrino telescope measurements may help to disentangle different scenarios. | [üîó Paper](https://arxiv.org/abs/2512.17886v1) |
| [Visually Prompted Benchmarks Are Surprisingly Fragile](https://arxiv.org/abs/2512.17875v1) | Haiwen Feng, Long Lian, Lisa Dunlap, Jiahao Shu, XuDong Wang, Renhao Wang, Trevor Darrell, Alane Suhr, Angjoo Kanazawa | 2025-12-19 | Training & Evaluation, Model Evaluation, LLM | A key challenge in evaluating VLMs is testing models' ability to analyze visual content independently from their textual priors. Recent benchmarks such as BLINK probe visual perception through visual prompting, where questions about visual content are paired with coordinates to which the question refers, with the coordinates explicitly marked in the image itself. While these benchmarks are an important part of VLM evaluation, we find that existing models are surprisingly fragile to seemingly irrelevant details of visual prompting: simply changing a visual marker from red to blue can completely change rankings among models on a leaderboard. By evaluating nine commonly-used open- and closed-source VLMs on two visually prompted tasks, we demonstrate how details in benchmark setup, including visual marker design and dataset size, have a significant influence on model performance and leaderboard rankings. These effects can even be exploited to lift weaker models above stronger ones; for instance, slightly increasing the size of the visual marker results in open-source InternVL3-8B ranking alongside or better than much larger proprietary models like Gemini 2.5 Pro. We further show that low-level inference choices that are often ignored in benchmarking, such as JPEG compression levels in API calls, can also cause model lineup changes. These details have substantially larger impacts on visually prompted benchmarks than on conventional semantic VLM evaluations. To mitigate this instability, we curate existing datasets to create VPBench, a larger visually prompted benchmark with 16 visual marker variants. VPBench and additional analysis tools are released at https://lisadunlap.github.io/vpbench/. | [üîó Paper](https://arxiv.org/abs/2512.17875v1) |
| [Data-Driven Calibration of Large Liquid Detectors with Unsupervised Learning](https://arxiv.org/abs/2512.17866v1) | Scott DeGraw, Steve Biller, Armin Reichold | 2025-12-19 | Training & Evaluation | This paper demonstrates a novel method to extract photomultiplier tube (PMT) calibration timing constants in large liquid scintillation detectors from physics data using the machinery of unsupervised deep learning. The approach uses a simplified physical model of optical photon transport in the loss function, with PMT calibration constants treated as free parameters, and the simple assumption that individual events represent point-like emission. The problem is, thus, effectively reduced to that of regression on a very large scale, made tractable by deep learning architectures and automatic differentiation frameworks. Using data from the 9,300 PMTs in the SNO+ detector, the method has been shown to reliably extract 3 calibration constants for each of the over 7,500 online PMTs using radioactive background events. We believe that this basic approach can be straightforwardly generalised for a wide range of applications. | [üîó Paper](https://arxiv.org/abs/2512.17866v1) |
| [Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN](https://arxiv.org/abs/2512.17864v1) | Balram Singh, Ram Prakash Sharma, Somnath Dey | 2025-12-19 | Training & Evaluation, AI Safety, Security & Adversarial ML | Plant diseases pose a significant threat to global food security, necessitating accurate and interpretable disease detection methods. This study introduces an interpretable attention-guided Convolutional Neural Network (CNN), CBAM-VGG16, for plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model enhances feature extraction and disease localization. Trained on five diverse plant disease datasets, our approach outperforms recent techniques, achieving high accuracy (up to 98.87%) and demonstrating robust generalization. Here, we show the effectiveness of our method through comprehensive evaluation and interpretability analysis using CBAM attention maps, Grad-CAM, Grad-CAM++, and Layer-wise Relevance Propagation (LRP). This study advances the application of explainable AI in agricultural diagnostics, offering a transparent and reliable system for smart farming. The code of our proposed work is available at https://github.com/BS0111/PlantAttentionCBAM. | [üîó Paper](https://arxiv.org/abs/2512.17864v1) |
## üîπ Model Evaluation

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Adversarial Robustness of Vision in Open Foundation Models](https://arxiv.org/abs/2512.17902v1) | Jonathon Fox, William J Buchanan, Pavlos Papadopoulos | 2025-12-19 | Model Evaluation, Training & Evaluation, Security & Adversarial ML, AI Safety, Responsible AI, LLM | With the increase in deep learning, it becomes increasingly difficult to understand the model in which AI systems can identify objects. Thus, an adversary could aim to modify an image by adding unseen elements, which will confuse the AI in its recognition of an entity. This paper thus investigates the adversarial robustness of LLaVA-1.5-13B and Meta's Llama 3.2 Vision-8B-2. These are tested for untargeted PGD (Projected Gradient Descent) against the visual input modality, and empirically evaluated on the Visual Question Answering (VQA) v2 dataset subset. The results of these adversarial attacks are then quantified using the standard VQA accuracy metric. This evaluation is then compared with the accuracy degradation (accuracy drop) of LLaVA and Llama 3.2 Vision. A key finding is that Llama 3.2 Vision, despite a lower baseline accuracy in this setup, exhibited a smaller drop in performance under attack compared to LLaVA, particularly at higher perturbation levels. Overall, the findings confirm that the vision modality represents a viable attack vector for degrading the performance of contemporary open-weight VLMs, including Meta's Llama 3.2 Vision. Furthermore, they highlight that adversarial robustness does not necessarily correlate directly with standard benchmark performance and may be influenced by underlying architectural and training factors. | [üîó Paper](https://arxiv.org/abs/2512.17902v1) |
## üîπ Responsible AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy](https://arxiv.org/abs/2512.17899v1) | Aditya Gahlawat, Ahmed Aboudonia, Sandeep Banik, Naira Hovakimyan, Nikolai Matni, Aaron D. Ames, Gioele Zardini, Alberto Speranzon | 2025-12-19 | Responsible AI, Model Evaluation, RLHF | Imitation learning (IL) enables autonomous behavior by learning from expert demonstrations. While more sample-efficient than comparative alternatives like reinforcement learning, IL is sensitive to compounding errors induced by distribution shifts. There are two significant sources of distribution shifts when using IL-based feedback laws on systems: distribution shifts caused by policy error and distribution shifts due to exogenous disturbances and endogenous model errors due to lack of learning. Our previously developed approaches, Taylor Series Imitation Learning (TaSIL) and $\mathcal{L}_1$ -Distributionally Robust Adaptive Control (\ellonedrac), address the challenge of distribution shifts in complementary ways. While TaSIL offers robustness against policy error-induced distribution shifts, \ellonedrac offers robustness against distribution shifts due to aleatoric and epistemic uncertainties. To enable certifiable IL for learned and/or uncertain dynamical systems, we formulate \textit{Distributionally Robust Imitation Policy (DRIP)} architecture, a Layered Control Architecture (LCA) that integrates TaSIL and~\ellonedrac. By judiciously designing individual layer-centric input and output requirements, we show how we can guarantee certificates for the entire control pipeline. Our solution paves the path for designing fully certifiable autonomy pipelines, by integrating learning-based components, such as perception, with certifiable model-based decision-making through the proposed LCA approach. | [üîó Paper](https://arxiv.org/abs/2512.17899v1) |
| [Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally](https://arxiv.org/abs/2512.17898v1) | Robin Schimmelpfennig, Mark D√≠az, Vinodkumar Prabhakaran, Aida Davani | 2025-12-19 | Responsible AI | Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance. | [üîó Paper](https://arxiv.org/abs/2512.17898v1) |
| [Constraining primordial non-Gaussianity from DESI DR1 quasars and Planck PR4 CMB Lensing](https://arxiv.org/abs/2512.17865v1) | Sofia Chiarenza, Alex Krolewski, Marco Bonici, Edmond Chaussidon, Roger de Belsunce, Will Percival, Jessica Nicole Aguilar, Steven Ahlen, Anton Baleato Lizancos, Davide Bianchi, David Brooks, Todd Claybaugh, Andrei Cuceu, Kyle Dawson, Axel de la Macorra, Peter Doel, Simone Ferraro, Andreu Font-Ribera, Jaime E. Forero-Romero, Enrique Gazta√±aga, Satya Gontcho A Gontcho, Gaston Gutierrez, Hiram K. Herrera-Alcantar, Klaus Honscheid, Dragan Huterer, Mustapha Ishak, Dick Joyce, David Kirkby, Anthony Kremin, Ofer Lahav, Claire Lamman, Martin Landriau, Laurent Le Guillou, Michael Levi, Marc Manera, Paul Martini, Aaron Meisner, Ramon Miquel, Seshadri Nadathur, Jeffrey A. Newman, Gustavo Niz, Nathalie Palanque-Delabrouille, Claire Poppett, Francisco Prada, Ignasi P√©rez-R√†fols, Graziano Rossi, Eusebio Sanchez, David Schlegel, Michael Schubnell, Hee-Jong Seo, Joseph Harry Silber, David Sprayberry, Gregory Tarl√©, Benjamin Alan Weaver, Christophe Y√®che, Rongpu Zhou, Hu Zou | 2025-12-19 | Responsible AI, Model Evaluation | We present the first measurement of local-type primordial non-Gaussianity from the cross-correlation between $1.2$ million spectroscopically confirmed quasars from the first data release (DR1) of the Dark Energy Spectroscopic Instrument (DESI) and the Planck PR4 CMB lensing reconstructions. The analysis is performed in three tomographic redshift bins covering $0.8 < z < 3.5$, covering a sky fraction of $\sim 20\%$. We adopt a catalog-based pseudo-$C_\ell$ estimator and apply linear imaging weights validated on noiseless mocks. Compared to previous analyses using photometric quasar samples, our results benefit from the high purity of the DESI spectroscopic sample, the reduced noise of PR4 lensing, and the absence of excess large-scale power in the spectroscopic quasar auto-correlation. Fitting simultaneously for the non-Gaussianity parameter $f_{\mathrm{NL}}$ and the linear bias amplitude in each redshift bin, we obtain $f_{\mathrm{NL}} = 2^{+28}_{-34}$ for a response parameter $p=1.6$, and $f_{\mathrm{NL}} = 6^{+20}_{-24}$ for $p=1.0$. These results improve the constraints on $f_{\mathrm{NL}}$ by $\sim 35\%$ compared to the previous analysis based on the Legacy Imaging Survey DR9. Our results demonstrate the statistical power of DESI quasars for probing inflationary physics, and highlight the promise of future DESI data releases. | [üîó Paper](https://arxiv.org/abs/2512.17865v1) |
## üîπ Autonomous Agents

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [XAgen: An Explainability Tool for Identifying and Correcting Failures in Multi-Agent Workflows](https://arxiv.org/abs/2512.17896v1) | Xinru Wang, Ming Yin, Eunyee Koh, Mustafa Doga Dogan | 2025-12-19 | Autonomous Agents, LLM Ops | As multi-agent systems powered by Large Language Models (LLMs) are increasingly adopted in real-world workflows, users with diverse technical backgrounds are now building and refining their own agentic processes. However, these systems can fail in opaque ways, making it difficult for users to observe, understand, and correct errors. We conducted formative interviews with 12 practitioners to identify mismatches between existing observability tools and users' needs. Based on these insights, we designed XAgen, an explainability tool that supports users with varying AI expertise through three core capabilities: log visualization for glanceable workflow understanding, human-in-the-loop feedback to capture expert judgment, and automatic error detection via an LLM-as-a-judge. In a user study with 8 participants, XAgen helped users more easily locate failures, attribute to specific agents or steps, and iteratively improve configurations. Our findings surface human-centered design guidelines for explainable agentic AI development and highlights opportunities for more context-aware interactive debugging. | [üîó Paper](https://arxiv.org/abs/2512.17896v1) |
## üîπ General AI

| üìÑ Title | üñä Authors | üìÖ Date | üè∑ Tags | üìú Summary | üîó Link |
|---------|---------|---------|---------|---------|---------|
| [Extra-Dimensional Œ∑-Invariants and Anomaly Theories](https://arxiv.org/abs/2512.17906v1) | Mirjam Cvetiƒç, Ron Donagi, Jonathan J. Heckman, Max H√ºbner | 2025-12-19 | General AI | Anomalies of a quantum field theory (QFT) constitute fundamental non-perturbatively robust data. In this paper we extract anomalies of 5D superconformal field theories (SCFTs) directly from the underlying extra-dimensional geometry. We show that all of this information can be efficiently extracted from extra-dimensional $Œ∑$-invariants, bypassing previously established approaches based on computationally cumbersome blowup / resolution techniques. We illustrate these considerations for 5D SCFTs engineered in M-theory by non-compact geometries $X=\mathbb{C}^3/Œì$ with finite subgroup $Œì\subset SU(3)$, where the anomalies are determined by the $Œ∑$-invariants of the asymptotic boundary $\partial X=S^5/Œì$. Our results apply equally to Abelian and non-Abelian $Œì$, as well as isolated and non-isolated singularities. In the setting of non-isolated singularities we further analyze the interplay of anomaly structures across different strata of the singular locus. Our considerations extend readily to backgrounds which are not global orbifolds, as well as those which do not preserve supersymmetry. | [üîó Paper](https://arxiv.org/abs/2512.17906v1) |
| [Fisher information for the multi-species Landau system](https://arxiv.org/abs/2512.17905v1) | Yuzhe Zhu | 2025-12-19 | General AI | We consider the Fisher information for spatially homogeneous multi-species Landau system. We show that the mass-weighted Fisher information is monotone decreasing in time along the solutions of the Landau system with a general class of interaction potentials. | [üîó Paper](https://arxiv.org/abs/2512.17905v1) |
| [Plane Strong Connectivity Augmentation](https://arxiv.org/abs/2512.17904v1) | St√©phane Bessy, Daniel Gon√ßalves, Amadeus Reinald, Dimitrios M. Thilikos | 2025-12-19 | General AI | We investigate the problem of strong connectivity augmentation within plane oriented graphs.   We show that deciding whether a plane oriented graph $D$ can be augmented with (any number of) arcs $X$ such that $D+X$ is strongly connected, but still plane and oriented, is NP-hard.   This question becomes trivial within plane digraphs, like most connectivity augmentation problems without a budget constraint.   The budgeted version, Plane Strong Connectivity Augmentation (PSCA) considers a plane oriented graph $D$ along with some integer $k$, and asks for an $X$ of size at most $k$ ensuring that $D+X$ is strongly connected, while remaining plane and oriented.   Our main result is a fixed-parameter tractable algorithm for PSCA, running in time $2^{O(k)} n^{O(1)}$.   The cornerstone of our procedure is a structural result showing that, for any fixed $k$, each face admits a bounded number of partial solutions "dominating" all others.   Then, our algorithm for PSCA combines face-wise branching with a Monte-Carlo reduction to the polynomial Minimum Dijoin problem, which we derandomize.   To the best of our knowledge, this is the first FPT algorithm for a (hard) connectivity augmentation problem constrained by planarity. | [üîó Paper](https://arxiv.org/abs/2512.17904v1) |
| [Feasibility to probe the dynamical scotogenic model at the LHC](https://arxiv.org/abs/2512.17903v1) | Gustavo Ardila-Tafurth, Andr√©s Fl√≥rez, Cristian Rodr√≠guez, Maud Sarazin, √ìscar Zapata | 2025-12-19 | General AI | We perform a feasibility study to probe dark matter (DM) production at the LHC within a global $U(1)_L$ scotogenic model. The study is conducted using the Markov Chain Monte Carlo numerical method, considering the viable parameter space of the model allowed by experimental constraints such as neutrino oscillation data, the Higgs to invisible branching fraction, and DM observables. The production of scalar and fermionic DM candidates, predicted by the model, is then studied under the LHC conditions for different luminosity scenarios imposing compressed mass spectra conditions between the lightest fermion and the $\mathbb{Z}_2$ odd scalars. We studied two production mechanisms, Drell-Yan and Vector Boson Fusion. It was found that the Drell-Yan mechanism gives better detection prospects for fermionic DM masses between 100-220~\textrm{GeV} at high luminosity scenarios. | [üîó Paper](https://arxiv.org/abs/2512.17903v1) |
| [Visualization of The Content of Surah al Fiil using Marker-Based Augmented Reality](https://arxiv.org/abs/2512.17895v1) | Ahmad Badru Al Husaeni, Dzakwanfaiq Nauval, Farid Muhtar Fathir, Mahesa Adlan Falah, Muhammad Miftahur Rizki Awalin | 2025-12-19 | General AI | This study presents the development of a marker-based augmented reality (AR) application designed to visualize the content of Surah al-Fil as an interactive and context-rich medium for Islamic education. Using a research and development approach, the system was developed through structured stages including data collection, user requirement analysis, interface design, 3D asset creation using Blender, and integration of Unity 3D with the Vuforia SDK. The application features key visual elements such as the elephant army, the Kaaba, and the Ababil birds, which were modeled in detail and linked to high-contrast image markers to ensure accurate and stable AR tracking. Functional testing demonstrated strong technical performance, achieving a 95 percent marker detection accuracy at an optimal distance of 30-40 cm with consistent real-time rendering across multiple Android devices. User evaluations involving students and Islamic education teachers indicated high acceptance, with an overall satisfaction score of 4.7 out of 5 in terms of usability, visual appeal, interactivity, and learning effectiveness. These findings indicate that AR-based learning media can enhance learner engagement, deepen understanding of Quranic narratives, and provide immersive insights into historical and spiritual contexts. Overall, this study demonstrates that marker-based AR technology has significant potential to support innovation in digital Islamic education by enriching traditional learning with interactive and visually intuitive experiences. | [üîó Paper](https://arxiv.org/abs/2512.17895v1) |
| [Visualizing Detection Efficiency in Optomechanical Scattering](https://arxiv.org/abs/2512.17894v1) | Youssef Tawfik, Shan Hao, Thomas P. Purdy | 2025-12-19 | General AI | Many optical measurement techniques, such as light scattering from wavelength-scale particles or detecting motion from a surface with an optical lever, encode information in a complex radiation pattern. Extracting all available information is essential for many quantum-enhanced sensing protocols but is often impractical, as it requires many channels to spatially resolve the scattered signal. We present a new method to visualize how efficiently a practical measurement scheme captures the information available in the scattered light by mapping out the local contribution to the detection efficiency on the detector surface. We use this tool to experimentally optimize the free space measurement of the amplitude of motion of an optomechanical resonator with a quadrant photodiode. We show that blocking sections of the photodetector enhances sensitivity, counterintuitively yielding a significant improvement in detecting higher-order mechanical modes in the system. We also show how our method can be applied to light scattering measurements of small particles. | [üîó Paper](https://arxiv.org/abs/2512.17894v1) |
| [Prefix Trees Improve Memory Consumption in Large-Scale Continuous-Time Stochastic Models](https://arxiv.org/abs/2512.17892v1) | Landon Taylor, Joshua Jeppson, Ahmed Irfan, Lukas Buecherl, Chris Myers, Zhen Zhang | 2025-12-19 | General AI | Highly-concurrent system models with vast state spaces like Chemical Reaction Networks (CRNs) that model biological and chemical systems pose a formidable challenge to cutting-edge formal analysis tools. Although many symbolic approaches have been presented, transient probability analysis of CRNs, modeled as Continuous-Time Markov Chains (CTMCs), requires explicit state representation. For that purpose, current cutting-edge methods use hash maps, which boast constant average time complexity and linear memory complexity. However, hash maps often suffer from severe memory limitations on models with immense state spaces. To address this, we propose using prefix trees to store states for large, highly concurrent models (particularly CRNs) for memory savings. We present theoretical analyses and benchmarks demonstrating the favorability of prefix trees over hash maps for very large state spaces. Additionally, we propose using a Bounded Model Checking (BMC) pre-processing step to impose a variable ordering to further improve memory usage along with preliminary evaluations suggesting its effectiveness. We remark that while our work is motivated primarily by the challenges posed by CRNs, it is generalizable to all CTMC models. | [üîó Paper](https://arxiv.org/abs/2512.17892v1) |
| [Spectro-temporal unitary transformations for coherent modulation: design trade-offs and practical considerations](https://arxiv.org/abs/2512.17890v1) | Callum Deakin, Xi Chen | 2025-12-19 | General AI | This paper analyzes the performance of spectro-temporal unitary transforms for coherent optical modulation. Unlike conventional IQ modulation, such transforms are based on a cascade of phase modulators and dispersive elements, so are theoretically lossless and not limited by the bandwidth of the constituent modulators. We analyse the performance limits and design trade-offs of this scheme: estimating how the number of stages, amount of dispersion, modulator bandwidth, symbol block length and electrical signal power impacts the achievable signal-to-distortion ratio (SDR). Importantly, we show that high (>30 dB) SDRs suitable for modern >200 GBd class coherent optical communications are achievable with a low (<6) number of stages and reasonable parameters for driver power, modulator bandwidth and on-chip dispersion. Finally we address the SDR penalties associated with potential phase, amplitude, or dispersion errors, and limited DAC resolution. | [üîó Paper](https://arxiv.org/abs/2512.17890v1) |
| [Simulation of topological superconductors and their competing orders using photon-mediated interactions](https://arxiv.org/abs/2512.17889v1) | Anjun Chu, Joyce Kwan, Eric Yilun Song, Seth Hew Peng Chew, James K. Thompson, Ana Maria Rey | 2025-12-19 | General AI | Realizing and controlling the unconventional pairing featured by topological superconductors remains a central challenge. We introduce a cavity QED quantum simulator that engineers competing chiral $p_x+ip_y$ and $d_{x^2-y^2}+id_{xy}$ orders by tailoring cavity-mediated couplings between atomic pseudospins that emulate momentum-dependent pairing channels. The desired spatially inhomogeneous cavity-mediated couplings can be engineered in a 2D optical lattice using incommensurate cavity-lattice wavelengths naturally occurring in cavity QED systems. This minimal and fully tunable platform enables controlled state preparation and continuous measurement of superconducting order parameters, revealing phases in both equilibrium and sudden-quench settings with a single dominant pairing channel, as well as coexistence regimes with competing pairing channels. Crucially, our implementation allows direct observation of topological transitions in and out of equilibrium, providing a powerful route to the quantum simulation of competing topological superconducting phases that remain elusive in solid-state and ultracold-atom systems. | [üîó Paper](https://arxiv.org/abs/2512.17889v1) |
| [Tuna-Like Swimmers Experience a Fluid-Mediated Stable Side-by-Side Formation](https://arxiv.org/abs/2512.17888v1) | Pedro C. Ormonde, Matthew Stasolla, Alec Menzer, Joseph Zhu, Hilary Bart-Smith, Haibo Dong, Keith W. Moored | 2025-12-19 | General AI | New free-swimming experiments and simulations are conducted on a pair of three-dimensional, bio-robotic swimmers composed of a body and tail section based on Yellowfin tuna, Thunnus albacares. It is discovered that the pair converges spontaneously to a side-by-side schooling formation that is stable to perturbations in the swimming direction at a fixed lateral spacing. We reveal that for close lateral spacings of 43% of the body length and thick, tuna-like bodies with a 22% thickness-to-length ratio, the flow between the swimmers is accelerated in a "channeling effect" due to flow constriction. Consequently, this creates a low-pressure zone that is the primary mechanism generating a fluid-mediated restorative force, thereby making the side-by-side formation hydrodynamically stable. This quasi-steady mechanism makes the stability of the formation insensitive to the phase synchronization between the bio-robots in contrast to previous results for schooling foils. Moreover, in the side-by-side formation tunalike swimmers are seen to have only a small reduction in their swimming speed and a concurrent small rise in their cost of transport. By leveraging this channeling effect, bio-robotic schools may be able to maintain a schooling formation with little or no control. This flow mechanism may also be present in biological schools of tuna-like fish where it may sculpt the formations observed in nature. | [üîó Paper](https://arxiv.org/abs/2512.17888v1) |
| [Trails of clouds in binary black holes](https://arxiv.org/abs/2512.17887v1) | Mateja Bo≈°koviƒá, Rafael A. Porto, Matthias Koschnitzke | 2025-12-19 | General AI | Superradiant instabilities of rotating black holes can give rise to long-lived bosonic clouds, offering natural laboratories to probe ultralight particles across a wide range of parameter space. The presence of a companion can dramatically impact both the cloud's evolution and the binary's orbital dynamics, generating a trail of feedback effects that require detailed modelling. Using a worldline effective field theory approach, we develop a systematic framework for binaries on generic (eccentric and inclined) orbits, capturing both resonant and non-resonant transitions without relying solely on balance laws. We demonstrate the existence of ``co-rotating'' floating orbits that can deplete the cloud prior to entering the detector's band, triggering eccentricity growth towards a sequence of fixed points. Likewise, we show that ``counter-rotating'' orbits can also deplete the cloud, driving (unbounded) growth of eccentricity. Furthermore, we uncover novel features tied to orbital inclination. Depending on the mass ratio, equatorial orbits can become unstable, and fixed points may arise not only for aligned or anti-aligned configurations but, strikingly, also at intermediate inclinations. We derive flow equations governing spin-orbit misalignment and eccentricity and identify distinctive signatures that can reveal the presence of boson clouds in the binary's history, as well as key features of possible in-band transitions. These results refine and extend earlier work, yielding a more faithful description of the imprints of ultralight particles in gravitational-wave signals from binary black holes, signatures that are within reach of future detectors such as LISA, Cosmic Explorer, and the Einstein~Telescope. | [üîó Paper](https://arxiv.org/abs/2512.17887v1) |
| [Asymptotic behaviour of galactic small-scale dynamos at modest magnetic Prandtl number](https://arxiv.org/abs/2512.17885v1) | Frederick A. Gent, Mordecai-Mark Mac Low, Maarit J. Korpi-Lagg, Touko Puro, Matthias Reinhardt | 2025-12-19 | General AI | Magnetic fields are critical at many scales to galactic dynamics and structure, including multiphase pressure balance, dust processing, and star formation. Dynamo action determines their dynamical structure and strength. Simulations of combined large- and small-scale dynamos have successfully developed mean fields with strength and topology consistent with observations but with turbulent fields much weaker than observed, while simulations of small-scale dynamos with parameters relevant to the interstellar medium yield turbulent fields an order of magnitude below the values observed or expected theoretically. We use the Pencil Code accelerated on GPUs with Astaroth to perform high-resolution simulations of a supernova-driven galactic dynamo including heating and cooling in a periodic domain. Our models show that the strength of the turbulent field produced by the small-scale dynamo approaches an asymptote at only modest magnetic Prandtl numbers. This allows us to use these models to suggest the essential characteristics of this constituent of the magnetic field for inclusion in global galactic models. The asymptotic limit occurs already at magnetic Prandtl number of only a few hundred, many orders of magnitude below physical values in the the interstellar medium and consistent with previous findings for isothermal compressible flows. | [üîó Paper](https://arxiv.org/abs/2512.17885v1) |
| [Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space](https://arxiv.org/abs/2512.17884v1) | Xinyue Yu, Hayden Schaeffer | 2025-12-19 | General AI | Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests. | [üîó Paper](https://arxiv.org/abs/2512.17884v1) |
| [Your Eyes Controlled the Game: Real-Time Cognitive Training Adaptation based on Eye-Tracking and Physiological Data in Virtual Reality](https://arxiv.org/abs/2512.17882v1) | Dominik Szczepaniak, Monika Harvey, Fani Deligianni | 2025-12-19 | General AI | Cognitive training for sustained attention and working memory is vital across domains relying on robust mental capacity such as education or rehabilitation. Adaptive systems are essential, dynamically matching difficulty to user ability to maintain engagement and accelerate learning. Current adaptive systems often rely on simple performance heuristics or predict visual complexity and affect instead of cognitive load. This study presents the first implementation of real-time adaptive cognitive load control in Virtual Reality cognitive training based on eye-tracking and physiological data. We developed a bidirectional LSTM model with a self-attention mechanism, trained on eye-tracking and physiological (PPG, GSR) data from 74 participants. We deployed it in real-time with 54 participants across single-task (sustained attention) and dual-task (sustained attention + mental arithmetic) paradigms. Difficulty was adjusted dynamically based on participant self-assessment or model's real-time cognitive load predictions. Participants showed a tendency to estimate the task as too difficult, even though they were objectively performing at their best. Over the course of a 10-minute session, both adaptation methods converged at equivalent difficulty in single-task scenarios, with no significant differences in subjective workload or game performance. However, in the dual-task conditions, the model successfully pushed users to higher difficulty levels without performance penalties or increased frustration, highlighting a user tendency to underestimate capacity under high cognitive load. Findings indicate that machine learning models may provide more objective cognitive capacity assessments than self-directed approaches, mitigating subjective performance biases and enabling more effective training by pushing users beyond subjective comfort zones toward physiologically-determined optimal challenge levels. | [üîó Paper](https://arxiv.org/abs/2512.17882v1) |
| [Three-loop pentagonal Wilson loop with Lagrangian insertion](https://arxiv.org/abs/2512.17881v1) | Dmitry Chicherin, Johannes Henn, Yongqun Xu, Shun-Qing Zhang, Yang Zhang | 2025-12-19 | General AI | Employing a cutting-edge bootstrap method, we analytically compute the three-loop pentagonal Wilson loop with Lagrangian insertion in planar $\mathcal{N}=4$ super-Yang-Mills theory. This object is conjectured to coincide with the maximally transcendental part of the four-loop five-point all-plus amplitude in pure Yang-Mills theory. Our starting point is an ansatz that encodes the known leading singularities of this object, as well as the relevant function space. The latter has become available only recently, thanks to an analytic computation of all three-loop five-point planar massless Feynman integrals. We determine the coefficients in the ansatz by imposing physical constraints. This includes a near-collinear expansion, which so far has not been applied to this observable. Taken together, the constraints allow us to uniquely determine the symbol of the answer. We verify the symbol result by an independent integral reduction calculation. | [üîó Paper](https://arxiv.org/abs/2512.17881v1) |
| [On the complex nature of coronal heating](https://arxiv.org/abs/2512.17880v1) | C. A. Breu, D. I. Pontin, E. Priest, I. De Moortel | 2025-12-19 | General AI | A large part of the hot corona consists of magnetically confined, bright plasma loops. These observed loops are in turn structured into bright strands. We investigate the relationship between magnetic field geometry, plasma properties and bright strands with the help of a 3D resistive MHD simulation of a coronal loop rooted in a self-consistent convection zone layer. We find that it is impossible to identify a loop as a simple coherent magnetic flux tube that coincides with plasma of nearly uniform temperature and density. The location of bright structures is determined by a complex interplay between heating, cooling and evaporation timescales. Current sheets form preferentially at the interfaces of magnetic flux from different sources. They may also form within bundles of magnetic field lines since motions within magnetic concentrations drive plasma flows on a range of timescales that provide further substructure and can locally enhance magnetic field gradients and thus facilitate magnetic reconnection. The numerical experiment therefore possesses aspects of both the flux tube tectonics and flux braiding models. While modelling an observed coronal loop as a cylindrical flux tube is useful to understand the physics of specific heating mechanisms in isolation, it does not describe well the structure of a coronal loop rooted in a self-consistently evolving convection zone. | [üîó Paper](https://arxiv.org/abs/2512.17880v1) |
| [Inverse-Designed Phase Prediction in Digital Lasers Using Deep Learning and Transfer Learning](https://arxiv.org/abs/2512.17879v1) | Yu-Che Wu, Kuo-Chih Chang, Shu-Chun Chu | 2025-12-19 | General AI | Digital lasers control the laser beam by dynamically updating the phase patterns of the spatial light modulator (SLM) within the laser cavity. Due to the presence of nonlinear effects, such as mode competition and gain saturation in digital laser systems, it is often necessary to rely on specifically manually tailored approach or iteration processes to find suitable loaded phases in Digital lasers. This study proposes a model based on Conditional Generative Adversarial Networks (cGAN) and a modified U-Net architecture, with designed loss functions to inverse design the loaded phases. In this work, we employ deep neural networks to learn the nonlinear effects in simulated L-shape digital lasers, enabling the prediction of SLM-loaded phases for both analytical and non-analytical arbitrary structured light fields. The results demonstrate superior performance on non-analytical light fields compared to the current methods in L-shape Digital lasers. Furthermore, a transfer learning strategy is introduced, allowing knowledge obtained from one class of structured beams to be effectively reused for another, thereby enhancing generalization and improving performance under limited training data. Importantly, this method, the first proposed learning framework for digital lasers, is not limited to the L-shaped digital lasers discussed in this study, providing an efficient alternative for generating structured light in other digital laser systems. | [üîó Paper](https://arxiv.org/abs/2512.17879v1) |
| [Learning vertical coordinates via automatic differentiation of a dynamical core](https://arxiv.org/abs/2512.17877v1) | Tim Whittaker, Seth Taylor, Elsa Cardoso-Bihlo, Alejandro Di Luca, Alex Bihlo | 2025-12-19 | General AI | Terrain-following coordinates in atmospheric models often imprint their grid structure onto the solution, particularly over steep topography, where distorted coordinate layers can generate spurious horizontal and vertical motion. Standard formulations, such as hybrid or SLEVE coordinates, mitigate these errors by using analytic decay functions controlled by heuristic scale parameters that are typically tuned by hand and fixed a priori. In this work, we propose a framework to define a parametric vertical coordinate system as a learnable component within a differentiable dynamical core. We develop an end-to-end differentiable numerical solver for the two-dimensional non-hydrostatic Euler equations on an Arakawa C-grid, and introduce a NEUral Vertical Enhancement (NEUVE) terrain-following coordinate based on an integral transformed neural network that guarantees monotonicity. A key feature of our approach is the use of automatic differentiation to compute exact geometric metric terms, thereby eliminating truncation errors associated with finite-difference coordinate derivatives. By coupling simulation errors through the time integration to the parameterization, our formulation finds a grid structure optimized for both the underlying physics and numerics. Using several standard tests, we demonstrate that these learned coordinates reduce the mean squared error by a factor of 1.4 to 2 in non-linear statistical benchmarks, and eliminate spurious vertical velocity striations over steep topography. | [üîó Paper](https://arxiv.org/abs/2512.17877v1) |
| [Impact of Heater Thermal Properties on Nucleate Pool Boiling: Insights from a Multiscale Automata Simulation](https://arxiv.org/abs/2512.17876v1) | Karina I. Mazzitello, T. Molina Blanco, C. P. Marcel, V. P. Masson | 2025-12-19 | General AI | This study investigates the influence of heater material properties on nucleate pool boiling using a comprehensive simulation model. Copper and silicon oxide are selected as reference materials due to their properties as excellent and poor heat conductors, respectively. The model integrates well-known heat transfer mechanisms, allowing for the assessment of the effects of these distinct heater materials. The results show that materials with superior thermal diffusivity, such as copper, significantly enhance cooling efficiency during nucleate boiling. Moreover, the study provides insights into the relationship between bubble growth, microlayer recovery beneath a bubble, temperature fluctuations, and heater properties. Comparisons between copper and silicon oxide underscore variations in bubble frequency, attributed to differences in bubble growth time, microlayer recovery time, and material-dependent behavior. The influence of neighboring boiling sites is especially pronounced in silicon oxide due to its low thermal conductivity and diffusivity values. Temperature variations in this material become highly visible due to its very slow response to temperature changes. Simulation results align well with semi-empirical correlations, confirming the model's success in capturing the intricate phenomena of nucleate pool boiling. In summary, the model reveals that changes in the thermal properties of the heater affect not only boiling performance but also key characteristics of the process, including bubble frequency, boiling patterns, regularity, and cavity reactivation speed. | [üîó Paper](https://arxiv.org/abs/2512.17876v1) |
| [Probing new physics in the Boosted $HH \to b\bar{b}Œ≥Œ≥$ channel at the LHC](https://arxiv.org/abs/2512.17874v1) | Mohamed Belfkir | 2025-12-19 | General AI | This paper presents the first dedicated study of the boosted $HH \to b\bar{b}Œ≥Œ≥$ topology as a key probe of physics beyond the Standard Model (SM) in the high-energy double-Higgs boson regime. The analysis presented in this paper, focuses on two classes of new-physics scenarios: non-resonant deviations of the quartic gauge--Higgs interaction, parameterized by the coupling modifier $Œ∫_{2V}$, and resonant enhancement arising from the decay of a heavy scalar state, modeled within a two-Higgs-doublet framework. We demonstrate that the boosted reconstruction category enhances sensitivity to beyond SM effects that populate the high-$m_{HH}$ tail, yielding improved constraints on $Œ∫_{2V}$ and extending the discovery reach for heavy resonances. | [üîó Paper](https://arxiv.org/abs/2512.17874v1) |
| [A note on Poincar√©-Sobolev type inequalities on compact manifolds](https://arxiv.org/abs/2512.17872v1) | Romain Gicquaud | 2025-12-19 | General AI | We prove a Poincar√©-Sobolev type inequality on compact Riemannian manifolds where the deviation of a function from a biased average, defined using a density, is controlled by the unweighted Lebesgue norm of its gradient. Unlike classical weighted Poincar√© inequalities, the density does not enter the measure or the Sobolev norms, but only the reference average. We show that the associated Poincar√© constant depends quantitatively on the Lebesgue norm of the density. This framework naturally arises in the analysis of coupled elliptic systems and seems not to have been addressed in the existing literature. | [üîó Paper](https://arxiv.org/abs/2512.17872v1) |
| [Experimentally Mapping the Phase Diagrams of Photoexcited Small Polarons](https://arxiv.org/abs/2512.17869v1) | Jocelyn L. Mendes, Scott K. Cushing | 2025-12-19 | General AI | Understanding the fundamental properties that dictate photoexcited polarons in materials is critical to tuning their properties. Theoretical models of polarons have only recently been extended to the excited state. Experimental measurements of polaron formation and transport have been widely undertaken across a range of materials, from photocatalysts and superconductors to soft conducting polymers. Here, we map experimental measurements of quantities such as polaron strength onto phase diagrams of the Holstein, Hubbard-Holstein, and t-J-Holstein models. This work demonstrates that tuning electron-phonon coupling strength, electron localization, and spin exchange can be leveraged to suppress or control polaron formation in transition metal oxides. We find that the t-J-Holstein model best describes the measured iron oxides and could be generally applied to a wide range of systems that exhibit polaron formation in the excited state. This work combines experimental data with ground state models to provide a robust parameter space for informing photoexcited polaron design. | [üîó Paper](https://arxiv.org/abs/2512.17869v1) |
| [Delayed Acceptance Slice Sampling](https://arxiv.org/abs/2512.17868v1) | Kevin Bitterlich, Daniel Rudolf, Bj√∂rn Sprungk | 2025-12-19 | General AI | Slice sampling is a well-established Markov chain Monte Carlo method for (approximate) sampling of target distributions which are only known up to a normalizing constant. The method is based on choosing a new state on a slice, i.e., a superlevel set of the given unnormalized target density (with respect to a reference measure). However, slice sampling algorithms usually require per step multiple evaluations of the target density, and thus can become computationally expensive. This is particularly the case for Bayesian inference with costly likelihoods. In this paper, we exploit deterministic approximations of the target density, which are relatively cheap to evaluate, and propose delayed acceptance versions of hybrid slice samplers. We show ergodicity of the resulting slice sampling methods, discuss the superiority of delayed acceptance (ideal) slice sampling over delayed acceptance Metropolis-Hastings algorithms, and illustrate the benefits of our novel approach in terms improved computational efficiency in several numerical experiments. | [üîó Paper](https://arxiv.org/abs/2512.17868v1) |
| [Interplay of Defects and the Charge Density Wave State in Hf-Doped ZrTe$_{3}$](https://arxiv.org/abs/2512.17867v1) | Ghilles Ainouche, Resmi Sudheer, Susree Mohapatra, Boning Yu, Muhammad Suhayb Malik, Yu Liu, Cedomir Petrovic, Abhilash Ravikumar, Michael C. Boyer | 2025-12-19 | General AI | We carry out temperature-dependent scanning tunneling microscopy (STM) studies of the charge density wave (CDW) compound ZrTe$_3$ which is intentionally doped with Hf. Previous bulk studies tie Hf doping to an enhancement of the CDW transition temperature (T$_{CDW}$). In our work, by combining STM measurements with density functional theory (DFT) calculations, we observe and identify multiple defects in Zr$_{0.95}$Hf$_{0.05}$Te$_3$. Surprisingly, instead of finding clear structural or electronic signatures associated with Hf dopants, we determine the origin of the observed defects are consistent with Te and Zr vacancies. Further, our temperature dependent STM measurements allow us to examine CDW pinning to both types of observed defects below and above T$_{CDW}$. | [üîó Paper](https://arxiv.org/abs/2512.17867v1) |
| [A Concept of Two-Point Propagation Field of a Single Photon: A Way to Picometer X-ray Displacement Sensing and Nanometer Resolution 3D X-ray Micro-Tomography](https://arxiv.org/abs/2512.17863v1) | Li Hua Yu | 2025-12-19 | General AI | We introduce the two-point propagation field (TPPF), a real-valued, phase-sensitive quantity defined as the functional derivative of the single-photon detection probability with respect to an infinitesimal opaque perturbation placed between source and detection slits. The TPPF is analytically derived and shown to exhibit a stable, high-frequency sinusoidal structure (6.7 nm period) near the detection slit. This structure enables shot-noise-limited displacement sensing at ~15 pm precision using routinely available synchrotron fluxes and practical nanofabricated slit/comb geometries, requiring mechanical stability only over the final 0.5 mm. The same principle provides a foundation for future nanometer-resolution 3D X-ray microtomography of bulk samples, potentially resulting in a reduced radiation dose. Two conceptual strategies, a central blocker and off-axis multi-slit arrays, are estimated to lower the required incident fluence by more than one order of magnitude each, yielding combined reductions of two to three orders of magnitude with near-term detector development. The TPPF concept, originally developed in a perturbative study of single-particle propagation, thus bridges fundamental quantum measurement questions with practical high-resolution X-ray metrology and imaging. | [üîó Paper](https://arxiv.org/abs/2512.17863v1) |
| [Stability of (Active) Bilayer Skyrmions in Synthetic Antiferromagnets](https://arxiv.org/abs/2512.17862v1) | Rai M. Menezes, Clecio C. de Souza Silva | 2025-12-19 | General AI | Synthetic antiferromagnetic (SAF) skyrmions are nanoscale composite textures that exhibit high-speed, Hall-free current-driven motion and recently demonstrated self-propulsion. These remarkable properties rely on the stability of the SAF skyrmion's topological bound state, whose underlying mechanisms remain unclear. Here, using an atomistic spin model, we analyze the collapse pathways of bilayer SAF skyrmions in homochiral systems, where both ferromagnetic layers share the same Dzyaloshinskii-Moriya interaction (DMI) vectors, and in heterochiral systems, where the DMI vectors have opposite directions. We find that pair destruction occurs either by decoupling or by sequential collapse into the homogeneous antiferromagnetic state, so the activation energy is set by the smaller of these two barriers. By examining how these barriers vary with DMI strength, anisotropy, magnetic field, and interlayer exchange, we identify regimes of enhanced stability. In particular, increasing interlayer coupling strengthens homochiral skyrmions but weakens heterochiral ones, while reducing the anisotropy constant effectively stabilizes heterochiral SAF skyrmions. These results outline viable strategies to optimize SAF heterostructures for enhanced skyrmion stability in racetrack devices and emerging active skyrmionic systems. | [üîó Paper](https://arxiv.org/abs/2512.17862v1) |
| [Revisited apparent horizon entropy and GSL in modified gravity](https://arxiv.org/abs/2512.17861v1) | Soma Heydari, Parastoo Askari, Kayoomars Karami | 2025-12-19 | General AI | This work presents a universal and revisited formalism for the entropy of the apparent horizon in modified gravity to investigate the validity of the Generalized Second Law (GSL) of thermodynamics. This revisited horizon entropy is constructed directly from the modified Friedmann equations in a non-flat Friedmann-Robertson-Walker (FRW) universe. The resulting entropy relation contains, beside the standard Bekenstein-Hawking term, an additional integral contribution that encodes the effective energy density and pressure generated by deviations from general relativity. Using this universal entropy formula, a compact expression for the GSL is derived. This formalism is then applied to some viable $f(T)$ and $f(R)$ gravity models, in order to re-evaluate the validity of the GSL as a function of redshift. The analysis demonstrates that including the integral term in the revisited entropy can relatively improve the late-time validity of the GSL for some of these models while living others unchanged, thereby reinforcing the profound connection between thermodynamics and gravity. | [üîó Paper](https://arxiv.org/abs/2512.17861v1) |
| [Witnessing Entanglement in Mixed-Particle Quantum Systems](https://arxiv.org/abs/2512.17860v1) | Irma Avdic, David A. Mazziotti | 2025-12-19 | General AI | We introduce an entanglement witness that identifies off-diagonal long-range order (ODLRO) -- a distinctive form of entanglement -- in systems containing both fermionic and bosonic particles. By analyzing the particle-hole reduced density matrices of each subsystem, the approach detects ODLRO independently in both fermionic and bosonic sectors and identifies when long-range order develops across the entire mixed-particle system. The witness also quantifies the magnitude of ODLRO within each particle type, revealing how fermionic and bosonic correlations combine to form the total entanglement of the system, including a bosonic condensation of particle-hole pairs driven by many-body correlations rather than particle statistics. Using the Lipkin-Meshkov-Glick spin model, we show how the transition from ODLRO localized to one particle type to ODLRO shared by both particle types captures the onset of collective entanglement in a mixed-particle environment, providing new insight into systems where fermionic and bosonic correlations coexist. | [üîó Paper](https://arxiv.org/abs/2512.17860v1) |
